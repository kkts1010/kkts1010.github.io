[
  {
    "objectID": "posts/Web_tools/Web_tools.html",
    "href": "posts/Web_tools/Web_tools.html",
    "title": "Web Tools",
    "section": "",
    "text": "ここでは、参考にさせていただいてるWeb URLを備忘録として保存する。"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#計量生物学会",
    "href": "posts/Web_tools/Web_tools.html#計量生物学会",
    "title": "Web Tools",
    "section": "1 計量生物学会",
    "text": "1 計量生物学会\n\n計量生物学会\n統計家の行動基準"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#医薬品開発",
    "href": "posts/Web_tools/Web_tools.html#医薬品開発",
    "title": "Web Tools",
    "section": "2 医薬品開発",
    "text": "2 医薬品開発\n\nPMDA 審査関連業務の概要について\nICH Efficacyガイドライン\n製薬協データサイエンス部会 成果物\n製薬協 医薬品評価委員会シンポジウム\nFDA Clinical Trials Guidance Documents\nFDA Real-World Evidence Documents\nEMA Biostatistics guidelines\nEMA Real-world evidence guidelines\nCDISC ADaM\nStatistical Analysi Plan(Australian Clinical Trials)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#統計",
    "href": "posts/Web_tools/Web_tools.html#統計",
    "title": "Web Tools",
    "section": "3 統計",
    "text": "3 統計\n\nPankaj Kumar Choudhary先生\nFrank Harrell先生\nBayesian Data Analysis Course\n早稲田大学 村田先生 講義資料等\nCamden Lopez（海外の生物統計家ブログ）\nBiostatistics for Biomedical Research\n久保川達也先生 書籍関連"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#sasプログラミング",
    "href": "posts/Web_tools/Web_tools.html#sasプログラミング",
    "title": "Web Tools",
    "section": "4 SASプログラミング",
    "text": "4 SASプログラミング\n\nSAS備忘録\nPharmaceutical Software Users Group\nConference Proceedings (1976 - present) … and more\nSASユーザー会\nSASユーザー総会 論文集アーカイブ\nSAS Forumユーザー会 2006\n大阪SAS勉強会\nデータステップ100万回　SAS新手一生\n晴れ時々SAS\nSAS One Dash\n我輩はブロガーではない。ネタもまだない\n僕の頁 \nデータサイエンス100本ノック（構造化データ加工編）のSAS版\nRTFファイルをPDF化するDDEプログラム"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング書籍",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング書籍",
    "title": "Web Tools",
    "section": "5 Rプログラミング（書籍）",
    "text": "5 Rプログラミング（書籍）\n\nR for Data Science (2nd Edtion)\nAdvanced R (2nd Edition)\nR Cookbook, 2nd Edition\nQuarto 公式guide"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング海外サイト",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング海外サイト",
    "title": "Web Tools",
    "section": "6 Rプログラミング（海外サイト）",
    "text": "6 Rプログラミング（海外サイト）\n\nTidyverse style guide\nR Workflow for Reproducible Data Analysis and Reporting\nBuilding reproducible analytical pipelines with R\nR Rpharma\nR Workflow（Frank Harrell先生\nReproducible Medical Research with R\nR for Clinical Study Reports and Submission\nAn Introduction to Statistical Programming Methods with R\nTables in Clinical Trials with R\nIntroduction to tern\nWorkshops at rstudio::conf 2022\nTLG Catalog\nIntroduction to {rtables}\nReproducible Environments(Posit社)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング日本語",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング日本語",
    "title": "Web Tools",
    "section": "7 Rプログラミング（日本語）",
    "text": "7 Rプログラミング（日本語）\n\nデータサイエンス100本ノック（構造化データ加工編）をRで解く\nRによる再現可能なデータ分析（瓜生真也先生）\nRによるデータ解析のための前処理（瓜生真也先生）\n次の一歩を踏み出すためのtidyverse入門（瓜生真也先生）\n今日からできる再現可能な論文執筆（国里愛彦先生・竹林由武先生）\nはじめよう！R（小杉考司先生）\n気軽にRでWebサイト\nRではじめようモダンなデータ分析\n私たちのR\nRプログラムの個人ブログ"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#研究関連",
    "href": "posts/Web_tools/Web_tools.html#研究関連",
    "title": "Web Tools",
    "section": "8 研究関連",
    "text": "8 研究関連\n\nWriting-Tips Series(Journal of Clinical Epidemiology)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#論文",
    "href": "posts/Web_tools/Web_tools.html#論文",
    "title": "Web Tools",
    "section": "9 論文",
    "text": "9 論文\n\nTen Simple Rules for Reproducible Computational Research\n山本先生_LatexによるBibTeXにおけるbibファイルの書き方"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#ブログ関係",
    "href": "posts/Web_tools/Web_tools.html#ブログ関係",
    "title": "Web Tools",
    "section": "10 ブログ関係",
    "text": "10 ブログ関係\n\n長島健悟先生のブログ\nKRSK先生のブログ\n司馬先生のブログ\nYanagimoto先生のブログ\nすきとほるさんのブログ"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#論文雑誌",
    "href": "posts/Web_tools/Web_tools.html#論文雑誌",
    "title": "Web Tools",
    "section": "11 論文雑誌",
    "text": "11 論文雑誌\n\n計量生物学\n薬剤疫学\nJournal of Epideimology\nStatistics in Medicine\nPharmaceutical Statistics\nすうがくぶんか株式会社\nQuarto\nGit公式書籍（日本語"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#quartoブログ",
    "href": "posts/Web_tools/Web_tools.html#quartoブログ",
    "title": "Web Tools",
    "section": "12 Quartoブログ",
    "text": "12 Quartoブログ\n\ntutorial\nBuilding a blog with Quarto\nMarkdown記法チート"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#tips",
    "href": "posts/Web_tools/Web_tools.html#tips",
    "title": "Web Tools",
    "section": "13 Tips",
    "text": "13 Tips\n\nExcelシートの一括変換 note\nExcelファイルをまとめてPDFファイルに変換したい\n複数のExcelファイルを一括でPDFファイルに変換する方法\nメモ帳だけで作成！複数のExcelファイルをPDFに一括変換\nWinMerge日本語版"
  },
  {
    "objectID": "posts/statistics/index.html",
    "href": "posts/statistics/index.html",
    "title": "Notes",
    "section": "",
    "text": "SAS：要約統計量作成マクロ\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nSASのProc SGPLOTに関するTips\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nProc Transpose/ARRAYによる転置\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\n加工プログラム例―少数ステップでの処理―\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nTTE総説論文\n\n\n\n薬剤疫学\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nSASプログラミングのPitfalls and Bad Habits\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-28\n\n\n\n\n\n\n\nProc Contents ProcedureとProc Dataset Procedure\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nプログラミング一般的な考え方（MUST DO , MUST NOT DO)\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nPROGRAMMING FOR JOB SECURITY REVISITED\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\n臨床試験における有害事象データの集計：PROC SQL\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nADaM IG1.3\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-18\n\n\n\n\n\n\n\nSASプログラミングTips1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-16\n\n\n\n\n\n\n\n解析用データセット作成の流れ2\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-16\n\n\n\n\n\n\n\nMarkdown記法について\n\n\n\nMarkdown\n\n\n\n\n\n\n2025-06-15\n\n\n\n\n\n\n\nSQL入門1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-15\n\n\n\n\n\n\n\ngithubのブログ更新手順について\n\n\n\ngithub\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\nSASプログラミング業務のフレームワーク\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\nSASマクロ入門1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n解析用データセット仕様書\n\n\n\nSAS\n\nR\n\n解析用データセット\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n解析用データセット作成の流れ1（フォルダ構造等）\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n第2相抗がん剤開発及び検証的試験の中間解析\n\n\n\n臨床試験\n\nSAS\n\n\n\n\n\n\n2025-05-24\n\n\n\n\n\n\n\n臨床試験のサンプルサイズ設計\n\n\n\n臨床試験\n\nSAS\n\n\n\n\n\n\n2025-05-17\n\n\n\n\n\n一致なし"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "効率的なフォルダ構成でプロジェクトを管理する\n\n\nSAS（Statistical Analysis System）を使ったデータ分析プロジェクトにおいて、最初に決めるべき重要な要素の一つがフォルダ構成です。適切なフォルダ構成を設定することで、プロジェクトの管理が格段に楽になり、チームでの作業効率も向上します。\n多くのSAS初心者は、とりあえずデスクトップやマイドキュメントにファイルを保存してしまいがちですが、プロジェクトが進むにつれて「あのファイルはどこに保存したっけ？」「これは最新バージョン？」といった問題に直面することになります。\n\n\n\n\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬）\n\n\n\n\nSASプログラミングを実施する際は、フォルダ構成をまず設定します。ここでは、実際の業務で使用することができそうな標準的な構成例を紹介します。 任意のプロジェクトフォルダに対して以下のようなフォルダを作成します。テンプレートを作成しておくのが便利でしょう。もしくはProjectフォルダを作成して、自動でフォルダを作成するSASプログラムを準備しておくこともよいかもしれません。ここでの例は、あくまで1つの例であり、より使いやすくなるようなフォルダ構成に変更しても差し支えない。なお、このフォルダ構成はTLF作成のプログラムにおいても引用できる可能性がある。、TLFの解析を踏まえたフォルダ構成は別途提案する。\n\nInput\nLog\nOutput\nPrg\nSetting\nSpec\n\n\n\nInput：分析に使用する元データを格納\n\n外部から受け取ったCSVファイル、Excelファイル -\nデータベースから抽出した生データ\n既存のSASデータセット\n\nLog：SASプログラムの実行ログを保存\n\nプログラム実行時に出力されるログファイル\nエラーメッセージや警告の記録\n処理時間やデータ件数の確認用\n\nOutput：分析結果や成果物を保存\n\n作成されたSASデータセット\nデータ品質チェック結果\n\nPrg：SASプログラムファイル（.sas）を格納\n\nデータ処理プログラム（1_xx、2_xxのように実行するプログラムの順番が分かる方が望ましい）\nデータクリーニングプログラム\n派生変数作成プログラム\n\nSetting：\n\n設定ファイルや共通処理を保存\nよく使用するマクロ定義\nプロジェクト固有の設定\n\nSpec：仕様書や設計書類を格納\n\n解析用データセット仕様書\n\n\n\n\n\n実際のプロジェクトでは、解析用データセット作成プログラミングと、解析プログラミングはフォルダを分けることを推奨しています。\nここでは、解析用データセット作成に焦点を当てたフォルダ構成について詳しく説明します。\n\n\n解析用データセット作成用のフォルダ構成例：\n\nProject/\nInput/\n\nRaw_Data/ # 生データ（CSV、Excel等）\nExternal/ # 外部参照データ、マスタ情報\n\nLog/ # データ処理ログ\nOutput/ # 作成されたSASデータセット\nPrg/ # データ処理プログラム\nSetting/ # 設定ファイル、マクロ\n\n\n\n\nデータ取り込み（PROC IMPORT）\n\n解析用データ仕様書に基づいて、変数のlength,format,labelが入った空データセット（メタデータ）を作成する。\n文字エンコーディングの統一\n変数名の標準化\n\nデータクリーニング\n\n欠損値の処理（削除、補完、フラグ付け）\n重複レコードの確認と処理\nデータ型の統一\n\n派生変数の作成\n\n年齢の計算（生年月日から）\nカテゴリ変数の作成（連続変数の区分化）\n合計値や比率の計算\nフラグ変数の作成\n\n\n\n\n\nSASプログラミングにおいて、プログラムの更新履歴を管理することは非常に重要です。特にデータ処理では、どの時点のプログラムで作成されたデータセットなのかを明確にする必要があります。\n\n\nデータセット作成プログラムの命名例\n\n01_data_import_20250614.sas # 初回作成\n01_data_import_20250615.sas # 修正版\n01_data_import_20250620.sas # 最新版\n02_data_cleaning_20250614.sas # データクリーニング\n03_variable_creation_20250615.sas # 派生変数作成\n04_quality_check_20250620.sas # 品質チェック\n\n\n\n\n各SASプログラムの冒頭には、以下のような標準的なヘッダーを記述することを必須とします。\n/*=================================\nプログラム名: 01_data_import.sas\nプロジェクト: プロジェクト名\n作成者      : 山田太郎\n作成日      : 2025/06/14\n最終更新日  : 2025/06/20\nバージョン  : v1.2\n目的        : 顧客アンケートデータの取り込みとクリーニング\n\n入力データ  : Raw_Data/survey_data.csv\n出力データ  : Output/cleaned_survey.sas7bdat\n\n更新履歴:\nv1.0 2025/06/14 初回作成\nv1.1 2025/06/15 欠損値処理ロジック追加\nv1.2 2025/06/20 外れ値検出機能追加\n=================================*/\n\n\n\n\n*---------------------- EOF （プログラム名.sas） ------------------------------- ;\n\n\n\n\nプログラム実行時に、実行日時をログに記録する仕組みを組み込むことも有効です：\n/* 実行開始時刻を記録 */\n%let start_time = %sysfunc(datetime());\n%put NOTE: データセット作成開始 - %sysfunc(datetime(), datetime19.);\n\n/* データ取り込み処理 */\nproc import datafile=\"Input/Raw_Data/survey_data.csv\"\n    out=work.raw_data\n    dbms=csv replace;\n    getnames=yes;\nrun;\n\n/* 実行終了時刻を記録 */\n%let end_time = %sysfunc(datetime());\n%let elapsed_time = %sysevalf(&end_time - &start_time);\n%put NOTE: データセット作成終了 - %sysfunc(datetime(), datetime19.);\n%put NOTE: 実行時間: %sysfunc(&elapsed_time, time8.);\n%put NOTE: 処理件数: %sysfunc(attrn(open(work.raw_data), nobs));\n\n\n\nログファイルの活用 データ処理では、どのような処理が行われたかを正確に記録することが重要です：\n/* ログファイルの出力先を指定（日付付き） */\n%let today = %sysfunc(today(), yymmddn8.);\nproc printto log=\"Log/data_creation_&today..log\";\nrun;\n\n/* データ処理 */\n/* ... */\n\n/* ログ出力を元に戻す */\nproc printto;\nrun;\n\n\n\nSettingフォルダでは、事前に解析用データセット仕様書のinputするファイル情報やPath、InputデータのPaht、OutputデータのPathを指定しておく。これを作成しておくことで、第3者に解析用データセット作成プログラムを提供した際でも、このSettingフォルダのPathだけを更新することで、再現可能な状態がすぐに作ることができる。\nExcelファイルには以下の3つの要素を設定します。：\n\nパス（Path）：ファイルの保存場所\nファイル名：Excelファイル名\nシート名：参照するワークシート名"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#はじめに",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SAS（Statistical Analysis System）を使ったデータ分析プロジェクトにおいて、最初に決めるべき重要な要素の一つがフォルダ構成です。適切なフォルダ構成を設定することで、プロジェクトの管理が格段に楽になり、チームでの作業効率も向上します。\n多くのSAS初心者は、とりあえずデスクトップやマイドキュメントにファイルを保存してしまいがちですが、プロジェクトが進むにつれて「あのファイルはどこに保存したっけ？」「これは最新バージョン？」といった問題に直面することになります。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#参考文献",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬）"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成における基本的なフォルダ構成案",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成における基本的なフォルダ構成案",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASプログラミングを実施する際は、フォルダ構成をまず設定します。ここでは、実際の業務で使用することができそうな標準的な構成例を紹介します。 任意のプロジェクトフォルダに対して以下のようなフォルダを作成します。テンプレートを作成しておくのが便利でしょう。もしくはProjectフォルダを作成して、自動でフォルダを作成するSASプログラムを準備しておくこともよいかもしれません。ここでの例は、あくまで1つの例であり、より使いやすくなるようなフォルダ構成に変更しても差し支えない。なお、このフォルダ構成はTLF作成のプログラムにおいても引用できる可能性がある。、TLFの解析を踏まえたフォルダ構成は別途提案する。\n\nInput\nLog\nOutput\nPrg\nSetting\nSpec\n\n\n\nInput：分析に使用する元データを格納\n\n外部から受け取ったCSVファイル、Excelファイル -\nデータベースから抽出した生データ\n既存のSASデータセット\n\nLog：SASプログラムの実行ログを保存\n\nプログラム実行時に出力されるログファイル\nエラーメッセージや警告の記録\n処理時間やデータ件数の確認用\n\nOutput：分析結果や成果物を保存\n\n作成されたSASデータセット\nデータ品質チェック結果\n\nPrg：SASプログラムファイル（.sas）を格納\n\nデータ処理プログラム（1_xx、2_xxのように実行するプログラムの順番が分かる方が望ましい）\nデータクリーニングプログラム\n派生変数作成プログラム\n\nSetting：\n\n設定ファイルや共通処理を保存\nよく使用するマクロ定義\nプロジェクト固有の設定\n\nSpec：仕様書や設計書類を格納\n\n解析用データセット仕様書"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成に特化したフォルダ構成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成に特化したフォルダ構成",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "実際のプロジェクトでは、解析用データセット作成プログラミングと、解析プログラミングはフォルダを分けることを推奨しています。\nここでは、解析用データセット作成に焦点を当てたフォルダ構成について詳しく説明します。\n\n\n解析用データセット作成用のフォルダ構成例：\n\nProject/\nInput/\n\nRaw_Data/ # 生データ（CSV、Excel等）\nExternal/ # 外部参照データ、マスタ情報\n\nLog/ # データ処理ログ\nOutput/ # 作成されたSASデータセット\nPrg/ # データ処理プログラム\nSetting/ # 設定ファイル、マクロ\n\n\n\n\nデータ取り込み（PROC IMPORT）\n\n解析用データ仕様書に基づいて、変数のlength,format,labelが入った空データセット（メタデータ）を作成する。\n文字エンコーディングの統一\n変数名の標準化\n\nデータクリーニング\n\n欠損値の処理（削除、補完、フラグ付け）\n重複レコードの確認と処理\nデータ型の統一\n\n派生変数の作成\n\n年齢の計算（生年月日から）\nカテゴリ変数の作成（連続変数の区分化）\n合計値や比率の計算\nフラグ変数の作成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#プログラムの日付管理とバージョン管理",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#プログラムの日付管理とバージョン管理",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASプログラミングにおいて、プログラムの更新履歴を管理することは非常に重要です。特にデータ処理では、どの時点のプログラムで作成されたデータセットなのかを明確にする必要があります。\n\n\nデータセット作成プログラムの命名例\n\n01_data_import_20250614.sas # 初回作成\n01_data_import_20250615.sas # 修正版\n01_data_import_20250620.sas # 最新版\n02_data_cleaning_20250614.sas # データクリーニング\n03_variable_creation_20250615.sas # 派生変数作成\n04_quality_check_20250620.sas # 品質チェック\n\n\n\n\n各SASプログラムの冒頭には、以下のような標準的なヘッダーを記述することを必須とします。\n/*=================================\nプログラム名: 01_data_import.sas\nプロジェクト: プロジェクト名\n作成者      : 山田太郎\n作成日      : 2025/06/14\n最終更新日  : 2025/06/20\nバージョン  : v1.2\n目的        : 顧客アンケートデータの取り込みとクリーニング\n\n入力データ  : Raw_Data/survey_data.csv\n出力データ  : Output/cleaned_survey.sas7bdat\n\n更新履歴:\nv1.0 2025/06/14 初回作成\nv1.1 2025/06/15 欠損値処理ロジック追加\nv1.2 2025/06/20 外れ値検出機能追加\n=================================*/\n\n\n\n\n*---------------------- EOF （プログラム名.sas） ------------------------------- ;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#自動的な実行日時記録",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#自動的な実行日時記録",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "プログラム実行時に、実行日時をログに記録する仕組みを組み込むことも有効です：\n/* 実行開始時刻を記録 */\n%let start_time = %sysfunc(datetime());\n%put NOTE: データセット作成開始 - %sysfunc(datetime(), datetime19.);\n\n/* データ取り込み処理 */\nproc import datafile=\"Input/Raw_Data/survey_data.csv\"\n    out=work.raw_data\n    dbms=csv replace;\n    getnames=yes;\nrun;\n\n/* 実行終了時刻を記録 */\n%let end_time = %sysfunc(datetime());\n%let elapsed_time = %sysevalf(&end_time - &start_time);\n%put NOTE: データセット作成終了 - %sysfunc(datetime(), datetime19.);\n%put NOTE: 実行時間: %sysfunc(&elapsed_time, time8.);\n%put NOTE: 処理件数: %sysfunc(attrn(open(work.raw_data), nobs));"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#実践的な運用のコツ",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#実践的な運用のコツ",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "ログファイルの活用 データ処理では、どのような処理が行われたかを正確に記録することが重要です：\n/* ログファイルの出力先を指定（日付付き） */\n%let today = %sysfunc(today(), yymmddn8.);\nproc printto log=\"Log/data_creation_&today..log\";\nrun;\n\n/* データ処理 */\n/* ... */\n\n/* ログ出力を元に戻す */\nproc printto;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#settingフォルダについて",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#settingフォルダについて",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "Settingフォルダでは、事前に解析用データセット仕様書のinputするファイル情報やPath、InputデータのPaht、OutputデータのPathを指定しておく。これを作成しておくことで、第3者に解析用データセット作成プログラムを提供した際でも、このSettingフォルダのPathだけを更新することで、再現可能な状態がすぐに作ることができる。\nExcelファイルには以下の3つの要素を設定します。：\n\nパス（Path）：ファイルの保存場所\nファイル名：Excelファイル名\nシート名：参照するワークシート名"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#attrib-statement",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#attrib-statement",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.1 Attrib statement",
    "text": "2.1 Attrib statement\n具体的なプログラミングについては、別記事で解説をするが、ここでは解析用データセットを作成する上で大事なAttrib Statementについて解説する。\n以下記事が参考になる。\n\nATTRIBステートメント\n変数属性を定義した空のデータセットを作成する方法【まとめ】\n\n解析用データ仕様書にて、各変数のLabel、Length、formatを指定する必要がある。 その際に、解析用データセットに対してattrib statementを適用することで簡単に設定できる。\nちなみに、変数の順番だけを入れ替えるならばformat Statementでも簡単にできる。こちらのブログが参考になります。\ndata ADSL;\n    set ADSL;\n    attrib \n        STUDYID   label=\"Study Identifier\"           length=$12  format=$12.\n        USUBJID   label=\"Unique Subject Identifier\"  length=$40  format=$40.\n        SUBJID    label=\"Subject Identifier\"         length=$20  format=$20.\n        AGE       label=\"Age\"                        length=8    format=8.\n        SEX       label=\"Sex\"                        length=$1   format=SEX.\n        TRT01P    label=\"Planned Treatment for Period 1\"  length=$200  format=$200.\n        TRT01A    label=\"Actual Treatment for Period 1\"   length=$200  format=$200.\n        TRT01PN   label=\"Planned Treatment for Period 1 (N)\"  length=8  format=8.\n        TRT01AN   label=\"Actual Treatment for Period 1 (N)\"  length=8  format=8.\n        FASFL     label=\"Full Analysis Set Flag\"     length=$1   format=NYFL.\n    ;\nrun;\n実際は手入力ですることは人為的ミスの元となるのでマクロ化等で自動化することを推奨するが考え方は上記の通りである。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#proc-format",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#proc-format",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.2 Proc format",
    "text": "2.2 Proc format\n以下記事が参考になる。 - PROC FORMAT入門1 : VALUEステートメント\nPROC FORMATは、SASにおいてユーザー定義フォーマットを作成するプロシージャです。数値や文字データを、より読みやすい形式に変換して表示することができます。 基本構文は以下の通りです。\nproc format;\n    value フォーマット名\n        値1 = \"ラベル1\"\n        値2 = \"ラベル2\"\n        値3 = \"ラベル3\";\nrun;\n文字フォーマットには先頭にドルマークを付けます。\nproc format;\n    value trtf\n        1 = \"プラセボ\"\n        2 = \"低用量\"\n        3 = \"高用量\"\n        . = \"欠測\";\n        \n    value sexf\n        1 = \"男性\"\n        2 = \"女性\"\n        . = \"不明\";\n        \n    value nyf\n        0 = \"No\"\n        1 = \"Yes\"\n        . = \"Missing\";\nrun;\n\nproc format;\n    value $sexf\n        \"M\" = \"男性\"\n        \"F\" = \"女性\"\n        \" \" = \"不明\";\n        \n    value $countryfmt\n        \"JPN\" = \"日本\"\n        \"USA\" = \"アメリカ合衆国\"\n        \"GBR\" = \"イギリス\"\n        other = \"その他\";\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#データセットからのフォーマット作成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#データセットからのフォーマット作成",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.3 データセットからのフォーマット作成",
    "text": "2.3 データセットからのフォーマット作成\n\n2.3.1 3.1 CNTLIN=オプションの使用\nデータセットからフォーマットを作成する場合、特定の変数名を持つデータセットを準備する必要があります。 必要な変数：\n\nFMTNAME：フォーマット名\nSTART：変換前の値（開始値）\nEND：変換前の値（終了値、範囲指定時）\nLABEL：変換後のラベル\nTYPE：フォーマットタイプ（‘N’=数値、‘C’=文字）\n\n/* 治療群フォーマット用データセット */\ndata trt_fmt;\n    retain fmtname 'trtf' type 'N';\n    input start end label $20.;\n    datalines;\n1 1 プラセボ\n2 2 低用量\n3 3 高用量\n. . 欠測\n;\nrun;\n\n/* 性別フォーマット用データセット */\ndata sex_fmt;\n    retain fmtname '$sexf' type 'C';\n    input start $1. end $1. label $10.;\n    datalines;\nM M 男性\nF F 女性\n   不明\n;\nrun;\n\n/* フォーマットの作成 */\nproc format cntlin=trt_fmt;\nrun;\n\nproc format cntlin=sex_fmt;\nrun;\nPROC FORMATは以下の2つの方法でフォーマットを作成できます：\nVALUEステートメント：直接コードに記述する方法。シンプルで直感的 CNTLIN=オプション：データセットから作成する方法。大量のフォーマットや動的な作成に適している\n適切なフォーマットの使用により、データの可読性が大幅に向上し、レポート作成時の効率も改善されます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#sasプログラムの例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#sasプログラムの例",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "3.1 SASプログラムの例",
    "text": "3.1 SASプログラムの例\n以下のプロジェクトは人間が主導でProjectフォルダを適当な場所に作成して、そのフォルダにて以下のプログラムを実行するだけで、上記のフォルダ構造を作成するものである。\nproc datasets kill nolist ; run ; quit ; \ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : 01_Folder_Setting.sas\n* Author          : Kota Sakamoto\n* Date created    : 20250617\n* Purpose         :　プロジェクト開始時のフォルダ構造の標準化\n* Revision History :\n***********************************************************************/\n\n/* 1. /* --- 日付設定 --- */ */;\ndata _null_;\n   dt = datetime();\n   Date1 = put(datepart(dt), yymmdds10.);\n   Date2 = compress(Date1, \"/\");\n   Time1 = put(timepart(dt), tod8.);\n   Time2 = compress(Time1, \":\");   \n   call symputx('StDates', Date1);\n   call symputx('StDate', Date2);\n   call symputx('StTimes', Time1);\n   call symputx('StTime', Time2);\nrun;\n\n%put 日付: &StDates. (&StDate.) 時刻: &StTimes. (&StTime.);\n\n/* 2. /* --- フォルダのマクロ変数の取得 --- */ */;\n%LET execpath=\" \";\n%MACRO setexecpath;\n    %LET execpath=%SYSFUNC(GETOPTION(SYSIN));\n    %IF %LENGTH(&execpath)=0\n    %THEN %LET execpath=%SYSGET(SAS_EXECFILEPATH);\n%MEND setexecpath;\n%setexecpath;\n%PUT &execpath;\n\n%let CURRENT_DIR = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n%put &CURRENT_DIR;\n\n\n/* 3. /* --- フォルダのlibnameの指定 --- */ */;\n%let folder1 = Document;\n%let folder2 = ADS_Program;\n%let folder3 = ADS_Program\\Input;\n%let folder4 = ADS_Program\\Input\\Raw;\n%let folder5 = ADS_Program\\Input\\External;\n%let folder6 = ADS_Program\\Log;\n%let folder7 = ADS_Program\\Output;\n%let folder8 = ADS_Program\\Prg;\n%let folder9 = ADS_Program\\Prg\\Develop;\n%let folder10 = ADS_Program\\Prg\\Fix;\n%let folder11 = ADS_Program\\Macro;\n%let folder12 = ADS_Program\\Setting;\n%let folder13 = ADS_Program\\Spec;\n%let folder14 = Analysis_Program;\n%let folder15 = Analysis_Program\\Input;\n%let folder16 = Analysis_Program\\Log;\n%let folder17 = Analysis_Program\\Output;\n%let folder18 = Analysis_Program\\Prg;\n%let folder19 = Analysis_Program\\Prg\\Develop;\n%let folder20 = Analysis_Program\\Prg\\Fix;\n%let folder21 = Analysis_Program\\Macro;\n%let folder22 = Analysis_Program\\Setting;\n%let folder23 = Analysis_Program\\Spec;\n%let folder24 = Paper;\n\n\n/* まとめて一気に実施する */\n%macro create_folder_paths;\n    data _null_;\n        %do i = 1 %to 24;\n            folder&i = cat(\"&CURRENT_DIR\", \"\\\", \"&&folder&i..\");\n            call symputx(\"folder&i\", folder&i);\n        %end;\n    run;\n%mend;\n\n%create_folder_paths;\n%put _user_;\n    \n\n/* 4. /* --- フォルダ作成 --- */ */;\n/* ディレクトリ自動作成マクロ */\n%macro create_dir(path);\n   %local parent_dir dir_name;\n   %let path = %sysfunc(strip(&path));\n   %let parent_dir = %substr(&path, 1, %length(&path)-%length(%scan(&path, -1, '\\')));\n   %let dir_name = %scan(&path, -1, '\\');\n   \n   %if %sysfunc(fileexist(&path)) = 0 %then %do;\n       %if %length(&parent_dir) &gt; 0 %then %do;\n           %if %sysfunc(fileexist(&parent_dir)) = 0 %then %do;\n               %create_dir(&parent_dir);\n           %end;\n       %end;\n       %let rc = %sysfunc(dcreate(&dir_name, &parent_dir));\n   %end;\n%mend;\n\n/* プロジェクトフォルダ構造の自動作成 */\n%macro create_all_folders;\n   %do i = 1 %to 24;\n       %create_dir(&&folder&i);\n   %end;\n%mend;\n\n%create_all_folders;\n\n/* 5. /* --- 解析用データセットと解析プログラムについて、開発日付を逐次作成する --- */ */;\ndata _null_;\n    /* 各フォルダパスを作成 */\n    Prg_Develop1= cat( \"&CURRENT_DIR\",\"ADS_Program\\Prg\\Develop\",\"\\\", \"&StDate\");\n    Prg_Develop2  = catx( \"&CURRENT_DIR\",\"Analysis_Program\\Prg\\Develop\",\"\\\", \"&StDate\");\n    \n    /* マクロ変数に格納 */\n    call symputx(\"Prg_Develop1\", Prg_Develop1);\n    call symputx(\"Prg_Develop2\", Prg_Develop2);\n  \nrun;\n\n/* 作成されたパスを確認 */\n%put &Prg_Develop1;\n%put  &Prg_Develop2;\n\n%create_dir(&Prg_Develop1);\n%create_dir(&Prg_Develop2);"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html",
    "href": "posts/statistics/2025/中間解析.html",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "中間解析は、試験の進行中にデータを評価し、治療効果や安全性に関する情報を得るために行われます。これにより、試験の進行状況を把握し、必要に応じて試験デザインやプロトコルを調整することができます。 中間解析は、特に以下の目的で実施されます。\n\n治療効果の初期評価: 中間解析は、治療効果の初期評価を行うために使用されます。これにより、治療が有効であるかどうかを早期に判断することができます。\n安全性の評価: 中間解析は、安全性に関する情報を収集するためにも使用されます。これにより、治療が安全であるかどうかを早期に判断することができます。\n早期終了の判断: 中間解析の結果に基づいて、試験を早期に終了するかどうか（無効中止や有効中止）を判断することができます。これにより、無駄なリソースを節約することができます。\n倫理的な配慮: 中間解析は、倫理的な配慮からも重要です。治療が有効でない場合や安全性に問題がある場合、試験を早期に終了することで、被験者の安全を確保することができます。\nリソースの最適化: 中間解析は、試験の進行状況を把握し、リソースを最適化するためにも使用されます。これにより、試験の効率を向上させることができます。\n\n本記事では、以下の内容について説明します。\n\n抗がん剤第2相における2値アウトカムの中間解析\n\nSimonの最適法\nSimonのMinmax法\nFlemingデザイン\nBayes流の方法\n\n検証的試験における中間解析\n\nO’Brien-Flemingデザイン\nPocockデザイン\nLan-DeMetsデザイン（α spending function）\n\n\n\n\n\n抗がん剤第2相試験においては、治療効果を評価するために2値アウトカム（例: 完全奏効、部分奏効、無効など）が使用されます。中間解析は、これらのアウトカムを評価するために行われます。試験統計家として試験計画時に中間解析を実施する必要があるかを考えておく必要があります。\nこれらの資料が参考になります。\n\n山本先生：SASユーザー総会2010\n\nまた、基本的に本節での手法はSASのProc power等のプロシジャで簡単に実装されていません。SASで実行する場合は、ネットからマクロを活用するか、社内でSASマクロを開発しておく必要があります。若干ハードルが高いかもしれないですが、SASでサンプルサイズ設計マクロを開発しておき、RやWebサイトの計算結果との一致をもってQCを行うことができるので、開発しておくことをお勧めします。\n\n\n\nこの節での記法について導入します。検証的試験における中間解析では別途記法を定義します。\n\np : 奏効確率（主要評価項目）\np_0 : 閾値奏効確率（p が p_0 以下の場合，薬剤は無効と判断）\np_1 : 期待奏効確率（p が p_1 以上の場合，薬剤は有効かもしれないと判断）\n\\alpha : 第 I 種の過誤確率（一般的に0.05と規定）\n\\beta : 第 II 種の過誤確率（一般的に0.20と規定）\n\n\n\n\n仮説検定は片側検定として以下のように定義する。\n\nH_0 : p \\leq p_0\nH_1 : p &gt; p_1"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#中間解析の目的",
    "href": "posts/statistics/2025/中間解析.html#中間解析の目的",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "中間解析は、試験の進行中にデータを評価し、治療効果や安全性に関する情報を得るために行われます。これにより、試験の進行状況を把握し、必要に応じて試験デザインやプロトコルを調整することができます。 中間解析は、特に以下の目的で実施されます。\n\n治療効果の初期評価: 中間解析は、治療効果の初期評価を行うために使用されます。これにより、治療が有効であるかどうかを早期に判断することができます。\n安全性の評価: 中間解析は、安全性に関する情報を収集するためにも使用されます。これにより、治療が安全であるかどうかを早期に判断することができます。\n早期終了の判断: 中間解析の結果に基づいて、試験を早期に終了するかどうか（無効中止や有効中止）を判断することができます。これにより、無駄なリソースを節約することができます。\n倫理的な配慮: 中間解析は、倫理的な配慮からも重要です。治療が有効でない場合や安全性に問題がある場合、試験を早期に終了することで、被験者の安全を確保することができます。\nリソースの最適化: 中間解析は、試験の進行状況を把握し、リソースを最適化するためにも使用されます。これにより、試験の効率を向上させることができます。\n\n本記事では、以下の内容について説明します。\n\n抗がん剤第2相における2値アウトカムの中間解析\n\nSimonの最適法\nSimonのMinmax法\nFlemingデザイン\nBayes流の方法\n\n検証的試験における中間解析\n\nO’Brien-Flemingデザイン\nPocockデザイン\nLan-DeMetsデザイン（α spending function）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#抗がん剤第2相における2値アウトカムの中間解析",
    "href": "posts/statistics/2025/中間解析.html#抗がん剤第2相における2値アウトカムの中間解析",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "抗がん剤第2相試験においては、治療効果を評価するために2値アウトカム（例: 完全奏効、部分奏効、無効など）が使用されます。中間解析は、これらのアウトカムを評価するために行われます。試験統計家として試験計画時に中間解析を実施する必要があるかを考えておく必要があります。\nこれらの資料が参考になります。\n\n山本先生：SASユーザー総会2010\n\nまた、基本的に本節での手法はSASのProc power等のプロシジャで簡単に実装されていません。SASで実行する場合は、ネットからマクロを活用するか、社内でSASマクロを開発しておく必要があります。若干ハードルが高いかもしれないですが、SASでサンプルサイズ設計マクロを開発しておき、RやWebサイトの計算結果との一致をもってQCを行うことができるので、開発しておくことをお勧めします。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#パラメータの定義",
    "href": "posts/statistics/2025/中間解析.html#パラメータの定義",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "この節での記法について導入します。検証的試験における中間解析では別途記法を定義します。\n\np : 奏効確率（主要評価項目）\np_0 : 閾値奏効確率（p が p_0 以下の場合，薬剤は無効と判断）\np_1 : 期待奏効確率（p が p_1 以上の場合，薬剤は有効かもしれないと判断）\n\\alpha : 第 I 種の過誤確率（一般的に0.05と規定）\n\\beta : 第 II 種の過誤確率（一般的に0.20と規定）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#仮説検定",
    "href": "posts/statistics/2025/中間解析.html#仮説検定",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "仮説検定は片側検定として以下のように定義する。\n\nH_0 : p \\leq p_0\nH_1 : p &gt; p_1"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#arguments",
    "href": "posts/statistics/2025/中間解析.html#arguments",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.1 Arguments",
    "text": "2.1 Arguments\n\n\n\n\n\n\n\nパラメータ\n説明\n\n\n\n\npu\nunacceptable response rate; baseline response rate that needs to be exceeded for treatment to be deemed promising\n\n\npa\nresponse rate that is desirable; should be larger than pu\n\n\nep1\nthreshold for the probability of declaring drug desirable under pu (target type 1 error rate); between 0 and 1\n\n\nep2\nthreshold for the probability of rejecting the drug under pa (target type 2 error rate); between 0 and 1\n\n\nnmax\nmaximum total sample size (default 100; can be at most 1000)\n\n\nx\nobject returned by ph2simon\n\n\n…\narguments to be passed onto plot and print commands called within"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#value",
    "href": "posts/statistics/2025/中間解析.html#value",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.2 Value",
    "text": "2.2 Value\nph2simon returns a list with pu, pa, alpha, beta and nmax as above and:\n\n\n\n\n\n\n\n出力\n説明\n\n\n\n\nout\nmatrix of best 2 stage designs for each value of total sample size n. The 6 columns in the matrix are:\n\n\n\n\n\n\nカラム\n説明\n\n\n\n\nr1\nnumber of responses needed to exceeded in first stage\n\n\nn1\nnumber of subjects treated in first stage\n\n\nr\nnumber of responses needed to exceeded at the end of trial\n\n\nn\ntotal number of subjects to be treated in the trial\n\n\nEN(pu)\nexpected number of patients in the trial under pu\n\n\nPET(pu)\nprobability of stopping after the first stage under pu\n\n\n\nTrial is stopped early if &lt;= r1 responses are seen in the first stage and treatment is considered desirable only when &gt;r responses seen."
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#methods",
    "href": "posts/statistics/2025/中間解析.html#methods",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.3 Methods",
    "text": "2.3 Methods\n\nprint(ph2simon): formats and returns the minimax, optimal and any admissible designs.\nplot(ph2simon): plots the expected sample size against the maximum sample size as in Jung et al., 2001"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#実務に応用する際において",
    "href": "posts/statistics/2025/中間解析.html#実務に応用する際において",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.4 実務に応用する際において",
    "text": "2.4 実務に応用する際において\nSimonのMinmax、SimonのOptimanデザインのいずれの方法においても、「薬剤が無効な場合に早期中止を判断するための2段階デザイン無効な場合の期待患者数/を最小にしたい」という無効中止のみを考えた試験デザインである。 すなわち、Rの出力結果から、第1段階目のn1人において、r1人未満の奏効例数であれば、試験を無効中止とするようなデザインである。Rのパッケージで症例数設計をする場合、この数値が正しいことを試験統計家としてValidationをしておく必要はある。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#数学的背景について",
    "href": "posts/statistics/2025/中間解析.html#数学的背景について",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.5 数学的背景について",
    "text": "2.5 数学的背景について\n別記事で解説します。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#試験概要",
    "href": "posts/statistics/2025/中間解析.html#試験概要",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.1 試験概要",
    "text": "6.1 試験概要\n今回設計した臨床試験の基本パラメータと解析計画をまとめました。この試験では2段階の逐次デザインを採用し、中間解析で早期中止の可能性を検討します。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#試験設計パラメータ",
    "href": "posts/statistics/2025/中間解析.html#試験設計パラメータ",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.2 試験設計パラメータ",
    "text": "6.2 試験設計パラメータ\n\n\n\n項目\n設定値\n\n\n\n\n登録期間\n2年\n\n\n追跡期間\n5年\n\n\n目標症例数\n126.7例（2群計128例）63.25例/年\n\n\n期待イベント数\n96.5例（対照群: 55.4例、治療群: 41.1例）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#解析スケジュール",
    "href": "posts/statistics/2025/中間解析.html#解析スケジュール",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.3 解析スケジュール",
    "text": "6.3 解析スケジュール\n\n6.3.1 中間解析（第1段階）\n\n実施時期: 試験開始から3年後（2.92年）\n期待イベント数: 48.3例（対照群: 30.4例、治療群: 17.9例）\n\n\n\n6.3.2 最終解析（第2段階）\n\n実施時期: 全症例の追跡完了後\n期待イベント数: 96.5例"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#統計的判定基準",
    "href": "posts/statistics/2025/中間解析.html#統計的判定基準",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.4 統計的判定基準",
    "text": "6.4 統計的判定基準\n\n\n\n\n\n\n\n\n\n解析段階\n統計量\n判定基準\n結論\n\n\n\n\n中間解析\nZ₁ &gt; 2.96259\n有効性境界を超過\n有効中止\n\n\n\nZ₁ &lt; 0.86994\n無効性境界を下回る\n無効中止\n\n\n\n0.86994 ≤ Z₁ ≤ 2.96259\n境界値の間\n試験継続\n\n\n最終解析\nZ₂ &gt; 1.89189\n有効性境界を超過\n有効"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#まとめ",
    "href": "posts/statistics/2025/中間解析.html#まとめ",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.5 まとめ",
    "text": "6.5 まとめ\nこの逐次デザインにより、試験の途中で明確な結果が得られた場合には早期中止が可能となり、患者さんの負担軽減と試験の効率化が期待できます。特に、中間解析時点で強い有効性が示された場合や、逆に無効性が明らかになった場合には、倫理的観点からも適切な判断ができる設計となっている。\nこの後は、Proc lifetest Procedure等で実際に解析を行い推定値に基づくZ統計量を算出した上で、Proc Seqtest Procedureで中間解析の結果を評価することとなる。"
  },
  {
    "objectID": "posts/statistics/2025/TTE総説.html",
    "href": "posts/statistics/2025/TTE総説.html",
    "title": "TTE総説論文",
    "section": "",
    "text": "本記事では、薬剤疫学会で公開された下記2つの論文を勉強する。"
  },
  {
    "objectID": "posts/statistics/2025/TTE総説.html#要約",
    "href": "posts/statistics/2025/TTE総説.html#要約",
    "title": "TTE総説論文",
    "section": "1 要約",
    "text": "1 要約\n\n観察研究におけるバイアス\n\nランダム化の欠如による交絡\n不適切な研究デザインがもたらす選択バイアス\nImmortal Time bias"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html",
    "href": "posts/statistics/2025/SASマクロ入門1.html",
    "title": "SASマクロ入門1",
    "section": "",
    "text": "本記事では、2022年SASユーザー総会の森田氏の「マクロのすすめ～SASにプログラムをかいてもらおう～」の文章を写経したものである。個人の勉強記録であるため、基本的には元の資料を参考にしていただきたい。\n\n\n基礎的な事項で参考になるものはいつも通り、以下のブログである。特に実務上で重要だが知られていないデータステップで変数をマクロ化するcall syputx、データステップ外で関数を使えるようにする%sysfuncはきちんと理解したい。また、マクロ言語入門9で紹介されている&macro_variable.の.は常に記載する、もしくは記載しない等を組織/個人開発で統一しておくことが望ましい。\n\nマクロ言語入門1：マクロ変数とは【%LET】\nマクロ言語入門2：マクロの登録と実行【%MACRO、%MEND】\nマクロ言語入門3：パラメータの設定【定位置パラメータ】\nマクロ言語入門4：パラメータの設定【キーワードパラメータ】\nマクロ言語入門5：クォート処理【%STR関数】\nマクロ言語入門6：クォート処理【%BQUOTE関数】\nマクロ言語入門7：マクロ内でのループ処理【%DO】\nマクロ言語入門8：マクロ内での条件分岐処理【%IF】\nマクロ言語入門9：マクロ変数とドット\nマクロ言語入門10：マクロ変数と&&\nマクロ言語入門11：演算評価 【%EVAL、%SYSEVALF】\n値をマクロ変数に格納する「CALL SYMPUTX」その1\nデータステップ外で関数を使えるようにする「%SYSFUNC」その１\n森岡 裕, %if-%then-%doのオープンコードでの利用と9.4以降のSASマクロ拡張点について, SASユーザー総会論文集, 2021.\n本本 早紀, クォート処理及びスコープへの理解を深める, SASユーザー総会論文集, 2019, p141-150\n竹田 真, 佐藤 智美, 社内マクロライブラリの構築について, SASユーザー総会論文集, 2001, p37-44\n柳沢 健太郎, 常吉 華奈, 山本 典子, 臨床試験における集計解析用 SASプログラムの標準化, SASユーザー総会論文集, 2004, p37-44\n田村 洋介, SASマクロライブラリの開発/管理/運用, SASユーザー総会論文集, 2007, p123-134\n“How to organize your SAS projects in Git”, SAS Blogs, 2020-11-10\n“Good Programming Practice In Macro Development”, PhUSE Advance Hub, 2021-09-21\nRon Cody, Cody’s Data Cleaning Techniques Using SAS, SAS Press, 2017, 234p\n市橋 里絵, 江口 幸子, 渡邊 大丞, 月田 あづき, “Standard Template Programs”の開発, SASユーザー総会論文集, 2010, p381-383\n\nまた、他にも応用上の使い方等は以下が参考になる。 - Compareプロシジャの結果が一致か不一致か、何が不一致かをマクロ変数で取得する話 なお、私が知る限りProc Compare Procedureの解説文献は、2022年度のSASユーザー総会資料のCOMPAREプロシジャの便利な使い方がおすすめである。Proc Compare Procedureについては別記事で解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#参考ブログ",
    "href": "posts/statistics/2025/SASマクロ入門1.html#参考ブログ",
    "title": "SASマクロ入門1",
    "section": "",
    "text": "基礎的な事項で参考になるものはいつも通り、以下のブログである。特に実務上で重要だが知られていないデータステップで変数をマクロ化するcall syputx、データステップ外で関数を使えるようにする%sysfuncはきちんと理解したい。また、マクロ言語入門9で紹介されている&macro_variable.の.は常に記載する、もしくは記載しない等を組織/個人開発で統一しておくことが望ましい。\n\nマクロ言語入門1：マクロ変数とは【%LET】\nマクロ言語入門2：マクロの登録と実行【%MACRO、%MEND】\nマクロ言語入門3：パラメータの設定【定位置パラメータ】\nマクロ言語入門4：パラメータの設定【キーワードパラメータ】\nマクロ言語入門5：クォート処理【%STR関数】\nマクロ言語入門6：クォート処理【%BQUOTE関数】\nマクロ言語入門7：マクロ内でのループ処理【%DO】\nマクロ言語入門8：マクロ内での条件分岐処理【%IF】\nマクロ言語入門9：マクロ変数とドット\nマクロ言語入門10：マクロ変数と&&\nマクロ言語入門11：演算評価 【%EVAL、%SYSEVALF】\n値をマクロ変数に格納する「CALL SYMPUTX」その1\nデータステップ外で関数を使えるようにする「%SYSFUNC」その１\n森岡 裕, %if-%then-%doのオープンコードでの利用と9.4以降のSASマクロ拡張点について, SASユーザー総会論文集, 2021.\n本本 早紀, クォート処理及びスコープへの理解を深める, SASユーザー総会論文集, 2019, p141-150\n竹田 真, 佐藤 智美, 社内マクロライブラリの構築について, SASユーザー総会論文集, 2001, p37-44\n柳沢 健太郎, 常吉 華奈, 山本 典子, 臨床試験における集計解析用 SASプログラムの標準化, SASユーザー総会論文集, 2004, p37-44\n田村 洋介, SASマクロライブラリの開発/管理/運用, SASユーザー総会論文集, 2007, p123-134\n“How to organize your SAS projects in Git”, SAS Blogs, 2020-11-10\n“Good Programming Practice In Macro Development”, PhUSE Advance Hub, 2021-09-21\nRon Cody, Cody’s Data Cleaning Techniques Using SAS, SAS Press, 2017, 234p\n市橋 里絵, 江口 幸子, 渡邊 大丞, 月田 あづき, “Standard Template Programs”の開発, SASユーザー総会論文集, 2010, p381-383\n\nまた、他にも応用上の使い方等は以下が参考になる。 - Compareプロシジャの結果が一致か不一致か、何が不一致かをマクロ変数で取得する話 なお、私が知る限りProc Compare Procedureの解説文献は、2022年度のSASユーザー総会資料のCOMPAREプロシジャの便利な使い方がおすすめである。Proc Compare Procedureについては別記事で解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロはsasにプログラムを書いてもらうための機能",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロはsasにプログラムを書いてもらうための機能",
    "title": "SASマクロ入門1",
    "section": "2.1 マクロはSASにプログラムを書いてもらうための機能",
    "text": "2.1 マクロはSASにプログラムを書いてもらうための機能\nマクロは、簡単に言うとテキストの置換機能である。Aという文字列をBという文字列に置き換える機能である。そして、このテキスト置換機能がたいへん役に立つ。なぜなら、プログラミング業務では、似たような解析やデータハンドリングを繰り返し行っている場合が多いからである。例えば、他のプロジェクトと同じ解析を行う、対象のデータセット名だけが異なる、対象データの抽出条件だけが異なる、処理対象の変数だけが異なる、設定値やオプション指定だけが異なる、出力形式（行数や列数、ファイル形式など）だけが異なる。こういった場合、各解析のSASプログラムの大部分が重複することになり、差異が生じるのは、ほんの一部となる。つまり、基準となるプログラムをコピー&ペーストで複製して、変更が必要な箇所だけをテキスト置換すれば済む場合が多い。この基準となるプログラムの設定とテキスト置換をSASプログラムで実現するための機能がマクロである。マクロがプログラムを書いてくれるのである。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロの仕組み",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロの仕組み",
    "title": "SASマクロ入門1",
    "section": "2.2 マクロの仕組み",
    "text": "2.2 マクロの仕組み\n私たちの書いたSASプログラムは、SASのコンパイラによって解釈され、実行される。このとき、実はSASには二種類のコンパイラがある。\n1. マクロを解析・実行するマクロプロセッサ、\n2. DATAステップおよびPROCステップを解析・実行するコンパイラである。\nSASプログラムをサブミットすると、まず、①マクロプロセッサがマクロ部分だけを解析・実行し、DATAステップまたはPROCステップの命令だけのプログラムを作成する。その後、②のコンパイラによって、マクロ部分が解析された後のプログラムを実行する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロ変数を使う",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロ変数を使う",
    "title": "SASマクロ入門1",
    "section": "2.3 マクロ変数を使う",
    "text": "2.3 マクロ変数を使う\n本章では、マクロの基本的な機能であるマクロ変数について概説する。シンプルな機能ながら応用場面は多い。マクロ変数を習得するだけでもプログラミングの効率化や品質向上が期待できる。\n\n2.3.1 マクロ変数とは\nマクロ変数はテキストを格納する容れものである。マクロ変数に格納したテキストはプログラム中で参照できる。マクロプロセッサは、SASプログラム内でマクロ変数の参照箇所を見つけると、そのマクロ変数に格納したテキストに置き換える。テキストファイルで行う一括置換をSASに実行してもらうイメージである。\n\n\n2.3.2 マクロ変数の作成と参照\nマクロ変数は%letステートメントを利用して作成する。\n%let マクロ変数名 = 格納したい値;\nマクロ変数名は最大32文字、最初の文字は英字またはアンダースコア、その後の文字は英字・数字・アンダースコアが使用可能である。また大文字と小文字は区別されない。設定値AF、DMS、SQL、SYSは該当する自動マクロ変数と名前が重複する可能性があるため、避けたほうがよい。\n%let greeting = Hello World;\n%put &greeting.;\n%put 「Hello World」と表示;\n\n%let year = 40;\n%let comment = おめでとうございます;\n%put SASユーザー総会&year.周年&comment.;\n%put 「SASユーザー総会40周年おめでとうございます」と表示;\n\n%let anavar = age; /* マクロ変数&anavarを定義し、ageという値を格納 */\n\n/* 単変量解析; */\nproc univariate data = sashelp.class;\nvar &anavar.; /* マクロプロセッサによって&age.に置換される */\nclass sex;\nrun;\n\n/* 単変量解析(bee-swarm plot)を作成; */\nproc sgplot data = sashelp.class;\nvbox &anavar. / category = sex nofill nooutliers;\nscatter y = &anavar. x = sex / jitter;\nrun;\nマクロ変数により、プログラムに一貫性を持たせることができる。例えば、追加解析や仕様変更により、年齢(age)ではなく体重(weight)の解析を行いたい場合は、%let anavarの定義部分だけを変更するだけで済む。人の手を介することで修正漏れやミスタイプのリスクがある。\nまた、CALL SYMPUTXルーチンを利用すれば、DATAステップでデータセットの変数の内容をマクロ変数に格納できる。次章で説明する制御構文と併せて、データセットの内容に応じて、プログラムを変更させることが可能になり、プログラムに柔軟性を与えられる。\ncall symputx('マクロ変数名', 格納したい値(DATAステップの変数名));\n\n/* 男女別の生徒数を数えて、それぞれをマクロ変数に格納する; */\nproc freq data = sashelp.class noprint;\ntables sex / out = out1;\nrun;\n\ndata _null_;\nset out1;\nif sex = \"男子\" then call symputx('N_Male', count);\nif sex = \"女子\" then call symputx('N_Female', count);\nrun;\n\n/* マクロ変数の値をログに出力して確認; */\n%put N_Male = &N_Male N_Female = &N_Female;/* 「N_Male : 10 N_Female : 9」と出力; */\nまた、SQLプロシジャのINTO句を利用して、データセットの変数の内容をマクロ変数に格納することも可能である。\nproc sql;\nselect 変数名1, 変数名2, ..., 変数名N\ninto :マクロ変数名1, :マクロ変数名2, ..., :マクロ変数名N\nfrom データセット名;\nquit;\n\nproc sql noprint;\ncreate table work.class as\nselect *\nfrom sashelp.class\nrun;\nquit;\n\n%put &sqlobs.; /* proc sqlで直近に処理したデータ(OBS数)を格納; */\n\n\n2.3.3 マクロ変数は文字型変数\nマクロ変数は、DATAステップと違って、すべて文字型変数として扱われる。このため、マクロプロセッサに数値演算をさせるような場面では、注意が必要である。数値の場合は%eval関数、小数を含む場合は%sysevalf関数に演算式を渡す必要がある。（ただし、%evalと%sysevalfは、演算のおよそについても調査した上で利用しないと）\n%let not5 = 1 + 4;\n%put &not5.; /* 「1 + 4」と表示; */\n\n%let equal5 = %eval(1 + 4);\n%put &equal5.; /* 「5」と表示; */\n\n%let not5 = 1.5 + 3.5;\n%put &not5.; /* 「1.5 + 3.5」と表示; */\n\n%let equal5 = %sysevalf(1.5 + 3.5);\n%put &equal5.; /* 「5」と表示; */\n\n%let not5 = %eval(1.5 + 3.5); /* %evalは整数計算だけなのでエラーとなる */\nなお、格納されるテキストによってマクロ変数の変数は自動的に調整されるため、データセットの文字型変数のように長さを気にする必要はない（ただし、SAS9.4の最大長は65,534文字である）。\n\n\n2.3.4 自動マクロ変数\nマクロプロセッサが自動的に作成する自動マクロ変数もある。自動マクロ変数は、実行環境の確認、プログラム実行時の表示などに利用できる。いくつか例を示す。\n\n\n\n\n\n\n\n自動マクロ変数名\n内容\n\n\n\n\nSYSVER\nSASのバージョンを格納（例：9.4）\n\n\nSYSDATEP\nSAS セッションの開始日をDATEフォーマットで格納（例：01SEP2022）\n\n\nSYSLAST\nSAS セッションで直近に作成したデータセットを格納（例：WORK.CLASS）\n\n\nSYSUSERID\n現在のSAS プロセスのユーザーIDを格納（例：morita.yusuke）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロプログラムを使う",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロプログラムを使う",
    "title": "SASマクロ入門1",
    "section": "2.4 マクロプログラムを使う",
    "text": "2.4 マクロプログラムを使う\n本章では、マクロの主要機能であるマクロプログラムについて概説する。前章のマクロ変数とマクロプログラムを組み合わせることで、より複雑なプログラムをマクロプロセッサに書いてもらうことができる。\n\n2.4.1 マクロプログラムとは\nマクロプログラムもマクロ変数と同様に、テキスト置換を行う機能である。マクロ変数は、プログラム中の変数名、データセット名、オプションまたは短いテキストの置換に用いられる場合が多い。一方、マクロプログラムは、あるまとまった単位のSAS プログラムへの置換に利用されるものであり、マクロ変数と組み合わせることで、また、制御構文を使用することで、さまざまなプログラムをマクロプロセッサに手軽に作成してもらうことができる。\n\n\n2.4.2 マクロプログラムの作成・呼び出し方法\nマクロプログラムは%macroおよび%mendステートメントを利用して作成する。\n%macro マクロプログラム名; （簡略したいテキスト） %mend マクロプログラム名;\nマクロプログラム名は最大32文字、最初の文字は英字またはアンダースコア、その後の文字は英字・数字・アンダースコアが使用可能である。\n\n\n2.4.3 マクロプログラムの特徴\n\n2.4.3.1 呼び出し時にマクロ変数を受け取ることができる\n基準となるプログラムをコピー&ペーストして、一部分を書き換えたい場合があ る。この基準となるプログラムをマクロプログラム内に格納して、書き換えたい箇所を呼び出し時に受け取れるマクロ変数として、マクロプログラムに指定できる。このマクロプログラム呼び出し時に受け取るマクロ変数をマクロパラメータという。マクロパラメータも、ユーザーが任意の名前を設定可能で、そのマクロプログラム内で参照可能なマクロ変数となる。マクロパラメータとしてデータセット名(dsn)および変数名(var)を指定する例を以下に示す。\n/* 呼び出し時にマクロパラメータを指定; */\n%macro univariate2(dsn, var); /* マクロ名の後にマクロパラメータを設定; */\n\nproc univariate data = &dsn.;\nvar &var.;\nclass sex;\nrun;\n\n%mend;\n\n/* 呼び出し時にマクロパラメータを指定して実行; */\n%univariate2(dsn=sashelp.class, var=age)\n%univariate2(dsn=sashelp.class, var=weight)\n%univariate2(dsn=sashelp.class, var=height)\nまた、マクロパラメータに予め既定値を与えることもできる。この既定値をもつマクロパラメータをキーワードパラメータという。キーワードパラメータは呼び出し時に指定しなければ、既定値が自動的に設定される。したがって、ほぼ毎回同じパラメータで実行する可能性があるパラメータはキーワードパラメータとして宣言すとよい。\n\n\n2.4.3.2 制御構文が使える\nDATAステップでは、条件分岐のIFステートメント、反復処理のDOステートメントが使用できる。マクロ言語にも同様に%ifステートメント、%doステートメントが用意されており、データセットの内容やマクロパラメータの内容に応じて、マクロプロセッサの動作を変更できる。これら制御構文はマクロ変数にはない機能で、マクロプログラムに柔軟性を与える機能の一つとなっている。\n制御構文の例として、条件分岐の%ifステートメントについて説明する。\n%if 条件文 %then %do;\n(条件文がTrueの場合の処理)\n%end;\n%else %if 条件文 %then %do;\n(条件文がTrueの場合の処理)\n%end;\n%else %do;\n(全条件文をも不満足している場合の処理)\n%end;\nなお、上記のdsn および var のように、既定値を持たないマクロパラメータを位置パラメータという。\nまた、DATAステップでは、条件分岐から反復処理の%doステートメントについて説明する。\n%macro list_by_4years(startyr, endyr);\n    title1 \"Customer List of &yr. to &endyr.\";\n    proc print data = work.customer;\n        where &yr. &lt;= year &lt;= &endyr., &by 4;\n        var year customer_revenue;\n    run;\n    title1 \"Customer List of 2000 to 2003\";\n    proc print data = work.customer;\n        where 2000 &lt;= year &lt;= 2003;\n        var year customer_revenue;\n    run;\n    title1 \"Customer List of 2004 to 2007\";\n    proc print data = work.customer;\n        where 2004 &lt;= year &lt;= 2007;\n        var year customer_revenue;\n    run;\n%mend;\n\n%list_by_4years(startyr=1996, endyr=2007)\nマクロの制御構文には、他にも%do-%while、%do-%until等がある。しかし、初心者のうちは%ifと%doの2つを事実としても余りがない。%ifと%doもマクロプロセッサに対する命令である。一方、DATAステップのコンパイラに対する命令であり、データセットの変数の内容を変更することになる。ただし、%ifと%do%sysevalfは、SAS9.4 M5からマクロプログラム内部でなくても（オープンコードで）%if%then%else等を使えるようになった。2021年のSASユーザー総会の発表資料に詳細が記載されている。\n\n\n\n2.4.4 マクロ関数\n字句SASで用意されたマクロ関数を利用できる。これらのマクロ関数は、マクロプロセッサによって実行されるマクロプログラムである。DATAステップでデータセットを編集するために利用される関数と同名・同機能であっても異なるものであることに留意されたい。以下にマクロ関数の一例を示す。\n\n\n\n\n\n\n\nマクロ関数名\n説明\n\n\n\n\n%upcase(文字列) / %lowcase(文字列)\n文字列を大文字/小文字に変換する\n\n\n%trim(文字列)\n文字列の末尾の余分なスペース文字を取り除く\n\n\n%index(文字列1, 文字列2)\n文字列1の中に文字列2が含まれていれば、最初の位置(何文字目)を返す。文字列2が含まれていなければ0を返す\n\n\n%sysfunc(関数名)\nDATAステップの関数をマクロプロセッサから使用する\n\n\n\n\n\n2.4.5 マクロ変数のスコープ\nマクロ変数にもスコープ、つまりプログラム中で参照可能な範囲がある。スコープによってglobal マクロ変数とlocal マクロ変数に区分される。global マクロ変数は、プログラムのどこからでも値を参照可能である。一方、local 変数は、その変数が宣言されたマクロプログラム内部でのみ値を参照可能である。\n/* マクロ変数のスコープ; */\n%global global_var; /* グローバルマクロ変数を宣言; */\n\n%macro global_local;\n    %let local_var = ローカル変数です; /* このマクロ内部だけで有効期間; */\n    %let global_var = グローバル変数です;\n%mend;\n\n%global_local /* マクロを実行; */\n\n%put &global_var.; /* グローバル変数なので、マクロ外でも参照可能; */\n%put &local_var.; /* マクロ外なでマイナ一ルで、変数を参照できない; */\n初心者のうちは、スコープを意識する機会はさほど無いかもしれない。しかし、チームでマクロプログラムを分担して構築する場合、マクロプログラムで構築されるシステムを利用する際は、マクロ変数の衝突を避けるため、マクロ変数のスコープに留意が必要となる。（local マクロ変数を明示的に作成するためのlocal ステートメントが用意されている。）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロをデバッグする",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロをデバッグする",
    "title": "SASマクロ入門1",
    "section": "2.5 5. マクロをデバッグする",
    "text": "2.5 5. マクロをデバッグする\n本節で同じ章にまとめ」で、マクロを書けばバグが生じる。したがって、マクロを効率的にデバッグする技術を重要である。以下に、マクロプロセッサが、マクロプログラムを生じさせたのかを知ることが有用である。このため、マクロのデバッグを効率的に行うためのオプションが用意されている。以下に、よく使用するオプションの例を示す。\n\n\n\n\n\n\n\nオプション名\n内容\n\n\n\n\nMPRINT\nマクロプロセッサによって生成されるSAS プログラムをSAS ログに表示する\n\n\nMLOGIC\nマクロプロセッサがマクロパラメータにどのような値を受け取ったか、%if条件分岐を True/Falseのどちらに判断したか、マクロの開始点と終了点をSASログに表示する\n\n\nSYMBOLGEN\nマクロプロセッサが、マクロ変数をどの値に置き換えたかSAS ログに表示する\n\n\n\nこれらのオプションを指定することで、SAS ログにマクロプロセッサからの情報が出力されるようになる。しかし、上記オプションを指定してもSAS ログを読み解くのが困難な場合もある。その場合、mfileオプションでマクロプロセッサが出力したプログラム全体を別ファイルとして出力することも可能である。（マクロの学習にも活用できる。）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロをライブラリとして整理して活用する",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロをライブラリとして整理して活用する",
    "title": "SASマクロ入門1",
    "section": "2.6 6. マクロをライブラリとして整理して活用する",
    "text": "2.6 6. マクロをライブラリとして整理して活用する\n作成したマクロは積極的に活用したほうがよい。一度制作したマクロプログラム、別の活用場面では思いがけずれなく再現全文が現在の場合がある。つまり、マクロはほとんど常設され、品質も向上していく。そこで本章では、作成したマクロプログラムをライブラリとして整理し、プログラムから呼び出し可能にする方法について説明する。\n以下にマクロライブラリを作成する手順を示す。\n\nマクロを格納するフォルダを用意する。（フォルダは複数あってもよい）\n各マクロプログラムを個別ファイルに格納していうフォルダに保存する。 このとき、ファイル名はマクロ名と同じにする必要がある。（マクロ名.sas とする）\nマクロを呼び出す側のプログラムで、以下のMAUTOSOURCE及びSASAUTOSの2つのオプションを指定する。このとき、SASAUTOSに（1）のフォルダを指定する。\n\n/* マクロをライブラリとして活用する; */\noptions mautosource sasautos=(sasautos, \"C:\\sasYearlyMacros\");\n/* （1）の sasautos内容ないこと; */\noptions mautosource sasautos=(sasautos, \"C:\\sasYearlyMacros\" \"C:\\sasYearMacros\");\nこれで、マクロライブラリ中のマクロプログラムが呼び出し可能になる。\nまた、本章では触れないが、継続として共有するライブラリを整備・活用した事例は、過去のSASユーザー総会の複数の発表がある。\nまた、SAS9.4 M6 以降、WebページのバージョンProgramming Tool であるGitHub との連携機能が搭載されている。GitHub上でマクロファイルのバージョン管理を行い、SASから直接GitHub上のマクロプログラムをinclude可能になっている。多くのオープンソースマクロがGitHub上で管理・公開されており、GitHub上での連携機能について今後の発展が注目される。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロのコツ",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロのコツ",
    "title": "SASマクロ入門1",
    "section": "2.7 マクロのコツ",
    "text": "2.7 マクロのコツ\nどんな項目もで正しく場合ほど拡張を発想する。本章ではマクロを作成する際に留意したいポイントを説明する。筆者にして筆者の経験に価値たけ書もあるかもしれない。PhUSE6が「Good Programming Practice In Macro Development」を公開しており、マクロ開発に関する考査ずべきポイントを学ぶことができる。なお、機械のコーディングルールやガイドラインがある場合には、それらを優先されたい。\n\n2.7.1 マクロでコードの重複を排除する\nマクロによりコードの重複部分を削減し、プログラム全体をコンパクトに保つのがポイントである。そのために、マクロ化する際には、どのようなポイントで構成するか、マクロのパラメータをどこに配置するかマクロ作成時の設計が大式である。しかし、このためには、一定の実装経験を積んで、マクロプロセッサに作成させたコードのイメージが持てるように下はないと無難い趣もある。まずはマクロを含まないプログラムを作成してから、重複部分をマクロ化していくというアプローチがある。いずれにせよコードの重複部分はマクロ化を考慮するポイントである。\n\n\n2.7.2 マクロの機能と入出力を明示する\nそのマクロプログラムが、どんな機能を提供するマクロか、出力は何か、入力は何かの3点を明示することは、便利でマクロを作成するうえで重要である。そのマクロプログラムのマクロパラメータとして明示する。そのマクロパラメータも馴染みやすいネーミングを心掛けたい。また、コメントも適切に活用して必要な情報を補記するべき利用を使用して説明する。以下に、データクリーニングの名前(Cody’s Data Cleaning Techniques Using SAS）に掲載されたもののマクロプログラムの冒頭部分である。\n\n\n2.7.3 マクロの機能と入出力を明示する\nそのマクロプログラムが、どんな機能を提供するマクロか、出力は何か、入力は何かの3点を明示することは、便利でマクロを作成するうえで重要である。そのマクロプログラムのマクロパラメータとして明示する。そのマクロパラメータも馴染みやすいネーミングを心掛けたい。また、コメントも適切に活用して必要な情報を補記するべき利用を使用して説明する。以下に、データクリーニングの名前(Cody’s Data Cleaning Techniques Using SAS）に掲載されたもののマクロプログラムの冒頭部分である。\n%macro auto_outliers(\n    Dsn=,       /* Data set name */\n    ID=,        /* Name of ID variable */ \n    Var_list=,  /* List of variables to check */\n    Trim=1,     /* Trim criterion */\n    N_sd=2      /* Number of standard deviations */\n);\nコメントの細部もあるがAuto_Outliersマクロは外れ値を検出するマクロであることが読み取れる。入力として、対象データセット名(Dsn)、オブザベーションのID変数名(ID)、外れ値を抽出したい対象変数名(Var_list)、統計的な判断基準であるTrim_N_sd)を指定すればよいことがわかる。数章では、外れ値の統計基準やプログラムの詳細より、当初マクロプログラムからできることがわかる。したがって方がユーザーにより使いやすかっただいられる（Auto,はプログラム内部からできること）。\n\n\n2.7.4 マクロの内部をブラックボックス化し、抽象化する\n細部は基本原理は「プログラムの内部アルゴリズムを知らずとも、マクロプログラムの機能を利用可能にすること」である。これはプロシジャで用いるイメージに近い。例えば、私たちは SORT プロシジャに入力かのデータセット名とソート変数を指定すれば、プロシジャ内部のソートアルゴリズムを意識することなく目的を達成できる。このように、マクロプログラムを作成する際は、ユーザーにマクロの内部を意識させない形式をイメージすべきである。\nやや哲学的な内容になるが、優れたマクロは、その出力だけを実行された課題が魅力を呈しない。マクロの内部にソート順を含めてカテゴリーゼットは変更しないようにする。また、マクロの内部だけで作成する一時的なデータセットを削除しなければ、ユーザーは、そのマクロ内部の構造する必要がないらならない。また、「文今後、新を適時」の結構で、マクロの終了時にマクロ内部で作成したworkデータセットを削除することもある。\n\n\n2.7.5 マクロプログラムはなるべくシンプルを保つ\nプログラム設計の原則に「分割して統治する」および「Keep it simple, stupid」があり、マクロプログラムもなるべくシンプルに保つことを推奨する。これは、マクロプログラムの汎用性を高めることと方針テンションスピ方向にあることも分かいている。また、新たにマクロプログラムを作成する際は、既存のマクロプログラムの入力方法を工夫すれば詳細なプロ先はせずとも済まない、あるいは既存のシンプルなマクロプログラムを利用して（呼び出して）作成できないか構想すべき場合がある。品質は既存されたシンプルのマクロプログラムを利用すれば、マクロプログラム全体のコードを予備し、かつ新たに作成するマクロプログラムの品質も維持しようといううがい対象である。\n\n\n2.7.6 コードの読みやすさや理解のしやすさにも配慮する\nマクロを書けば、いろいろな場面で活用できるようになるが、SASにプログラムを書いてもらうのが楽しくなり、%や&が使いびう複雑なプログラムになる場合がある。もちろん、そのことは体はマクロを理解している範囲であり、マクロプロセッサも文法的に問題ないよう限りは説明に動いてくれる。一方で、保存する他のプログラマや求人の自分がプログラムを読み機会もあり、コードの読みやすさや理解のしやすさを保持して、あえてマクロ化しない（マクロ化しすぎない）という判断場合もある。\nまた、マクロプログラミングでも、DATAステップ同様にネーミングが重要である。インデント（字下げ）を適切に行い、マクロの条件分岐や反復構造などを把握しやすくする、効果的にコメントを入れるなど、コードの読みやすさについても心掛けたい。\n\n\n2.7.7 小さく始める\n小さく始めて、少しずつ理解するのが習得のコツである。最初はマクロ変数を使うところからでもよい。基本プログラムによく変更する部分だけをマクロ変数化して、プラクマの電用管理を設定可能にする、先行するすプロジェクトの設定を改めてせることも多いし、実はここまででも十分な効果が着込まれる場合がある。また、簡単なマクロプログラムを作成する際給与も設ける。マクロを作成する手順として、まずマクロを含まないプログラムを作成し、少しずつマクロ化していくアプローチが推奨されている。これによりマクロプロセッサに命令があるかが明り分けすされる。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロの実例",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロの実例",
    "title": "SASマクロ入門1",
    "section": "2.8 マクロの実例",
    "text": "2.8 マクロの実例\n筆者らが業務で実際に作成したマクロプログラムを紹介する。筆者で簡切と練習する事例であり、なるべく小題のプログラム編集で対応できるよう意図している。\n\n2.8.1 特定のフォルダ内のSASデータセットを1つのExcelファイルに変換する\nSASデータセットをデータセット別にシートを分けてExcelファイルに変換してほしいと依頼を受ける。もちろんデータセットの教だけprocexportまたはsetステートメントを記述してもよいのだが、そのような縮り返し処理はマクロ化したときに自動転するのがよい。なお、以下でマクロプログラムが直後されたフォルダ内のSASデータセットを、同フォルダに既定のExcelファイルを指定する必要がある。\n%macro sas2xlsx;\n\n    /* データセット一覧を取得する */\n    proc sql noprint;\n        select memname into :dsname1-\n        from dictionary.tables\n        where libname = \"SAS\";\n    quit;\n\n    do i = 1 to &sqlobs.;\n\n        data work.&&&dsname&i..;\n            set sas.&&&dsname&i..;\n        run;\n\n    %end;\n\n%mend;\n上記マクロでは、現在でデータセットのあるフォルダを出力先のExcelファイルに指定する必要がある。そこで、上記マクロプログラムが配置されたフォルダ内のSASデータセットを、同フォルダに既定のExcelファイルとして出力するようにプログラムを変更すれば、条件ごとにプログラムを編集する必要がなくなる。（もちろん不測の事象が生じする能性があるため、SASログ確認および出力ファイルの確認は時う。）\n\n\n2.8.2 特定のフォルダ内のSASデータセットをXPTファイルに一括変換する\n医療機関医療品の承認申請では、原則として申請電子データ提出が求められており、既導データをXPT形式で提出する必要がある。このためSASデータセットをXPT形式に変換する機会がよくある。なお、以下ではfilel.sasという名前でマクロプログラムを保存し、指定したデータセットが配置されたフォルダに配置してくれる。細部の具い事例である。\n/* 指定フォルダ内のSASデータセットをXPTファイルに一括変換する; */\noption nofmterr nologic print symbol;\n%let xpt = %str(C:\\workXpt);  \n%let sas = %str(C:\\workXsas); \n\nlibname _sas \"&sas.\";\nlibname _xpt xport \"&sas.\";\n\n%macro sas2xpt(sptdir, sasdir);\n\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n/* ファイル一覧を取得する; */\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n%filelist(\n    directory=%superq(sasdir), /* Directory to read */\n    out=_sas,                  /* Output data set to create */\n    extensions=sas7bdat        /* Space delimited extensions to include. Not case\n                                sensitive. Leave blank or set other based on extension */\n)\n\n/* ファイル一覧を読み込む; */\nproc sql noprint;\n    select dsname into :_dsname1 - \n    from _sas;\nquit;\n\n/* 各ファイルがない場合は終了する; */\n%if &sqlobs. = 0 %then %return;\n\nlibname _sas %superq(sasdir)\" access=readonly;\n\n%do i = 1 to &sqlobs.;\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n/* SAS7BDATをXPTに変換する; */\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\nlibname _xpt xport \"&sptdir\\&&&_dsname&i..&_xpt\";\ndata _xpt.&&&_dsname&i..;\n    set _sas.&&&_dsname&i..;\nrun;\n%end;\n\n/* ～～～～～～終了処理～～～～～～; */\nlibname _sas clear;\nlibname _xpt clear;\nproc datasets library=work nolist;\n    delete _sas;\nquit;\nrun;\nquit;\n\n%mend;\n\n%sas2xpt(sptdir=%superq(xpt), sasdir=%superq(sas))"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#終わりに",
    "href": "posts/statistics/2025/SASマクロ入門1.html#終わりに",
    "title": "SASマクロ入門1",
    "section": "2.9 終わりに",
    "text": "2.9 終わりに\nマクロ言語を対象にマクロの基礎から応用、そして利用のコツを概説した。マクロプロセッサにプログラムを書いてもらうライブラリ化により大量軸な共通化に及ぶまで、マクロは様々な場面で雄用いと感じてもらえれば幸いしたい。しかし、一度にすべてを理解する必要はなく、筆者ももともくさんのトライ&エラーを経験し、必要に迫られながら時間をかけてレットたという自分求むのが実情である。やがり理解できる自然に身につくき交鎖に考え、引用文献もご参照頂ければ幸いである。マクロプロセッサは、そこと出番を待っている。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips010.html",
    "href": "posts/statistics/2025/SASプログラミングTips010.html",
    "title": "加工プログラム例―少数ステップでの処理―",
    "section": "",
    "text": "0.1 SASプログラマ必見！ADaM作成を効率化するデータステップ重要機能6選\nこんにちは！臨床試験のSASプログラマの皆さん、日々の業務でADaMデータセットの作成に多くの時間を費やしていませんか？\nADaMの仕様は複雑で、元となるSDTMデータから多くの新しい変数を導出したり、レコードを跨いだ計算を行ったりする必要があります。こうした処理を愚直にコーディングすると、プログラムが長くなり、ミスも起こりがちです。\nしかし、SASデータステップには、こうした複雑なデータ加工を驚くほどスマートに解決するための強力な機能が備わっています。\nこの記事では、あなたのADaM作成業務を劇的に効率化する、6つの重要な関数とステートメントを厳選し、具体的な活用例とともに徹底解説します。\n\n\n0.2 【第1部】データステップの基本機能とADaM作成への応用\nまずは、データ加工の基本となる6つの機能の役割と、ADaM作成における具体的な使い方を見ていきましょう。\n\n0.2.1 1 & 2. LENGTH関数とSUBSTR関数 - 文字列操作の基本\n\nLENGTH関数: 文字列の長さを返します。\nSUBSTR関数: 文字列の一部を抜き出（抽出）します。\n\n\n0.2.1.1 実行可能なサンプルコード\nPROC TRANSPOSEで生成されるようなデータ（変数名_NAME_を持つ）から、パラメータ(PARAM)と訪問番号(VISITNUM)を分割する例です。\n/* 1. サンプルデータ作成 */\ndata transposed_data;\n  input _NAME_ $ AVAL;\n  cards;\nTC_1 212\nHDL_1 50\nTC_2 224\nHDL_2 64\n;\nrun;\n\n/* 2. LENGTHとSUBSTRを使った処理 */\ndata parsed_data;\n  set transposed_data;\n\n  /* LENGTH関数で全体の長さを取得 */\n  NAME_LEN = length(_NAME_); \n\n  /* SUBSTR関数で文字列を分割 */\n  PARAM    = substr(_NAME_, 1, NAME_LEN - 2); \n  VISITNUM = input(substr(_NAME_, NAME_LEN, 1), 8.); \n\n  drop NAME_LEN;\nrun;\n\n/* 3. 結果表示 */\ntitle \"LENGTHとSUBSTRによる変数名分割の結果\";\nproc print data=parsed_data;\nrun;\ntitle;\n\n\n\n\n0.3 3. RETAINステートメント - 値を次の行へ引き継ぐ魔法\n\n0.3.0.1 「RETAIN」とは？\nRETAINステートメントで指定された変数は、データステップのループを越えて値を保持します。 通常、変数はループの開始時に欠損値にリセットされますが、\nRETAINを使うと前の行の値を引き継ぐことができます。\n\n\n0.3.0.2 実行可能なサンプルコード\n1から5までの累積和（1, 1+2, 1+2+3, …）を計算する例です。\n/* 1. サンプルデータ作成 (入力データは不要) */\n\n/* 2. RETAINを使った処理 */\ndata sample_sum;\n  retain SUM 0; /* SUM変数の値を保持し、初期値を0に設定 */ \n\n  do i = 1 to 5;\n    SUM = SUM + i; /* 前のループのSUMに現在のiを足す */ \n    output;\n  end;\nrun;\n\n/* 3. 結果表示 */\ntitle \"RETAINによる累積和の計算結果\";\nproc print data=sample_sum;\nrun;\ntitle;\n\n\n\n0.4 4 & 5. first.by / last.by変数 - グループ処理の案内人\n\n0.4.0.1 「first.by」「last.by」とは？\nBYステートメントと一緒に使う特殊な一時変数です。 BYグループ内で、\n\nfirst.by変数: グループの最初の行である場合に 1 になります。\nlast.by変数: グループの最後の行である場合に 1 になります。\n\n\n\n0.4.0.2 実行可能なサンプルコード\nBDSデータセットで、被験者ごと、パラメータごとにレコード番号（ASEQ）を振る例です。\n/* 1. サンプルデータ作成 */\ndata ADVS;\n  input USUBJID $ PARAMCD $ AVAL;\n  cards;\nP01 HR 70\nP01 HR 72\nP01 DIABP 80\nP02 HR 65\nP02 HR 68\nP02 DIABP 75\n;\nrun;\n\n/* 2. first.byを使った処理 */\nproc sort data=ADVS;\n  by USUBJID PARAMCD;\nrun;\n\ndata ADVS_ASEQ;\n  set ADVS;\n  by USUBJID PARAMCD;\n\n  if first.PARAMCD then ASEQ = 0; /* パラメータが切り替わったらASEQを0にリセット */\n  ASEQ = ASEQ + 1;\nrun;\n\n/* 3. 結果表示 */\ntitle \"first.byによるグループ内連番(ASEQ)の作成結果\";\nproc print data=ADVS_ASEQ;\nrun;\ntitle;\n\n\n\n0.5 6. VNAME関数 - 変数名を文字列として取得\n\n0.5.0.1 「VNAME」とは？\nVNAME関数は、引数に指定した変数の名前を文字列として返します。\n\n\n0.5.0.2 実行可能なサンプルコード\nARRAYステートメントと組み合わせて、横持ちデータから縦持ちデータを作成する際に、PARAMCDを動的に生成する例です。\n/* 1. サンプルデータ作成 (横持ち) */\ndata source_data;\n  input USUBJID $ TC_1 HDL_1 TC_2 HDL_2;\n  cards;\nP01 212 50 224 64\n;\nrun;\n\n/* 2. VNAMEを使った処理 */\ndata vertical_data;\n  set source_data;\n  array aval_group[*] TC_1 HDL_1 TC_2 HDL_2; /* アスタリスク(*)で変数を指定 */\n\n  do i = 1 to dim(aval_group);\n    AVAL = aval_group{i};\n\n    /* VNAMEで変数名(例: \"TC_1\")を取得 */\n    VAR_NAME = VNAME(aval_group{i});\n\n    /* 変数名からPARAMCDとVISITNUMを動的に生成 */\n    PARAMCD  = scan(VAR_NAME, 1, '_');\n    VISITNUM = input(scan(VAR_NAME, 2, '_'), 8.);\n    \n    output;\n  end;\n  keep USUBJID PARAMCD VISITNUM AVAL;\nrun;\n\n/* 3. 結果表示 */\ntitle \"VNAMEによる動的な縦持ち変換の結果\";\nproc print data=vertical_data;\nrun;\ntitle;\n\n\n\n0.6 【第2部】さらにステップアップ！各機能の応用テクニック\n基本を理解したところで、次はいよいよ実践です。これらの機能を組み合わせることで、どのような強力な処理が実現できるか見ていきましょう。\n\n0.6.1 応用例1：RETAINとfirst.byによるグループ情報の引き継ぎ（Fill Down）\nシナリオ: ADSLにしかない被験者レベルの情報（例: 治験薬群 ARM）を、ADVSのような測定データセットの全レコードにコピーします。これにより、ADVSデータセット単体で、治験薬群による層別解析が可能になります。\n解説: MERGEでデータを結合しただけでは、ARMの値は各被験者の最初のレコードにしか入りません。そこでRETAINを使い、first.USUBJID（被験者の最初の行）のタイミングでARMの値を一度キャッチし、その値をlast.USUBJID（被験者の最後の行）まで保持し続けることで、グループ内の全レコードに値を「引き継ぐ」ことができます。\n/* ADSLとADVSをマージし、RETAINでARM情報を引き継ぐ */\ndata ADVS_with_ARM;\n  merge ADSL(keep=USUBJID ARM) ADVS(in=in_vs);\n  by USUBJID;\n\n  retain RETAINED_ARM;\n  if first.USUBJID then RETAINED_ARM = ARM;\n  ARM = RETAINED_ARM;\n  \n  if in_vs;\n  drop RETAINED_ARM;\nrun;\n\n\n0.6.2 応用例2：RETAINとfirst.byによるAUCの計算\nシナリオ: 薬物動態データ（ADPC）において、台形公式を用いて血中濃度時間曲線下面積（AUC）を算出します。これは重要な薬物動態パラメータの一つです。\n解説: 台形公式 (値1 + 値2) * (時間2 - 時間1) / 2 を計算するには、現在行の値/時間に加え、前の行の値/時間が必要です。RETAINを使って前の行の時間（PREV_ATPT）と値（PREV_AVAL）を保持します。first.byでパラメータが切り替わるタイミングを検知し、累積AUCや保持している変数を初期化することで、パラメータごとに正しく計算を実行できます。\n/* ADPCデータでAUCを計算 */\ndata ADPC_AUC;\n  set ADPC;\n  by USUBJID PARAMCD;\n\n  retain PREV_ATPT PREV_AVAL AUC_CUM;\n\n  if first.PARAMCD then do;\n    AUC_CUM = 0;\n    call missing(PREV_ATPT, PREV_AVAL);\n  end;\n\n  if not missing(PREV_AVAL) then do;\n    AUC_INTERVAL = (AVAL + PREV_AVAL) * (ATPT - PREV_ATPT) / 2;\n    AUC_CUM + AUC_INTERVAL;\n  end;\n\n  PREV_ATPT = ATPT;\n  PREV_AVAL = AVAL;\nrun;\n\n\n0.6.3 応用例3：last.byとRETAINによるグループ集計\nシナリオ: PROC MEANSやPROC SQLとMERGEを組み合わせる複数ステップの処理を、1回のDATAステップで実現し、各被験者のバイタルサイン（AVAL）の最大値を求めます。\n解説: このテクニックのキモはlast.byです。RETAINとmax関数を使い、各レコードを読み進めるごと に、その時点での最大値を計算し保持し続けます。そして、if last.USUBJID then output;とすることで、計算は全レコードで行いつつ、最終的な集計結果は各被験者の最後のレコードを処理したタイミングで一度だけ出力します。これにより、プログラムのステップを削減し、処理を効率化できます。\n/* 各被験者のバイタルサインの最大値を求める */\ndata VS_MAX;\n  set ADVS_SORTED; /* 事前にUSUBJIDでソート済み */\n  by USUBJID;\n  retain MAX_AVAL;\n\n  if first.USUBJID then MAX_AVAL = .;\n  \n  MAX_AVAL = max(MAX_AVAL, AVAL);\n  \n  if last.USUBJID then output;\nrun;\n\n\n0.6.4 応用例4：VNAMEによる汎用的なデータ品質チェック（QC）\nシナリオ: 複数の変数（AVAL, BASE, CHG）に負の値が含まれていないかチェックし、問題があれば具体的な変数名と情報をログに出力します。\n解説: データ品質チェック（QC）では、同じロジックを多くの変数に適用することが多々あります。ARRAYでチェック対象の変数をグループ化し、VNAMEでエラーが発生した変数名を動的に取得することで、保守性の高いプログラムを作成できます。もし将来、チェック対象の変数が追加されても、ARRAYステートメントに変数名を加えるだけで対応でき、ログ出力部分のコードを修正する必要がありません。\n/* 汎用的なQCプログラム */\ndata _NULL_; /* データセットを作成しない場合は _NULL_ を使う */\n  set ADVS;\n  array checks[*] AVAL BASE CHG;\n\n  do i = 1 to dim(checks);\n    if checks[i] &lt; 0 then do;\n      VAR_NAME = VNAME(checks[i]);\n      put \"ERROR: Negative value found in \" VAR_NAME= \"at OBS=\" _N_ \"for USUBJID=\" USUBJID;\n    end;\n  end;\nrun;\n\n\n\n0.7 まとめ：機能を組み合わせて、データ加工の達人へ\n今回ご紹介した6つの機能は、それぞれが強力ですが、真価は組み合わせることで発揮されます。BYステートメント、RETAIN、first.byを組み合わせれば、複雑なグループ処理が1つのデータステップで完結します。ARRAY、VNAME、SUBSTRを組み合わせれば、保守性の高い動的なプログラムが実現できます。\nこれらの武器を使いこなし、日々のADaM作成業務をより速く、より正確に進めていきましょう！\n\n\n0.8 Appendix: 応用テクニックのサンプルプログラム集\n記事の第2部で紹介した応用テクニックを、実際に動作させて試せる完全なサンプルプログラムです。\n\n0.8.1 応用例1：RETAINによるグループ情報の引き継ぎ（Fill Down）\n/* 1. サンプルデータ作成 */\ndata ADSL;\n  input USUBJID $ ARM $;\n  cards;\nP01 Drug A\nP02 Drug B\n;\nrun;\ndata ADVS;\n  input USUBJID $ VISIT $ AVAL;\n  cards;\nP01 VISIT 1 120\nP01 VISIT 2 125\nP02 VISIT 1 110\nP02 VISIT 2 112\n;\nrun;\n/* 2. メイン処理 */\nproc sort data=ADVS; by USUBJID; run;\nproc sort data=ADSL; by USUBJID; run;\ndata ADVS_with_ARM;\n  merge ADSL(keep=USUBJID ARM) ADVS(in=in_vs);\n  by USUBJID;\n  retain RETAINED_ARM;\n  if first.USUBJID then RETAINED_ARM = ARM;\n  ARM = RETAINED_ARM;\n  if in_vs;\n  drop RETAINED_ARM;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例1: ARM情報を全レコードに引き継いだ結果\";\nproc print data=ADVS_with_ARM;\nrun;\ntitle;\n\n\n0.8.2 応用例2：RETAINとfirst.byによるAUCの計算\n/* 1. サンプルデータ作成 */\ndata ADPC;\n  input USUBJID $ PARAMCD $ ATPT AVAL;\n  cards;\nPK-01 AUC 0 0\nPK-01 AUC 1 50\nPK-01 AUC 2 40\nPK-01 AUC 4 20\nPK-01 AUC 8 5\n;\nrun;\n/* 2. メイン処理 */\ndata ADPC_AUC;\n  set ADPC;\n  by USUBJID PARAMCD;\n  retain PREV_ATPT PREV_AVAL AUC_CUM;\n  if first.PARAMCD then do;\n    AUC_CUM = 0;\n    call missing(PREV_ATPT, PREV_AVAL);\n  end;\n  if not missing(PREV_AVAL) then do;\n    AUC_INTERVAL = (AVAL + PREV_AVAL) * (ATPT - PREV_ATPT) / 2;\n    AUC_CUM + AUC_INTERVAL;\n  end;\n  PREV_ATPT = ATPT;\n  PREV_AVAL = AVAL;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例2: AUCを計算した結果\";\nproc print data=ADPC_AUC;\nrun;\ntitle;\n\n\n0.8.3 応用例3：last.byとRETAINによるグループ集計\n/* 1. サンプルデータ作成 */\ndata ADVS_SORTED;\n  input USUBJID $ AVAL;\n  cards;\nP01 120\nP01 135\nP01 128\nP02 110\nP02 105\n;\nrun;\n/* 2. メイン処理 */\ndata VS_MAX;\n  set ADVS_SORTED;\n  by USUBJID;\n  retain MAX_AVAL;\n  if first.USUBJID then MAX_AVAL = .;\n  MAX_AVAL = max(MAX_AVAL, AVAL);\n  if last.USUBJID then output;\n  drop AVAL;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例3: 各被験者の最大値を求めた結果\";\nproc print data=VS_MAX;\nrun;\ntitle;\n\n\n0.8.4 応用例4：VNAMEによる汎用的なデータ品質チェック（QC）\n/* 1. サンプルデータ作成 (意図的に負の値を含む) */\ndata ADVS_QC;\n  input USUBJID $ AVAL BASE CHG;\n  cards;\nP01 120 120 0\nP01 110 120 -10\nP02 100 105 -5\n;\nrun;\n/* 2. メイン処理 (結果はデータセットではなくログに出力) */\ntitle \"応用例4: QCチェックの結果 (SASログを確認してください)\";\ndata _NULL_;\n  set ADVS_QC;\n  array checks[*] AVAL BASE CHG;\n  do i = 1 to dim(checks);\n    if checks[i] &lt; 0 then do;\n      VAR_NAME = VNAME(checks[i]);\n      put \"ERROR: Negative value found in \" VAR_NAME= \"at OBS=\" _N_ \"for USUBJID=\" USUBJID;\n    end;\n  end;\nrun;\ntitle;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips008.html",
    "href": "posts/statistics/2025/SASプログラミングTips008.html",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "",
    "text": "参考文献\n\n2023年SAS User総会：太田さん資料：\n\n小さく始めるSGPLOT／SGPANEL ～データに語らせよう～\n\nSAS One DashのSGplotブログ\n武田薬品：舟尾先生、SAS Sgplot超入門\n\nTips\n\nvlineにおいて最終時点のみ線で結ばないⅡ\nSGPlotのカプランマイヤー図にログランク検定のp値を書き入れる\nSGPlot内に記述統計量を書き込む方法"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips008.html#sgplotに関する基礎的事項と発展的な内容をまとめる",
    "href": "posts/statistics/2025/SASプログラミングTips008.html#sgplotに関する基礎的事項と発展的な内容をまとめる",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "",
    "text": "参考文献\n\n2023年SAS User総会：太田さん資料：\n\n小さく始めるSGPLOT／SGPANEL ～データに語らせよう～\n\nSAS One DashのSGplotブログ\n武田薬品：舟尾先生、SAS Sgplot超入門\n\nTips\n\nvlineにおいて最終時点のみ線で結ばないⅡ\nSGPlotのカプランマイヤー図にログランク検定のp値を書き入れる\nSGPlot内に記述統計量を書き込む方法"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips008.html#introduction",
    "href": "posts/statistics/2025/SASプログラミングTips008.html#introduction",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "2 Introduction",
    "text": "2 Introduction\nSGPLOTプロシジャとは、ODS Graphics機能で使用できるStatistical Graphics Proceduresに分類されるプロシジャ。解析用データセットや他Procedureにて計算した統計量データを用いて、様々なグラフを生成することができる。\nODS Graphics機能\n代表的な作成できるグラフ\n\n散布図\n折れ線グラフ"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html",
    "href": "posts/statistics/2025/SASプログラミングTips006.html",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "臨床試験における有害事象（Adverse Event: AE）の集計は、薬剤の安全性評価において最も重要な分析の一つです。特に治療群間での比較は、薬剤の安全性プロファイルを理解する上で欠かせません。本記事では、標準的なADSL（Subject-Level Analysis Dataset）とADAE（Adverse Event Analysis Dataset）を使用して、Treatment群、Control群、Total の3つの観点からSOC（System Organ Class）/PT（Preferred Term）別の有害事象集計を実装する方法を詳しく解説します。\n標準データセットの作成 ADSLデータセット（被験者レベル）\n/* ADSL（被験者レベル分析データセット）の作成 */\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\nDATA STEPの基本解説：\n\ndata adsl; - 新しいデータセット「adsl」を作成開始\nlength - 変数の型と最大長を事前定義（$は文字型、数値は文字数）\ndo i = 1 to 50; - 1から50まで繰り返し処理（50人の被験者作成）\ncats() - 複数の文字列を結合する関数（空白なしで連結）\nput(i, z3.) - 数値iを3桁のゼロパディング文字列に変換（001, 002, …）\nmod(i, 3) - iを3で割った余りを計算（0, 1, 2のサイクル）\noutput; - 現在の変数値でレコードを出力\ndrop i; - 作業用変数iを最終データセットから除外\nrun; - DATA STEPの実行\n\n\n\n/* ADAE（有害事象分析データセット）の作成 - より豊富なデータ */\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\nStatement解説：\n\nADAEデータの特徴：\n\naesoc: 器官別大分類（MedDRA SOC相当）\naedecod: 基本語（MedDRA PT相当）\naerel: 因果関係（Y=あり, N=なし）\naeser: 重篤性（Y=重篤, N=非重篤）\naestdy: 投与開始からの日数\n\n\n\n\n\n\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\nPROC SQLの基本解説：\n1. PROC SQLの開始と終了：\n\nproc sql; - SQLプロシジャの開始\nquit; - SQLプロシジャの終了（他のプロシジャはrun;だがSQLはquit;）\n\n2. CREATE TABLE文：\n\ncreate table ae_safety_arm as - 新しいテーブル「ae_safety_arm」を作成\nselect ... from ... where ...; の結果でテーブルを作成\n\n3. SELECT文の基本構造：\nselect 列名1, 列名2, 計算式 as 新しい列名 from テーブル名 where 条件;\n4. CASE文（条件分岐）：\ncase when 条件1 then 値1\n     else 値2 end as 新列名\n\nIF-THEN-ELSEのSQL版\ncase when s.arm = \"Placebo\" then \"Control\" - PlaceboをControlに表示変更\n\n5. INNER JOIN（内部結合）：\nfrom adae a\ninner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\"\n\n2つのテーブルを結合\na, s はテーブルエイリアス（短縮名）\non の条件を満たすレコードのみ結果に含める\nand s.saffl = \"Y\" で安全性解析対象のみ抽出\n\n6. INTO句（マクロ変数への格納）：\nselect count(*) into :total_n\nfrom adsl\nwhere saffl = \"Y\";\n\ncount(*) - レコード数をカウント\ninto :total_n - 結果をマクロ変数&total_nに格納\n後で分母として使用\n\n\n\n\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n1. サブクエリ（副問い合わせ）：\nfrom (select aesoc, usubjid, arm\n      from ae_safety_arm\n      group by aesoc, usubjid, arm) as subj_arm\n\n() 内のSELECT文が先に実行される\nその結果をsubj_armという名前のテーブルとして使用\n重要な目的: 同一被験者の同一SOCで複数AEがある場合の重複除去\n\n2. GROUP BY句：\ngroup by aesoc, usubjid, arm\n\n指定した列の組み合わせでデータをグループ化\n各グループに対して集計関数（COUNT, SUMなど）を適用\n例：被験者001の心臓障害は1つのグループとして扱われる\n\n3. 集計関数：\ncount(distinct usubjid)  -- ユニークな被験者数をカウント\n4. 文字列処理：\ncompress(put(count(distinct usubjid), 8.)) || '(' || \ncompress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c\n\nput() - 数値を文字列に変換\ncompress() - 不要な空白を除去\n|| - 文字列結合演算子\n結果例：「5(10.0)」形式の文字列作成\n\n5. OUTER UNION CORRESPONDING：\nselect ... from ...\nunion all  \nselect ... from ...\n\n複数のSELECT結果を縦に結合\n\n\n\nall - 重複行も含めて全て結合\n\n\n\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n重要なポイント：\n1. PROC SORTの必要性：\n\nPROC TRANSPOSEはBY変数で指定した順序でデータが並んでいることを要求\n事前にソートしないとエラーが発生\n\n2. PROC TRANSPOSEの解説：\n\ndata=ae_comprehensive - 入力データセット\nout=ae_arm_pivot - 出力データセット名\nby aesoc aept; - グループ化変数（これらの組み合わせごとに転置）\nid arm_group; - 新しい列名になる変数（Treatment, Control, Totalが列名になる）\nvar c; - 転置する値の変数\n\n転置前:\naesoc    aept  arm_group  c\n心臓障害  \"\"   Treatment  2(6.7)\n心臓障害  \"\"   Control    1(3.3)\n心臓障害  \"\"   Total      3(6.0)\n\n転置後:\naesoc    aept  Treatment  Control  Total\n心臓障害  \"\"   2(6.7)     1(3.3)   3(6.0)\n//* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\nDATA STEPでの後処理解説：\n\nset ae_arm_pivot; - 入力データセットを読み込み\nif Y = \"\" then Y = \"0(0.0)\"; - 空文字列を”0(0.0)“に置換\n\"  \" || aept - PTの前に2つのスペースでインデント追加\n階層表示の仕組み:\n\n-    SOCレベル: `display_term = aesoc`（例：「心臓障害」）\n\n-    PTレベル: `display_term = \"  \" || aept`（例：「 完全房室ブロック」）\n\n\n\n\n/*======================================================================================*/\n/* プログラム名: 治療群別有害事象集計 (SOC/PT別) - シンプル版                           */\n/* 作成者: [作成者名]                                                                   */\n/* 作成日: [作成日]                                                                     */\n/* 目的: 臨床試験における有害事象データの治療群別集計                                   */\n/*      Treatment群、Control群、Total の3つの観点からSOC/PT別に集計                   */\n/*======================================================================================*/\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 1: ADSLデータセット（被験者レベル）の作成                                       */\n/*---------------------------------------------------------------------------------------*/\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 2: ADAEデータセット（有害事象レベル）の作成                                     */\n/*---------------------------------------------------------------------------------------*/\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 3: 治療群別有害事象集計の実行                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\n\n/* Step 3-2: 治療群別SOC/PT集計の実行 */\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 4: データの転置と整形                                                           */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n\n/* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    retain display_term Treatment Control Total;  /* 列順序の明示的制御 */\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\n\n/* Step 4-4: 最終ソート */\nproc sort data=final_display_ordered;\n    by aesoc sort_level aept;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 5: 結果表示                                                                     */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 5-1: 最終結果の表示 */\nproc print data=final_display_ordered noobs;\n    title1 \"有害事象集計表（治療群別）\";\n    title3 \"被験者数 (%)\";\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 6: 検証用出力                                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 6-1: 基本統計の確認 */\nproc sql;\n    title \"データ整合性チェック\";\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value from (select 1 as dummy);\nquit;\n\n/* Step 6-2: SOC別詳細検証 */\nproc sql;\n   title \"SOC別被験者数検証\";\n   select aesoc,\n          count(distinct case when arm = \"Treatment\" then usubjid else null end) as treatment_subj,\n          count(distinct case when arm = \"Control\" then usubjid else null end) as control_subj,\n          count(distinct usubjid) as total_subj\n   from ae_safety_arm\n   group by aesoc\n   order by total_subj desc;\nquit;\n\n/* Step 6-3: 治療群配分の確認 */\nproc freq data=adsl;\n   tables arm / nocum;\n   title \"治療群配分\";\nrun;\n\n\n\n/*---------------------------------------------------------------------------------------*/\n/* プログラム終了                                                                       */\n/*---------------------------------------------------------------------------------------*/\n\n/* タイトルクリア */\ntitle;\n\n/* マクロ変数の確認（ログ出力） */\n%put NOTE: Treatment群被験者数 = &treatment_n;\n%put NOTE: Control群被験者数 = &control_n;\n%put NOTE: Total被験者数 = &total_n;\n\n%put NOTE: 治療群別有害事象集計プログラム実行完了;\n\n/*======================================================================================*/\n/* プログラム終了                                                                       */\n/* 出力データセット:                                                                    */\n/*   - final_display_ordered: 最終的な治療群別集計表                                   */\n/*   - ae_safety_arm: 安全性解析対象AEデータ                                           */\n/*   - ae_comprehensive: 中間集計データ                                                */\n/*======================================================================================*/\n\n\n\n/* 集計結果の検証 */\nproc sql;\n    /* 元データとの整合性チェック */\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value;\nquit;\n検証SQLの解説：\n\nunion all - 複数のSELECT結果を縦に結合（重複も含める）\n&treatment_n - 事前に計算したマクロ変数の値を表示\n検証の重要性: 各ステップで期待する件数が得られているか確認\n\n/* SOC別被験者数の詳細検証 */\nproc sql;\n    select aesoc,\n           count(distinct case when arm = \"Treatment\" then usubjid end) as treatment_subj,\n           count(distinct case when arm = \"Control\" then usubjid end) as control_subj,\n           count(distinct usubjid) as total_subj\n    from ae_safety_arm\n    where aerel = \"Y\"  /* 因果関係ありのみ */\n    group by aesoc\n    order by total_subj desc;\nquit;\nCASE文の高度な使用：\ncount(distinct case when arm = \"Treatment\" then usubjid end)\n\ncase when ... then ... end - 条件を満たす場合のみ値を返す\nTreatment群の場合のみusubjidをカウント対象にする\n1つのクエリで治療群別の集計が可能\n\n\n\n\n\n\nSELECT 何を選ぶか\nFROM どのテーブルから  \nWHERE どんな条件で\nGROUP BY どうグループ化するか\nORDER BY どう並び替えるか\n\n\n\n/* 内部結合の例 */\nfrom adae a                    -- メインテーブル\ninner join adsl s              -- 結合するテーブル  \non a.usubjid = s.usubjid       -- 結合条件\nand s.saffl = \"Y\"              -- 追加フィルタ\n\n\n\n\ncount(*) - 全行数\ncount(distinct 列名) - ユニークな値の数\nsum() - 合計\nmin(), max() - 最小値、最大値\n\n\n\n\nfrom (select ... from ... group by ...) as 別名\n\n内側のクエリから読む\n外側のクエリは内側の結果を使用\n\n\n\n\n\n本記事では、臨床試験における有害事象データの治療群別集計を、PROC SQLを用いて段階的に実装しました。初心者の方にとって重要なポイントは：\n\n\n\n小さく始める: 複雑なクエリは段階的に構築\n中間結果確認: 各ステップでPROC PRINTで結果確認\nエラー対処: エラーメッセージから問題箇所を特定\nコメント活用: 処理の目的を明記\n\nこの段階的アプローチにより、初心者でも確実に治療群別有害事象集計をマスターできます。重要なのは、各ステップの目的を理解しながら進めることです。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html#治療群別有害事象集計の実装",
    "href": "posts/statistics/2025/SASプログラミングTips006.html#治療群別有害事象集計の実装",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\nPROC SQLの基本解説：\n1. PROC SQLの開始と終了：\n\nproc sql; - SQLプロシジャの開始\nquit; - SQLプロシジャの終了（他のプロシジャはrun;だがSQLはquit;）\n\n2. CREATE TABLE文：\n\ncreate table ae_safety_arm as - 新しいテーブル「ae_safety_arm」を作成\nselect ... from ... where ...; の結果でテーブルを作成\n\n3. SELECT文の基本構造：\nselect 列名1, 列名2, 計算式 as 新しい列名 from テーブル名 where 条件;\n4. CASE文（条件分岐）：\ncase when 条件1 then 値1\n     else 値2 end as 新列名\n\nIF-THEN-ELSEのSQL版\ncase when s.arm = \"Placebo\" then \"Control\" - PlaceboをControlに表示変更\n\n5. INNER JOIN（内部結合）：\nfrom adae a\ninner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\"\n\n2つのテーブルを結合\na, s はテーブルエイリアス（短縮名）\non の条件を満たすレコードのみ結果に含める\nand s.saffl = \"Y\" で安全性解析対象のみ抽出\n\n6. INTO句（マクロ変数への格納）：\nselect count(*) into :total_n\nfrom adsl\nwhere saffl = \"Y\";\n\ncount(*) - レコード数をカウント\ninto :total_n - 結果をマクロ変数&total_nに格納\n後で分母として使用\n\n\n\n\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n1. サブクエリ（副問い合わせ）：\nfrom (select aesoc, usubjid, arm\n      from ae_safety_arm\n      group by aesoc, usubjid, arm) as subj_arm\n\n() 内のSELECT文が先に実行される\nその結果をsubj_armという名前のテーブルとして使用\n重要な目的: 同一被験者の同一SOCで複数AEがある場合の重複除去\n\n2. GROUP BY句：\ngroup by aesoc, usubjid, arm\n\n指定した列の組み合わせでデータをグループ化\n各グループに対して集計関数（COUNT, SUMなど）を適用\n例：被験者001の心臓障害は1つのグループとして扱われる\n\n3. 集計関数：\ncount(distinct usubjid)  -- ユニークな被験者数をカウント\n4. 文字列処理：\ncompress(put(count(distinct usubjid), 8.)) || '(' || \ncompress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c\n\nput() - 数値を文字列に変換\ncompress() - 不要な空白を除去\n|| - 文字列結合演算子\n結果例：「5(10.0)」形式の文字列作成\n\n5. OUTER UNION CORRESPONDING：\nselect ... from ...\nunion all  \nselect ... from ...\n\n複数のSELECT結果を縦に結合\n\n\n\nall - 重複行も含めて全て結合\n\n\n\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n重要なポイント：\n1. PROC SORTの必要性：\n\nPROC TRANSPOSEはBY変数で指定した順序でデータが並んでいることを要求\n事前にソートしないとエラーが発生\n\n2. PROC TRANSPOSEの解説：\n\ndata=ae_comprehensive - 入力データセット\nout=ae_arm_pivot - 出力データセット名\nby aesoc aept; - グループ化変数（これらの組み合わせごとに転置）\nid arm_group; - 新しい列名になる変数（Treatment, Control, Totalが列名になる）\nvar c; - 転置する値の変数\n\n転置前:\naesoc    aept  arm_group  c\n心臓障害  \"\"   Treatment  2(6.7)\n心臓障害  \"\"   Control    1(3.3)\n心臓障害  \"\"   Total      3(6.0)\n\n転置後:\naesoc    aept  Treatment  Control  Total\n心臓障害  \"\"   2(6.7)     1(3.3)   3(6.0)\n//* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\nDATA STEPでの後処理解説：\n\nset ae_arm_pivot; - 入力データセットを読み込み\nif Y = \"\" then Y = \"0(0.0)\"; - 空文字列を”0(0.0)“に置換\n\"  \" || aept - PTの前に2つのスペースでインデント追加\n階層表示の仕組み:\n\n-    SOCレベル: `display_term = aesoc`（例：「心臓障害」）\n\n-    PTレベル: `display_term = \"  \" || aept`（例：「 完全房室ブロック」）"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html#修正されたappendixプログラム列順序修正版",
    "href": "posts/statistics/2025/SASプログラミングTips006.html#修正されたappendixプログラム列順序修正版",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/*======================================================================================*/\n/* プログラム名: 治療群別有害事象集計 (SOC/PT別) - シンプル版                           */\n/* 作成者: [作成者名]                                                                   */\n/* 作成日: [作成日]                                                                     */\n/* 目的: 臨床試験における有害事象データの治療群別集計                                   */\n/*      Treatment群、Control群、Total の3つの観点からSOC/PT別に集計                   */\n/*======================================================================================*/\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 1: ADSLデータセット（被験者レベル）の作成                                       */\n/*---------------------------------------------------------------------------------------*/\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 2: ADAEデータセット（有害事象レベル）の作成                                     */\n/*---------------------------------------------------------------------------------------*/\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 3: 治療群別有害事象集計の実行                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\n\n/* Step 3-2: 治療群別SOC/PT集計の実行 */\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 4: データの転置と整形                                                           */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n\n/* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    retain display_term Treatment Control Total;  /* 列順序の明示的制御 */\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\n\n/* Step 4-4: 最終ソート */\nproc sort data=final_display_ordered;\n    by aesoc sort_level aept;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 5: 結果表示                                                                     */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 5-1: 最終結果の表示 */\nproc print data=final_display_ordered noobs;\n    title1 \"有害事象集計表（治療群別）\";\n    title3 \"被験者数 (%)\";\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 6: 検証用出力                                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 6-1: 基本統計の確認 */\nproc sql;\n    title \"データ整合性チェック\";\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value from (select 1 as dummy);\nquit;\n\n/* Step 6-2: SOC別詳細検証 */\nproc sql;\n   title \"SOC別被験者数検証\";\n   select aesoc,\n          count(distinct case when arm = \"Treatment\" then usubjid else null end) as treatment_subj,\n          count(distinct case when arm = \"Control\" then usubjid else null end) as control_subj,\n          count(distinct usubjid) as total_subj\n   from ae_safety_arm\n   group by aesoc\n   order by total_subj desc;\nquit;\n\n/* Step 6-3: 治療群配分の確認 */\nproc freq data=adsl;\n   tables arm / nocum;\n   title \"治療群配分\";\nrun;\n\n\n\n/*---------------------------------------------------------------------------------------*/\n/* プログラム終了                                                                       */\n/*---------------------------------------------------------------------------------------*/\n\n/* タイトルクリア */\ntitle;\n\n/* マクロ変数の確認（ログ出力） */\n%put NOTE: Treatment群被験者数 = &treatment_n;\n%put NOTE: Control群被験者数 = &control_n;\n%put NOTE: Total被験者数 = &total_n;\n\n%put NOTE: 治療群別有害事象集計プログラム実行完了;\n\n/*======================================================================================*/\n/* プログラム終了                                                                       */\n/* 出力データセット:                                                                    */\n/*   - final_display_ordered: 最終的な治療群別集計表                                   */\n/*   - ae_safety_arm: 安全性解析対象AEデータ                                           */\n/*   - ae_comprehensive: 中間集計データ                                                */\n/*======================================================================================*/"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html#結果の検証とデバッグ",
    "href": "posts/statistics/2025/SASプログラミングTips006.html#結果の検証とデバッグ",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/* 集計結果の検証 */\nproc sql;\n    /* 元データとの整合性チェック */\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value;\nquit;\n検証SQLの解説：\n\nunion all - 複数のSELECT結果を縦に結合（重複も含める）\n&treatment_n - 事前に計算したマクロ変数の値を表示\n検証の重要性: 各ステップで期待する件数が得られているか確認\n\n/* SOC別被験者数の詳細検証 */\nproc sql;\n    select aesoc,\n           count(distinct case when arm = \"Treatment\" then usubjid end) as treatment_subj,\n           count(distinct case when arm = \"Control\" then usubjid end) as control_subj,\n           count(distinct usubjid) as total_subj\n    from ae_safety_arm\n    where aerel = \"Y\"  /* 因果関係ありのみ */\n    group by aesoc\n    order by total_subj desc;\nquit;\nCASE文の高度な使用：\ncount(distinct case when arm = \"Treatment\" then usubjid end)\n\ncase when ... then ... end - 条件を満たす場合のみ値を返す\nTreatment群の場合のみusubjidをカウント対象にする\n1つのクエリで治療群別の集計が可能"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html#初心者向けsql学習のポイント",
    "href": "posts/statistics/2025/SASプログラミングTips006.html#初心者向けsql学習のポイント",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "SELECT 何を選ぶか\nFROM どのテーブルから  \nWHERE どんな条件で\nGROUP BY どうグループ化するか\nORDER BY どう並び替えるか\n\n\n\n/* 内部結合の例 */\nfrom adae a                    -- メインテーブル\ninner join adsl s              -- 結合するテーブル  \non a.usubjid = s.usubjid       -- 結合条件\nand s.saffl = \"Y\"              -- 追加フィルタ\n\n\n\n\ncount(*) - 全行数\ncount(distinct 列名) - ユニークな値の数\nsum() - 合計\nmin(), max() - 最小値、最大値\n\n\n\n\nfrom (select ... from ... group by ...) as 別名\n\n内側のクエリから読む\n外側のクエリは内側の結果を使用"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips006.html#まとめ",
    "href": "posts/statistics/2025/SASプログラミングTips006.html#まとめ",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "本記事では、臨床試験における有害事象データの治療群別集計を、PROC SQLを用いて段階的に実装しました。初心者の方にとって重要なポイントは：\n\n\n\n小さく始める: 複雑なクエリは段階的に構築\n中間結果確認: 各ステップでPROC PRINTで結果確認\nエラー対処: エラーメッセージから問題箇所を特定\nコメント活用: 処理の目的を明記\n\nこの段階的アプローチにより、初心者でも確実に治療群別有害事象集計をマスターできます。重要なのは、各ステップの目的を理解しながら進めることです。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html",
    "href": "posts/statistics/2025/SASプログラミングTips004.html",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "",
    "text": "How Not to SAS: Avoiding Common Pitfalls and Bad Habits\nSAS is a powerful tool for data analysis, but its flexibility can sometimes lead you into developing bad programming habits. Although these shortcuts might not break your programs immediately, they can lead to inefficient, error-prone, and hard-to-maintain code. This paper identifies common pitfalls and provides straightforward, practical solutions to avoid them.\nEffective code organization is foundational to successful SAS programming. Yet, it’s easy to overlook best practices and fall into poor habits. Here are three common pitfalls you should avoid:"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#本記事では以下の文献を参考にsasのpitfallsとbad-hatibsをまとめます",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#本記事では以下の文献を参考にsasのpitfallsとbad-hatibsをまとめます",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "",
    "text": "How Not to SAS: Avoiding Common Pitfalls and Bad Habits\nSAS is a powerful tool for data analysis, but its flexibility can sometimes lead you into developing bad programming habits. Although these shortcuts might not break your programs immediately, they can lead to inefficient, error-prone, and hard-to-maintain code. This paper identifies common pitfalls and provides straightforward, practical solutions to avoid them.\nEffective code organization is foundational to successful SAS programming. Yet, it’s easy to overlook best practices and fall into poor habits. Here are three common pitfalls you should avoid:"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#code-organization-readability",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#code-organization-readability",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "2 CODE ORGANIZATION ＆ READABILITY",
    "text": "2 CODE ORGANIZATION ＆ READABILITY\nGood Practice\n\nUse Clear and concise SAS Comments in SAS Code\n\nblock comments like /* my comment */\nsingle-line comments like * my comment;\n\n\n/* my program comment */\ndata one; set sashelp.cars;\n*subset to certain car types - SUV;\nwhere type = \"SUV\";\nrun;\nBad Tips\n\nWRITE ALL YOUR CODE IN ONE LONG, CONTINUOUS BLOCK\n\n「コードを延々とスクロールして見ることは、忍耐力と視力を試すエキサイティングな方法だから」。コードを1つの巨大なブロックとして書くのは、よくある有害な習慣です。このような方法はデバッグやコード修正を煩雑にし、エラーが見逃される可能性を高めます。\n推奨される方法：モジュラーにコードを書く\nコードをより小さく、論理的なステップに分割し、明確なヘッダーやモジュラーセクションを使って各ブロックの目的を定義しましょう。モジュラーコードは読みやすさを向上させるだけでなく、他のプロジェクトや分析でセクションを簡単に再利用でき、貴重な時間を節約できます。\n/* 悪い例：すべてが1つのブロック */\ndata work.analysis;set mylib.rawdata;if age &gt;= 18 and status='Active';length category $20;if score &gt;= 90 then category='Excellent';else if score &gt;= 80 then category='Good';else category='Needs Improvement';run;proc sort data=work.analysis;by category descending score;run;proc means data=work.analysis mean std;class category;var score;output out=work.summary mean=avg_score std=std_score;run;\n\n/* 良い例：モジュラー構造 */\n/*************************************/\n/* Step 1: Data Filtering & Cleanup */\n/*************************************/\ndata work.filtered_data;\n    set mylib.rawdata;\n    where age &gt;= 18 and status = 'Active';\nrun;\n\n/********************************/\n/* Step 2: Category Assignment */\n/********************************/\ndata work.categorized_data;\n    set work.filtered_data;\n    length category $20;\n    \n    if score &gt;= 90 then category = 'Excellent';\n    else if score &gt;= 80 then category = 'Good';\n    else category = 'Needs Improvement';\nrun;\n\n/************************/\n/* Step 3: Data Sorting */\n/************************/\nproc sort data=work.categorized_data;\n    by category descending score;\nrun;\n\n/****************************/\n/* Step 4: Summary Analysis */\n/****************************/\nproc means data=work.categorized_data mean std;\n    class category;\n    var score;\n    output out=work.summary \n           mean=avg_score \n           std=std_score;\nrun;\nGood Practice：\n\nUse modular, structured code\n\nclearly separate different steps with comments\nさっきと同じことですね。\n\n\nBad Tips：\n\nUSE UNCLEAR OR ARBITRARY VARIABLE NAMES （不明確または恣意的な変数名を使用する）\n\nVAR1やXのような暗号的な変数名を使うことは、あなたのコードを、あなた自身や後にそのコードを引き継ぐ人にとって解けないパズルゲームに変えてしまいます。VAR1、X、TEMPのような貧弱な変数名を選択することは、可読性を低下させ、コードに混乱をもたらします（Program 2）。また、汎用的な名前は、エラーや結果の誤解釈の可能性を高めます。\n推奨：意味のある説明的な変数名を使用する\ndata new;\n    set old;\n    x = a * b;\n    y = x + c;\n    if z &gt; 10 then flag = 1;\n    temp = var1 / var2;\nrun;\nGood Practice：Use meaningful and descriptive variable names\n意味のある説明的な変数名（Xの代わりにCustomerAgeなど）を使用することで、あなたや同僚が各変数の目的と内容を素早く把握できるようになります（Program 3）。アンダースコア（customer_age）やキャメルケース（CustomerAge）などの一貫した命名規則を採用することで、さらに明確性が向上します。明確に命名された変数は、デバッグを簡素化し、分析中のエラーの可能性を大幅に削減します。\ndata salaryinfo2021;\n    set salaryinfo2020;\n    newsalary = oldsalary + increase;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#debugging-error-handling",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#debugging-error-handling",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "3 DEBUGGING ＆ ERROR HANDLING",
    "text": "3 DEBUGGING ＆ ERROR HANDLING\nProper debugging and error handling are critical for creating reliable SAS programs. Here are common pitfalls and the best practices you should follow:\nBad Tips:\n\nIGNORING THE SAS LOG WINDOW\n\nRed text is just a suggestion. Who needs to debug when you can keep running the code? Ignoring the log window means missing critical information about errors and warnings, causing unnoticed mistakes and incorrect results.\nGood Practices:\n\nCheck all the messages in your log\n\nAlways check for ERROR, WARNING, and NOTE messages in your log. Each of these messages can indicate fatal failures in your code . Understanding SAS Log Messages:\n\nERROR: Critical issues that prevent SAS from executing your code. Your results are incomplete or incorrect until these are resolved.\nWARNING: Potential issues that SAS identifies but doesn’t stop execution. These should be reviewed and addressed to ensure accuracy.\nNOTE: Informational messages about code execution. These offer insights into dataset creation, memory usage, and other operational details.\n\nBad Tips:\n\nNEVER USE DEBUGGING OPTIONS\n\nSkipping debugging options is a great way to keep your coding life exciting—who doesn’t love spending hours chasing hidden bugs? Avoiding the use of debugging options can significantly hinder your ability to troubleshoot and resolve standard SAS code and macro-related issues efficiently.\nGood Practices:\n\nUse system options to help your debug SAS code\n\n便利なGlobal option\n\nMSGLEVEL=I: Provides additional informational messages in the log, especially useful when merging datasets to identify issues such as mismatches or data alignment problems.（ndefined）\nSOURCE: Displays the original SAS statements in the log.\nSOURCE2: Shows included SAS code from %INCLUDE statements.\nFMTERR: Issues an error if a specified format cannot be found.\nDSNFERR: Issues an error when a referenced dataset does not exist.\nOBS=0: Compiles the program without executing it, useful for syntax checking.\nNOREPLACE: Prevents accidental overwriting of existing datasets.\n\nプログラム開発時（デバック環境）と本番環境実行時でglobal optionを使い分けることができると上級者になれるかもしれないですね。\noptions MSGLEVEL=I \n        SOURCE \n        SOURCE2 \n        FMTERR \n        DSNFERR \n        OBS=0 \n        NOREPLACE;\nマクロ実行時は以下のglobal optionが役に立つ。\nUse debugging options specifically designed for macros: OPTIONS MPRINT SYMBOLGEN MLOGIC;\n\nMPRINT: Displays the actual SAS statements generated by macro execution, helping you identify issues within macros.\nSYMBOLGEN: Shows the resolution of macro variables, assisting you in confirming that macro variables resolve correctly.\nMLOGIC: Provides detailed information about macro execution, including macro parameter values and logical branching, useful for troubleshooting complex macro logic.\n\n/* Turn on options */\noptions mprint symbolgen mlogic mautosource mcompilenote=ALL;\nBad Tips:\n\nRUNNING CODE WITHOUT VERIFYING INPUT DATA\n\nJust assume your dataset is perfect—because real-world data is always flawless, right? Trusting imported data without verification can lead to incorrect analyses, wasted time, and unreliable results.\nGood Practices:\nAssume all data is “guilty until proven innocent”\n\nInspect dataset properties using PROC CONTENTS, PROC MEANS, and PROC FREQ before analysis.\nValidate key uniqueness, check for missing values, and confirm data quality before merging datasets.\nCheck for numeric-to-character conversions and unexpected results to avoid unintended data type changes and associated analytical errors."
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#data-management-mistakes",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#data-management-mistakes",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "4 DATA MANAGEMENT MISTAKES",
    "text": "4 DATA MANAGEMENT MISTAKES\nEfficient data management is crucial in SAS programming to avoid data loss, facilitate easy retrieval, and ensure accurate analyses. Here are some common mistakes to avoid and best practices to adopt:\nBad Tips:\n\nSTORE ALL YOUR DATA IN WORK\n\nBecause who doesn’t enjoy the adrenaline rush of potentially losing hours of work? Storing all data in the temporary WORK library is risky because data stored there is deleted once your SAS session ends. This practice can lead to significant data loss, especially if you encounter unexpected session closures or interruptions.\nGood Practices:\n\nStore important data in permanent libraries\n\nStore important datasets in permanent libraries to ensure data persistence beyond the current session. Permanent libraries help secure your data, enabling long-term storage, sharing across sessions, and preventing accidental data loss.\nBAD TIP:\n\nAVOID USING LIBRARIES Why make things easy when you can spend extra hours hunting for files? Avoiding the use of libraries can lead to disorganized file management, making it challenging to locate datasets and maintain clean project structures.\n\nGood Practice:\n\nCreate and use SAS libraries Use SAS libraries to streamline data management by logically grouping related datasets. Clearly named and structured libraries improve data accessibility, simplify data sharing, and enhance project collaboration.\n\nBAD TIP:\n\nRUNNING CODE ON PRODUCTION DATABASE WITHOUT TESTING IT FIRST Nothing spices up the workday quite like taking unnecessary risks with live data! Running untested code directly on a production database risks data integrity, can cause significant disruptions, and might lead to costly errors or downtime.\n\nGood Practice:\n\nUse a development or test environment for creating code\nAlways test your code thoroughly in a safe, isolated environment before deploying it to production.Comprehensive testing helps identify potential issues early, ensuring that your code operates reliably and safeguards the production environment."
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#working-with-dates-times-in-sas",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#working-with-dates-times-in-sas",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "5 WORKING WITH DATES ＆ TIMES IN SAS",
    "text": "5 WORKING WITH DATES ＆ TIMES IN SAS\nAccurate handling of dates and times is critical for reliable analyses in SAS. Mistakes in this area can lead to serious analytical errors and confusion. Here are common pitfalls and best practices to adopt:\nUNDERSTANDING SAS DATES\nSAS dates are numeric values representing the number of days since January 1, 1960. This numeric representation simplifies calculations involving dates, such as finding differences between two dates or shifting dates by specific intervals.\nExample:\n\nJanuary 1, 1960, is represented as 0.\nJanuary 2, 1960, is represented as 1.\nDecember 31, 1959, is represented as -1. When printed or displayed, SAS applies date formats to convert these numeric values into readable dates.\n\ndata _null_;\n today_date = today();\n put today_date= date9.;\nrun;\n\ntoday_date=17MAR2025\nGood Practice:\n\nEfficiently handle date values\n\nSAS dates, times, and datetime values are stored as numbers, making them ideal for calculations and comparisons.\nUse the DATEPART(datetime_variable) function to easily extract date values from datetime variables.\nUtilize the INTNX function for precise date shifting, such as adjusting to the first day of the next month.\n\ndata one;\ndtvalue=2064365417;\nStartDate=put(datepart(dtvalue), date9.);\nEndDate=put(intnx('DAY', datepart(dtvalue), 3), date9.);\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips004.html#automationreusability",
    "href": "posts/statistics/2025/SASプログラミングTips004.html#automationreusability",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "6 AUTOMATION＆REUSABILITY",
    "text": "6 AUTOMATION＆REUSABILITY\nAutomation and reuse of code are essential for improving efficiency, accuracy, and maintainability in your SAS workflows. Here are two common pitfalls to avoid and best practices to adopt:\nここは、基本的にマクロを使おうという趣旨。原文を参照。\n## Bad\n\ndata report1;\n set sales;\n where year = 2025;\nrun;\ndata report2;\n set expenses;\n where year = 2025;\nrun;\n## Good\n%let report_year = 2025;\ndata report1;\n set sales;\n where year = &report_year;\nrun;\ndata report2;\n set expenses;\n where year = &report_year;\nrun;\n## Bad\n\nproc means data=dataset1;\n var sales;\nrun;\nproc means data=dataset2;\n var sales;\nrun;\n## Good\n%macro summarize_sales(dataset);\nproc means data=&dataset;\n var sales;\nrun;\n%mend;\n%summarize_sales(dataset1);\n%summarize_sales(dataset2);"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html",
    "href": "posts/statistics/2025/SASプログラミングTips002.html",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "",
    "text": "本記事では、Proc Contents ProcedureとProc Dtaset Procecdureについて解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#sas",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#sas",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "",
    "text": "本記事では、Proc Contents ProcedureとProc Dtaset Procecdureについて解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#proc-contents-procedure",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#proc-contents-procedure",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.2 Proc Contents Procedure",
    "text": "0.2 Proc Contents Procedure\nCONTENTS プロシージャは、SAS データセットの内容を表示し、SAS ライブラリのディレクトリを印刷します。一般的に、CONTENTS プロシージャは DATASETS プロシージャの CONTENTS ステートメントと同じ機能を持ちます。CONTENTS プロシージャと PROC DATASETS の CONTENTS ステートメントの違いは以下の通りです：\n\nPROC CONTENTS の DATA= オプションにおける libref のデフォルトは Work です。CONTENTS ステートメントでは、デフォルトはプロシージャ入力ライブラリの libref です。\nPROC CONTENTS は順次ファイルを読み取ることができます。CONTENTS ステートメントはできません。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#proc-contents-procedureの特徴",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#proc-contents-procedureの特徴",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.3 Proc Contents Procedureの特徴",
    "text": "0.3 Proc Contents Procedureの特徴\n\nPROC CONTENTS reports metadata about the table and the metadata about the variables.\nデータセットにおけるVariable、Type(Char、Num） 、Fromat、Labelをデータセット化できる！"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#構文",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#構文",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.4 構文",
    "text": "0.4 構文\nPROC CONTENTS &lt;options&gt;;\n\n0.4.1 DATA=SAS-file-specification\nspecifies an entire library or a specific SAS data set within a library. SAS-file-specification can take one of the following forms:\n\n\n0.4.2 &lt;libref.&gt;SAS-data-set\nnames one SAS data set to process. The default for libref is the libref of the procedure input library. For example, to obtain the contents of the SAS data set HtWt from the procedure input library, use the following CONTENTS statement:\ncontents data=HtWt;\nTo obtain the contents of a specific version from a generation group, use the GENNUM= data set option as shown in the following CONTENTS statement:\ncontents data=HtWt(gennum=3);\n\n\n0.4.3 &lt;libref.&gt;_ALL_\ngives you information about all SAS data sets that have the type or types specified by the MEMTYPE= option. libref refers to the SAS library. The default for libref is the libref of the procedure input library.\n\nIf you are using the _ALL_ keyword, you need Read access to all read-protected SAS data sets in the SAS library.\nDATA=_ALL_ automatically prints a listing of the SAS files that are contained in the SAS library. Note that for SAS views, all librefs that are associated with the views must be assigned in the current session in order for them to be processed for the listing.\n\n\n\n\n\n\n\n\nDefault\nmost recently created data set in your job or session, from any SAS library.\n\n\n\n\nTip\nIf you specify a read-protected data set in the DATA= option but do not give the Read password, by default the procedure looks in the PROC DATASETS statement for the Read password. However, if you do not specify the DATA= option and the default data set (last one created in the session) is Read protected, the procedure does not look in the PROC DATASETS statement for the Read password.\n\n\n\nすなわち指定したlibraryに含まれるSASデータセット全てを指定することもできるし、指定したlibraryの特定のデータセットを指定することもできる。\n\n\n0.4.4 MEMTYPE=(member-type(s))\nrestricts processing to one or more member types. The CONTENTS statement produces output only for member types DATA, VIEW, and ALL, which includes DATA and VIEW.\nMEMTYPE= in the CONTENTS statement differs from MEMTYPE= in most of the other statements in the DATASETS procedure in the following ways:\n\nA slash does not precede the option.\nYou cannot enclose the MEMTYPE= option in parentheses to limit its effect to only the SAS file immediately preceding it.\n\nMEMTYPE= results in a directory of the library in which the DATA= member is located. However, MEMTYPE= does not limit the types of members whose contents are displayed unless the _ALL_ keyword is used in the DATA= option. For example, the following statements produce the contents of only the SAS data sets with the member type DATA:\nproc datasets memtype=data;   \nmentypeはデータセットのみが欲しいときは指定したらよいと思うが、基本的にする必要はないだろう。\n\n\n0.4.5 NOPRINT\nsuppresses printing the output of the CONTENTS statement.\n\n\n0.4.6 ORDER=COLLATE | CASECOLLATE | IGNORECASE | VARNUM\n基本的にorder = varnumとしておけばよい。\n\n\n\n\n\n\n\nCOLLATE\nprints a list of variables in alphabetical order beginning with uppercase and then lowercase names.\n\n\nCASECOLLATE\nprints a list of variables in alphabetical order even if they include mixed-case names and numerics.\n\n\nIGNORECASE\nprints a list of variables in alphabetical order ignoring the case of the letters.\n\n\nVARNUM\nis the same as the VARNUM option.\n\n\n\n\n\n\nNote\nThe ORDER= option does not affect the order of the OUT= and OUT2= data sets.\n\n\n\n\nSee\nVARNUM\n\n\nExample\nSee Using the ORDER= Option to compare the default and the four options for ORDER=.\n\n\n\n\n\n0.4.7 OUT=SAS-data-set\nnames an output SAS data set.\n\n\n\nTip\nOUT= does not suppress the printed output from the statement. If you want to suppress the printed output, you must use the NOPRINT option.\n\n\n\n\nSee\nThe OUT= Data Set for a description of the variables in the OUT= data set.\n\n\n\n\n\n0.4.8 OUT2=SAS-data-set\nnames the output data set to contain information about indexes and integrity constraints.\n\n\n\nNote\nWhen you use the OUT2=PermanentLibrary_ALL_ option within PROC CONTENTS or PROC DATASETS with the CONTENTS statement, you must also set the REPLACE=YES data set option or the REPLACE system option.\n\n\n\n\nTips\nIf UPDATECENTILES was not specified in the index definition, then the default value of 5 is used in the re-create variable of the OUT2 data set.\n\n\nOUT2= does not suppress the printed output from the statement. To suppress the printed output, use the NOPRINT option.\n\n\n\nSee\nThe OUT2= Data Set for a description of the variables in the OUT2= data set.\n\n\n\n以下のようにしておけばよい\nproc contents data=sashelp.class out=out1 varnum ; run;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#short-option",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#short-option",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.5 Short Option",
    "text": "0.5 Short Option\nShort Optionを使えば、データセットに格納されている順番で、全変数を1つのマクロ変数に格納できる！たまに便利では？\n\n参考記事：PROC CONTENTSのSHORTオプションはアイディア次第で役に立ちそう。\n\n\n*** 全変数名を（データセットに格納されてる順で）1つのマクロ変数に格納する ;\nods output PositionShort = OUT1;\n    proc contents data=sashelp.class  short  varnum;\n    run;\nods output close;\n\ndata _NULL_ ;\n    set OUT1 ;\n    call symputx(\"VARS\", VARIABLES);\nrun;\n\n%put &VARS;\nOUT1にVARIABLESという1変数が格納され、そこにデータセットに含まれる全変数が格納されている。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#copy",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#copy",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.1 Copy",
    "text": "1.1 Copy\nUsed to copy or move a SAS member from one library to another.To limit copying to specific members, use either the SELECT or EXCLUDE options. To specify a different library to copy from use either the DATASETS LIBRARY option to specify a default library or use the IN= option. To move a member from one library to another and then delete the original member, use the MOVE optionThe following example moves two members from lib1 to lib2:\nLIBNAME lib1 ‘SAS-data-library’;\nLIBNAME lib2 ‘SAS-data-library’;\nPROC DATASETS;\nCOPY IN=lib1 OUT=lib2 MOVE;\nSELECT member1 member2;\nRUN;\nデータセットのCopyについてはProc Copyも役に立つ\n\n【PROC COPY】データセットを他のライブラリに一括コピー\n\n  PROC COPY\n       IN                =   コピー対象のライブラリ\n       OUT            =   出力先のライブラリ\n       MEMTYPE  =   (コピー対象のデータのタイプ) ;\n       SELECT     コピー対象のデータ ;\n       EXCLUDE  コピー対象外のデータ ;\n   RUN;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#kill",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#kill",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.2 Kill",
    "text": "1.2 Kill\nThe following example shows how to delete all the members within a permanent SAS library using the KILL option:\nLIBNAME input ‘SAS-data-library’;\nPROC DATASETS LIBRARY=input KILL;\nRUN;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips002.html#データセットのattribを全部消す",
    "href": "posts/statistics/2025/SASプログラミングTips002.html#データセットのattribを全部消す",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.3 データセットのattribを全部消す",
    "text": "1.3 データセットのattribを全部消す\nlibname mylib 'c:\\mylib';\nproc contents data=mylib.class;\nrun;\nproc datasets lib=mylib memtype=data;\n   modify class;\n     attrib _all_ label=' ';\n     attrib _all_ format=;\ncontents data=mylib.class;\nrun;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/github.html",
    "href": "posts/statistics/2025/github.html",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "GitHubでブログを更新する際の標準的な手順は以下の通りです。\n\n\nquarto render\ngit add .\ngit commit -m \"新記事追加/編集\"\ngit push origin main\n\n\n\nなお、quartoが多くなってきた場合、特定のファイルのみでrenderすることも可能である。\nquarto render\nquarto render post.qmd\n\n\n\ngit add .\n\n\n\ngit commit -m \"コミットメッセージ\"\n\n\n\ngit push origin main"
  },
  {
    "objectID": "posts/statistics/2025/github.html#一括実行",
    "href": "posts/statistics/2025/github.html#一括実行",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "quarto render\ngit add .\ngit commit -m \"新記事追加/編集\"\ngit push origin main"
  },
  {
    "objectID": "posts/statistics/2025/github.html#quartoサイトをレンダリング",
    "href": "posts/statistics/2025/github.html#quartoサイトをレンダリング",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "なお、quartoが多くなってきた場合、特定のファイルのみでrenderすることも可能である。\nquarto render\nquarto render post.qmd"
  },
  {
    "objectID": "posts/statistics/2025/github.html#変更内容をステージングエリアに追加",
    "href": "posts/statistics/2025/github.html#変更内容をステージングエリアに追加",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git add ."
  },
  {
    "objectID": "posts/statistics/2025/github.html#変更をコミット",
    "href": "posts/statistics/2025/github.html#変更をコミット",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git commit -m \"コミットメッセージ\""
  },
  {
    "objectID": "posts/statistics/2025/github.html#リモートリポジトリにプッシュ",
    "href": "posts/statistics/2025/github.html#リモートリポジトリにプッシュ",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git push origin main"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kota Sakamoto",
    "section": "",
    "text": "本サイトは個人の学習記録であり、内容の正確性は保証いたしません。所属組織とは無関係の個人的見解です。\n当サイトのご利用により生じたいかなる損害・トラブルについて当サイトでは一切の責任を負いかねます事をご了承ください。\n所属先\n\n岡山大学病院 新医療研究開発センター データサイエンス部\n\n連絡先\n本ブログ等について、誤り/疑問点がありましたら以下までご連絡ください。\n\nkota.sakamoto0514@gmail.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "坂本航太（さかもと こうた）です。私は岡山大学病院 新医療研究開発センター データサイエンス部 統計解析室にて、生物統計家を目指して勤務しています。\n私の関心・興味は以下の通りです。"
  },
  {
    "objectID": "about.html#学歴",
    "href": "about.html#学歴",
    "title": "About",
    "section": "1 学歴",
    "text": "1 学歴\n\n2015.3 私立中央大学杉並高校卒業\n2015.4 中央大学理工学部人間総合理工学科入学\n2017.8 香港城市大学 交換留学開始\n2018.5 香港城市大学 交換留学終了\n2019.3 中央大学理工学部人間総合理工学科卒業\n2019.4 東京大学学際情報学府学際情報学専攻 生物統計情報学コース 入学\n2021.3 東京大学学際情報学府学際情報学専攻 生物統計情報学コース 修了\n2024.4 岡山大学大学院医歯薬学研究科医歯薬学専攻入学\n2028.3 岡山大学大学院医歯薬学研究科医歯薬学専攻修了予定"
  },
  {
    "objectID": "about.html#学位",
    "href": "about.html#学位",
    "title": "About",
    "section": "2 学位",
    "text": "2 学位\n\n博士（医学）（2028.3 岡山大学（取得予定））\n修士（学際情報学）（2021.3 東京大学）\n学士（理工学）（2019.3 中央大学）"
  },
  {
    "objectID": "about.html#職歴",
    "href": "about.html#職歴",
    "title": "About",
    "section": "3 職歴",
    "text": "3 職歴\n\n2021.4 - 現在 岡山大学病院新医療研究開発センター データサイエンス部 統計解析室 助教"
  },
  {
    "objectID": "about.html#資格",
    "href": "about.html#資格",
    "title": "About",
    "section": "4 資格",
    "text": "4 資格\n\n日本統計学会 統計検定1級（統計数理、統計応用（医薬生物学）） 2024.11"
  },
  {
    "objectID": "about.html#所属学会",
    "href": "about.html#所属学会",
    "title": "About",
    "section": "5 所属学会",
    "text": "5 所属学会\n\n日本計量生物学会"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html",
    "href": "posts/statistics/2025/ADaM1.html",
    "title": "ADaM IG1.3",
    "section": "",
    "text": "本記事では、自己学習用にADaM IGの文書を和訳する。基本的には以下の文献を読んでいただきたい。\n\n\n\nADaMIG v1.3"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#文献",
    "href": "posts/statistics/2025/ADaM1.html#文献",
    "title": "ADaM IG1.3",
    "section": "",
    "text": "ADaMIG v1.3"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#basic-data-structure-definitions",
    "href": "posts/statistics/2025/ADaM1.html#basic-data-structure-definitions",
    "title": "ADaM IG1.3",
    "section": "2.1 1.5.2 Basic Data Structure Definitions",
    "text": "2.1 1.5.2 Basic Data Structure Definitions\n\nAnalysis parameter – 共通の定義を持つ値のグループを一意に特徴づけるために使用される行識別子。ADaM解析パラメータには、関連する解析値のグループを一意に識別するために必要なすべての情報が含まれていることに注意してください。対照的に、SDTM –TEST列は、関連する値のグループを識別するために–STRESU、–POS、–LOC、–SPECなどの修飾子列と組み合わせる必要がある場合があります。本文書では、「パラメータ」という語は「解析パラメータ」の同義語として使用されています。例：主要有効性解析パラメータは「座位収縮期血圧（mmHg）」です。\nAnalysis timepoint – 解析パラメータ内の値を解析に使用される時間的または概念的グループに分類するために使用される行識別子。これらのグループ化は、観測された、計画された、または導出されたものである可能性があります。例：主要有効性解析は、第2週、第6週、およびエンドポイント解析タイムポイントで実施されました。\nAnalysis value – （1）解析パラメータによって記述される数値（AVAL）または文字（AVALC）値。解析値は、入力データに存在する、入力データ値のカテゴリ化、または導出されたものである可能性があります。例：パラメータ「体格指数」の解析値は、収集された身長と体重からADaMデータセットで導出されました。（2）さらに、特定の関数の値は解析値とみなされます。例：ベースライン値（BASE）、ベースラインからの変化量（CHG）。 Parameter-variant – AVAL（またはAVALC）の関数として導出される列で、データセットで変数が設定される一部のパラメータに対して異なって計算される場合、パラメータ可変となります。したがって、列がパラメータ可変であるのは、その導出方法が行にあるパラメータに依存する場合です。例えば、AVALCATyはAVAL（またはAVALC）をカテゴリ化します。カテゴリはパラメータによって異なる可能性があり、これによりAVALCATyがパラメータ可変となります。\nParameter-invariant – AVAL（またはAVALC）の関数として導出される列で、データセットで変数が設定されるすべてのパラメータに対して同じ方法で計算される場合、パラメータ不変となります。したがって、列がパラメータ不変であるのは、その導出方法が行にあるパラメータに依存しない場合です。パラメータ不変の導出は、適用されないパラメータに対してはnullのままにされる可能性がありますが、すべてのパラメータにわたって同じままです。例えば、ベースラインからの変化量変数の導出はCHG = AVAL-BASEであり、これはすべてのパラメータで同じ式です。したがって、CHGはパラメータ不変変数です。パラメータ不変性の概念は、BDSの整合性にとって不可欠であり、第4.2節「導出列の作成対導出行の作成」で定義されたルールの不可欠な構成要素であり、モデルが代わりに新しい行が必要であることを示している場合にプロデューサーによる「水平化」（新しい列の作成）を禁止するものです。"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#analysis-datasets-and-adam-datasets",
    "href": "posts/statistics/2025/ADaM1.html#analysis-datasets-and-adam-datasets",
    "title": "ADaM IG1.3",
    "section": "2.2 Analysis Datasets and ADaM Datasets",
    "text": "2.2 Analysis Datasets and ADaM Datasets\n現在、ADaMには3つの構造があります： - ADSL（SUBJECT LEVEL ANALYSIS DATASET） - BDS　（BASIC DATA STRUCTURE） - OCCDS（OCCURRENCE DATA STRUCTURE）\nADaMの基本原則およびその他のADaM規則に従うが、定義された3つの構造（ADSL、BDS、OCCDS）のいずれにも従わない解析データセットは、ADAM OTHERクラスのADaMデータセットと見なされます。解析データセットメタデータのクラス要素の統制用語は、http://www.cdisc.org/terminology でダウンロードできます。\n解析データセットのカテゴリを示す図では、最上位レベルで「Analysis Datasets」があり、その下に「ADaM Datasets」と「Non-ADaM Analysis Datasets」に分かれています。 - ADaM Datasets ADaM Datasetsは以下の4つのカテゴリに分類されます：\n\nADSL: ADSL（被験者レベル解析データセット）\nBDS: ADLB、ADEFF、ADTTE*（基本データ構造の例）\nOCCDS: ADAE、ADCM（発生データ構造の例）\nOTHER: ADMV*（その他のADaMデータセットの例）\n\n\nNon-ADaM Analysis Datasets Non-ADaM Analysis Datasetsには：PATP、AXEVT（ADaMの基本原則に従わずに開発されたデータセットの例）"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#fundamental-principles",
    "href": "posts/statistics/2025/ADaM1.html#fundamental-principles",
    "title": "ADaM IG1.3",
    "section": "2.3 Fundamental Principles",
    "text": "2.3 Fundamental Principles\nADaMデータセットは、ADaMモデル文書に記載されている特定の基本原則に従う必要があります：\n\nADaMデータセットおよび関連するメタデータは、臨床試験で実施される統計解析を支援するデータセットの内容とソースを明確かつ曖昧さなく伝達しなければなりません。\nADaMデータセットおよび関連するメタデータは、値または変数のソースまたは導出を示すトレーサビリティを提供しなければなりません（すなわち、データの系譜または値とその前身との関係）。メタデータは、解析データがいつ、どのように導出または補完されたかを特定しなければなりません。\nADaMデータセットは、一般的に利用可能なソフトウェアツールで容易に使用できなければなりません。\nADaMデータセットは、明確で曖昧さのないコミュニケーションを促進するためのメタデータと関連付けられなければなりません。理想的には、メタデータは機械可読であることが望ましいです。\nADaMデータセットは、最小限のプログラミングで統計解析を実行できる構造と内容を持つべきです。このようなデータセットは「Analysi Ready」と表現されます。ADaMデータセットには、特定の統計解析のレビューと再作成に必要なデータが含まれています。データリスティングやその他の非解析的な表示をサポートするためだけに、データを解析準備完了データセットに照合する必要はありません。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html",
    "href": "posts/statistics/2025/Markdown記法1.html",
    "title": "Markdown記法について",
    "section": "",
    "text": "R Quartoでは、Markdownを使って文書を作成し、Rコードと組み合わせて美しいレポートや論文を生成できます。本記事では、Quarto環境で効果的に使えるMarkdown記法を体系的に解説します。\n\n\n\n私たちのR　再現可能な研究24.Quarto［基礎］\n私たちのR　再現可能な研究25.Quarto［文書］\n私たちのR　再現可能な研究25.Quarto［スライド］\n私たちのR　Appendix F — R Markdown [基礎]\n私たちのR　Appendix G — R Markdown [応用]\n私たちのR　Appendix H — Quarto入門\n\n\n\n\nMarkdownは、プレーンテキストで記述した文書を構造化された文書に変換するためのマークアップ言語です。R Quartoでは、このMarkdownとRコードを組み合わせて、データ分析レポートや学術論文を作成できます。\n\n\n\n可読性が高い：マークアップが最小限で、プレーンテキストでも内容が理解しやすい\n学習コストが低い：基本的な記法は数時間で習得可能\nQuartoとの親和性：Rコードチャンクとシームレスに統合\n多様な出力形式：HTML、PDF、Word、PowerPointなど\n\n\n\n\n\n\n\nコードを美しく表示するには、バッククオート3つ（```）でコードを囲みます。 これだけだとSAS/Rに限らず、プログラムは実行はされないが、サンプルとして提示する際に便利である。\n# Rコードの例\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# データの読み込みと前処理\ndata &lt;- mtcars %&gt;%\n  mutate(efficiency = ifelse(mpg &gt; 20, \"High\", \"Low\"))\n\n# 散布図の作成\nggplot(data, aes(x = wt, y = mpg, color = efficiency)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"車重と燃費の関係\",\n       x = \"車重 (1000 lbs)\",\n       y = \"燃費 (mpg)\")\nQuartoでRプログラムも実行させたい場合は以下のように記載する。なお、SASは実行させない前提とする。 なお、SASの設定環境をQuartoに構築したらSASも実行可能である。\nプログラムも実行させるには、バッククオート3つ（```）でコードを囲み、{r}と書く。そうすると、Rプログラムの実行できる。\nオプションとしてRプログラムを非表示にしたり、表や図を表示する際は、2つの図表を横に並べたりとオプションは様々ある。それらは、こちらのブログを参考にしていただきたい。デフォルトではプログラムが表示されてしまうので、非表示にする場合は、\n\n\nコード\n1+1\n\n\n[1] 2\n\n\nQuartoでの頻用するであろうオプション記法：\n\n\n\n\n実行制御：このコードを実際に実行するかを指定\ntrue：コードを実行する（デフォルト）\nfalse：コードを実行せず、表示のみ\n\n\n\n\n\n出力形式：コードの実行結果をそのまま（as-is）出力\n通常はコードの出力結果が整形されますが、asisでは生の形式で出力\nHTMLタグやMarkdown記法をそのまま文書に挿入したい場合に使用\n\n\n\n\n\nコード表示制御：コードブロックを折りたたみ状態で表示する\ntrue：コードを折りたたんで、クリック可能なボタンで展開\nfalse：コードを通常通り表示（デフォルト）\n読者が必要に応じてコードの詳細を確認できる柔軟性を提供\n\n\n\n\n\n折りたたみボタンのラベル：折りたたまれたコードを展開するボタンのテキストを設定\nデフォルトでは「Show code」や「コードを表示」が表示される\nカスタムテキストで、そのコードブロックの内容を説明できる\n絵文字や詳細な説明文を使用して、読みやすさを向上させる\n\n以下のプログラムを回すと、その下の結果が得らえる。プログラムが表示されないので結果だけを提示する際には有用である。\n#| eval: true\n#| output: asis\n#| code-fold: true\n#| code-summary: \"Show Code\"\n\n1 + 1\n\nShow Code\n1 + 1\n\n[1] 2\n\n\n\n本文中にRの結果を直接入れることができます！これをインラインコードと呼びます。 “r 引数”で本文中に簡単にRの出力結果を入れることができる。これは論文作成の文章案を作成するときに便利であろう。\n以下のように書くことでできます。普通はRチャンクで計算したものを引用するのがよいだろう。\n年齢の平均は r mean(mtcars$mpg) です。\nサンプルサイズは r nrow(mtcars) でした。\n最大値は r max(mtcars$hp) 馬力です。\n年齢の平均は 20.090625 です。 サンプルサイズは 32 でした。 最大値は 335 馬力です。\n\n\n\n\n\nコード\n# データの事前計算\nmean_age &lt;- round(mean(mtcars$mpg), 1)\nsd_age &lt;- round(sd(mtcars$mpg), 2)\nn_cars &lt;- nrow(mtcars)\n\n\nここで、上で事前にRチャンクで計算をしておく。今回は練習のためプログラムを表示しているが、Rプログラムを非表示にしてもよいだろう。記載としては以下のように書けばよい。\n\n\nコード\n本研究では `r n_cars` 台の自動車を分析しました。\n燃費の平均は `r mean_age`mpg（標準偏差 = `r sd_age`）でした。\n\n\n上記のように書くとこのように出力できる。\n本研究では 32 台の自動車を分析しました。\n燃費の平均は 20.1mpg（標準偏差 = 6.03）でした。\n\n\n\n\nMarkdownにおける改行はやや特殊だ。特殊といっても難しいことはない。普段よりもう一行改行するだけだ。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識する。結構難しい。\n文章1 文章2\n文章1\n文章2\n\n\n\nWebページを作成する際、ブラウザが理解できる言語がHTMLです。例えば、ブログ記事でリンクを作成したい場合、HTMLでは以下のように記述します：文章中に簡単にURLを参照できます。\n例：私のブログ\n[私のブログ](https://example-blog.com)\nまた、以下のように{}内に.externalを付けると、リンクのテキストの右側にアイコンを付く。\n[私のブログ](https://example-blog.com){.external target=\"_blank\"}\n例：私のブログ\n\n\n\n文章中でコードや関数名を表示する場合は、バッククオート1つで囲みます。単純にかっこいい。\n例：ggplot()関数やdplyr::filter()を使用してデータを処理します。平均値はmean()で計算できます。\n\n\n\n\n\n見出しは#の数で階層を表現します。学術文書では、適切な階層構造が重要です。 ちなみに#は6つまで使える。\n# 1. はじめに（H1）\n## 1.1 研究背景（H2）\n### 1.1.1 先行研究（H3）\n#### データの特徴（H4）\n##### 変数の詳細（H5）\n###### 補足事項（H6）\n\n\n\n\n\n\n\n重要な結果：**重要な結果**\n統計的有意：*統計的有意*\n仮説は棄却：~~仮説は棄却~~\nアンダーライン：アンダーラインはHTMLタグを使う。\n\n\n\n\n\n\n\n`-`を書いて、blankを入れるだけで順序なしリストができます。\n- データ収集\n  - アンケート調査\n  - 実験データ\n  - 公開データセット\n- データ前処理\n  - 欠損値処理\n  - 外れ値検出\n  - 変数変換\n- 分析手法\n  - 記述統計\n  - 回帰分析\n  - 機械学習\n結果：\n\nデータ収集\n\nアンケート調査\n実験データ\n公開データセット\n\nデータ前処理\n\n欠損値処理\n外れ値検出\n変数変換\n\n分析手法\n\n記述統計\n回帰分析\n機械学習\n\n\n\n\n\n普通に1.みたいにかけばよいだけ。単純。.の付け忘れに注意しよう！\n1. 研究目的の設定\n2. データ収集計画の策定\n   1. サンプルサイズの決定\n   2. 測定項目の選択\n   3. 倫理的配慮\n3. データ収集の実施\n4. 統計解析\n5. 結果の解釈\n6. 考察と結論\n\n\n\n\nQuartoで画像を入れるには![代替テキスト](ファイルのパス名 or URL)と入力します。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもあるが、視覚障害者用のウェブブラウザーのためにも使われる。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれる。\n例えば、Figsフォルダー内のex.pngというファイルを読み込むとしたら以下のように書く。\n![画像](Figs/ex.png)\n\n\n相対パス（推奨）が最も一般的で推奨される方法です。Quartoファイル（.qmd）からの相対位置で指定します。以下のように結果の図を記載するのが楽であろう。絶対パスでも可能であるが、あまりお勧めはできない。\n#相対パス\n![図1: データの分布](images/distribution.png)\n![図2: 回帰分析結果](figs/regression_plot.png)\n![図3: 比較グラフ](../shared_images/comparison.png)\n\n#絶対パス\n![画像](/Users/username/Documents/project/images/plot.png)\n![Windows例](C:\\Users\\username\\Documents\\project\\images\\plot.png)\n\n\n\n\n脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要だ。まず、文末脚注を入れる箇所に[^xxxx]を挿入する。xxxxは任意の文字列で構わない。しかし、同じQuarto文書内においてこの識別子は被らないようにすること。実際の脚注の内容は[^xxxx]: 内容のように入力する。これはどこに位置しても構わない。文書の途中でも、最後に入れても、脚注の内容は文末に位置する。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいだろう。\n統計的有意性[^1]は重要な概念ですが、効果量[^2]も同様に考慮すべきです。\n\n[^1]: p値が設定した有意水準（通常0.05）を下回ること。\n\n[^2]: 統計的有意性とは独立した、実際的な重要性を示す指標。\n統計的有意性1は重要な概念ですが、効果量2も同様に考慮すべきです。\n\n\n\nテーブルを自分で書くことはないと思う。生成AIに書いてもらおう。Rでもkableを使えば出てくる。\n\n\n| 変数名 | データ型 | 欠損値 | 説明 |\n|:-------|:---------|:------:|:-----|\n| age | numeric | 0 | 年齢（歳） |\n| gender | factor | 2 | 性別（M/F） |\n| income | numeric | 15 | 年収（万円） |\n| education | factor | 3 | 教育レベル |\n結果：\n\n\n\n変数名\nデータ型\n欠損値\n説明\n\n\n\n\nage\nnumeric\n0\n年齢（歳）\n\n\ngender\nfactor\n2\n性別（M/F）\n\n\nincome\nnumeric\n15\n年収（万円）\n\n\neducation\nfactor\n3\n教育レベル\n\n\n\nRでの例\n\n\nコード\nlibrary(knitr)\nkable(head(mtcars))\n\n\n\n\n表 1: mtcarsデータの基本統計量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&gt; 統計学における最も重要な概念の一つは、\n&gt; サンプルから母集団について推論を行うことである。\n&gt; この過程では、不確実性を適切に評価することが不可欠である。\n&gt; \n&gt; &gt; データは語るが、解釈は人間が行うものである。\n結果：\n\n統計学における最も重要な概念の一つは、 サンプルから母集団について推論を行うことである。 この過程では、不確実性を適切に評価することが不可欠である。\n\nデータは語るが、解釈は人間が行うものである。\n\n\n\n\n\n\nGFMは数式に対応していないが、$数式$でインライン数式を埋め込むことができる。Quartoの数式はMathJaxと呼ばれるJavaScriptのライブラリによってレンダリングされる。このMathJaxライブラリはHTMLにデフォルトで埋め込まれるわけではではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されないため、インターネット接続を忘れないこと。MathJaxの記法は とほぼ変わらない。Texでの数式の書き方は別途まとめる。\n\n\n回帰係数は $\\beta_1 = 0.73$ で統計的に有意でした（$p &lt; 0.001$）。 決定係数は $R^2 = 0.85$ でした。\n表示は以下の通り。\n回帰係数は \\beta_1 = 0.73 で統計的に有意でした（p &lt; 0.001）。 決定係数は R^2 = 0.85 でした。\n\n\n\n数式を独立した行として出力する場合は、の代わりに$を使用する。\n$$\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n$$\n\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n\n\n\n\nもし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用する。むろん、 Latexと記法は同じだ。\n\\begin{align}\nY_i &= \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_i \\\\\n\\epsilon_i &\\sim N(0, \\sigma^2) \\\\\n\\hat{\\beta}_1 &= \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\end{align}\n複数の行にわたる数式の書き方\n\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n\n\n\n\n\nRの場合、#でコメントを付けられるように、Quartoでもコメントを付けることができる。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法だろう。ただし、Rのように#は使えない。なぜなら#は見出しを意味する体。QuartoのコメントはHTMLと同様、で囲まれた領域がコメント扱いとなり、レンダリングに影響を与えない。\n例\n文章1\n\n&lt;!--\nここはコメントです。\n--&gt;\n\n文章2\n\n\n\nQuartoを使う意義 以上の内容まで抑えると、Quartoを使って、簡単な文法のみで構造化された文書が作成できるでしょう。しかし、これまでの内容はQuartoの良さではなく、Markdownの良さです。別にQuartoでなくても、TyporaやGhostwriterのようなMarkdownエディターを使えば良いでしょう。Quartoを使う真の意義は、文章とコード、結果が統合されることです。それではQuarto文書にRコードを入れる方法について解説します。 チャンク（Chunk） Quarto文書にRコードを入れる方法は2つあります：\n\nチャンクにRコードを入れる方法\nインラインコードを入れる方法\n\nチャンク内のRコードは独立した段落にコードと結果が両方出力されます。一方、インラインコードは文中に結果のみ出力されます。\n\n\nチャンクが始まるとの宣言は {r}、終わるとの宣言は です。つまり、{r} と ちょんちょんの間にRコードを入れるだけです。前の方にも書きました。\n“Hello World!”を出力するコード\n\n\nコード\nprint(\"Hello World!\")\n\n\n[1] \"Hello World!\"\n\n\n\n\n\nインラインコードの基本概念 他にもインラインコードを使って文中にRコードを埋め込むことも可能です。ただし、Rコードは出力されず、結果のみが出力されます。例えば、ベクトル X &lt;- c(2, 3, 5, 7, 12) があり、この平均値を文中で示したいとしましょう。むろん、文中に「5.8」と直接書いても問題ありません。しかし、Xの入力ミスが見つかり、実は c(2, 3, 5, 7, 11) になったらどうでしょうか。この「5.8」と書いた箇所を見つけて「5.6」と修正しなければいけません。これは非常に面倒な作業であり、ミスも起こりやすいです。絶対やめましょう。\n\nインラインコードの利点\n\n文中に mean(X) の結果を埋め込めるならこういったミスを未然に防ぐことができ、文書のメンテナンスも楽になるでしょう。インラインコードの記法文中でRコードを入れるためには r と ` の間にRコードを入力すれば良いです。\nこうかけばいいのです。\n\n\nコード\nmean(X)の実行結果：`r mean(X)`\n\n\n出力は以下\nmean(X)の実行結果：5.6\nコードスパンとインラインコードの違い mean(X) のように r でなく、単に `` だけで囲まれたコードは実行されません。文中に短いコードを入れたり、オブジェクト名を表記する際などに使う機能です。つまり、\n\n`コード` = コードを文字として見せるだけ\n`R コード` = コードを実行して結果を表示 （r コード）\n\n\n\n\n\nオプションの基本構文\nここではチャンクに指定可能なオプションについて紹介します。実際は本記事で紹介する内容の十数倍のオプションが用意されていますが、あまりにも膨大すぎるため、ここではよく使う機能のみを紹介します。 チャンクオプションはチャンク内の最上段に #| 仮引数: 実引数 のように表記します。 基本例：\n\n\nコード\n#| eval: false\n1+1\n\n\n[1] 2\n\n\neval は true か false の値が指定できます。evalは「コードを実行するかどうか」を決めるオプションです。\n\n\n\n\nチャンク名は #| label: チャンク名 で指定します。これはチャンクに名前を付けるオプションですが、多くの場合分析に影響を与えることはありません（それでもチャンク名は指定することを強く推奨します）。\nラベルの例は以下の通り。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\n\nこのチャンク名が重要となるのは cache オプションを付ける場合です。\ncache オプションは処理結果を保存しておくことを意味します。チャンク内のコードはrenderする度に計算されますが、演算にかなりの時間を必要とするコードが含まれている場合、renderの時間も長くなります。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n時間のかかる処理cache: true オプションを付けておくと、最初のrender時に結果を別途のファイルとして保存しておき、次回からはその結果を読み込むだけとなります。基本的にはこのオプションはおすすめしない。\n\n\n\n\n次は「コードだけ見せたい」、「結果だけ見せたい」場合に使うオプションを紹介します。これは技術書、授業用資料、スライドでよく使う機能です。\n\n\n\n\n\nオプション\n説明\nデフォルト値\n\n\n\n\necho\nコードの出力有無\ntrue\n\n\neval\nコードの実行有無\ntrue\n\n\ninclude\nコードと結果両方の表示有無\ntrue\n\n\n\n\n\n\nコードのみ出力（実行なし）：\n\n\nコード\nこのコードは表示されるが実行されない\n\n\n結果のみ出力（コード非表示）：\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nコードと結果を両方隠す：\nパッケージの読み込みコードやメタ変数の作成の際に include: false は有用なオプションです。\n\n\n\n\n既に見てきた通り、Quartoは作図の結果も出力してくれます。図のサイズや解像度を変えることもできます。\n\n\n\n\n\nオプション名\n説明\n値の例\n\n\n\n\nfig-height\n図の高さ（インチ）\n数値\n\n\nfig-width\n図の幅（インチ）\n数値\n\n\nfig-align\n図の位置\n“left”, “center”, “right”\n\n\nfig-cap\n図のキャプション\n文字列\n\n\ndpi\n図の解像度（印刷用なら300以上を推奨）\n数値\n\n\n\n\n\n\n\n\nコード\nlibrary(ggplot2)\nlibrary(dplyr)\n\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal()\n\n\n\n\n\nirisデータセットの可視化\n\n\n\n\n\n\n\n\n\n\n自分だけが見るコードなら別に推奨されない書き方でも問題ないかもしれませんが、Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事でしょう。\nここで便利なオプションが tidy オプションです。tidy: true を加えると、自動的にコードを読みやすい形に調整してくれます。\n\n\n\ntidy: false（デフォルト）の場合：\n\n\nコード\nfor(i in 1:10){\nprint(i*2)\n}\n\n\ntidy: TRUEの場合： Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事だろう。ここで便利なオプションがtidyオプションだ。tidy: trueを加えると、自動的にコードを読みやすい形に調整してくれる。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないダメなコードだが、tidy: trueを付けた場合と付けなかった場合の出力結果の違いを見てみよう。tidy: trueを付けただけで、読みやすいコードになった。ちなみにtidyオプションを使うためには事前に{formatR}パッケージをインストールしておく必要がある。ただし、{formatR}パッケージはQuarto文書内にて読み込んでおく必要はない。また、{formatR}パッケージは万能ではないため、普段から読みやすいコードを書くように心がけよう。\n\n\nコード\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n\nR Quartoでのデータ分析レポート作成において、Markdownの適切な使用は以下のメリットをもたらします：\n\n構造化された文書：見出しとセクションで論理的な流れを作成\n美しい数式表示：LaTeX記法による専門的な数式表現\n効果的な表現：テーブル、リスト、引用による情報整理\n再現可能性：コードと文章の統合による透明性の確保\n\nこれらの記法を活用して、読みやすく、理解しやすいデータ分析レポートを作成しましょう。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#参考文献",
    "href": "posts/statistics/2025/Markdown記法1.html#参考文献",
    "title": "Markdown記法について",
    "section": "",
    "text": "私たちのR　再現可能な研究24.Quarto［基礎］\n私たちのR　再現可能な研究25.Quarto［文書］\n私たちのR　再現可能な研究25.Quarto［スライド］\n私たちのR　Appendix F — R Markdown [基礎]\n私たちのR　Appendix G — R Markdown [応用]\n私たちのR　Appendix H — Quarto入門"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#markdownとは何か",
    "href": "posts/statistics/2025/Markdown記法1.html#markdownとは何か",
    "title": "Markdown記法について",
    "section": "",
    "text": "Markdownは、プレーンテキストで記述した文書を構造化された文書に変換するためのマークアップ言語です。R Quartoでは、このMarkdownとRコードを組み合わせて、データ分析レポートや学術論文を作成できます。\n\n\n\n可読性が高い：マークアップが最小限で、プレーンテキストでも内容が理解しやすい\n学習コストが低い：基本的な記法は数時間で習得可能\nQuartoとの親和性：Rコードチャンクとシームレスに統合\n多様な出力形式：HTML、PDF、Word、PowerPointなど"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#コードの記述方法",
    "href": "posts/statistics/2025/Markdown記法1.html#コードの記述方法",
    "title": "Markdown記法について",
    "section": "",
    "text": "コードを美しく表示するには、バッククオート3つ（```）でコードを囲みます。 これだけだとSAS/Rに限らず、プログラムは実行はされないが、サンプルとして提示する際に便利である。\n# Rコードの例\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# データの読み込みと前処理\ndata &lt;- mtcars %&gt;%\n  mutate(efficiency = ifelse(mpg &gt; 20, \"High\", \"Low\"))\n\n# 散布図の作成\nggplot(data, aes(x = wt, y = mpg, color = efficiency)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"車重と燃費の関係\",\n       x = \"車重 (1000 lbs)\",\n       y = \"燃費 (mpg)\")\nQuartoでRプログラムも実行させたい場合は以下のように記載する。なお、SASは実行させない前提とする。 なお、SASの設定環境をQuartoに構築したらSASも実行可能である。\nプログラムも実行させるには、バッククオート3つ（```）でコードを囲み、{r}と書く。そうすると、Rプログラムの実行できる。\nオプションとしてRプログラムを非表示にしたり、表や図を表示する際は、2つの図表を横に並べたりとオプションは様々ある。それらは、こちらのブログを参考にしていただきたい。デフォルトではプログラムが表示されてしまうので、非表示にする場合は、\n\n\nコード\n1+1\n\n\n[1] 2\n\n\nQuartoでの頻用するであろうオプション記法：\n\n\n\n\n実行制御：このコードを実際に実行するかを指定\ntrue：コードを実行する（デフォルト）\nfalse：コードを実行せず、表示のみ\n\n\n\n\n\n出力形式：コードの実行結果をそのまま（as-is）出力\n通常はコードの出力結果が整形されますが、asisでは生の形式で出力\nHTMLタグやMarkdown記法をそのまま文書に挿入したい場合に使用\n\n\n\n\n\nコード表示制御：コードブロックを折りたたみ状態で表示する\ntrue：コードを折りたたんで、クリック可能なボタンで展開\nfalse：コードを通常通り表示（デフォルト）\n読者が必要に応じてコードの詳細を確認できる柔軟性を提供\n\n\n\n\n\n折りたたみボタンのラベル：折りたたまれたコードを展開するボタンのテキストを設定\nデフォルトでは「Show code」や「コードを表示」が表示される\nカスタムテキストで、そのコードブロックの内容を説明できる\n絵文字や詳細な説明文を使用して、読みやすさを向上させる\n\n以下のプログラムを回すと、その下の結果が得らえる。プログラムが表示されないので結果だけを提示する際には有用である。\n#| eval: true\n#| output: asis\n#| code-fold: true\n#| code-summary: \"Show Code\"\n\n1 + 1\n\nShow Code\n1 + 1\n\n[1] 2\n\n\n\n本文中にRの結果を直接入れることができます！これをインラインコードと呼びます。 “r 引数”で本文中に簡単にRの出力結果を入れることができる。これは論文作成の文章案を作成するときに便利であろう。\n以下のように書くことでできます。普通はRチャンクで計算したものを引用するのがよいだろう。\n年齢の平均は r mean(mtcars$mpg) です。\nサンプルサイズは r nrow(mtcars) でした。\n最大値は r max(mtcars$hp) 馬力です。\n年齢の平均は 20.090625 です。 サンプルサイズは 32 でした。 最大値は 335 馬力です。\n\n\n\n\n\nコード\n# データの事前計算\nmean_age &lt;- round(mean(mtcars$mpg), 1)\nsd_age &lt;- round(sd(mtcars$mpg), 2)\nn_cars &lt;- nrow(mtcars)\n\n\nここで、上で事前にRチャンクで計算をしておく。今回は練習のためプログラムを表示しているが、Rプログラムを非表示にしてもよいだろう。記載としては以下のように書けばよい。\n\n\nコード\n本研究では `r n_cars` 台の自動車を分析しました。\n燃費の平均は `r mean_age`mpg（標準偏差 = `r sd_age`）でした。\n\n\n上記のように書くとこのように出力できる。\n本研究では 32 台の自動車を分析しました。\n燃費の平均は 20.1mpg（標準偏差 = 6.03）でした。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#改行",
    "href": "posts/statistics/2025/Markdown記法1.html#改行",
    "title": "Markdown記法について",
    "section": "",
    "text": "Markdownにおける改行はやや特殊だ。特殊といっても難しいことはない。普段よりもう一行改行するだけだ。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識する。結構難しい。\n文章1 文章2\n文章1\n文章2"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#urlの挿入",
    "href": "posts/statistics/2025/Markdown記法1.html#urlの挿入",
    "title": "Markdown記法について",
    "section": "",
    "text": "Webページを作成する際、ブラウザが理解できる言語がHTMLです。例えば、ブログ記事でリンクを作成したい場合、HTMLでは以下のように記述します：文章中に簡単にURLを参照できます。\n例：私のブログ\n[私のブログ](https://example-blog.com)\nまた、以下のように{}内に.externalを付けると、リンクのテキストの右側にアイコンを付く。\n[私のブログ](https://example-blog.com){.external target=\"_blank\"}\n例：私のブログ"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#インラインコード",
    "href": "posts/statistics/2025/Markdown記法1.html#インラインコード",
    "title": "Markdown記法について",
    "section": "",
    "text": "文章中でコードや関数名を表示する場合は、バッククオート1つで囲みます。単純にかっこいい。\n例：ggplot()関数やdplyr::filter()を使用してデータを処理します。平均値はmean()で計算できます。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#見出しと文書構造",
    "href": "posts/statistics/2025/Markdown記法1.html#見出しと文書構造",
    "title": "Markdown記法について",
    "section": "",
    "text": "見出しは#の数で階層を表現します。学術文書では、適切な階層構造が重要です。 ちなみに#は6つまで使える。\n# 1. はじめに（H1）\n## 1.1 研究背景（H2）\n### 1.1.1 先行研究（H3）\n#### データの特徴（H4）\n##### 変数の詳細（H5）\n###### 補足事項（H6）"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#テキストの装飾とフォーマット",
    "href": "posts/statistics/2025/Markdown記法1.html#テキストの装飾とフォーマット",
    "title": "Markdown記法について",
    "section": "",
    "text": "重要な結果：**重要な結果**\n統計的有意：*統計的有意*\n仮説は棄却：~~仮説は棄却~~\nアンダーライン：アンダーラインはHTMLタグを使う。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#リストとチェックボックス",
    "href": "posts/statistics/2025/Markdown記法1.html#リストとチェックボックス",
    "title": "Markdown記法について",
    "section": "",
    "text": "`-`を書いて、blankを入れるだけで順序なしリストができます。\n- データ収集\n  - アンケート調査\n  - 実験データ\n  - 公開データセット\n- データ前処理\n  - 欠損値処理\n  - 外れ値検出\n  - 変数変換\n- 分析手法\n  - 記述統計\n  - 回帰分析\n  - 機械学習\n結果：\n\nデータ収集\n\nアンケート調査\n実験データ\n公開データセット\n\nデータ前処理\n\n欠損値処理\n外れ値検出\n変数変換\n\n分析手法\n\n記述統計\n回帰分析\n機械学習\n\n\n\n\n\n普通に1.みたいにかけばよいだけ。単純。.の付け忘れに注意しよう！\n1. 研究目的の設定\n2. データ収集計画の策定\n   1. サンプルサイズの決定\n   2. 測定項目の選択\n   3. 倫理的配慮\n3. データ収集の実施\n4. 統計解析\n5. 結果の解釈\n6. 考察と結論"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#画像の挿入",
    "href": "posts/statistics/2025/Markdown記法1.html#画像の挿入",
    "title": "Markdown記法について",
    "section": "",
    "text": "Quartoで画像を入れるには![代替テキスト](ファイルのパス名 or URL)と入力します。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもあるが、視覚障害者用のウェブブラウザーのためにも使われる。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれる。\n例えば、Figsフォルダー内のex.pngというファイルを読み込むとしたら以下のように書く。\n![画像](Figs/ex.png)\n\n\n相対パス（推奨）が最も一般的で推奨される方法です。Quartoファイル（.qmd）からの相対位置で指定します。以下のように結果の図を記載するのが楽であろう。絶対パスでも可能であるが、あまりお勧めはできない。\n#相対パス\n![図1: データの分布](images/distribution.png)\n![図2: 回帰分析結果](figs/regression_plot.png)\n![図3: 比較グラフ](../shared_images/comparison.png)\n\n#絶対パス\n![画像](/Users/username/Documents/project/images/plot.png)\n![Windows例](C:\\Users\\username\\Documents\\project\\images\\plot.png)"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#脚注",
    "href": "posts/statistics/2025/Markdown記法1.html#脚注",
    "title": "Markdown記法について",
    "section": "",
    "text": "脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要だ。まず、文末脚注を入れる箇所に[^xxxx]を挿入する。xxxxは任意の文字列で構わない。しかし、同じQuarto文書内においてこの識別子は被らないようにすること。実際の脚注の内容は[^xxxx]: 内容のように入力する。これはどこに位置しても構わない。文書の途中でも、最後に入れても、脚注の内容は文末に位置する。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいだろう。\n統計的有意性[^1]は重要な概念ですが、効果量[^2]も同様に考慮すべきです。\n\n[^1]: p値が設定した有意水準（通常0.05）を下回ること。\n\n[^2]: 統計的有意性とは独立した、実際的な重要性を示す指標。\n統計的有意性1は重要な概念ですが、効果量2も同様に考慮すべきです。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#テーブルの活用",
    "href": "posts/statistics/2025/Markdown記法1.html#テーブルの活用",
    "title": "Markdown記法について",
    "section": "",
    "text": "テーブルを自分で書くことはないと思う。生成AIに書いてもらおう。Rでもkableを使えば出てくる。\n\n\n| 変数名 | データ型 | 欠損値 | 説明 |\n|:-------|:---------|:------:|:-----|\n| age | numeric | 0 | 年齢（歳） |\n| gender | factor | 2 | 性別（M/F） |\n| income | numeric | 15 | 年収（万円） |\n| education | factor | 3 | 教育レベル |\n結果：\n\n\n\n変数名\nデータ型\n欠損値\n説明\n\n\n\n\nage\nnumeric\n0\n年齢（歳）\n\n\ngender\nfactor\n2\n性別（M/F）\n\n\nincome\nnumeric\n15\n年収（万円）\n\n\neducation\nfactor\n3\n教育レベル\n\n\n\nRでの例\n\n\nコード\nlibrary(knitr)\nkable(head(mtcars))\n\n\n\n\n表 1: mtcarsデータの基本統計量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#引用とノート",
    "href": "posts/statistics/2025/Markdown記法1.html#引用とノート",
    "title": "Markdown記法について",
    "section": "",
    "text": "&gt; 統計学における最も重要な概念の一つは、\n&gt; サンプルから母集団について推論を行うことである。\n&gt; この過程では、不確実性を適切に評価することが不可欠である。\n&gt; \n&gt; &gt; データは語るが、解釈は人間が行うものである。\n結果：\n\n統計学における最も重要な概念の一つは、 サンプルから母集団について推論を行うことである。 この過程では、不確実性を適切に評価することが不可欠である。\n\nデータは語るが、解釈は人間が行うものである。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#数式の表示",
    "href": "posts/statistics/2025/Markdown記法1.html#数式の表示",
    "title": "Markdown記法について",
    "section": "",
    "text": "GFMは数式に対応していないが、$数式$でインライン数式を埋め込むことができる。Quartoの数式はMathJaxと呼ばれるJavaScriptのライブラリによってレンダリングされる。このMathJaxライブラリはHTMLにデフォルトで埋め込まれるわけではではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されないため、インターネット接続を忘れないこと。MathJaxの記法は とほぼ変わらない。Texでの数式の書き方は別途まとめる。\n\n\n回帰係数は $\\beta_1 = 0.73$ で統計的に有意でした（$p &lt; 0.001$）。 決定係数は $R^2 = 0.85$ でした。\n表示は以下の通り。\n回帰係数は \\beta_1 = 0.73 で統計的に有意でした（p &lt; 0.001）。 決定係数は R^2 = 0.85 でした。\n\n\n\n数式を独立した行として出力する場合は、の代わりに$を使用する。\n$$\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n$$\n\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n\n\n\n\nもし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用する。むろん、 Latexと記法は同じだ。\n\\begin{align}\nY_i &= \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_i \\\\\n\\epsilon_i &\\sim N(0, \\sigma^2) \\\\\n\\hat{\\beta}_1 &= \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\end{align}\n複数の行にわたる数式の書き方\n\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#quart内でのコメントアウト",
    "href": "posts/statistics/2025/Markdown記法1.html#quart内でのコメントアウト",
    "title": "Markdown記法について",
    "section": "",
    "text": "Rの場合、#でコメントを付けられるように、Quartoでもコメントを付けることができる。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法だろう。ただし、Rのように#は使えない。なぜなら#は見出しを意味する体。QuartoのコメントはHTMLと同様、で囲まれた領域がコメント扱いとなり、レンダリングに影響を与えない。\n例\n文章1\n\n&lt;!--\nここはコメントです。\n--&gt;\n\n文章2"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#quartoにおけるrコードの挿入と活用法",
    "href": "posts/statistics/2025/Markdown記法1.html#quartoにおけるrコードの挿入と活用法",
    "title": "Markdown記法について",
    "section": "",
    "text": "Quartoを使う意義 以上の内容まで抑えると、Quartoを使って、簡単な文法のみで構造化された文書が作成できるでしょう。しかし、これまでの内容はQuartoの良さではなく、Markdownの良さです。別にQuartoでなくても、TyporaやGhostwriterのようなMarkdownエディターを使えば良いでしょう。Quartoを使う真の意義は、文章とコード、結果が統合されることです。それではQuarto文書にRコードを入れる方法について解説します。 チャンク（Chunk） Quarto文書にRコードを入れる方法は2つあります：\n\nチャンクにRコードを入れる方法\nインラインコードを入れる方法\n\nチャンク内のRコードは独立した段落にコードと結果が両方出力されます。一方、インラインコードは文中に結果のみ出力されます。\n\n\nチャンクが始まるとの宣言は {r}、終わるとの宣言は です。つまり、{r} と ちょんちょんの間にRコードを入れるだけです。前の方にも書きました。\n“Hello World!”を出力するコード\n\n\nコード\nprint(\"Hello World!\")\n\n\n[1] \"Hello World!\"\n\n\n\n\n\nインラインコードの基本概念 他にもインラインコードを使って文中にRコードを埋め込むことも可能です。ただし、Rコードは出力されず、結果のみが出力されます。例えば、ベクトル X &lt;- c(2, 3, 5, 7, 12) があり、この平均値を文中で示したいとしましょう。むろん、文中に「5.8」と直接書いても問題ありません。しかし、Xの入力ミスが見つかり、実は c(2, 3, 5, 7, 11) になったらどうでしょうか。この「5.8」と書いた箇所を見つけて「5.6」と修正しなければいけません。これは非常に面倒な作業であり、ミスも起こりやすいです。絶対やめましょう。\n\nインラインコードの利点\n\n文中に mean(X) の結果を埋め込めるならこういったミスを未然に防ぐことができ、文書のメンテナンスも楽になるでしょう。インラインコードの記法文中でRコードを入れるためには r と ` の間にRコードを入力すれば良いです。\nこうかけばいいのです。\n\n\nコード\nmean(X)の実行結果：`r mean(X)`\n\n\n出力は以下\nmean(X)の実行結果：5.6\nコードスパンとインラインコードの違い mean(X) のように r でなく、単に `` だけで囲まれたコードは実行されません。文中に短いコードを入れたり、オブジェクト名を表記する際などに使う機能です。つまり、\n\n`コード` = コードを文字として見せるだけ\n`R コード` = コードを実行して結果を表示 （r コード）"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#チャンクオプション2",
    "href": "posts/statistics/2025/Markdown記法1.html#チャンクオプション2",
    "title": "Markdown記法について",
    "section": "",
    "text": "オプションの基本構文\nここではチャンクに指定可能なオプションについて紹介します。実際は本記事で紹介する内容の十数倍のオプションが用意されていますが、あまりにも膨大すぎるため、ここではよく使う機能のみを紹介します。 チャンクオプションはチャンク内の最上段に #| 仮引数: 実引数 のように表記します。 基本例：\n\n\nコード\n#| eval: false\n1+1\n\n\n[1] 2\n\n\neval は true か false の値が指定できます。evalは「コードを実行するかどうか」を決めるオプションです。\n\n\n\n\nチャンク名は #| label: チャンク名 で指定します。これはチャンクに名前を付けるオプションですが、多くの場合分析に影響を与えることはありません（それでもチャンク名は指定することを強く推奨します）。\nラベルの例は以下の通り。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\n\nこのチャンク名が重要となるのは cache オプションを付ける場合です。\ncache オプションは処理結果を保存しておくことを意味します。チャンク内のコードはrenderする度に計算されますが、演算にかなりの時間を必要とするコードが含まれている場合、renderの時間も長くなります。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n時間のかかる処理cache: true オプションを付けておくと、最初のrender時に結果を別途のファイルとして保存しておき、次回からはその結果を読み込むだけとなります。基本的にはこのオプションはおすすめしない。\n\n\n\n\n次は「コードだけ見せたい」、「結果だけ見せたい」場合に使うオプションを紹介します。これは技術書、授業用資料、スライドでよく使う機能です。\n\n\n\n\n\nオプション\n説明\nデフォルト値\n\n\n\n\necho\nコードの出力有無\ntrue\n\n\neval\nコードの実行有無\ntrue\n\n\ninclude\nコードと結果両方の表示有無\ntrue\n\n\n\n\n\n\nコードのみ出力（実行なし）：\n\n\nコード\nこのコードは表示されるが実行されない\n\n\n結果のみ出力（コード非表示）：\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nコードと結果を両方隠す：\nパッケージの読み込みコードやメタ変数の作成の際に include: false は有用なオプションです。\n\n\n\n\n既に見てきた通り、Quartoは作図の結果も出力してくれます。図のサイズや解像度を変えることもできます。\n\n\n\n\n\nオプション名\n説明\n値の例\n\n\n\n\nfig-height\n図の高さ（インチ）\n数値\n\n\nfig-width\n図の幅（インチ）\n数値\n\n\nfig-align\n図の位置\n“left”, “center”, “right”\n\n\nfig-cap\n図のキャプション\n文字列\n\n\ndpi\n図の解像度（印刷用なら300以上を推奨）\n数値\n\n\n\n\n\n\n\n\nコード\nlibrary(ggplot2)\nlibrary(dplyr)\n\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal()\n\n\n\n\n\nirisデータセットの可視化\n\n\n\n\n\n\n\n\n\n\n自分だけが見るコードなら別に推奨されない書き方でも問題ないかもしれませんが、Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事でしょう。\nここで便利なオプションが tidy オプションです。tidy: true を加えると、自動的にコードを読みやすい形に調整してくれます。\n\n\n\ntidy: false（デフォルト）の場合：\n\n\nコード\nfor(i in 1:10){\nprint(i*2)\n}\n\n\ntidy: TRUEの場合： Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事だろう。ここで便利なオプションがtidyオプションだ。tidy: trueを加えると、自動的にコードを読みやすい形に調整してくれる。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないダメなコードだが、tidy: trueを付けた場合と付けなかった場合の出力結果の違いを見てみよう。tidy: trueを付けただけで、読みやすいコードになった。ちなみにtidyオプションを使うためには事前に{formatR}パッケージをインストールしておく必要がある。ただし、{formatR}パッケージはQuarto文書内にて読み込んでおく必要はない。また、{formatR}パッケージは万能ではないため、普段から読みやすいコードを書くように心がけよう。\n\n\nコード\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n\nR Quartoでのデータ分析レポート作成において、Markdownの適切な使用は以下のメリットをもたらします：\n\n構造化された文書：見出しとセクションで論理的な流れを作成\n美しい数式表示：LaTeX記法による専門的な数式表現\n効果的な表現：テーブル、リスト、引用による情報整理\n再現可能性：コードと文章の統合による透明性の確保\n\nこれらの記法を活用して、読みやすく、理解しやすいデータ分析レポートを作成しましょう。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#footnotes",
    "href": "posts/statistics/2025/Markdown記法1.html#footnotes",
    "title": "Markdown記法について",
    "section": "脚注",
    "text": "脚注\n\n\np値が設定した有意水準（通常0.05）を下回ること。↩︎\n統計的有意性とは独立した、実際的な重要性を示す指標。↩︎"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html",
    "href": "posts/statistics/2025/SASプログラミングTips001.html",
    "title": "SASプログラミングTips1",
    "section": "",
    "text": "本記事では、実務上便利なSASプログラミングのTipsを紹介する。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説",
    "title": "SASプログラミングTips1",
    "section": "2.1 プログラム解説",
    "text": "2.1 プログラム解説\nこのSASプログラムは現在の日時を取得し、異なる形式でマクロ変数に格納するコードです。\n処理の流れ：\n\n%sysfunc(datetime())で現在日時を数値形式で取得\ndate()とtime()で日付・時刻を個別に取得\nput()関数でフォーマット適用（日付：YYYY/MM/DD、時刻：HH:MM:SS）\ncompress()で区切り文字を除去（日付：YYYYMMDD、時刻：HHMMSS）\ncall symputx()で4つのマクロ変数を作成\n\n作成されるマクロ変数：\n\n&StDates：2025/06/16（スラッシュ付き日付）\n&StDate：20250616（スラッシュなし日付）\n&StTimes：14:30:25（コロン付き時刻）\n&StTime：143025（コロンなし時刻）\n\n用途： ログファイル名生成、バックアップのタイムスタンプ、処理開始時刻の記録など、バッチ処理でよく使用される汎用的なコードです。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-1",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-1",
    "title": "SASプログラミングTips1",
    "section": "3.1 プログラム解説",
    "text": "3.1 プログラム解説\nこのSASプログラムは、実行中のプログラムの場所を自動判定し、プロジェクトの標準フォルダ構造に基づいて各種パスを動的に設定する汎用的なパス管理コードです。\n\n3.1.1 実行パス取得マクロ\n最初の部分では、現在実行中のSASプログラムの完全パスを取得するマクロを定義しています。このマクロは実行環境に関係なく動作するよう設計されており、バッチ実行時はGETOPTION(SYSIN)関数を、対話的実行時はSAS_EXECFILEPATH環境変数を使用します。IF文による条件分岐により、どちらの環境でも確実にプログラムパスを取得できる仕組みになっています。\n\n\n3.1.2 階層パス解析\n次に、取得したフルパスから階層構造を解析し、プロジェクト内での相対位置を把握する処理を行います。SCAN関数とQSUBSTR関数を組み合わせて、パスを階層別に分解します。PROGRAM_NAMEには実行中のプログラム名（拡張子なし）、CURRENT_DIRには現在のディレクトリの完全パス、PARENT_DIRには1つ上の階層ディレクトリのパス、PROJECT_ROOTにはプロジェクトルートディレクトリのパス（2つ上の階層）がそれぞれ格納されます。\n\n各変数の役割：\n\nPROGRAM_NAME：実行中のプログラム名（拡張子なし）\nCURRENT_DIR：現在のディレクトリの完全パス\nPARENT_DIR：1つ上の階層ディレクトリのパス\nPROJECT_ROOT：プロジェクトルートディレクトリのパス（2つ上の階層）\n\n\n\n\n3.1.3 標準パス自動生成\n最後のデータステップでは、プロジェクト標準フォルダ構造に基づいて必要なパスを自動生成します。CAT関数でPROJECT_ROOTを基準として各フォルダパスを結合し、CALL SYMPUTX文でマクロ変数として定義します。生データ格納用のINPUT_RAW、外部データ格納用のINPUT_EXT、出力ファイル格納用のOUTPUT_PATH、ログファイル格納用のLOG_PATH、マクロファイル格納用のMACRO_PATH、設定ファイル格納用のSETTING_PATH、仕様書格納用のSPEC_PATHが設定されます。\n設定されるパス：\n\nINPUT_RAW：生データ（Raw data）格納パス\nINPUT_EXT：外部データ（External data）格納パス\nOUTPUT_PATH：出力ファイル格納パス\nLOG_PATH：ログファイル格納パス\nMACRO_PATH：マクロファイル格納パス\nSETTING_PATH：設定ファイル格納パス\nSPEC_PATH：仕様書格納パス\n\n\n\n3.1.4 活用メリット\nこのコードをプロジェクトの各SASプログラム冒頭に配置することで、プロジェクトフォルダの移動や環境変更時にパス設定の修正が不要になります。チーム開発での設定統一と保守性向上を実現でき、どのサブフォルダからプログラムを実行しても、常に正しいプロジェクトルートを基準とした一貫したパス管理が可能になります。手動でのパス設定ミスを防ぎ、開発効率の向上にも寄与します。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-2",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-2",
    "title": "SASプログラミングTips1",
    "section": "4.1 プログラム解説",
    "text": "4.1 プログラム解説\nこのSASマクロは、指定されたディレクトリパスが存在しない場合に、必要な階層構造を含めて自動的にフォルダを作成する汎用的なディレクトリ作成マクロです。\n\n4.1.1 マクロの動作原理\nマクロは再帰的なアルゴリズムを採用しており、深い階層のフォルダ構造でも一度の呼び出しで全ての必要なディレクトリを作成できます。まず入力されたパスを親ディレクトリ部分と最終フォルダ名に分解し、指定されたパスが存在するかをチェックします。存在しない場合、親ディレクトリの存在も確認し、親ディレクトリが存在しなければマクロが自分自身を呼び出して上位階層から順次作成していきます。\n\n\n4.1.2 パス解析のロジック\nSTRIP関数で入力パスの前後空白を除去した後、SUBSTR関数とSCAN関数を組み合わせてパスを分解します。SCAN関数でパス区切り文字（バックスラッシュ）を基準に最終フォルダ名を抽出し、SUBSTR関数で親ディレクトリ部分を切り出します。この処理により、どのような深さのパスでも正確に階層構造を解析できます。\n\n\n4.1.3 条件分岐による効率的な処理\nFILEEXIST関数による存在チェックを各段階で実行し、既に存在するディレクトリに対しては何も処理を行いません。これにより無駄な処理を避け、既存の構造を保護しながら必要な部分のみを作成します。実際のフォルダ作成はDCREATE関数で実行され、作成結果は戻り値で確認できます。\n\n\n4.1.4 プロジェクト管理での活用\nこのマクロを前回のパス設定コードと組み合わせることで、プロジェクト開始時のフォルダ構造セットアップを完全自動化できます。新しい環境でプロジェクトを開始する際や、チームメンバーが初めてプロジェクトに参加する際に、手動でフォルダを作成する手間を省き、標準的なフォルダ構造を確実に構築できます。\n\n\n4.1.5 エラー処理と保守性\nマクロはエラーハンドリングも考慮されており、作成に失敗した場合でも処理が停止することなく、次の処理に進みます。また、既存のフォルダ構造に影響を与えることなく、必要な部分のみを安全に追加できる設計になっています。プロジェクトの成長に合わせて新しいフォルダが必要になった場合も、このマクロを呼び出すだけで簡単に対応できます"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-3",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-3",
    "title": "SASプログラミングTips1",
    "section": "5.1 プログラム解説",
    "text": "5.1 プログラム解説\nこのSASプログラムは、実行日ベースのプログラム管理フォルダを自動作成する汎用的なコードです。\n\n5.1.1 基本的な仕組み\nまず現在の日付をYYYYMMDD形式で取得し、実行中のプログラムパスからプロジェクトルートを自動判定します。その後、プロジェクトルート配下のPrgフォルダ内に実行日付のサブフォルダ（例：Prg\\20250616）を作成します。\n\n\n5.1.2 日付ベースフォルダ管理の利点\nこのシステムにより、プログラムの実行履歴を日付別に整理できます。同じプログラムを異なる日に実行しても結果が混在せず、過去の実行内容を簡単に追跡できます。特に開発段階では、日々の変更内容を時系列で管理できるため、問題発生時の原因特定や以前のバージョンへの戻しが容易になります。\n\n\n5.1.3 自動ディレクトリ作成の活用\ncreate_dir_structureマクロの再帰処理により、深い階層構造でも一度の呼び出しで必要なフォルダが全て作成されます。既存フォルダの存在チェック機能により、重複実行しても安全で、チーム開発での環境差異も自動的に解決されます。\nこのコードをプログラム冒頭に配置することで、実行のたびに適切な作業フォルダが準備され、プロジェクトの標準化と履歴管理を同時に実現できます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-4",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-4",
    "title": "SASプログラミングTips1",
    "section": "6.1 プログラム解説",
    "text": "6.1 プログラム解説\nこのコードは、FILENAME文とINCLUDE文を組み合わせて、特定フォルダ内の複数のSASファイルを効率的に読み込む汎用的な手法です。\n\n6.1.1 FILENAME文による論理参照の設定\nFILENAME文で論理名「MACROLIB」を定義し、マクロ変数で指定されたフォルダパスを割り当てます。これにより、以降の処理では物理的なフォルダパスではなく、論理名を使用してファイルにアクセスできるようになります。\n\n\n6.1.2 INCLUDE文による選択的ファイル読み込み\n各INCLUDE文では、論理名に続けて括弧内にファイル名を指定することで、指定フォルダ内の特定ファイルを読み込みます。この記法により、フォルダ内の全ファイルではなく、必要なファイルのみを選択的に読み込むことが可能です。\n\n\n6.1.3 この手法の優位性\n従来の絶対パス指定と比較して、コードの保守性と可読性が大幅に向上します。フォルダパスの変更時は最初のFILENAME文のみを修正すれば良く、同一フォルダ内の複数ファイルを扱う際の記述量も削減されます。また、論理名を使用することで、プラットフォーム間でのパス記法の違いも吸収できます。\n\n\n6.1.4 応用範囲\nこの手法は、マクロライブラリの管理以外にも、設定ファイルの読み込み、データセットの一括処理、プログラムの分割実行など、様々な場面で活用できます。プロジェクトの規模が大きくなり、複数のファイルを体系的に管理する必要がある場合に特に有効な手法です。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-5",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#プログラム解説-5",
    "title": "SASプログラミングTips1",
    "section": "7.1 プログラム解説",
    "text": "7.1 プログラム解説\nこのSASプログラムは、メタデータを基にして解析プログラムのテンプレートを動的に生成する自動化システムです。\n\n7.1.1 プログラム生成マクロの構造\ncreate_pgマクロは、プログラム名、テーブル名、解析対象集団の3つのパラメータを受け取り、指定されたフォルダに新しいSASプログラムファイルを作成します。FILENAME文で出力先ファイルを指定し、FILE文とPUT文を使用してプログラムのヘッダー部分を標準化されたフォーマットで出力します。\n\n\n7.1.2 標準化されたヘッダー生成\n各生成プログラムには、プロジェクト情報、プログラム説明、解析対象集団、バージョン情報、履歴管理欄を含む統一フォーマットのヘッダーが自動挿入されます。これにより、手動作成時に発生しがちな記載漏れや形式の不統一を防ぎ、プロジェクト全体でのドキュメント品質を保証します。\n\n\n7.1.3 メタデータ駆動型の一括生成\n最後のデータステップでは、OUT2データセットに格納されたメタデータを読み込み、CALL EXECUTE文を使用してマクロを動的に実行します。CATS関数でマクロ呼び出し文を構築し、データセットの各レコードに対して個別のプログラムファイルを生成します。\n\n\n7.1.4 自動化の利点とメリット\nこの手法により、数十から数百の解析プログラムを一度に生成できるため、大規模プロジェクトでの開発効率が大幅に向上します。メタデータの変更時も該当部分のみを修正して再実行すれば、全プログラムに変更が反映されるため、保守性も高くなります。また、ヒューマンエラーの削減と品質の均一化も実現できます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#cats関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#cats関数",
    "title": "SASプログラミングTips1",
    "section": "8.1 CATS関数",
    "text": "8.1 CATS関数\n機能： 複数の文字列を連結し、各引数の前後の空白を自動削除\ndata example1;\n    name = \"田中\";\n    id = \"001\";\n    dept = \"営業部\";\n    \n    /* 従来の方法 */\n    result1 = trim(name) || trim(id) || trim(dept);\n    \n    /* CATS関数を使用 */\n    result2 = cats(name, id, dept);\n    \n    put result1= result2=;\nrun;\n出力： result1=田中001営業部 result2=田中001営業部\nCATS関数は自動的に前後の空白を削除するため、TRIMやLEFT関数が不要になり、コードがシンプルになります。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#catx関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#catx関数",
    "title": "SASプログラミングTips1",
    "section": "8.2 CATX関数",
    "text": "8.2 CATX関数\n機能： 指定した区切り文字で複数の文字列を連結\ndata example2;\n    year = 2025;\n    month = 6;\n    day = 16;\n    \n    /* 日付文字列の作成 */\n    date_slash = catx(\"/\", year, month, day);\n    date_hyphen = catx(\"-\", year, month, day);\n    \n    /* CSVフォーマットの作成 */\n    csv_line = catx(\",\", \"田中太郎\", 30, \"東京都\");\n    \n    put date_slash= date_hyphen= csv_line=;\nrun;\n出力： date_slash=2025/6/16 date_hyphen=2025-6-16 csv_line=田中太郎,30,東京都"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#whichnwhichc関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#whichnwhichc関数",
    "title": "SASプログラミングTips1",
    "section": "8.3 WHICHN・WHICHC関数",
    "text": "8.3 WHICHN・WHICHC関数\n機能： 指定した値がリストの何番目にあるかを返す\ndata ae_severity;\n    input pt $ severity $;\n    \n    /* 重篤度レベルをコード化 */\n    severity_code = whichc(severity, \"軽度\", \"中等度\", \"重度\", \"重篤\");\n    \n    /* グレード分類への変換 */\n    ctcae_grade = whichc(severity, \"Grade1\", \"Grade2\", \"Grade3\", \"Grade4\", \"Grade5\");\n    \ndatalines;\n頭痛 軽度\n発熱 中等度\n呼吸困難 重度\n;\nrun;\npt=頭痛 severity=軽度 severity_code=1 ctcae_grade=0\npt=発熱 severity=中等度 severity_code=2 ctcae_grade=0\npt=呼吸困難 severity=重度 severity_code=3 ctcae_grade=0\n\nseverity_code：指定したリスト内での位置を返す\n\n“軽度” → 1番目 → 1\n“中等度” → 2番目 → 2\n“重度” → 3番目 → 3\n\n\n\n\nctcae_grade：CTCAEグレード用のリストにマッチしないため全て0\n\nデータの”軽度”、“中等度”、“重度”は”Grade1”、“Grade2”等とマッチしない\nマッチしない場合はWHICHC関数は0を返す"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#choosenchoosec関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#choosenchoosec関数",
    "title": "SASプログラミングTips1",
    "section": "8.4 CHOOSEN・CHOOSEC関数",
    "text": "8.4 CHOOSEN・CHOOSEC関数\n機能： インデックス番号に基づいてリストから値を選択\ndata example4;\n    do i = 1 to 4;\n        /* 数値版：CHOOSEN */\n        threshold = choosen(i, 60, 70, 80, 90);\n        \n        /* 文字版：CHOOSEC */\n        grade = choosec(i, \"D\", \"C\", \"B\", \"A\");\n        \n        put i= threshold= grade=;\n    end;\nrun;\n出力： i=1 threshold=60 grade=D i=2 threshold=70 grade=C i=3 threshold=80 grade=B i=4 threshold=90 grade=A\n・Y番目のXの値を返す。\n・第2引数以降に数値型の変数または値を指定する場合はCHOOSEN関数を用いる。\n・第2引数以降に文字型の変数または値を指定する場合はCHOOSEC関数を用いる。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#coalescecoalescec関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#coalescecoalescec関数",
    "title": "SASプログラミングTips1",
    "section": "8.5 COALESCE・COALESCEC関数",
    "text": "8.5 COALESCE・COALESCEC関数\n機能： 最初の非欠損値を返す\n/* サンプルデータの作成 */\ndata sample_data;\n    input ID X1 $ X2 $ X3 $;\n    datalines;\n1 AA    BB\n2    CC DD\n3       EE\n4 FF    \n5          \n6 GG HH II\n;\nrun;\n\n/* 方法1: IF-ELSE文を使用 */\ndata result1;\n    set sample_data;\n    length Y $2.;\n    if X1^=\"\" then Y=X1;\n    else if X2^=\"\" then Y=X2;\n    else if X3^=\"\" then Y=X3;\nrun;\n\n/* 方法2: COALESCEC関数を使用 */\ndata result2;\n    set sample_data;\n    length Y $2.;\n    Y = coalescec(X1, X2, X3);\nrun;\nポイント：\n\nこの関数は「引数のうち最初に欠損値以外で登場する値を返す」という機能を持っています。\nCOALESCE： 数値の場合、欠損値（.）をスキップして最初の有効な値（85）を返す\nCOALESCEC： 文字の場合、空白をスキップして最初の有効な文字列を返す"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#vvaluevvaluex関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#vvaluevvaluex関数",
    "title": "SASプログラミングTips1",
    "section": "8.6 VVALUE・VVALUEX関数",
    "text": "8.6 VVALUE・VVALUEX関数\n機能： フォーマットが適用された値を文字列として取得\ndata DT1;\n  format X yymmdd10.;\n  X = '13jun2017'd;\nrun;\n\n\ndata DT2;\n  set DT1;\n  length Y $20.;\n  Y = put( X, yymmdd10.);\nrun;\n\n\ndata DT2;\n  set DT1;\n  length Y1 Y2 $20.;\n\n  /* vvalue関数を使った例 */\n  Y1 = vvalue( X );\n\n  /* vvaluex関数を使った例 */\n  Y2 = vvaluex( \"X\" );\n\nrun;\n\nY1 = vvalue( X )：「 vvalue( X ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。\nY2 = vvaluex( “X” );vvaluex も vvalue と同じ機能を持っているのですが、違いは以下の通り。\nvvalue( X )      … 変数名を指定\nvvaluex( “X” )  … 変数名を表す文字値を指定\nつまり、「 vvaluex( “X” ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#cmiss関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#cmiss関数",
    "title": "SASプログラミングTips1",
    "section": "8.7 CMISS関数",
    "text": "8.7 CMISS関数\n機能： 欠損値の個数をカウント\ndata example7;\n    input name $ age height weight;\n    \n    missing_count = cmiss(age, height, weight);\n    complete_data = (missing_count = 0);\n    \n    put name= missing_count= complete_data=;\n    \ndatalines;\n田中 25 170 65\n佐藤 . 165 .\n山田 30 . 70\n;\nrun;\n出力： name=田中 missing_count=0 complete_data=1 name=佐藤 missing_count=2 complete_data=0 name=山田 missing_count=1 complete_data=0"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#ifnifc関数",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#ifnifc関数",
    "title": "SASプログラミングTips1",
    "section": "8.8 IFN・IFC関数",
    "text": "8.8 IFN・IFC関数\n機能： 条件に基づいて値を返す三項演算子\ndata DT1;\n   length X1 $10.;\n   X1=\"YES\"; output;\n   X1=\"NO\"; output;\nrun;\n\n#Before\ndata DT2;\n   set DT1;\n   if X1 = \"YES\" then X2=1;\n   else  X2=0;\nrun;\n\n#After\ndata DT2;\n   set DT1;\n   X2 = ifn(X1=\"YES\",1,0);\nrun;\nRのifelse関数みたいな気持ち。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#call-missing",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#call-missing",
    "title": "SASプログラミングTips1",
    "section": "8.9 CALL MISSING",
    "text": "8.9 CALL MISSING\n機能： 複数の変数を一度に欠損値に設定\ndata example9;\n    name = \"田中\";\n    age = 25;\n    score = 85;\n    \n    /* 条件に応じて全データを欠損値に */\n    if age &lt; 20 then call missing(of name age score);\n    \n    put name= age= score=;\nrun;\nこのSASコードはCALL MISSINGルーチンを使って、条件に応じて複数の変数を一度に欠損値に設定する例です。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips001.html#call-symputx",
    "href": "posts/statistics/2025/SASプログラミングTips001.html#call-symputx",
    "title": "SASプログラミングTips1",
    "section": "8.10 CALL SYMPUTX",
    "text": "8.10 CALL SYMPUTX\n機能： データステップ内でマクロ変数を作成・更新\ndata example10;\n    input dept $ sales;\n    \n    /* 部門別に動的にマクロ変数を作成 */\n    call symputx(cats(\"sales_\", dept), sales);\n    \n    /* 最大売上をマクロ変数に格納 */\n    retain max_sales;\n    if _n_ = 1 then max_sales = sales;\n    else max_sales = max(max_sales, sales);\n\n   if  _EOF then call symputx(\"OBS\", _N_);\n    \ndatalines;\n営業 1200\n技術 800\n総務 300\n;\nrun;\n\n/* データステップ終了後に最大値を取得 */\ndata _null_;\n    set example10 end=last;\n    retain max_sales;\n    if _n_ = 1 then max_sales = sales;\n    else max_sales = max(max_sales, sales);\n    if last then call symputx(\"max_sales_total\", max_sales);\nrun;\n\n%put &sales_営業 &sales_技術 &sales_総務;\n%put &max_sales_total;\n出力： 1200 800 300 1200\nこれらの関数を使いこなすことで、SASプログラミングの効率と可読性が大幅に向上します。特にデータクリーニングや条件分岐処理において威力を発揮する関数群です。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips003.html",
    "href": "posts/statistics/2025/SASプログラミングTips003.html",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "",
    "text": "本記事では、組織でSASプログラミングを実行する際に、注意すべきことをまとめます。また初学者向けにPitfall and Bad Habitsについてまとめます。\n引用：\n\nGood Programming Practices in Clinical Trial – a Check Program\nHow Not to SAS: Avoiding Common Pitfalls and Bad Habits\n\nAbstract\n\nLarge pharmaceutical companies typically have many programmers, data managers and statisticians producing trial analysis and reporting programs. Each of these has their own style in programming. Unfortunately, such a large variety in program styles can lead to problems in the quality, readability, verifiability and maintainability of the program code.\nEstablishing a central standard, or guideline, for good programming practices (GPP) is therefore a necessary first step for large companies. By requiring all programs to meet the GPP guideline, we can insure that we produce high quality programs that are easily readable by others, can be verified easily and can be easily maintained.\n\nということで、MUST DO、MUST NOT DO、AVOID、RECCOMENTを組織として決めたら良い。\n\n\n\n\n\n\n\nカテゴリ\n説明\n\n\n\n\nMUST DO\nThese requirements for coding style and techniques must be met in the program.\n\n\nMUST NOT DO\nThe styles and techniques in this category must not be used in the program.\n\n\nAVOID\nThe styles and techniques items in this category should not be used in the program.\n\n\nRECOMMEND\nThe styles and techniques items in this category should be used in order to promote good readability, verifiability, maintainability and efficiency"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips003.html#sasプログラミングtipsについてまとめます",
    "href": "posts/statistics/2025/SASプログラミングTips003.html#sasプログラミングtipsについてまとめます",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "",
    "text": "本記事では、組織でSASプログラミングを実行する際に、注意すべきことをまとめます。また初学者向けにPitfall and Bad Habitsについてまとめます。\n引用：\n\nGood Programming Practices in Clinical Trial – a Check Program\nHow Not to SAS: Avoiding Common Pitfalls and Bad Habits\n\nAbstract\n\nLarge pharmaceutical companies typically have many programmers, data managers and statisticians producing trial analysis and reporting programs. Each of these has their own style in programming. Unfortunately, such a large variety in program styles can lead to problems in the quality, readability, verifiability and maintainability of the program code.\nEstablishing a central standard, or guideline, for good programming practices (GPP) is therefore a necessary first step for large companies. By requiring all programs to meet the GPP guideline, we can insure that we produce high quality programs that are easily readable by others, can be verified easily and can be easily maintained.\n\nということで、MUST DO、MUST NOT DO、AVOID、RECCOMENTを組織として決めたら良い。\n\n\n\n\n\n\n\nカテゴリ\n説明\n\n\n\n\nMUST DO\nThese requirements for coding style and techniques must be met in the program.\n\n\nMUST NOT DO\nThe styles and techniques in this category must not be used in the program.\n\n\nAVOID\nThe styles and techniques items in this category should not be used in the program.\n\n\nRECOMMEND\nThe styles and techniques items in this category should be used in order to promote good readability, verifiability, maintainability and efficiency"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips003.html#must-do-and-must-not-do-categories",
    "href": "posts/statistics/2025/SASプログラミングTips003.html#must-do-and-must-not-do-categories",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "2 Must Do and Must Not Do Categories",
    "text": "2 Must Do and Must Not Do Categories\n\n2.1 MUST DO\n\n\n\n\n\n\n項目\n\n\n\n\nMake a backup copy of the program prior to updates (Not checked by the program).\nプログラムはフォルダとして、yyyymmddで日付管理をしましょう。1つのフォルダで管理するのは間違っています。\n都度、プログラムを実行する際にフォルダを移動させましょう。注意点：プロジェクトのプログラムが開発が終了したら、最後は1つのプログラムで全プログラムが実行されて、.rtfで解析帳票が出てくるようにしましょう。途中でExcelに吐き出してExcelで結果を加工するのはご法度です。ありえません。\n\n\nUse program documentation, e.g. Headers and Comments. Write documentation in English. Imbedded comments within the body of the program code should detail the modular flow.\nこれも大事です。手動でHeadersをつけるの大変ですので、自動化させましょう。ただし、プログラム内にはコメントを残すのが良いです。\n\n\nTypically, write only one SAS® statement per line.\n\n\nUse indentation to arrange the code clearly.\n\n\nUse unique names for datasets and files within the program / macro.\nこれも大事です。var、tmpが楽でよいですが、きちんと名前をつけましょう。\n\n\nReference datasets and/or files explicitly in each step or proc.\n1つの帳票に対して原則1つのプログラムです。\n\n\nDisplay ‘Draft’ in the output before program validation.\nこれもいいですね。1人でやるのは悩ましいが。\n\n\nReset global options to original settings – if changed by the program / macro.\nglobal optionsやproc datasetでwork フォルダを空にしたりlogをresetしましょう。\n\n\nDelete all temporary datasets after program execution.\n上と同じ考えですね。\n\n\nUse ‘RUN;’ or ‘QUIT;’ at the end of each data step / proc.\nこれは基本です。\n\n\nUse defensive coding.\nよく分かりません。\n\n\nDisplay the name of the program on the output when running outside of RAGE (our document control system).\n\n\nOptimize the data. Do not re-read data.\n\n\n\n\n\n2.2 MUST NOT DO\n\n\n\n\n\n\n項目\n\n\n\n\nHard-Code data.\n手で記載するのをやめましょう。表のheaderやグラフにおけるY軸、X軸のlength等はマクロ変数、Rであれば事前にベクトルにしておきましょう。\n/* ハードコードの悪い例 */ data work.sales_analysis; set mylib.sales_data; where year = 2024 and region = ‘Tokyo’; /* 年度と地域を直接記述 */\n/* 固定値を直接計算に使用 */ bonus = salary * 0.15; /* ボーナス率15%をハードコード */\n/* ファイルパスをハードコード */ if _n_ = 1 then call symputx(‘output_path’, ‘C:\\Reports\\sales_2024.xlsx’); run;\n/* マクロ変数で設定値を管理 */ %let target_year = 2024; %let target_region = Tokyo; %let bonus_rate = 0.15; %let output_dir = C:\\Reports; %let library_name = mylib;\n/* または外部設定ファイルから読み込み */ %include “C:\\Config\\sas_config.sas”;\ndata work.sales_analysis; set &library_name..sales_data; where year = &target_year and region = “&target_region”;\n/* マクロ変数を使用 */ bonus = salary * &bonus_rate; run;\n/* 動的なファイル名生成 */ %let output_file = &output_dir.\\sales_&target_year..xlsx;\nproc export data=work.sales_analysis outfile=“&output_file” dbms=xlsx replace; run;\n\n\nManually edit output.\nこれは論外です。どんな理由であれ解析結果を手で直すことはあってはなりません。\n上のHard codingと同様に事前にマクロ変数やベクトルで準備しておきましょう。\n\n\nOverwrite input data.\nこれはlibname statementにおいて、readonly optionをつけておきましょうか。\n\n\nUse macro names that are already used by CARE Standard macros (our standardized reporting macros)\n既にあるマクロと同じ名前は利用してはいけません。\n\n\nUse of SAS® keywords for dataset and variable names.\n\n\n\nAny programmers that have supported clinical trial analysis and reporting understand the complexity of derived datasets that are ready to produce tables and graphs for efficacy and safety analysis. Taking data from several domains, many-to-many merging, transposing data, imputing dates and values, averaging within visits for duplicate results, and creating intermediate datasets for the final ADaM are more complex than we expect."
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips003.html#参考",
    "href": "posts/statistics/2025/SASプログラミングTips003.html#参考",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "3 参考",
    "text": "3 参考\n\nChallenges in Implementing ADaM datasets: Balancing the Analysis-Ready and Traceability Concepts"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "",
    "text": "本記事では、以下の2つの文献をまとめる。\n参考文献"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#はじめに",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#はじめに",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.1 はじめに",
    "text": "1.1 はじめに\n「保守しやすいコードは少ない人員で管理できる。つまり、あなたの雇用が危険にさらされる」\nこの皮肉な視点から、意図的に読みにくく、保守困難なSASコードを書く「技法」を紹介します。もちろん、これは反面教師として学ぶべき内容です。\n\n“Don’t be irreplaceable, if you can’t be replaced, you can’t be promoted.” - Dilbert’s Laws of Work"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#プログラミングスタイルやってはいけないこと",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#プログラミングスタイルやってはいけないこと",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.2 🚫 プログラミングスタイル（やってはいけないこと）",
    "text": "1.2 🚫 プログラミングスタイル（やってはいけないこと）\n\n1.2.1 論理的分離の回避\n/* 悪い例：本来分けるべき処理を無理やり1つにまとめる */\ndata result;\n   set patients;\n   if age &lt; 18 then group='pediatric'; else group='adult';\n   weight_kg = weight_lb / 2.2;\n   bmi = weight_kg / (height_m * height_m);\n   if bmi &gt; 30 then obese_flag = 1; else obese_flag = 0;\n   /* 複数の異なる処理が混在 */\nrun;\n解説: このコードは年齢分類、重量変換、BMI計算、肥満判定という4つの異なる処理を1つのデータステップに混在させています。本来なら機能ごとに分割すべきですが、すべてを混ぜることで何をしているのか分かりにくくしています。\n\n\n1.2.2 過度なネスト化（3層以上で複雑さ倍増）\n/* 悪い例：無意味に深いネスト */\ndate = mdy(month(date), day(date), year(date));\ndepth2 = input(substr(station, index(station,'-')+1), 3.);\nname = substr(name, index(name,',')+1, length(name));\n解説:\n\n1行目：既にSAS日付値の変数を、わざわざ分解して再構築する無意味な処理\n2行目：文字列から数値抽出を3つの関数で複雑にネスト\n3行目：名前の後半部分を取得する処理を複雑化 これらは全て、より単純な方法で書けるものを意図的に複雑にしています。\n\n\n\n1.2.3 関数の不適切な使用\n/* 悪い例：関数で置き換え可能な処理を冗長に記述 */\nif a &lt; 0 then b = a*-1;\nelse b = a;\n/* ABS(a)で済む処理 */\n\n/* 悪い例：非標準的な書き方 */\nab = (a*(a&gt;0) + b*(b&gt;0))/((a&gt;0)+(b&gt;0));\n/* 2つの正数の平均を求める処理 */\n解説:\n\n1つ目：ABS(a)関数で済む絶対値計算を、わざわざIF文で書いている\n2つ目：2つの正数の平均を求めるのに、論理値を数値として使う複雑な式を使用。(a+b)/2で済むところを意図的に分かりにくくしている\n\n\n\n1.2.4 マクロの悪用\n/* 悪い例：ローカル・グローバル変数の混乱 */\n%macro inside(aa);\n    %put inside &aa;\n%mend inside;\n\n%macro outside;\n    %let aa = 5;\n    %inside(3)\n    %put outside &aa;\n%mend outside;\n\n%outside\n/* 出力: inside 3, outside 5 */\n解説: マクロパラメータとマクロ変数の名前を同じにして混乱を誘発。%inside(3)では引数として3が渡されるため「inside 3」と出力されますが、%outsideマクロ内の&aaは依然として5のままです。これによりマクロ変数のスコープについて混乱を招きます。\n\n\n1.2.5 不必要な複雑化\n/* 悪い例：PROC SQLを無理やり複数ステップに分解 */\nproc sort data=sales;\n    by region;\nproc summary data=sales nway;\n    by region;\n    var saleprce;\n    output out=stats mean=meansale;\ndata report;\n    merge stats sales;\n    by region;\n    if saleprce gt meansale;\n\n/* 本来は以下の1ステップで済む */\nproc sql;\n    create table report as\n    select * from sales\n    having saleprce gt mean(saleprce)\n    group by region;\n解説: 1つのSQL文で書ける処理を、わざわざSORT→SUMMARY→DATA stepの3段階に分けています。これにより一時データセット（stats）が作成され、処理が複雑になり、エラーの可能性も増加します。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#システムオプションの悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#システムオプションの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.3 🎭 システムオプションの悪用",
    "text": "1.3 🎭 システムオプションの悪用\n\n1.3.1 デバッグ機能の無効化\n/* 悪い例：重要な情報を隠す */\noptions NOSOURCE NOSOURCE2 NONOTES NOLABEL NOMACRO;\n解説:\n\nNOSOURCE: 実行されたSASコードをログに表示しない\nNOSOURCE2: %INCLUDEで読み込まれたコードも表示しない\nNONOTES: 通常のNOTEメッセージを非表示\nNOLABEL: 変数ラベルを無効化\nNOMACRO: マクロ機能自体を無効化 これらによりデバッグが困難になります。\n\n\n\n1.3.2 観測数制御の悪用\n/* 悪い例：事前告知なしでのデータ制限 */\noptions obs=100 firstobs=50;  /* 隠して設定 */\n解説: データセットの50-100番目の観測値のみを処理対象にしていますが、これを他の人に知らせていません。全データを処理していると思い込ませる悪質な手法です。\n\n\n1.3.3 ワークエリアの操作\n/* 悪い例：一時ファイルの場所を変更 */\noptions user=sasuser;\ndata new;  /* 実際はSASUSER.NEWに保存される */\n    set project.master;\n解説: USER=オプションにより、一時的なデータセットNEWがSASUSERライブラリに保存されます。セッション終了後も残存し、ディスク容量の問題や混乱を引き起こします。\n\n\n1.3.4 危険なオプション\n/* 悪い例：エラー時即座終了 */\noptions ERRORABEND;\n\n/* 悪い例：年の解釈を混乱させる */\noptions YEARCUTOFF=1800;\ndata a;\n    date = '23mar98'd;\n    year = year(date);  /* 1897になる */\n解説:\n\nERRORABEND: エラー発生時にSASセッションが即座に終了し、ログも確認できない\nYEARCUTOFF=1800: 2桁年表記の解釈基準を1800年に設定。’98’が1998年ではなく1898年と解釈される\n\n\n\n1.3.5 S=オプションによる列数制限\n/* 悪い例：最初の10桁のみ読み取り */\noptions s=10;\ndata new;\n    set olddata    /* OLDDATになる */\n        master\n        adj;\n    profit =\n        sales + tax;  /* TAXが使われない */\n    cnt+1;  /* PROFITの計算に含まれる */\n解説: S=10により、各行の最初の10文字のみが読み取られます。olddataはolddatに、sales + taxはsales +のみが読まれ、変数taxは無視されます。また、cnt+1;が前の行に繋がってしまいます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#編集スタイル可読性を破壊する方法",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#編集スタイル可読性を破壊する方法",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.4 📝 編集スタイル（可読性を破壊する方法）",
    "text": "1.4 📝 編集スタイル（可読性を破壊する方法）\n\n1.4.1 インデントの無視\n/* 悪い例：インデントなし */\ndata sasclass.biomass;\ninfile rawdat missover;\ninput @1 STATION $\n@12 DATE DATE7.\n@20 BMPOLY\n@25 BMCRUS\n@31 BMMOL\n@36 BMOTHR\n@41 BMTOTL ;\n解説: インデントがないため、どの行がどのステートメントに属するかが分かりにくくなっています。特にINPUTステートメントの変数リストが見づらく、修正時にミスを誘発しやすくなります。\n\n\n1.4.2 複数ステートメントの詰め込み\n/* 悪い例：1行に複数ステートメント */\ndata new;set old;if age&gt;65 then senior=1;else senior=0;weight_kg=weight_lb/2.2;output;\n解説: 5つのステートメントを1行に詰め込んでいます。どこで1つのステートメントが終わり、次が始まるのかが分からず、デバッグや修正が困難になります。\n\n\n1.4.3 行の途中での改行\n/* 悪い例：意味のない場所での改行 */\ndata sasclass.biomass;infile rawdat\nmissover;\ninput @1 STATION $ @12 DATE DATE7.\n@20 BMPOLY @25 BMCRUS @31 BMMOL @36\nBMOTHR @41 BMTOTL ;\n解説: 文法的に意味のない場所で改行しています。infile rawdatとmissoverオプションが分離され、inputステートメントも不自然に分割されています。\n\n\n1.4.4 画面外への重要コード配置\n/* 悪い例：80桁以降に重要な変数を配置 */\n                                                                              /*80桁*/\ndata newdata;\n    set olddata (drop=name                                                   fname\n                     address city state);  /* 重要な変数が見えない */\n解説: 80桁以降に重要な変数名を配置しています。多くのエディタでは80桁以降が表示されないか、画面外に隠れるため、重要な処理内容が見えなくなります。\n\n\n1.4.5 会社ロゴ形式のコード\n/* 悪い例：見た目重視のコード配置 */\n         data\n      sasclass.biomass;\n      infile cards missover;\n      input @1 STATION $\n      @12 DATE DATE7.\n      @20 BMPOLY\n   @25 BMCRUS @31 BMMOL\n  @36 BMOTHR @41 BMTOTL\n      ; format\n      date date7.\n      ;label BMCRUS=\n   'CRUSTACEAN BIOMASS'\n         BMMOL=\n   'MOLLUSC BIOMASS'\n      ;\n      run;\n解説: 機能性を完全に無視して、見た目の形（おそらく会社ロゴや図形）を優先してコードを配置しています。読みやすさが完全に犠牲になっています。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#コメントの悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#コメントの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.5 💬 コメントの悪用",
    "text": "1.5 💬 コメントの悪用\n\n1.5.1 実行可能コメント\n/* 悪い例：コメント内に実行文を隠す */\n* The comments in this section do more ;\n* than it seems ;\n* ;\n* modify data to prep for; proc means ;\n* after adjusting the data using ;\n* the; var for weight ;\n解説: 一見コメントに見えますが、実際にはproc means; var for weight;という実行可能なコードが隠されています。3行目の* ;でコメントが終了し、4-6行目が実際に実行されます。\n\n\n1.5.2 ネストできないコメントの悪用\n/* 悪い例：未完了コメントでコード全体を隠す */\n/* *****************\n* Apply the\n* ***very ***\n* important adjustment;\ndata yearly;\n    set yearly;\n    income = income*adjust;\nrun;\n/* Plot the adjusted income */\nproc gplot data=yearly......\n解説: 最初の/*コメントが閉じられていないため、その後のコード全体がコメント扱いになります。/* Plot the adjusted income */の*/で最初のコメントが閉じられ、それ以降のコードが実行されます。\n\n\n1.5.3 埋め込みコメントによる部分実行\n/* 悪い例：コメント内の一部のみ実行 */\n/* *****************\nREMOVE FOR PRODUCTION\nproc print data=big obs=25;\n    title1 'Test print of BIG';\n    var company dept mgr /*clerk*/;\ndata big;\n    set big;\n    if name='me' then salary=salary+5;\n*END OF REMOVED SECTION;\n****************** */\n解説: 全体がコメントで囲まれているように見えますが、/*clerk*/の部分で一時的にコメントが閉じ、その後のdataステップが実行されます。給与を不正に操作するコードが隠されて実行されてしまいます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#命名規則の悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#命名規則の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.6 🔤 命名規則の悪用",
    "text": "1.6 🔤 命名規則の悪用\n\n1.6.1 混乱を招く命名\n/* 悪い例：意味不明な変数名 */\ndata analysis;\n    set patient_data;\n    /* デバッグ時は meaningful names を使い、後でCHANGEコマンドで変更 */\n    /* ===&gt; c 'age' 'qwrtxzqr' all */\n    QWRTXZQR = age;           /* 年齢なのに意味不明な名前 */\n    QWRTZXQR = weight;        /* 似たような名前で混乱 */\n    QWRZTXQR = height;        /* 微妙な違いで判別困難 */\n    HHHIIHIH = height;        /* HとIの区別が困難 */\n    WVWVWVVW = weight;        /* VとWの区別が困難 */\n    testnuml = test_result;   /* 1（数字）とl（小文字L）の混用 */\n    test0001 = test_id;       /* 0（ゼロ）とO（オー）の混用 */\n    QWRT2XQR = group;         /* ZとNの混用 */\n解説:\n\n母音を避けた無意味な文字列を使用\n似たような文字の組み合わせで視覚的混乱を誘発\n数字と文字の見た目が似ているものを混用（1とl、0とO、2とZ）\nコメントで「デバッグ時には意味のある名前を使い、後で置換する」という悪質な手法を示唆\n\n\n\n1.6.2 SASキーワードの変数名使用\n/* 悪い例：SASキーワードを変数名に使用 */\nDATA SET; \nSET DATA;\nDO = 5+ TO -15;  /* DO loopに見えるが変数代入 */\n解説: DATA、SET、DO、TOなどのSASキーワードを変数名として使用しています。DO = 5+ TO -15;は一見DO loopに見えますが、実際は変数DOに5 + TO - 15を代入するステートメントです。\n\n\n1.6.3 誤解を招く命名\n/* 悪い例：変数名と内容が一致しない */\ndata patients;\n    set raw_data;\n    SEX = fish_count;        /* SEXという名前だが魚の数 */\n    WEIGHT = height_cm;      /* WEIGHTという名前だが身長 */\n    INCHES = height_cm;      /* INCHESだがセンチメートル */\n    \n    /* 出力先も混乱させる */\n    IF SEX = 'MALES' THEN OUTPUT FEMALES;\n    \n    /* ラベルでさらに混乱 */\n    LABEL sex = 'Sex of the Patient';  /* 実際は魚の数 */\n解説:\n\n変数名と実際の内容が完全に異なる（SEXに魚の数、WEIGHTに身長など）\nOUTPUT文で条件と出力先が逆転（MALESの条件でFEMALESデータセットに出力）\nLABELでさらに混乱を助長（魚の数に「患者の性別」というラベル）\n\n\n\n1.6.4 一貫性のない命名\n/* 悪い例：YES/NOの値が一貫しない */\ndata flags;\n    set survey;\n    /* 通常: YES=0, NO=1 */\n    response1 = (answer='YES') * 0 + (answer='NO') * 1;\n    \n    /* どこかで例外: YES=1, NO=0 */\n    response2 = (answer='YES') * 1 + (answer='NO') * 0;\n    \n    /* さらに混乱: Y=NOの意味、N=YESの意味 */\n    if answer='YES' then code='N';\n    else if answer='NO' then code='Y';\n解説:\n\n同じプログラム内でYES/NOのコーディングが一貫していない\n通常の論理（YES=1, NO=0）とは逆の設定\n最後は完全に逆転（YESなのにN、NOなのにY）"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#データステップの境界をぼかす技法",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#データステップの境界をぼかす技法",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.7 🌀 データステップの境界をぼかす技法",
    "text": "1.7 🌀 データステップの境界をぼかす技法\n\n1.7.1 コメントによる境界隠し\n/* 悪い例：セミコロンなしコメントで次ステップを隠す */\ndata new; \n    set old;\n    x = 5 * y;\n    /* この行で次のステップが始まっている\n    data second; \n    set gudstuff;\n    x = zzstuff;\n/* 結果：NEWにはzsstuffの値が入る */\n解説: 4行目のコメントにセミコロンがないため、5-7行目がコメント扱いになりません。実際には1つのDATAステップで2つのSETステートメントが実行され、最後のx = zzstuff;の値が最終的に変数xに残ります。\n\n\n1.7.2 コロンによる巧妙な隠蔽\n/* 悪い例：セミコロンの代わりにコロンを使用 */\ndata new; \n    set old;\n    x = 5 * y;\n    /* この行で次のステップが始まっている:\n    data second; \n    set gudstuff;\n    x = zzstuff;\n解説: コメント行の最後がセミコロンではなくコロンになっています。SASではコロンはコメントの終了記号として認識されないため、次のdataステップが隠されて実行されます。\n\n\n1.7.3 不完全な引用符による隠蔽\n/* 悪い例：不完全な引用符で後続コードを隠す */\ndata new;\n    y = 5;\n    frankwt = 0;\n    x = 5 * y;\n    length name $6;\n    name = 'weight;\n    data second; set gudstuff;  /* この行が隠されている */\n    *for weight use Franks';\n    x = frankwt;\nproc print; run;\n/* 結果：xは常に0（25ではない） */\n解説:\n\n6行目で開始された文字列リテラル'weight;が閉じられていない\nそのため7-8行目が文字列の一部として扱われ、実行されない\n9行目の'で文字列が閉じられ、その後のコードが実行される\n結果としてx = frankwt;（0）が実行され、期待されたx = 5 * y;（25）は無効になる"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#さらに極端な技法上級者向け悪魔術",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#さらに極端な技法上級者向け悪魔術",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.8 🔥 さらに極端な技法（上級者向け悪魔術）",
    "text": "1.8 🔥 さらに極端な技法（上級者向け悪魔術）\n\n1.8.1 ソースコードの隠蔽・削除\n/* 悪い例：コンパイル後にソースを削除・改名 */\n/* SCL source code for SAS/AF applications */\n/* Compiled DATA steps */\n/* Compiled stored macros */\n/* DATA step views */\n/* SQL views（DESCRIBE optionで復元可能だが...） */\n\n/* エディタの文字色を背景色と同じにして隠す */\n解説:\n\nコンパイル済みのSAS/AFアプリケーション、ストアドマクロなどの元ソースコードを削除\nDATA step viewやSQL viewのソースも隠蔽\nエディタで文字色を背景色と同じにして視覚的に見えなくする これらにより、動作するプログラムがあっても、どのように動作しているかが分からなくなります。\n\n\n\n1.8.2 AUTOEXEC.SASとCONFIG.SASの悪用\n/* 悪い例：AUTOEXEC.SASでセッション終了 */\nENDSAS;\n/* または */\nABORT;\n/* または */\n%MACRO DUMMY;  /* %MENDまでのすべてのコードを無効化 */\n\n/* 悪い例：CONFIG.SASで隠れたERRORABEND設定 */\n-ERRORABEND\n\n/* 悪い例：AUTOEXEC.SASの最後に未完了コメント */\n/* 以降のすべてのコードがコメント扱いに */\n解説:\n\nENDSASやABORTをAUTOEXEC.SASに入れると、ユーザーのプログラムが実行される前にセッションが終了\n%MACRO DUMMY;を入れると、%MENDが現れるまでのすべてのコードがマクロ定義として扱われ実行されない\nCONFIG.SASでのERRORABEND設定は非常に見つけにくい\nAUTOEXEC.SASの最後に/*を入れると、以降のすべての投入コードがコメント扱いになる\n\n\n\n1.8.3 危険なデータステップ技法\n/* 悪い例：BYステートメント変数の途中変更 */\ndata merged;\n    merge data1 data2;\n    by id;\n    id = id + 1;  /* BYステートメント変数を変更 */\n解説: MERGEステートメントのBY変数idを、マージ処理の途中で変更しています。これにより予期しないマージ結果が生成され、データの整合性が失われます。\n\n\n1.8.4 POINT/NOBSオプションの落とし穴\n/* 悪い例：削除された観測値との相互作用 */\ndata a;\n    do i = 1 to 5;\n        output;\n    end;\nrun;\n/* FSEDITでi=2の観測値を削除 */\n\ndata b;\n    do point=1 to nobs;\n        set a point=point nobs=nobs;\n        output;\n    end;\n    stop;\nrun;\n/* 結果：削除された観測値が読まれ、iの値が不正になる */\n解説:\n\nデータセットAから観測値2（i=2）を削除\nPOINT/NOBSオプションで順次読み取ると、削除された位置でも読み取りが行われる\n削除された観測値を読み取ると、変数iには予期しない値（この場合は1）が入る\n結果として観測値2の位置でi=1が読まれ、データの整合性が失われる\n\n\n\n1.8.5 マクロクォート関数の悪用\n/* 悪い例：マクロ変数の解決を阻害 */\n%macro doit(city);\n    %put &city;\n    %let city=%nrstr(&city);  /* 文字列として固定 */\n    %put &city;\n    %if &city = LA %then\n        %put CITY is LOS ANGELES;\n    %else \n        %put city is not LA;  /* 常にこちらが実行される */\n%mend doit;\n\n%doit(LA)\n/* 出力: LA, &city, city is not LA */\n解説:\n\n%nrstr(&city)により、マクロ変数&cityが文字列リテラル「&city」として固定される\n以降の比較&city = LAでは、「&city」と「LA」が比較されるため、常にfalseになる\n引数として「LA」を渡しても、条件判定では常に「not LA」の結果になる\n\n\n\n1.8.6 特殊システムオプションの悪用\n/* 悪い例：エラーメッセージ抑制 */\noptions DKRICOND=NOWARN;  /* DROP/KEEP/RENAME文のエラーを隠す */\n\n/* 悪い例：データセット置き換え防止 */\noptions NOREPLACE;  /* 永続データセットの置き換えを阻止 */\n\n/* 悪い例：WORK領域のクリーンアップ抑制 */\noptions NOWORKINIT NOWORKTERM;  /* セッション終了後もファイル残存 */\n解説:\n\nDKRICOND=NOWARN: DROP/KEEP/RENAMEステートメントで存在しない変数を指定してもエラーが出ない\nNOREPLACE: 既存の永続データセットを上書きしようとするとエラーになる（一見良いが、予期しない場所で設定されると混乱）\nNOWORKINIT/NOWORKTERM: SASセッション終了後もWORKライブラリのファイルが残り、ディスク容量やセキュリティの問題を引き起こす"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#正しいプログラミング実践推奨事項",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#正しいプログラミング実践推奨事項",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.9 ✅ 正しいプログラミング実践（推奨事項）",
    "text": "1.9 ✅ 正しいプログラミング実践（推奨事項）\n\n1.9.1 良いコードの原則\n/* 良い例：読みやすく保守しやすいコード */\noptions MSGLEVEL=I SOURCE FMTERR DSNFERR NOREPLACE;\n\n/* Step 1: Demographics data preparation */\ndata adam.adsl;\n    set raw.demographics;\n    \n    /* Treatment group coding */\n    if trt01a = 'Placebo' then trt01pn = 1;\n    else if trt01a = 'Active 10mg' then trt01pn = 2;\n    else if trt01a = 'Active 20mg' then trt01pn = 3;\n    \n    /* Age group classification */\n    if age &lt; 65 then agegroup = 'Under 65';\n    else agegroup = '65 and Over';\n    \n    /* Safety population flag */\n    if cmstdt ne . then saffl = 'Y';\n    else saffl = 'N';\n    \n    /* Variable labels */\n    label trt01pn = 'Treatment Group (Numeric)'\n          agegroup = 'Age Group'\n          saffl = 'Safety Population Flag';\nrun;\n\n/* Step 2: Data validation */\nproc freq data=adam.adsl;\n    tables trt01pn*trt01a / missing;\n    title1 'Treatment Group Verification';\nrun;\n\nproc means data=adam.adsl n nmiss min max;\n    var age;\n    title1 'Age Distribution Check';\nrun;\n解説:\n\n明確なコメントで各ステップの目的を説明\n意味のある変数名とラベルを使用\n処理を論理的に分離（データ準備→検証）\n品質管理オプションを適切に設定\n一貫したインデントとフォーマット\n\n\n\n1.9.2 臨床試験での品質管理\n/* Step 3: Efficacy endpoint derivation */\ndata adam.adeff;\n    set adam.adsl(keep=usubjid trt01pn saffl);\n    \n    /* Merge with vital signs */\n    merge adam.adsl(in=demo)\n          raw.vitals(in=vital \n                     keep=usubjid visitnum aval param);\n    by usubjid;\n    \n    /* Only include subjects with baseline and post-baseline values */\n    if demo and vital;\n    \n    /* Derive change from baseline */\n    retain baseline;\n    if visitnum = 1 then baseline = aval;\n    else if visitnum &gt; 1 and baseline ne . then do;\n        chg = aval - baseline;\n        pchg = (chg / baseline) * 100;\n    end;\n    \n    /* Quality checks */\n    if baseline = . then put \"WARNING: Missing baseline for \" usubjid=;\n    if aval = . and visitnum &gt; 1 then put \"WARNING: Missing post-baseline value for \" usubjid= visitnum=;\n    \n    label chg = 'Change from Baseline'\n          pchg = 'Percent Change from Baseline'\n          baseline = 'Baseline Value';\nrun;\n解説:\n\nデータセットの結合条件を明確に指定（in=demo and vital）\nベースライン値の適切な保持と計算\n品質チェックを組み込み、問題があればログに出力\n計算ロジックを段階的に記述し、理解しやすくする\n派生変数には適切なラベルを付与"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#心理的トリックと認知バイアスの悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#心理的トリックと認知バイアスの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.10 🧠 心理的トリックと認知バイアスの悪用",
    "text": "1.10 🧠 心理的トリックと認知バイアスの悪用\n\n1.10.1 先入観を利用した混乱\n/* 悪い例：一般的な変数名で全く違う内容を格納 */\ndata demographics;\n    set patient_roster;\n    \n    /* 通常なら患者情報だが... */\n    age = protocol_version;      /* 年齢ではなくプロトコル番号 */\n    sex = randomization_seed;    /* 性別ではなく乱数シード */\n    height = study_duration;     /* 身長ではなく研究期間 */\n    weight = site_number;        /* 体重ではなく施設番号 */\n    \n    /* ラベルで更なる混乱を誘発 */\n    label age = 'Patient Age (Years)'\n          sex = 'Patient Gender'\n          height = 'Height (cm)'\n          weight = 'Weight (kg)';\nrun;\n解説: プログラマーの先入観を悪用した極めて悪質な手法。変数名から期待される内容と実際の内容が完全に異なり、さらにラベルでも嘘の情報を提供しています。これにより重大な解析エラーを引き起こす可能性があります。\n\n\n1.10.2 視覚的類似性を利用した混乱\n/* 悪い例：見た目が似ている文字・数字の混用 */\ndata confusion;\n    /* 数字の1と小文字のl */\n    testnum1 = score_1;\n    testnuml = score_l;  /* 実際は小文字のL */\n    \n    /* 数字の0と大文字のO */\n    patient0 = id_zero;\n    patientO = id_oh;    /* 実際は大文字のO */\n    \n    /* 数字の2とアルファベットのZ */\n    group2 = treatment_2;\n    groupZ = treatment_z; /* 実際はZ */\n    \n    /* IとlとlIの組み合わせ */\n    IlllIlIl = result_a;  /* 何がIで何がlか判別不可能 */\n    lIlIlIll = result_b;\nrun;\n解説: フォントによっては区別が困難な文字を意図的に混用しています。特にプログラミング用でないフォントでは、これらの違いを見分けることは非常に困難になります。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#プロシージャの悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#プロシージャの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.11 🔄 プロシージャの悪用",
    "text": "1.11 🔄 プロシージャの悪用\n\n1.11.1 PROC SQLの危険な使用法\n/* 悪い例：副作用のあるSQL */\nproc sql;\n    /* 一見単純な選択に見えるが... */\n    create table summary as\n    select *,\n           (select count(*) from work.temp_calc \n            where temp_calc.id = main.id) as calc_count\n    from main_data as main;\n    \n    /* work.temp_calcは実際には存在せず、\n       このクエリ実行中に副作用で作成される隠しプロセスがある */\nquit;\n\n/* 隠された前処理（別の場所に配置） */\ndata work.temp_calc / view=work.temp_calc;\n    set main_data;\n    /* 複雑な計算でmain_dataを変更 */\n    call execute('data main_data; modify main_data; id = id + 1000; run;');\nrun;\n解説:\n\n一見単純なSELECTクエリに見えるが、サブクエリが隠された副作用を持つ\nVIEWを使って実行時に元データを変更する隠れた処理を組み込む\nCALL EXECUTEにより、クエリ実行中に予期しないデータ変更が発生\n\n\n\n1.11.2 PROC SORTの落とし穴\n/* 悪い例：NODUPKEY vs NODUPLICATESの混乱 */\n/* 同じファイル名で異なる結果を生成 */\nproc sort data=patients out=clean_data NODUPKEY;\n    by patient_id visit_date;\nrun;\n/* patient_idとvisit_dateの組み合わせで重複削除 */\n\n/* どこか別の場所で... */\nproc sort data=patients out=clean_data NODUPLICATES;\n    by patient_id visit_date;\nrun;\n/* 完全に同一の行のみ重複削除（結果が異なる） */\n解説:\n\nNODUPKEYとNODUPLICATESは似ているが動作が異なる\n同じ出力データセット名を使うことで、どちらが実行されたかが分からなくなる\n結果として異なるデータセットが同じ名前で作成される"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#マクロプログラミングの悪魔術",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#マクロプログラミングの悪魔術",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.12 🎭 マクロプログラミングの悪魔術",
    "text": "1.12 🎭 マクロプログラミングの悪魔術\n\n1.12.1 動的マクロ生成の混乱\n/* 悪い例：実行時にマクロを動的生成して混乱させる */\n%macro generate_confusion(type);\n    %if &type = A %then %do;\n        %macro process_data;\n            data result; set input; value = value * 2; run;\n        %mend;\n    %end;\n    %else %if &type = B %then %do;\n        %macro process_data;\n            data result; set input; value = value / 2; run;\n        %mend;\n    %end;\n    %else %do;\n        %macro process_data;\n            data result; set input; value = .; run;\n        %mend;\n    %end;\n%mend;\n\n/* 実行時に決定される処理内容 */\n%generate_confusion(A)\n%process_data  /* 何が実行されるかは実行時まで不明 */\n解説:\n\n実行時に条件によって異なるマクロ定義を生成\n同名のマクロprocess_dataが異なる処理を行う\nプログラムを読んだだけでは実際の処理内容が予測できない\n\n\n\n1.12.2 マクロ変数の隠蔽と再定義\n/* 悪い例：グローバル変数を局所的に再定義 */\n%let important_factor = 1.5;  /* グローバル設定 */\n\n%macro sneaky_calculation(data);\n    %local important_factor;  /* 局所的に再定義 */\n    %let important_factor = 0.1;  /* 全く違う値 */\n    \n    data &data._adjusted;\n        set &data;\n        adjusted_value = original_value * &important_factor;\n    run;\n    \n    %put NOTE: Applied factor &important_factor to &data;\n%mend;\n\n/* 使用者は1.5倍されると期待するが... */\n%sneaky_calculation(patient_data)  /* 実際は0.1倍 */\n解説:\n\nグローバル変数と同名の局所変数を定義\n使用者はグローバル値（1.5）が使われると期待\n実際は局所変数の値（0.1）が使用される\nPUTステートメントで正しい値を表示するため、ログを見ても気づきにくい\n\n\n\n1.12.3 マクロクォート関数の連鎖\n/* 悪い例：複数のクォート関数を連鎖させて混乱 */\n%macro quote_chaos(input);\n    %let step1 = %nrstr(&input);\n    %let step2 = %superq(step1);\n    %let step3 = %nrbquote(&step2);\n    %let step4 = %unquote(&step3);\n    \n    %if &step4 = &input %then\n        %put SUCCESS: Values match;\n    %else\n        %put ERROR: Values do not match - &step4 vs &input;\n%mend;\n\n%quote_chaos(test_value)\n解説:\n\n複数のマクロクォート関数を意味もなく連鎖\n各ステップで文字列の扱いが微妙に変化\n最終的な比較結果が予測困難\nデバッグが非常に困難"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#データアクセスとライブラリの混乱",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#データアクセスとライブラリの混乱",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.13 🗃️ データアクセスとライブラリの混乱",
    "text": "1.13 🗃️ データアクセスとライブラリの混乱\n\n1.13.1 ライブラリ参照の動的変更\n/* 悪い例：実行中にライブラリ参照を変更 */\nlibname mydata \"/path/to/original/data\";\n\ndata important_analysis;\n    set mydata.patients;  /* 最初のデータソース */\n    \n    /* 途中で同じライブラリ名を別パスに変更 */\n    call execute('libname mydata \"/path/to/different/data\";');\n    \n    /* この後のmydata参照は別のデータを指す */\n    merge mydata.treatments mydata.outcomes;  /* 異なるデータソース */\n    by patient_id;\nrun;\n解説:\n\nCALL EXECUTEを使って実行中にライブラリ参照を変更\n同一プログラム内で同じライブラリ名が異なるデータを指すことになる\nデータの整合性が完全に失われる可能性\n\n\n\n1.13.2 隠れたデータ変更\n/* 悪い例：読み取り専用に見えるが実際は変更している */\ndata summary_report;\n    set master_data;  /* 読み取りのみに見える */\n    \n    /* 隠されたMODIFYステートメント */\n    if _n_ = 1 then do;\n        call execute('\n            data master_data;\n                modify master_data;\n                if patient_id = \"DUMMY001\" then delete;\n            run;\n        ');\n    end;\n    \n    /* 集計処理 */\n    summary_stat = mean(value);\n    output;\nrun;\n解説:\n\n一見データを読み取りのみしているように見える\n実際はCALL EXECUTEで元データを変更している\n集計レポート作成時に元データが変更されるという予期しない副作用"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#統計プロシージャの悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#統計プロシージャの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.14 📊 統計プロシージャの悪用",
    "text": "1.14 📊 統計プロシージャの悪用\n\n1.14.1 PROC REGの隠れた前提条件違反\n/* 悪い例：前提条件を満たさないデータで回帰分析 */\nproc reg data=patient_data;\n    model outcome = treatment age weight;  /* 一見正常な回帰式 */\n    \n    /* 隠された問題：\n       - outcomeには欠測値が50%\n       - treatmentは完全に共線性のある3つのダミー変数\n       - ageとweightは完全相関（r=1.0）\n       - データには外れ値が意図的に挿入済み\n    */\nrun;\n解説:\n\n統計的前提条件を全く満たさないデータで分析実行\n多重共線性、欠測値、外れ値などの問題を隠蔽\n結果は統計的に無意味だが、出力は正常に見える\n\n\n\n1.14.2 PROC FREQの誤解を招く使用\n/* 悪い例：意図的に誤解を招くクロス集計 */\nproc freq data=clinical_data;\n    /* 一見、治療効果の評価に見えるが... */\n    tables treatment*outcome / chisq;\n    \n    /* 実際のデータには重大な問題：\n       - outcomeは治療開始前の状態\n       - treatmentは別の研究での割り付け\n       - 同一患者が複数回カウントされている\n    */\n    \n    title \"Treatment Effect Analysis\";  /* 誤解を招くタイトル */\nrun;\n解説:\n\n変数名から因果関係があるように見せかける\n実際は時系列が逆転していたり、関係のないデータ\nタイトルで意図的に誤解を招く"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#セキュリティと権限の悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#セキュリティと権限の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.15 🔒 セキュリティと権限の悪用",
    "text": "1.15 🔒 セキュリティと権限の悪用\n\n1.15.1 パスワードとアクセス制御の隠蔽\n/* 悪い例：隠されたデータベース接続 */\n%let hidden_pw = %substr(%sysfunc(compress('pass1word2',,'kd')),1,8);\n\nlibname secret oracle user=admin password=\"&hidden_pw\" \n                   path=\"//hidden.server.com:1521/secret_db\"\n                   schema=confidential;\n\n/* 一見通常のデータ処理 */\ndata public_summary;\n    set secret.classified_data;  /* 実際は機密データにアクセス */\n    /* パスワードは暗号化されて見えない */\nrun;\n解説:\n\nパスワードを関数で暗号化・難読化\n機密データベースへの隠れたアクセス\n表面上は通常のデータ処理に見せかけ"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#オペレーティングシステム固有の悪用",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#オペレーティングシステム固有の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.16 🌐 オペレーティングシステム固有の悪用",
    "text": "1.16 🌐 オペレーティングシステム固有の悪用\n\n1.16.1 Windows環境での隠れた設定\n/* 悪い例：アイコンのプロパティで隠れたオプション設定 */\n/* SASアイコンのプロパティで以下を設定（見えない場所） */\n/*\nTarget: \"C:\\SAS\\sas.exe\" -CONFIG \"C:\\hidden\\malicious.cfg\" \n                          -AUTOEXEC \"C:\\hidden\\autoexec.sas\"\n                          -SYSIN \"C:\\decoy\\normal_program.sas\"\n                          -ARCH=BIT16\n*/\n\n/* 実際に実行されるのは hidden/autoexec.sas の内容 */\n/* ユーザーは normal_program.sas が実行されると思っている */\n解説:\n\nWindowsのアイコンプロパティで隠れた設定を行う\nユーザーには見えない設定ファイルや自動実行ファイルを指定\n16ビットモードで実行して性能を意図的に低下\nユーザーが期待するプログラムとは異なるものを実行\n\n\n\n1.16.2 外部DLLとシステムコールの悪用\n/* 悪い例：外部ライブラリで隠れた処理 */\nfilename hidden 'hidden_malicious.dll';\n\ndata _null_;\n    /* 表面上は時刻の取得 */\n    current_time = datetime();\n    \n    /* 実際は外部DLLで隠れた処理を実行 */\n    call module(hidden, 'secret_function', current_time, result);\n    \n    /* DLLの中身：\n       - ファイルシステムの操作\n       - ネットワーク通信\n       - データの外部送信\n       - ログの改竄\n    */\nrun;\n解説:\n\n外部DLLを使って隠れた処理を実行\nSASのログには通常の処理のみ記録\n実際の悪意ある処理はDLL内に隠蔽\nシステム権限を悪用した危険な操作"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#実際の被害例と教訓",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#実際の被害例と教訓",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.17 ⚠️ 実際の被害例と教訓",
    "text": "1.17 ⚠️ 実際の被害例と教訓\n\n1.17.1 臨床試験での重大インシデント\n/* 実際にあった危険な例（教育目的で再現） */\n\n/* 悪い例：効果量の計算で隠れたバイアス */\ndata efficacy_analysis;\n    set clinical_data;\n    \n    /* 表面的には標準的な効果量計算 */\n    if treatment = 'Active' then trt_num = 1;\n    else if treatment = 'Placebo' then trt_num = 0;\n    \n    /* 隠されたバイアス：特定の患者のみ除外 */\n    if patient_id in ('001', '047', '089') and trt_num = 0 then delete;\n    /* これらは偶然プラセボ群で改善した患者 */\n    \n    /* 通常の統計計算 */\n    effect_size = (active_mean - placebo_mean) / pooled_sd;\nrun;\n\n/* 結果：人為的に効果が過大評価される */\n解説:\n\n一見正常な効果量計算に見える\n実際は特定の患者（プラセボ群で改善した例）を意図的に除外\n結果として薬剤効果が過大評価される\n規制当局への提出データに重大な問題を作り出す\n\n\n\n1.17.2 データ管理での混乱事例\n/* 実際にあった混乱例 */\n\n/* 悪い例：バックアップのつもりが本番データを破壊 */\n%let backup_date = %sysfunc(today(), yymmddd6.);\n\n/* 本番データの「バックアップ」 */\ndata backup.patient_data_&backup_date;\n    set production.patient_data;\nrun;\n\n/* 隠れた問題：productionとbackupが同じ場所を指している */\n/* libname production \"//server/data/current\"; */\n/* libname backup    \"//server/data/current\"; */\n\n/* 結果：バックアップではなく上書きが発生 */\n解説:\n\nバックアップ処理のつもりで実装\n実際は両方のライブラリが同じ場所を指している\nバックアップではなく本番データの上書きが発生\nデータロストの原因となる"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTIps005.html#まとめ",
    "href": "posts/statistics/2025/SASプログラミングTIps005.html#まとめ",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.18 まとめ",
    "text": "1.18 まとめ\nこの記事で紹介した「技法」は、実際のプログラムでは絶対に使用してはいけません。これらは全て、実際に遭遇する可能性のある問題パターンです。\n\n“In reality there is a constant demand for SAS programmers. Just knowing how to write good, clean, and tight SAS code provides a high level of job security.”\n\n良いSASプログラマーになるためには：\n\n可読性を重視したコード作成\n適切な命名規則の遵守\n十分なドキュメント化とコメント\n論理的な構造の維持\n品質管理オプションの適切な使用\n一貫したプログラミングスタイル\n他者が保守しやすいコード設計\n\n特に臨床試験の統計解析では、コードの品質が直接患者の安全性と規制当局への信頼性に関わるため、これらの原則を厳格に守ることが重要です。\nこの記事は、Arthur L. Carpenter氏とTony Payne氏の「Programming for Job Security」シリーズを基に作成されました。元の論文は風刺的な内容ですが、実際のプログラミングにおいて避けるべき問題を明確にする優れた教材として、SAS界隈で長く愛され続けています。\n参考文献:\n\nCarpenter, Arthur L. (1993, 1996). “Programming For Job Security: Tips and techniques to Maximize Your Indispensability”\nCarpenter, Arthur L. & Payne, Tony. “Programming For Job Security Revisited: Even More Tips and Techniques to Maximize Your Indispensability”"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html",
    "href": "posts/statistics/2025/SASプログラミングTips007.html",
    "title": "SAS：要約統計量作成マクロ",
    "section": "",
    "text": "第3回：演題4「要約統計量マクロ」坂尻大樹さん\n\n要約統計量マクロ\n\n\n/* 疑似データの作成 */\ndata AAA;\n   input Name $ Age Height Treatment $;\n   datalines;\nアルフレッド 14 69.2 A群\nアリス 13 56.8 B群\nバーバラ 13 65.5 A群\nキャロル 14 62.9 B群\nヘンリー 14 63.7 A群\nジェームズ 12 . B群\nジェーン 12 59.9 A群\nジャネット 15 62.7 B群\nジェフリー 13 62.6 A群\nジョン 12 59.1 B群\n;\nrun;\n\n/* 分析設定 */\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = TREATMENT;\n\n/* ステップ1: 原データから桁数を取得 */\ndata SUMMARY_KETA1;\n   set &DS.;\n   if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n\nproc summary data=SUMMARY_KETA1;\n   var KETA;\n   output out=SUMMARY_KETA2 max=MAXKETA;\nrun;\n\ndata SUMMARY_KETA3;\n   set SUMMARY_KETA2;\n   if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n   else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n   \n   call symputx(\"KETA\", KETA);\nrun;\n\n/* ステップ2: クラスデータを作成 */\ndata SUMMARY_CLASS;\n   length &CVAR. $8.;\n   &CVAR. = \"A群\"; output;\n   &CVAR. = \"B群\"; output;\nrun;\n\n/* ステップ3: 要約統計量を算出 */\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n   class &CVAR.;\n   var &VAR.;\n   output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n\ndata SUMMARY_2;\n   length PREOUT1-PREOUT9 $12.;\n   set SUMMARY_1;\n   \n   /* 表示桁数の設定 */\n   PREOUT1 = cats(&VAR._N);\n   \n   /* 平均値 */\n   if &VAR._MEAN ^= . then \n       PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\n   else \n       PREOUT2 = \"-\";\n   \n   /* 標準偏差 */\n   if &VAR._STD ^= . then \n       PREOUT3 = cats(put(round(&VAR._STD, 0.01), 8.2));\n   else \n       PREOUT3 = \"-\";\n   \n   /* 最小値 */\n   if &VAR._MIN ^= . then \n       PREOUT4 = cats(put(round(&VAR._MIN, 1), 8.0));\n   else \n       PREOUT4 = \"-\";\n       \n   /* 第一四分位値 */\n   if &VAR._Q1 ^= . then \n       PREOUT5 = cats(put(round(&VAR._Q1, 0.1), 8.1));\n   else \n       PREOUT5 = \"-\";\n       \n   /* 中央値 */\n   if &VAR._MEDIAN ^= . then \n       PREOUT6 = cats(put(round(&VAR._MEDIAN, 0.1), 8.1));\n   else \n       PREOUT6 = \"-\";\n       \n   /* 第三四分位値 */\n   if &VAR._Q3 ^= . then \n       PREOUT7 = cats(put(round(&VAR._Q3, 0.1), 8.1));\n   else \n       PREOUT7 = \"-\";\n       \n   /* 最大値 */\n   if &VAR._MAX ^= . then \n       PREOUT8 = cats(put(round(&VAR._MAX, 1), 8.0));\n   else \n       PREOUT8 = \"-\";\n       \n   /* 欠測数 */\n   PREOUT9 = cats(&VAR._NMISS);\n   \n   /* ID変数 */\n   ID + 1;\n   keep ID &CVAR. PREOUT1-PREOUT9;\nrun;\n\n/* ステップ4: 整形&出力 */\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n   prefix=OUT;\n   var PREOUT1-PREOUT9;\n   id ID;\nrun;\n\n/* 統計項目ラベルを追加 */\ndata SUMMARY_FINAL;\n   length STAT_ITEM $12.;\n   set SUMMARY_3;\n   select(_N_);\n       when(1) STAT_ITEM = \"症例数\";\n       when(2) STAT_ITEM = \"平均値\";\n       when(3) STAT_ITEM = \"標準偏差\";\n       when(4) STAT_ITEM = \"最小値\";\n       when(5) STAT_ITEM = \"第一四分位値\";\n       when(6) STAT_ITEM = \"中央値\";\n       when(7) STAT_ITEM = \"第三四分位値\";\n       when(8) STAT_ITEM = \"最大値\";\n       when(9) STAT_ITEM = \"欠測数\";\n   end;\nrun;\n\n/* 結果出力 */\nproc print data=SUMMARY_FINAL noobs;\n   title \"統計量サマリー（&CVAR.別 - &VAR.）\";\n   var STAT_ITEM OUT1 OUT2;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#大阪sas-user総会にて紹介されていたプログラムの紹介",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#大阪sas-user総会にて紹介されていたプログラムの紹介",
    "title": "SAS：要約統計量作成マクロ",
    "section": "",
    "text": "第3回：演題4「要約統計量マクロ」坂尻大樹さん\n\n要約統計量マクロ\n\n\n/* 疑似データの作成 */\ndata AAA;\n   input Name $ Age Height Treatment $;\n   datalines;\nアルフレッド 14 69.2 A群\nアリス 13 56.8 B群\nバーバラ 13 65.5 A群\nキャロル 14 62.9 B群\nヘンリー 14 63.7 A群\nジェームズ 12 . B群\nジェーン 12 59.9 A群\nジャネット 15 62.7 B群\nジェフリー 13 62.6 A群\nジョン 12 59.1 B群\n;\nrun;\n\n/* 分析設定 */\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = TREATMENT;\n\n/* ステップ1: 原データから桁数を取得 */\ndata SUMMARY_KETA1;\n   set &DS.;\n   if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n\nproc summary data=SUMMARY_KETA1;\n   var KETA;\n   output out=SUMMARY_KETA2 max=MAXKETA;\nrun;\n\ndata SUMMARY_KETA3;\n   set SUMMARY_KETA2;\n   if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n   else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n   \n   call symputx(\"KETA\", KETA);\nrun;\n\n/* ステップ2: クラスデータを作成 */\ndata SUMMARY_CLASS;\n   length &CVAR. $8.;\n   &CVAR. = \"A群\"; output;\n   &CVAR. = \"B群\"; output;\nrun;\n\n/* ステップ3: 要約統計量を算出 */\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n   class &CVAR.;\n   var &VAR.;\n   output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n\ndata SUMMARY_2;\n   length PREOUT1-PREOUT9 $12.;\n   set SUMMARY_1;\n   \n   /* 表示桁数の設定 */\n   PREOUT1 = cats(&VAR._N);\n   \n   /* 平均値 */\n   if &VAR._MEAN ^= . then \n       PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\n   else \n       PREOUT2 = \"-\";\n   \n   /* 標準偏差 */\n   if &VAR._STD ^= . then \n       PREOUT3 = cats(put(round(&VAR._STD, 0.01), 8.2));\n   else \n       PREOUT3 = \"-\";\n   \n   /* 最小値 */\n   if &VAR._MIN ^= . then \n       PREOUT4 = cats(put(round(&VAR._MIN, 1), 8.0));\n   else \n       PREOUT4 = \"-\";\n       \n   /* 第一四分位値 */\n   if &VAR._Q1 ^= . then \n       PREOUT5 = cats(put(round(&VAR._Q1, 0.1), 8.1));\n   else \n       PREOUT5 = \"-\";\n       \n   /* 中央値 */\n   if &VAR._MEDIAN ^= . then \n       PREOUT6 = cats(put(round(&VAR._MEDIAN, 0.1), 8.1));\n   else \n       PREOUT6 = \"-\";\n       \n   /* 第三四分位値 */\n   if &VAR._Q3 ^= . then \n       PREOUT7 = cats(put(round(&VAR._Q3, 0.1), 8.1));\n   else \n       PREOUT7 = \"-\";\n       \n   /* 最大値 */\n   if &VAR._MAX ^= . then \n       PREOUT8 = cats(put(round(&VAR._MAX, 1), 8.0));\n   else \n       PREOUT8 = \"-\";\n       \n   /* 欠測数 */\n   PREOUT9 = cats(&VAR._NMISS);\n   \n   /* ID変数 */\n   ID + 1;\n   keep ID &CVAR. PREOUT1-PREOUT9;\nrun;\n\n/* ステップ4: 整形&出力 */\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n   prefix=OUT;\n   var PREOUT1-PREOUT9;\n   id ID;\nrun;\n\n/* 統計項目ラベルを追加 */\ndata SUMMARY_FINAL;\n   length STAT_ITEM $12.;\n   set SUMMARY_3;\n   select(_N_);\n       when(1) STAT_ITEM = \"症例数\";\n       when(2) STAT_ITEM = \"平均値\";\n       when(3) STAT_ITEM = \"標準偏差\";\n       when(4) STAT_ITEM = \"最小値\";\n       when(5) STAT_ITEM = \"第一四分位値\";\n       when(6) STAT_ITEM = \"中央値\";\n       when(7) STAT_ITEM = \"第三四分位値\";\n       when(8) STAT_ITEM = \"最大値\";\n       when(9) STAT_ITEM = \"欠測数\";\n   end;\nrun;\n\n/* 結果出力 */\nproc print data=SUMMARY_FINAL noobs;\n   title \"統計量サマリー（&CVAR.別 - &VAR.）\";\n   var STAT_ITEM OUT1 OUT2;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#各プログラムの工夫点",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#各プログラムの工夫点",
    "title": "SAS：要約統計量作成マクロ",
    "section": "2 各プログラムの工夫点",
    "text": "2 各プログラムの工夫点"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#桁数自動取得の工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#桁数自動取得の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "3 1. 桁数自動取得の工夫",
    "text": "3 1. 桁数自動取得の工夫\ndata SUMMARY_KETA1;\n    set &DS.;\n    if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n工夫点:\n\n小数点以下の桁数を自動検出: &VAR. - int(&VAR.)で小数点以下のみを抽出\n文字列変換による桁数計算: cats()で文字列に変換し、length()で桁数を取得\n例: 62.75の場合 → 62.75 - 62 = 0.75 → “0.75” → length = 4文字 → 小数点第2位\n\ndata SUMMARY_KETA3;\n    set SUMMARY_KETA2;\n    if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n    else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n    \n    call symputx(\"KETA\", KETA);\nrun;\n工夫点:\n\n整数判定: MAXKETA=1は”0”（整数）を意味するため、KETA=0に設定\n桁数計算: “0.75”なら4文字-2=“.”と”0”を除く=2桁\nマクロ変数への格納: call symputx()でグローバルマクロ変数に設定"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#クラスデータ作成の工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#クラスデータ作成の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "4 2. クラスデータ作成の工夫",
    "text": "4 2. クラスデータ作成の工夫\n\n4.1 数値変数（年齢）の場合:\ndata SUMMARY_CLASS;\n    if _N_ = 0 then set &DS.(keep=&CVAR.);\n    do &CVAR. = &CSTR. to &CEND.;\n        output;\n    end;\n    stop;\nrun;\n工夫点:\n\n変数定義の継承: if _N_ = 0 then setで元データの変数属性を継承\n連続値の生成: doループで指定範囲の全ての値を生成\n効率的な処理: stopで無限ループを防止\n\n\n\n4.2 文字変数（治療群）の場合:\ndata SUMMARY_CLASS;\n    length &CVAR. $8.;\n    &CVAR. = \"A群\"; output;\n    &CVAR. = \"B群\"; output;\nrun;\n工夫点:\n\n文字変数の明示的定義: lengthで文字変数の長さを指定\n必要な値のみ生成: 存在する治療群のみを明示的に作成"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#統計量計算での工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#統計量計算での工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "5 3. 統計量計算での工夫",
    "text": "5 3. 統計量計算での工夫\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n    class &CVAR.;\n    var &VAR.;\n    output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n工夫点:\n\nCLASSDATA使用: 存在しないクラス値も強制的に出力（0件でも表示）\nEXCLUSIVE: 元データにないクラス値も処理対象に含める\nNWAY: 最下位レベルのクロス集計のみ出力\nAUTONAME: 変数名を自動生成（HEIGHT_N, HEIGHT_MEAN等）"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#数値フォーマットの工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#数値フォーマットの工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "6 4. 数値フォーマットの工夫",
    "text": "6 4. 数値フォーマットの工夫\nif &VAR._MEAN ^= . then \n    PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\nelse \n    PREOUT2 = \"-\";\n工夫点:\n\n統計量別の桁数制御:\n\n平均値: 小数点第1位（0.1で四捨五入、8.1で表示）\n標準偏差: 小数点第2位（0.01で四捨五入、8.2で表示）\n最小値・最大値: 整数（1で四捨五入、8.0で表示）\n\n欠損値の統一処理: 欠損値は全て”-“で表示\n文字列への変換: cats()で余分な空白を除去"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#データ構造変換の工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#データ構造変換の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "7 5. データ構造変換の工夫",
    "text": "7 5. データ構造変換の工夫\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n    prefix=OUT;\n    var PREOUT1-PREOUT9;\n    id ID;\nrun;\n工夫点:\n\n行列の転置: 統計量（行）×群（列）の表形式に変換\n列名の制御: prefix=OUTで列名をOUT1, OUT2…に統一\n不要変数の削除: drop=_NAME_で転置時の不要変数を除去"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#最終出力での工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#最終出力での工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "8 6. 最終出力での工夫",
    "text": "8 6. 最終出力での工夫\ndata SUMMARY_FINAL;\n    length STAT_ITEM $12.;\n    set SUMMARY_3;\n    select(_N_);\n        when(1) STAT_ITEM = \"症例数\";\n        when(2) STAT_ITEM = \"平均値\";\n        /* ... */\n    end;\nrun;\n工夫点:\n\n日本語ラベル: 統計量に分かりやすい日本語名を付与\n順序の制御: select(_N_)で行番号に基づいた処理\n表示用の最終調整: ユーザーフレンドリーな出力形式"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips007.html#マクロ設計の工夫",
    "href": "posts/statistics/2025/SASプログラミングTips007.html#マクロ設計の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "9 7. マクロ設計の工夫",
    "text": "9 7. マクロ設計の工夫\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = AGE;  /* または Treatment *\n工夫点:\n\nパラメータ化: データセット名、変数名を簡単に変更可能\n汎用性: 数値・文字変数どちらでも対応\n再利用性: マクロ変数を変更するだけで異なる分析に適用可能\n\nこれらの工夫により、元の複雑な%SUMMARYマクロの機能を再現しつつ、理解しやすく保守しやすいコードになっています。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングTips009.html",
    "href": "posts/statistics/2025/SASプログラミングTips009.html",
    "title": "Proc Transpose/ARRAYによる転置",
    "section": "",
    "text": "0.1 SAS初心者必見！横持ちデータを縦持ちに変換する3つの方法【ADaM対応・完全コード付き】\nこんにちは！SASプログラミングを学び始めたばかりの皆さん、データ形式の「横持ち」「縦持ち」で困ったことはありませんか？\n臨床試験データの標準モデルであるADaMでは、基本的に「1行に1つの分析結果」を格納する縦持ち形式が求められます。しかし、元のデータは被験者IDごとに検査結果が横に並んだ横持ち形式であることがよくあります。\n今回は、この横持ちデータを縦持ちに変換するための代表的な3つの方法を、ADaM変数（PARAM, AVAL, AVISITNなど）を使いながら、初心者向けにじっくり解説していきます。すべてのコードはコピー＆ペーストで実行可能です。\n\n0.1.1 準備：今回のサンプルデータとゴール\nまず、変換元となる横持ちデータ（source_data）を見てみましょう。被験者ごと、訪問ごと（VISIT 1, 2, 3）の検査値（TC: 総コレステロール, HDL: HDLコレステロール）が横に並んでいます。\n【変換元】横持ちデータ\nUSUBJID | TC_1 | HDL_1 | TC_2 | HDL_2 | TC_3 | HDL_3\n-------------------------------------------------------\nP01     | 212  | 50    | 224  | 64    | 204  | 73\nP02     | 206  | 58    | 208  | 63    | 212  | 58\nP03     | 221  | 47    | 236  | 70    | 242  | 38\nそして、このデータを以下の縦持ち形式に変換するのが今回のゴールです。\n【ゴール】縦持ちデータ (ADaM風)\nUSUBJID | PARAMN | PARAM     | AVISITN | AVAL\n-------------------------------------------------\nP01     | 1      | TC        | 1       | 212\nP01     | 1      | TC        | 2       | 224\nP01     | 1      | TC        | 3       | 204\nP01     | 2      | HDL       | 1       | 50\n...     | ...    | ...       | ...     | ...\nそれでは、具体的な変換方法を見ていきましょう！\n\n\n\n0.2 方法1：PROC TRANSPOSE - SASの変形マジック\nPROC TRANSPOSEは、その名の通りデータセットの行と列を入れ替える（転置する）ための強力なプロシジャです。\n\n0.2.1 ステップ1：まず転置してみる\nproc transpose data=source_data out=transposed_data(rename=(COL1=AVAL _NAME_=VARNAME));\n  by USUBJID;\n  var TC_1--TC_3 HDL_1--HDL_3;\nrun;\n\nproc transpose ...; run;: PROC TRANSPOSEの開始と終了を示します。\ndata=source_data: 変換の対象データセットを指定します。\nout=transposed_data(...): 変換後のデータセット名と、オプションを指定します。\nrename=(...): 自動生成される変数名を、より分かりやすい名前に変更します。\nby USUBJID;: 非常に重要なステートメントです。「どの変数を基準にグループ化するか」を指定します。今回はUSUBJIDごとに行をまとめたいので、USUBJIDを指定します。\nvar ...;: どの変数を縦持ちに変換（転置）するかを指定します。\n\n\n\n0.2.2 ステップ2：データステップでADaM変数に整える\n次に、この中間データをデータステップで加工し、VARNAMEからPARAMとAVISITNを作り出します。\ndata final_data_transpose;\n  set transposed_data;\n  \n  PARAM   = scan(VARNAME, 1, '_');\n  AVISITN = input(scan(VARNAME, 2, '_'), 8.);\n  \n  if PARAM = 'TC' then PARAMN = 1;\n  else if PARAM = 'HDL' then PARAMN = 2;\n  \n  drop VARNAME;\nrun;\nscan関数は、指定した区切り文字（今回は_）で文字列を分割してくれる便利な関数です。これでPROC TRANSPOSEを使った変換が完成です！\n\n\n\n0.3 方法2：ARRAYステートメント - 最もスマートな方法\nARRAYは**「複数の変数を一時的にグループ化して、番号で扱えるようにする」**機能です。 これを使いこなすと、非常に効率的なプログラミングが可能になります。\ndata final_data_array;\n  set source_data;\n  \n  /*【重要ポイント】\n   * '--'記法は変数の物理的順序に依存しエラーの原因になりうるため、\n   * ここでは変数をすべて明示的にリストアップします。\n   */\n  array aval_group{2, 3} TC_1 TC_2 TC_3 HDL_1 HDL_2 HDL_3; \n  \n  array params{2} $ _temporary_ ('TC', 'HDL');\n  array paramns{2} _temporary_ (1, 2);\n  \n  do j = 1 to 2; [cite: 434]\n    do i = 1 to 3; [cite: 435]\n      PARAMN  = paramns{j};\n      PARAM   = params{j};\n      AVISITN = i;\n      AVAL    = aval_group{j, i}; [cite: 436]\n      output; [cite: 437]\n    end;\n  end;\n  \n  keep USUBJID PARAMN PARAM AVISITN AVAL;\nrun;\n\narray aval_group{2, 3} ...;: 2行3列の二次元配列を定義します。 SASはリストされた変数を行優先で配列に格納します。\n_temporary_: このオプションで定義した配列は、データセットに出力されない一時的な作業領域として使えます。\ndo j = 1 to 2; do i = 1 to 3;: 外側のループで検査項目を、内側のループで訪問を回しています。\n\nこの方法は、一つのデータステップで完結するため、非常に効率的でコードもスッキリします。\n\n\n0.4 方法3：マクロ - 同じ作業はSASに任せよう\n最後は、地道なDATAステップの繰り返しを自動化するマクロを使った方法です。\n%macro reshape(param_nm, param_num);\n  %do visit = 1 %to 3;\n    data temp_&param_nm._&visit.;\n      set source_data;\n      PARAMN  = &param_num.;\n      PARAM   = \"&param_nm.\";\n      AVISITN = &visit.;\n      AVAL    = &param_nm._&visit;\n      keep USUBJID PARAMN PARAM AVISITN AVAL;\n    run;\n  %end;\n%mend reshape;\n\n%reshape(TC, 1);\n%reshape(HDL, 2);\n\ndata final_data_macro;\n  /*【重要ポイント】\n   * '--'記法はデータセットの物理的順序に依存しエラーの原因になるため、\n   * ここでは結合したいデータセット名をすべて明示的にリストアップします。\n   */\n  set temp_TC_1 temp_TC_2 temp_TC_3\n      temp_HDL_1 temp_HDL_2 temp_HDL_3;\nrun;\n\n%macro ... %mend;: このブロックで一連の処理をマクロとして定義します。\n%do ... %end;: マクロ内で繰り返し処理を行います。\n&param_nm.や&visit.はマクロ変数と呼ばれ、マクロ呼び出し時に指定された値に置き換わります。\n\nこの方法は、一つ一つの処理は単純ですが、中間データセットが複数作られるのが特徴です。\n\n\n0.5 まとめとAppendix\n3つの方法を紹介しましたが、いかがでしたか？\n\n\n\n\n\n\n\n\n\nアプローチ\nメリット\nデメリット\nこんな人におすすめ\n\n\nPROC TRANSPOSE\n大量の変数を一度に転置できる\n複数ステップが必要になることがある\nまずはSASのプロシジャに慣れたい人\n\n\nARRAY\nコードが簡潔で最も効率的\n配列の概念（特に二次元）に慣れが必要\nSASでのデータ加工を極めたい人\n\n\nマクロ\n繰り返し処理を自動化できる\n中間データセットが多くなりがち\n特定の定型処理を何度も再利用したい人\n\n\n\n初学者の皆さんは、まずはPROC TRANSPOSEから試してみて、慣れてきたらぜひARRAYステートメントに挑戦してみてください。\n\n0.5.1 Appendix: 全手法の完全なサンプルプログラム\n以下に、本稿で紹介した3つのアプローチについて、横持ちの疑似データ作成から縦持ちデータへ変換するまでの一連のSASプログラムを掲載します。\n/* ============================================== */\n/* 1. 変換元となる横持ちデータを作成              */\n/* ============================================== */\ndata source_data;\n  input USUBJID $ TC_1 HDL_1 TC_2 HDL_2 TC_3 HDL_3;\n  cards;\nP01 212 50 224 64 204 73\nP02 206 58 208 63 212 58\nP03 221 47 236 70 242 38\n;\nrun;\n\ntitle \"変換前の横持ちデータ (source_data)\";\nproc print data=source_data;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法1: PROC TRANSPOSE を使用したプログラム       */\n/* ============================================== */\nproc transpose data=source_data out=transposed_data(rename=(COL1=AVAL _NAME_=VARNAME));\n  by USUBJID;\n  var TC_1--TC_3 HDL_1--HDL_3;\nrun;\n\ndata final_data_transpose;\n  set transposed_data;\n  PARAM   = scan(VARNAME, 1, '_');\n  AVISITN = input(scan(VARNAME, 2, '_'), 8.);\n  if PARAM = 'TC' then PARAMN = 1;\n  else if PARAM = 'HDL' then PARAMN = 2;\n  drop VARNAME;\nrun;\n\nproc sort data=final_data_transpose;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法1 (PROC TRANSPOSE) による変換結果\";\nproc print data=final_data_transpose;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法2: ARRAY を使用したプログラム              */\n/* ============================================== */\ndata final_data_array;\n  set source_data;\n  \n  array aval_group{2, 3} TC_1 TC_2 TC_3 HDL_1 HDL_2 HDL_3;\n  \n  array params{2} $ _temporary_ ('TC', 'HDL');\n  array paramns{2} _temporary_ (1, 2);\n  \n  do j = 1 to 2;\n    do i = 1 to 3;\n      PARAMN  = paramns{j};\n      PARAM   = params{j};\n      AVISITN = i;\n      AVAL    = aval_group{j, i};\n      output;\n    end;\n  end;\n  \n  keep USUBJID PARAMN PARAM AVISITN AVAL;\nrun;\n\nproc sort data=final_data_array;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法2 (ARRAY) による変換結果\";\nproc print data=final_data_array;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法3: マクロを使用したプログラム              */\n/* ============================================== */\n%macro reshape(param_nm, param_num);\n  %do visit = 1 %to 3;\n    data temp_&param_nm._&visit.;\n      set source_data;\n      PARAMN  = &param_num.;\n      PARAM   = \"&param_nm.\";\n      AVISITN = &visit.;\n      AVAL    = &param_nm._&visit;\n      \n      keep USUBJID PARAMN PARAM AVISITN AVAL;\n    run;\n  %end;\n%mend reshape;\n\n%reshape(TC, 1);\n%reshape(HDL, 2);\n\ndata final_data_macro;\n  set temp_TC_1 temp_TC_2 temp_TC_3\n      temp_HDL_1 temp_HDL_2 temp_HDL_3;\nrun;\n\nproc sort data=final_data_macro;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法3 (マクロ) による変換結果\";\nproc print data=final_data_macro;\nrun;\ntitle;\n\nproc datasets lib=work nolist;\n  delete temp_:;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "",
    "text": "大阪SASユーザー総会の下記資料が大変勉強になるので、自分の備忘録用にコピペさせていただきた。基本的に下記資料をみればよい。\n\nThink Framework"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#はじめに",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#はじめに",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.1 はじめに",
    "text": "2.1 はじめに\nSASプログラミングにおいて、毎回同じような処理を一から書くのは非効率的です。本記事では、Yugo Mikiさんの「Think Framework」の知見を参考に、SASプログラムをフレームワーク化することで、開発効率を大幅に向上させる手法について解説します。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#library-vs-framework根本的な発想の違い",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#library-vs-framework根本的な発想の違い",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.2 Library vs Framework：根本的な発想の違い",
    "text": "2.2 Library vs Framework：根本的な発想の違い\n\n2.2.1 従来のLibraryアプローチ\n\nマクロライブラリなどが有名\nライブラリからマクロやプログラムを参照してプログラム中に利用する\nプログラムの再利用に特化した使い方\nプログラミングコードを部品化し、組み合わせる事でプログラムを作成する\n\n\n\n2.2.2 新しいFrameworkアプローチ\n\nSAS LSAFなどが有名。一方、「それって一体何なの？」ってくらい実体が見えない\n一般的な機能を持つ共通コードを持つ\n標準的なコードはフレームワークが持ち、要求されるコードの実現にプログラマーのリソースを集中させる事で効率化を達成する"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#だからどういうことなのさ",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#だからどういうことなのさ",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.3 「だからどういうことなのさ？」",
    "text": "2.3 「だからどういうことなのさ？」\nつまり：\n\nいつも書くコードはフレームワークに持たせましょう！\n\n- いつも使う機能はフレームワークに持たせましょう！\n- よく使うマクロとかもフレームワークに持たせましょう！\n- ついでに社内ルールとかもフレームワークに持たせておきましょう！\nってこと。\nこれをSASで良い感じに実現して、快適な開発環境を作りましょう！"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasプログラムの要素分析とフレームワーク化判断",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasプログラムの要素分析とフレームワーク化判断",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.4 SASプログラムの要素分析とフレームワーク化判断",
    "text": "2.4 SASプログラムの要素分析とフレームワーク化判断\n\n2.4.1 SDTM to ADaM変換の場合\n\n\n\n\n\n\n\n\n処理項目\n考察\nフレームワーク化判断\n\n\n\n\nClear log and data\n毎回使う。対象とする。\n✅ 完全自動化\n\n\nSetting macros\n毎回使うところだけ対象とする。\n⚡ 部分自動化\n\n\nSetting library\n毎回違う。出来るだけ一箇所に集約したい。\n🔧 設定管理\n\n\nSetting format\n仕様書のコードリストにあるものは対象とする。\n✅ 完全自動化\n\n\nImport data and files\nファイル名と仕様が毎回違う。やや無理。\n⚡ テンプレート化\n\n\nMerge\n毎回違う。対象外。\n❌ プログラマーの腕の見せ所\n\n\nMapping to new variables\n毎回違う。対象外。\n❌ プログラマーの腕の見せ所\n\n\nSort\nマクロ化してライブラリへ。\n✅ 共通化\n\n\nDrop extra variables\n仕様書から自動取得。\n✅ メタデータ連携\n\n\nUpload\nマクロ化してライブラリへ。\n✅ 共通化\n\n\nHeader, sections, comments\nSOPや手順との兼ね合い。対象とする。\n✅ テンプレート自動生成\n\n\n\n\n\n2.4.2 ADaM to TFLs変換の場合\n\nClear log and data\nSetting macros\nSetting library\nSetting format\nImport data and files\nMerge\nCall procedures（プロシージャの呼び出し）\nSort\nMake up to requests from mockup（モックアップからのリクエスト作成）\nUpload\nHeader, section, and comments\n\n🎯 重要な気づき\nプログラマーに頑張って欲しい所はここ！（MergeとMapping）\nということはそれ以外の所はフレームワークに持たせた方がいい！"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasによるフレームワーク設計",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasによるフレームワーク設計",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.5 SASによるフレームワーク設計",
    "text": "2.5 SASによるフレームワーク設計\n\n2.5.1 基本コンセプト\n\nSASプログラム開発時を想定\nSASによるプログラムテンプレート作成の一歩先\n\n\n\n2.5.2 URS（User Requirement Specification）\n\n使用するのはBase SASと一般的な外部ファイル（EXCEL）\nプログラムからプログラムをcallしても良い\n本番実行時のみログを外部に保管\nマクロは今回はmacro.sasを毎回includeする\nフレームワーク化検討のほぼ全てを実装する\n\n\n\n2.5.3 フレームワーク仕様\n\n2.5.3.1 全実行プログラム\n\n全実行時ログを保管\n\n\n\n2.5.3.2 Macro.sas\n\nSort\nインポート（proc sort）\nエクスポート（proc sort）\n仕様書から変数のattribute作成\n仕様書からcodelistのformat作成\n仕様書からkeepする変数リスト作成\n\n\n\n2.5.3.3 Each_dsn.sas\n\nStand aloneで動く\n実施時にログ、データセット等をクリアする\n社内規則に従ったheader, section, commentを作成する\n\nプログラムにおける面倒な”いつもの”を持たせておくのがフレームワークです。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実装例とテクニック",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実装例とテクニック",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.6 実装例とテクニック",
    "text": "2.6 実装例とテクニック\n\n2.6.1 全実行プログラム：環境分離の巧妙な仕組み\n/* 基本的にはマクロで実装 */\n%macro derive(dsn, title);\n   proc printto log = \"&path.¥&project._&dsn._log.txt\" new;\n   title1 \"&project.:&title.\";\n   run;\n   \n   %include \"&pgpath.¥&dsn..sas\";\n   \n   proc printto; \n   run;\n%mend;\n\n%derive(adsl)\n%derive(adae)\nPrinttoでincludeを挟むだけで開発環境と本番実行環境を分離できる！ 開発時：それぞれのプログラムで実行。ログはログ画面へ出力される 本番実行時：ログはprinttoで指定したフォルダへ出力される\n%macro derive(lib, dsn, key, where);\n    proc sort data = &lib..&dsn out = work.&dsn;\n        by &key.;\n        &where.;\n    run;\n%mend;\nMacroはlibraryにして保管・管理しておくと楽です。今回のmacro.sasはそれ自体がマクロライブラリとして機能します。 フレームワークからライブラリが読み込まれるような仕様にしています。 個別プログラムの構造化 ログクリアとヘッダーの順序問題 常識的に考えるとheaderが先である。だって”head”erだから。でも少し考えてみてもいい。\n/* パターン1 */\ndm \"log; clear;\";\n/* program name : test */\n/* author : anonymous */\n\n/* パターン2 */\n/* program name : test */\n/* author : anonymous */\ndm \"log; clear;\";\nどっちも同じ？ でも少し考えてみてもいい。もし、printtoではなくdmステートメントでログを保存していたら？後者の場合、ログからheaderが消えてしまう。どうやってログを残すかによって使えないパターンがあるので注意しよう。\nPhUSE GPPの参考から持ってきました。立派なヘッダーです。 これを作るの時間かかるんじゃない？ → こういうものはフレームワークに持たせましょう。 ちょっと工夫すると結構作れちゃったりするものです。 よく見たら進捗管理ファイル、帳票一覧、ADaM仕様書にほとんどの情報が入っている。\n/***********************************************************************\n* Project         : Sample Drug, Sample Indication,Study1\n* Program name    : sample.sas\n* Author          : smithb\n* Date created    : 20100816\n* Purpose         : Summarize demographics data for the study.\n* Revision History :\n* Date        Author      Ref     Revision (Date in YYYYMMDD format)\n* 20100818    smithb      1       Removed subjects with who have not been dosed per spec.\n***********************************************************************/"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#マクロの使用パターン",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#マクロの使用パターン",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.7 マクロの使用パターン",
    "text": "2.7 マクロの使用パターン\nマクロはいつもどうやって使う？\n/* 1. %include statement */\n%include \"macro.sas\";\n\n/* 2. Set auto compiled macro */\nFILENAME fileref 'the path to the AUTOCALL library';\nOPTIONS MAUTOSOURCE SASAUTOS=(SASAUTOS fileref);\n\n/* 3. Set stored macro */\nLIBNAME mylib 'C:¥temp';\nOPTIONS MSTORED SASMSTORE=mylib;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実践的な考察",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実践的な考察",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.1 実践的な考察",
    "text": "6.1 実践的な考察\n\n6.1.1 良かった点\n\nHeaderの記入箇所が少なくて楽\n毎回やってた設定が不要になり、ミスもなくなった\n余計な設定や処理に悩まされないので、データを見る時間などに作業時間を使えている気がする\n\n\n\n6.1.2 良くなかった点（正直な評価）\n\n簡単なプログラムのはずなんだけどやたらとコードが長い\n少しプログラムの構造が変わると、適用できない\n開発計画が大きく変わると対応できない"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#組織レベルでの戦略的価値",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#組織レベルでの戦略的価値",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.2 組織レベルでの戦略的価値",
    "text": "6.2 組織レベルでの戦略的価値\n\n6.2.1 会社としての評価\n\nやってみてもいい。\n申請や海外に提供するなど、プログラムへの要求が高くなればなるほど威力が出る\n会社として基本的なプログラムの書き方やセクションわけなどを決めてしまっても、この方法ならコスト高にならない。むしろ、いつもここにこういう事が書かれていると分かった方が開発、またはそのための教育においても有利。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#フレームワーク化の本質的な価値",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#フレームワーク化の本質的な価値",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.3 フレームワーク化の本質的な価値",
    "text": "6.3 フレームワーク化の本質的な価値\n\n6.3.1 抽象化レベルの設定\n\n6.3.1.1 高レベル抽象化（完全自動化）\n\n環境設定、ログ管理、基本的なハウスキーピング\n一度設定すれば、プログラマーは意識する必要がない\n\n\n\n6.3.1.2 中レベル抽象化（テンプレート化）\n\nプログラム構造、ヘッダー、セクション分け\n骨格は提供するが、中身はプログラマーが記述\n\n\n\n6.3.1.3 低レベル抽象化（ユーティリティ提供）\n\nよく使う処理の関数化\n呼び出すかどうかはプログラマーの判断\n\n\n\n\n6.3.2 組織的導入戦略\n\n6.3.2.1 段階的導入アプローチ\n\nPhase 1: 基盤整備：標準的なフォルダ構造とユーティリティマクロ\nPhase 2: テンプレート化：プログラムテンプレートとヘッダー標準化\nPhase 3: 自動化拡張：設定管理の自動化とバリデーション機能\nPhase 4: 最適化：継続的な改善とパターンの蓄積\n\n\n\n\n6.3.3 フレームワーク化の真の価値は：\n🎯 焦点の明確化 本当に重要な作業（データ変換ロジック、分析手法の選択）に集中できる環境の構築\n🚀 スケーラビリティの確保 個人の経験や知識に依存しない、組織として継続可能な開発体制\n🔄 継続的改善の文化 一度作って終わりではなく、常に最適化し続ける仕組み\n🤝 協働の促進 標準化されたアプローチにより、チームメンバー間の連携と知識共有の促進"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html",
    "href": "posts/statistics/2025/SQL入門1.html",
    "title": "SQL入門1",
    "section": "",
    "text": "本記事では、SASによるProc SQL Procedureについて解説する。参考文献は以下の通りである。\n\n\n\n2021年度SASユーザー総会：臨床試験のデータハンドリングとSQLプロシジャ\n2007年度SASユーザー総会：臨床試験データの加工におけるSAS/Proc SQL の活用事例：データセット併合と図表作成\n2007年度SASユーザー総会：SQL プロシジャの利用－安全性の集計を題材に－\n2016年度：データハンドリングにおけるSQLプロシジャの利活用 -PROC SQL入門ー"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#参考文献",
    "href": "posts/statistics/2025/SQL入門1.html#参考文献",
    "title": "SQL入門1",
    "section": "",
    "text": "2021年度SASユーザー総会：臨床試験のデータハンドリングとSQLプロシジャ\n2007年度SASユーザー総会：臨床試験データの加工におけるSAS/Proc SQL の活用事例：データセット併合と図表作成\n2007年度SASユーザー総会：SQL プロシジャの利用－安全性の集計を題材に－\n2016年度：データハンドリングにおけるSQLプロシジャの利活用 -PROC SQL入門ー"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点1事前ソートが不要",
    "href": "posts/statistics/2025/SQL入門1.html#利点1事前ソートが不要",
    "title": "SQL入門1",
    "section": "2.1 利点1：事前ソートが不要",
    "text": "2.1 利点1：事前ソートが不要\nData Stepの場合：\n/* 各データセットを事前にソートする必要がある */\nproc sort data=dataset1; by id; run;\nproc sort data=dataset2; by id; run;\ndata merged;\n    merge dataset1 dataset2;\n    by id;\nrun;\nProc SQLの場合：\n/* ソート不要で直接結合可能 */\nproc sql;\n    create table merged as\n    select * from dataset1 a\n    left join dataset2 b\n    on a.id = b.id;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点2併合と同時にソートが可能",
    "href": "posts/statistics/2025/SQL入門1.html#利点2併合と同時にソートが可能",
    "title": "SQL入門1",
    "section": "2.2 利点2：併合と同時にソートが可能",
    "text": "2.2 利点2：併合と同時にソートが可能\nProc SQLでは、order byを用いることにより、データセットの併合と同時にデータをソートすることが可能である。そのため、データセットの併合後にProc sortで改めてソートすることはせずに、Proc SQLのみで目的に応じた並び順にすることが可能である。\nproc sql;\n    create table result as\n    select * from dataset1 a\n    left join dataset2 b\n    on a.id = b.id\n    order by id, visit_date;  /* 結合と同時にソート */\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点3同名変数の上書き回避",
    "href": "posts/statistics/2025/SQL入門1.html#利点3同名変数の上書き回避",
    "title": "SQL入門1",
    "section": "2.3 利点3：同名変数の上書き回避",
    "text": "2.3 利点3：同名変数の上書き回避\nData Stepの問題： 併合前の2つのデータセットに同じ変数名が存在する場合、データステップでマージするとその変数名のデータは上書きされてしまう\nProc SQLの解決策：\n/* 表4.1.5のような状況での外部結合 */\nproc sql;\n    create table result as\n    select a.subject_id, a.sex as patient_sex, a.test_code, a.value,\n           b.sex as reference_sex, b.lower_limit, b.upper_limit\n    from measurement_data a\n    left join reference_data b\n    on a.test_code = b.test_code\n    and (b.sex = '.' or a.sex = b.sex);\nquit;\n基準値データセットに「性別」のデータが存在し、かつ測定値データセットの「性別」と他の異なるオブザベーションは結合データセットから削除される"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点4集計関数による個別値と平均値の比較",
    "href": "posts/statistics/2025/SQL入門1.html#利点4集計関数による個別値と平均値の比較",
    "title": "SQL入門1",
    "section": "2.4 利点4：集計関数による個別値と平均値の比較",
    "text": "2.4 利点4：集計関数による個別値と平均値の比較\n従来の方法の問題： 従来方向のデータの平均値を求めることは、SAS関数のmeanを用いることでデータステップでも可能である。しかし、オブザベーション方向のデータの平均値を求めるためには、Proc MEANSなどの別のプロシジャを用いる必要がある。また、retainステートメントを用いたオブザベーション方向の累計の計算により、データステップでもオブザベーション方向の平均値を求めることは可能であるが、個々の測定値と求めた平均値を比較するためには別工程の処理が必要である。\nProc SQLの解決策：\nproc sql;\n    create table comparison as\n    select subjid, paramcd, value,\n           mean(value) as group_mean,\n           value - mean(value) as deviation_from_mean\n    from lab_data\n    group by paramcd;\nquit;\nそれに対して、Proc SQLでは、集計するための関数を用いることで、個々の測定値とオブザベーション方向の平均値を比較することが可能となる。"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#基本構文",
    "href": "posts/statistics/2025/SQL入門1.html#基本構文",
    "title": "SQL入門1",
    "section": "3.1 基本構文",
    "text": "3.1 基本構文\n1つのデータセットを加工して、1つのデータセットを作成する場合の基本的なProc SQLの構文：他にも諸々の指定ができるが、基礎的な事項は以下の通りである。\nProc SQL ;\n    create table 作成データセット名    as\n    select      元のデータセット名.変数名1,\n                元のデータセット名.変数名2    as  変更後の変数名2\n    from        元のデータセット名\n    where       データ抽出の条件1\n    group by    グループ分け\n    having      データ抽出の条件2\n    order by    ソート変数\n;\n複数SQLステートメントのまとめ書き\nproc sql &lt;オプション&gt; ;\n    sqlステートメント1 ;\n    sqlステートメント2 ;\n    sqlステートメント3 ;\n;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#各構文要素の説明",
    "href": "posts/statistics/2025/SQL入門1.html#各構文要素の説明",
    "title": "SQL入門1",
    "section": "3.2 各構文要素の説明",
    "text": "3.2 各構文要素の説明\n\n3.2.1 create table 作成データセット名 as\n作成するデータセットの名称を定義する。\n\n\n3.2.2 select\nselect  元のデータセット名.変数名1,\n        元のデータセット名.変数名2 as 変更後の変数名2\n\n作成するデータセットに保存する変数を定義する（データステップではkeepステートメントに相当）\n元のデータセットにおける変数名を指定した後に「as」を加え、変更後の変数名を記載することで、作成するデータセットに保存する変数の変数名を変更することが可能（データステップではrenameステートメントに相当）\n基本的に作成するデータセットに保存する全ての変数を定義する必要がある\n元のデータセットに存在する全ての変数をそのまま用いる場合には「*」で代用することも可能\n定義された変数名の順でデータセットが作成されるため、変数の並び順を変更することが簡単\n\n\n\n3.2.3 from 元のデータセット名\n元のデータセットを指定する（データステップではsetステートメントに相当）。\n\n\n3.2.4 where データ抽出の条件1\n元のデータセットからデータを抽出する条件を指定する。\n\n\n3.2.5 group by グループ分け\n集計する場合などの状況においてグループ分けの条件を設定する。\n\n\n3.2.6 having データ抽出の条件2\n元のデータセットからデータを抽出する条件を指定する。集計するための関数を利用して条件を指定する場合には、「where」ではなく「having」で指定する。\n\n\n3.2.7 order by ソート変数\nデータのソートに用いる変数を指定する。Proc SQLでは、データセット作成と同時にデータをソートすることが可能である。"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#data-stepとの比較",
    "href": "posts/statistics/2025/SQL入門1.html#data-stepとの比較",
    "title": "SQL入門1",
    "section": "3.3 Data Stepとの比較",
    "text": "3.3 Data Stepとの比較\n上記のProc SQLで作成したプログラムをデータステップおよびProc SQL以外のプロシジャで作成する場合：\nData 作成データセット名 ;\n    set 元のデータセット名 ;\n    where       データ抽出の条件1 ;\n    rename      変数名2 = 変更後の変数名2 ;\n    keep        変数名1  変更後の変数名2 ;\n    if          データ抽出の条件2 ;\nrun ;\n\nProc sort data=作成データセット名 ;\n    by ソート変数 ;\nrun ;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#proc-sqlの利点",
    "href": "posts/statistics/2025/SQL入門1.html#proc-sqlの利点",
    "title": "SQL入門1",
    "section": "3.4 Proc SQLの利点",
    "text": "3.4 Proc SQLの利点\n\n複数の工程を1工程にまとめられる：プログラム作成においてエラーを少なくするという利点がある\n変更箇所の特定が容易：変更箇所を見つけやすいため、変数名の変更や条件の変更を行なう際に変更漏れを少なくするという利点がある\n統一された記法：Proc SQLでは「Proc SQL;」～「quit」、データステップでは「Data」～「run;」、Proc SQL以外のプロシジャでは「Proc」～「run;」を1工程と表現する"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html",
    "href": "posts/statistics/2025/サンプルサイズ設計.html",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "",
    "text": "本書は、頻繁に利用されるサンプルサイズ設計SASプログラムをまとめます。実務において、本記事のSASプログラムをコピーして利用することのみを念頭に置いています。数学的な導出は省略します。"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "3.1 2値アウトカム",
    "text": "3.1 2値アウトカム\n単群試験で2値アウトカムの場合、サンプルサイズは、P0（閾値奏効割合）、P1（期待奏効割合）、α（第一種の過誤確率）、β（第二種の過誤確率）を事前に仮定することで計算できます。閾値奏効割合とは、これ以上の奏効割合がなければ治療効果がない（開発中止をしたい）と考えられる割合のことです。期待奏効割合とは、治療効果があると考えられる割合（次相に進みたい程度）のことです。これらの割合は臨床仮説や先行研究に基づいて決定するため、試験統計家がコメントすることはあまりありません。ICHガイドラインに準じて、SASプログラムは全て両側検定として両側有意水準5%としています。これは、なお、ICH E9では以下のような記載があります。すなわち、GCP準拠の治験においては原則として以下の記載に準じて試験計画を考える必要があります。\n「規制上の観点から、本ガイドラインの施行に伴い、原則として片側仮説を検証する場合は2.5％、両側仮説の場合は5％とすることとした。」\nなお、ICH E9にはQ＆AがありQ2で有意水準について言及されている。\n\n\n\n\n\n\nQ2\n\n\n\n片側検定又は両側検定のどちらを用いるか、またそこでの有意水準をいくらにすべき かを、優越性試験と非劣性試験のそれぞれで説明願いたい。\n(答) ガイドラインでは、同等性を示す場合には両側信頼区間、非劣性試験では片側信頼 区間による解析を行うことが記載されているが、一般には推測を片側と考えるか両側 と考えるかには議論があり一概に決められるものではないとされている。また、有意 水準についても、個々の試験において適切な基準を設定すべきである旨の記載がある。 しかしながら、推論を片側とするか両側とするかにより統計的な判断に大きな差異 が生じることは規制上の観点から望ましくない。また、一方で、臨床試験における有 効性の評価では、検定により有意差があるか否かを判断するだけでなく、試験治療効 果の大きさ(比較群間の差の大きさ)がどの程度であるかを推定することも重要である。 そこで、今後は、検証的試験においては、仮説の検定においてどちらの方法を用いる 場合であっても、効果の推定には95％信頼係数の両側信頼区間を用い、検定の際の有水準は、これによる判断との整合性を図るため、優越性試験、非劣性試験のいずれにおいても、片側2.5％又は両側5％とすることを原則とする。用量反応試験についても、用量反応性を示すことにより薬剤の有効性を検証するような試験においては上記と同様である。ただし、適切な説明ができるのであれば、より強固な有効性の根拠を 示すために有意水準を厳しくする、稀少疾病用医薬品にみられる例のように十分な被 験者を集めることが困難な場合は有意水準を緩くする、などの措置をとってもよい。 なお、生物学的同等性試験については、「後発医薬品の生物学的同等性試験ガイドライン(平成9年12月22日医薬審第487号)」により、90％信頼係数の両側信頼区間を用いるとされているが、臨床効果を指標に標準製剤との同等性を検証しようとする場合(臨床的同等性試験)は、上記と同様に95％信頼係数の両側信頼区間を用いることを原則とする。\n\n\n　特に重要なのは、「適切な説明ができるのであれば、より強固な有効性の根拠を示すために有意水準を厳しくする、稀少疾病用医薬品にみられる例のように十分な被験者を集めることが困難な場合は有意水準を緩くする、などの措置をとってもよい。」の記載である。すなわち、両側10%や片側5%も、きちんと説明をして納得していただければ許容されるということである。これらの【5%か2.5%か】の議論については、以下のJCOGプロトコールマニュアルにも記載がある。\n\n\n\n\n\n\nJCOGプロトコール\n\n\n\n国立がん研究センターでの第2相相当の臨床試験では、片側検定を用いることもありえます。これは、標準治療 vs 試験治療であり、少なくとも試験治療が標準治療より劣っているとは考えておらず、片側検定の方が適切と考えられるからです。 JCOGのプロトコールマニュアルのURLは以下です。 JCOGプロトコールマニュアル\n\n\n試験計画時の例：\n\np0 = 0.1（閾値奏効割合）\np1 = 0.3（期待奏効割合）\nα = 0.05（第一種の過誤、片側）\nβ = 0.2（第二種の過誤）\n\n以下は、正規近似を用いたサンプルサイズ計算の例です。 連続修正は行いません。正規近似に基づく症例数設計では、H0におけるp0を用いて分散が計算されている点に注意してください。数理統計学を学ばれた方からみるとスコア検定に基づく方法に相当します。Wald検定に基づく例数設計とするとp1を用いて分散が計算されることになります。中間解析を勉強するとWald検定に基づく方法でサンプルサイズ設計がされることもあると気付きます。中間解析では検定統計量間の相関を考えるため、漸近正規性を仮定したサンプルサイズ設計をするためWald型の統計量を利用します。\n　実務上では、抗がん剤の単群試験では中間解析を事前に規定して、2項分布に基づいてに基づいて無効中止や有効中止を考慮したくなる場面が多いです。それは患者さんにとっての倫理性や開発戦略の観点からも重要な要素です。中間解析を行う場合、無効中止や有効中止の基準を事前に規定する必要があります。無効中止や有効中止の基準は、試験の目的やデザインに応じて異なるため、試験統計家と相談して決定することが重要です。無効中止や有効中止の基準を事前に規定することで、試験の透明性が向上し、倫理的な問題を回避することができます。そのような場合は、単純な2値データの割合のサンプルサイズ設計では実施できず、適切な試験統計家がSimonの2段階デザインやFlemingの2段階デザインを用いて例数設計がなされます。また、単群試験において、ベイズ流の例数設計も提案されていることから、ベイズ流例数設計も考慮していただきたい。なお、中間解析やベイズ流例数設計は常に必要ではなく、SASでの実装はシンプルではないため、ここでは割愛します。別記事で説明します。\n通常の単群試験の例数設計は以下のように行います。以下のSASプログラムは、対照群のリスクp0 = 0.1、実験群のリスクp1 = 0.3、リスク差 = 0.2を想定しています。なお、sides = 2は両側検定を意味します。片側検定を行う場合は、sides = 1としてください。\nproc power;\nonesamplefreq test=z\n    method = normal\n    sides = 2\n    alpha = 0.05\n    nullproportion = 0.1\n    proportion = 0.3\n    ntotal = .\n    power = 0.8;\nrun;\n対象者数が多い場合（シミュレーションによる確認要です）、上記の正規分布に基づく方法でも良いと考えます。しかし、一般的に2項分布による正確な検定に基づく症例数設計を利用することが標準的な方法です。理由は正規近似による例数設計が二項分布の中心極限定理を用いているため、あくまで対象者数が十分多い状況における中心極限定理を仮定しているためです。中心極限定理を利用せず、2項分布を用いて症例数設計をするSASプログラムは以下です。\n先ほどと異なり、test = exactを指定しています。これにより、2項分布に基づく正確な検定が行われます。これにより、サンプルサイズ計算がより正確になります。また、plotオプションを使用して、サンプルサイズに対する検出力の変化を視覚化しています。これにより、必要なサンプルサイズをより直感的に理解できます。\nproc power;\n    onesamplefreq test=exact\n        sides = 2\n        alpha = 0.05\n        nullproportion = 0.1\n        proportion = 0.3\n        ntotal = 30.\n        power = .;\n        plot x = n min =2 max = 100 step = 1 yopts = (ref  = 0.8);\nrun;\nExact法に基づく症例数設計では、検出力は単調増加にならず、test = normalと異なり、N = xxのように数値が出力されません。そのため、SASの出力を結果を見ながら、目標とする検出力を満たす最小の整数値 or 目標とする検出力を満たす最大の整数値とします。個人的には、より保守的であるため後者を推奨します。実際、より大きなサンプルサイズを選ぶことで、検出力の目標値をより確実に達成できる可能性が高まります。ただし、リソースの制約がある場合は、目標検出力を満たす最小の症例数を選ぶことも実用的な選択肢となり得ます。どちらのアプローチを取るかは、研究の目的やリソースの制約によって相談の上、決定してください。\n\n3.1.1 参考文献\n\nOneSampleFreq Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#連続量アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#連続量アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.1 連続量アウトカム",
    "text": "4.1 連続量アウトカム\n連続量アウトカムの場合、サンプルサイズは以下の式で計算できます。 以下では優越性を示す検証的試験を想定しています。 twosamplemeans test = diffを用いて、2群間の平均値の差を検定する方法を想定しています。以下では、対照群の平均値μ0 = 0、実験群の平均値μ1 = 0.5、標準偏差σ = 1を想定しています。\nproc power;\n    twosamplemeans test=diff\n        meandiff = 0.5\n        stddev = 1\n        alpha = 0.05\n        power = 0.8\n        nptotal = .;\nrun;\n複数の状況をまとめて計算する場合は、以下のようにします。\nproc power;\n    twosamplemeans test=diff\n        meandiff = 0.5 , 1 , 1.5\n        stddev = 1 , 2 , 3\n        alpha = 0.05\n        power = 0.8\n        ntotal = .;\nrun;\n　平均値の差の検定は一般的であり、連続量のアウトカムを用いた試験では最も多く利用される方法です。平均値の差の検定は、通常、正規分布に従うと仮定される連続量データに適用されます。連続量アウトカムにおける経時測定データのサンプルサイズ設計が求められることもあるかと思います。その場合、最終観察時点における平均値の差を検定する方法として上記のプログラムを利用することが保守的で望ましいと考えます。例数設計としてはt検定に基づきより保守的なサンプルサイズ設計をする。統計解析においては、共分散分析やMMRMなどの同じEstimandを推定する方法で、より検出力の高い解析方法を適用することが治験の分野では求められると考えます。\n\n4.1.1 参考文献\nTwoSampleMeans Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム-1",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム-1",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.2 2値アウトカム",
    "text": "4.2 2値アウトカム\n2値アウトカムの場合、サンプルサイズは以下の式で計算できます。リスク差（割合の差）に基づいて優越性を検討することを想定しています。p0を対照群のリスク、p1を実験群のリスクとします。リスク差は、対照群のリスクp0に基づいて計算されるため、対照群のp0を指定する必要があります。以下では、対照群のリスクp0 = 0.1、実験群のリスクp1 = 0.3、リスク差 = 0.2を想定しています。\n\np0 = 0.1（対照群の和依頼）\np1 = 0.3（実験群の割合）\nα = 0.05（第一種の過誤、両側）\nβ = 0.2（第二種の過誤）\n\nSASプログラムは以下となります。ここでは、対照群のリスク及びリスク差を指定している。リスク差は、対照群のp0に基づいて計算されるため、対照群のp0を指定する必要があります。\nproc power;\ntwosamplefreq test=pchi\n    sides = 2\n    alpha = 0.05\n    refproportion = 0.1\n    proportiondiff = 0.2\n    npergroup = .\n    power = 0.8;\nrun;\n\n4.2.1 参考文献\n\nTWOSAMPLEFREQ Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#生存時間アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#生存時間アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.3 生存時間アウトカム",
    "text": "4.3 生存時間アウトカム\n生存時間アウトカムの場合、サンプルサイズは以下の式で計算できます。以下では優越性を示す検証的試験を想定しています。アウトカムはハザード比として、生存時間解析のノンパラメトリック検定（ログランク検定等）を前提とした例数設計を想定する。例えば生存時間アウトカムとして生存割合（死亡、生存）を前提として例数設計を考える場合、本節に基づく方法での例数設計も考えられるが、より保守的に2値データに基づく例数設計を行うことが望ましい場合もありえます。この違いについては、別記事で説明します。生存時間の例数設計については、SAS user総会のSASプロシジャを用いた生存時間データに対する例数設計の変革が参考になります。\nSASのtwosamplesurvival statementではLakatosの方法が採用されています。これは区分指数分布を前提としており解析的にN = xxの形で表すことはできません。教育的な立場だと、解析的にN = xxの形で表すことができる方法としてFreedmanの方法やSchoenfeldの方法がありますが、上記のSASユーザー総会の資料によると、Lakatosの方法の方が性能が良いことが報告されているそうです。実務上もproc power procedureを用いて、再現可能な状態で例数設計を行うことが望ましいので、基本的にLakatosの方法を採用します。\n生存時間アウトカムに基づく症例数設計では以下のような情報が必要です。特徴的なのは、登録期間とフォローアップ期間の情報が必要な点です。登録期間は、患者さんを試験に登録するための期間であり、フォローアップ期間は、患者さんを追跡するための期間です。これらの情報は、試験のデザインや目的に応じて異なるため、試験統計家と相談して決定することが重要です。 なお、通常登録は一様に登録されると仮定され、一様分布を仮定することがデフォルトです。\n\nS_c(3) = 0.3（対照群Cの3年あたりの生存率）\nS_a(2) = 0.2（実験群Aの3年あたりの生存率）\n登録期間：A = 3年\nフォローアップ期間：F = 2年\nα = 0.05（第一種の過誤、両側）\nβ = 0.2（第二種の過誤）\n\nSASでは以下のように実行します。ここでは、対照群の生存率S_c(3) = 0.3、実験群の生存率S_a(2) = 0.2を想定しています。登録期間は3年、フォローアップ期間は2年としています。これにより、試験のデザインや目的に応じたサンプルサイズを計算することができます。\nproc power;\n    twosamplesurvival test = logrank\n    curve(\"Control\") = 3:0.3\n    curve(\"Experimental\") = 3:0.2\n    groupsurvival = \"Control\" | \"Experimental\"\n    groupweights = (1 1)\n    accrualtime = 3 \n    followuptime = 2\n    ntotal = .\n    power = 0.8\n    alpha = 0.05\n    sides = 2;\nrun;\n通常、生存時間の例数設計で3年間での生存割合20%や、30%ということを仮定できる状況は多くないと思います。例えば第2相試験では1年間の追跡しかしていない場合に3年生存割合を仮定することは難しいです。そこで、通常は生存時間Tが指数分布に従うとして以下の式を用いてハザードを基にサンプルサイズ設計は有用です。ただし、ハザード比は生存時間の分布に依存するため、注意が必要です。生存時間Tが指数分布に従う場合、ハザード比は以下のように表されます。\n\nS(t) = 1-F(t) = exp(-λt) ⇔ λ = -\\frac{log(S(t))}{t}\n\nこの関係を用いて、ある時点tとその時点のKM推定量の結果を用いて各群のハザードを指定してサンプルサイズ計算をする方法は以下となります。\nproc power;\n    twosamplesurvival test = logrank\n    groupsurvexphazards = (0.05 0.01)\n    groupweights = (1 1)\n    accrualtime = 3 \n    followuptime = 2\n    ntotal = .\n    power = 0.8\n    alpha = 0.05\n    sides = 2;\nrun;\n他にも、中央生存時間を用いて計算することもできる。これも生存時間アウトカムに指数分布を仮定すると簡単に示せます。\n\nS(1/2) = exp(-λt) ⇔ λ = -\\frac{log(S(1/2))}{t}\n\nこの関係を用いて、KM推定量の結果を用いて各群の中央生存時間からハザードを推定することもできる。いずれの方法もTに指数分布を仮定している。\n\n4.3.1 参考文献\n\nTwoSsampleSurvival Statement"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html",
    "href": "posts/statistics/2025/解析用データセット仕様書.html",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "臨床試験や統計解析プロジェクトにおいて、解析用データセット仕様書は分析の設計図とも言える重要な文書です。本記事では、実用的な解析用データセット仕様書の構成と記載内容について、主要な3つのデータセット（ADSL、ADLB、ADTTE）を例に解説し、さらに仕様書に基づくデータセット作成とバリデーションプロセスについても説明します。探索的解析であっても事前に解析用データセット仕様書を作成することを推奨する。\n\n\n\n\nSASユーザー総会2014年度：SASとExcelを用いたCDISCADaM標準における作業効率化の試み（武田薬品、高浪さん：PDFのP351）\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬：）\nSASユーザー総会2013年度：ライブラリ参照と名前の定義を利用して EXCELファイルへの柔軟なデータ入出力を実現する 解析結果のレポーティングからセルオートマトンまで\nSASユーザー総会2010年度：“Standard Template Programs”の開発\n生存時間解析用ADaMデータセット（ADTTE）のソースコード紹介"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#はじめに",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "臨床試験や統計解析プロジェクトにおいて、解析用データセット仕様書は分析の設計図とも言える重要な文書です。本記事では、実用的な解析用データセット仕様書の構成と記載内容について、主要な3つのデータセット（ADSL、ADLB、ADTTE）を例に解説し、さらに仕様書に基づくデータセット作成とバリデーションプロセスについても説明します。探索的解析であっても事前に解析用データセット仕様書を作成することを推奨する。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#参考文献",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "SASユーザー総会2014年度：SASとExcelを用いたCDISCADaM標準における作業効率化の試み（武田薬品、高浪さん：PDFのP351）\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬：）\nSASユーザー総会2013年度：ライブラリ参照と名前の定義を利用して EXCELファイルへの柔軟なデータ入出力を実現する 解析結果のレポーティングからセルオートマトンまで\nSASユーザー総会2010年度：“Standard Template Programs”の開発\n生存時間解析用ADaMデータセット（ADTTE）のソースコード紹介"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#例",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#例",
    "title": "解析用データセット仕様書",
    "section": "2.1 例",
    "text": "2.1 例\nAnalysis Dataset Metadata シート：データセットの一覧\n\n\n\n\n\n\n\n\n\n\n\n\nDataset Name\nDataset Description\nDataset Location\nDataset Structure\nKey Variables of Interest\nClass of Dataset\nDocumentation\n\n\n\n\nADSL\nSubject Population, demographic and baseline characteristics\nADSL.xpt\none record per subject\nUSUBJID\nADSL\nSAP, ADSL.sas\n\n\nADAE\nAdverse Event Analysis Dataset\nADAE.xpt\none record per subject per each AE recorded\nUSUBJID, AESEQ\nADAE\nADAE.sas\n\n\nADEF\nAnalysis Dataset for Efficacy Disease Parameters\nADEF.xpt\n1 record per subject parameter\nUSUBJID, PARAMCD\nBDS\nDictionary used in MedDRA VOL.X\n\n\n\nADSL シート：ADSL データセットの変数一覧（ADAE、ADEF も同様に作成）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist/Controlled Term\nCodelist Name\nOrigin\nSource/Derivation\n\n\n\n\nADSL\nSTUDYID\nStudy Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.STUDYID\n\n\nADSL\nUSUBJID\nUnique Subject Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.USUBJID\n\n\nADSL\nSUBJID\nSubject Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.SUBJID\n\n\nADSL\nSITEID\nStudy Site Identifier\ntext\n200\n$3\n\n\nPredecessor\nDM.SITEID\n\n\nADSL\nAGE\nAge\ninteger\n8\n8.0\nAGEU\nAGEU\nPredecessor\nDM.AGE\n\n\nADSL\nAGEU\nAge Units\ntext\n200\n$20\nAGEU\nAGEU\nPredecessor\nDM.AGEU\n\n\nADSL\nSEX\nSex\ntext\n1\n$1\nSEX\nSEX\nPredecessor\nDM.SEX\n\n\nADSL\nSEXN\nSex (N)\ntext\n8\n8.0\nSEXN\nSEXN\nPredecessor\n1=F,FEMALE=M,2=M\n\n\nADSL\nRACE\nRace\ntext\n200\n$200\nRACE\nRACE\nPredecessor\nDM.RACE\n\n\nADSL\nRACEN\nRace (N)\ninteger\n8\n8.0\nRACEN\nRACEN\nAssigned\n1=DM.RACE=“ASIAN”\n\n\n\nCodelist シート：コードリストの一覧\n\n\n\nName\nCodeValue\nCodeText\nData Type\n\n\n\n\nSEX\nF\nFemale\ntext\n\n\nSEX\nM\nMale\ntext\n\n\nSEXN\n1\nMale\ninteger\n\n\nSEXN\n2\nFemale\ninteger\n\n\nAGEU\nYEARS\n\ntext\n\n\nARM\nDrug A\nDrug A\ntext\n\n\nARM\nDrug B\nDrug B\ntext\n\n\nARM\nScreen Failure\nScreen Failure\ntext\n\n\nTRT\nDrug A\nDrug A\ntext\n\n\nTRT\nDrug B\nDrug B\ntext\n\n\nTRTN\n1\nDrug A\ninteger\n\n\nTRTN\n2\nDrug B\ninteger\n\n\n\nValue List シート：解析パラメータの一覧\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDataset Name\nVariable Name\nVariable Label\nParameter_variable\nComparator\nParameters\nVariable Type\nLength\nDisplay Format\n\n\n\n\n\nADEF\nAVAL\nAnalysis Value\nPARAMCD\nIN\nHEAL\ninteger\n8\n1.0\n\n\n\nAnalysis Results Metadata シート：解析結果メタデータ\n前向きの臨床試験であれば、ここまでAnalysis Result Metadataを作成することは可能であろう。ただし、探索的にデータを解析する場合は事前に解析方法を定義することは難しいように思われる。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay Identifier\nDisplay Name\nAnalysis\nPopulation\nDataset\nParameter\nReason\nSelection Criteria\nDocumentation\nProgramming Statements\n\n\n\n\nTable14.2.1\n主要評価項目\nFAS\nADEFF\nAVAL\nPre-specified in SAP\nFASFL=“Y” and PARAMCD = 1 and AVISTN = 4\nSAP\nproc format; value TRTFMT 1 = “Drug A” 2 = “Drug B”; run; proc freq data=ADSL ADEF; where FASFL = “Y” and PARAMCD = 1; table AVISTN　TRT AVAL/chisq nocol nopct format TRT01N TRT1FMT.;run;\n\n\nTable2\n副次評価項目\nFAS\nADEFF\nAVAL\nPre-specified in SAP\nPPROTFL=“Y” and PARAMCD = 1 and AVISTN = 4\nSAP\nproc format; value TRTFMT 1 = “Drug A” 2 = “Drug B”; run; proc freq data=ADSL ADEF; where PPROTFL = “Y” and PARAMCD = 1; table AVISTN TRT AVAL/chisq nocol nopct format TRT01N TRT1FMT.;run;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#解析用データセット仕様書の基本構成",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#解析用データセット仕様書の基本構成",
    "title": "解析用データセット仕様書",
    "section": "2.2 解析用データセット仕様書の基本構成",
    "text": "2.2 解析用データセット仕様書の基本構成\n解析用データセット仕様書は、主に以下の要素で構成されます：\n\n表紙・改訂履歴：文書管理情報\nDataset Definition：データセットの基本定義\nSpecification：変数の詳細仕様\nADLB_PARAM / ADTTE_PARAM：パラメータ定義表（ADLB、ADTTE用）\nCodelist：コード値の定義\n\nこれらの情報をExcelファイルの複数シートに整理することで、管理しやすく実用的な仕様書が作成できます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#specificationシートの構成",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#specificationシートの構成",
    "title": "解析用データセット仕様書",
    "section": "2.3 Specificationシートの構成",
    "text": "2.3 Specificationシートの構成\n変数仕様を記載するSpecificationシートでは、以下の項目を含めることを推奨します：\n\n2.3.1 基本項目\n\nVarnum：変数番号（並び順）\nDomain：データセット名（ADSL、ADLB、ADTTE等）\nVariable Name：変数名\nVariable Label：変数ラベル\nType：データタイプ（Char/Num）\nLength：変数長\nDisplay Format：表示フォーマット\nCodelist：コードリスト参照名\nCore：必須度（Req=必須、Perm=任意、Cond=条件付き）\nDefinition：定義・導出方法\n\n\n\n2.3.2 ADSLのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADSL\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADSL\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADSL\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADSL\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADSL\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADSL\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADSL\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADSL\nTRT01PN\nPlanned Treatment for Period 1 (N)\nNum\n8\n\n\nReq\nDerived from TRT01P\n\n\n9\nADSL\nTRT01AN\nActual Treatment for Period 1 (N)\nNum\n8\n\n\nReq\nDerived from TRT01A\n\n\n10\nADSL\nFASFL\nFull Analysis Set Flag\nChar\n1\n\nNYFL\nReq\nExternal derivation\n\n\n\n\n\n2.3.3 ADLBのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADLB\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADLB\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADLB\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADLB\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADLB\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADLB\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADLB\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADLB\nPARAM\nParameter\nChar\n200\n\n\nReq\nParameter description\n\n\n9\nADLB\nPARAMCD\nParameter Code\nChar\n8\n\n\nReq\nParameter short name\n\n\n10\nADLB\nPARAMN\nParameter (N)\nNum\n8\n\n\nReq\nNumeric representation of PARAM\n\n\n11\nADLB\nAVISIT\nAnalysis Visit\nChar\n200\n\n\nReq\nAnalysis visit description\n\n\n12\nADLB\nAVISITN\nAnalysis Visit (N)\nNum\n8\n\n\nReq\nNumeric representation of AVISIT\n\n\n13\nADLB\nAVAL\nAnalysis Value\nNum\n8\n\n\nReq\nNumeric analysis value\n\n\n14\nADLB\nAVALC\nAnalysis Value (C)\nChar\n200\n\n\nCond\nCharacter analysis value\n\n\n15\nADLB\nBASE\nBaseline Value\nNum\n8\n\n\nPerm\nBaseline analysis value\n\n\n16\nADLB\nBASEC\nBaseline Value (C)\nChar\n200\n\n\nPerm\nBaseline character value\n\n\n17\nADLB\nCHG\nChange from Baseline\nNum\n8\n\n\nPerm\nAVAL - BASE\n\n\n18\nADLB\nPCHG\nPercent Change from Baseline\nNum\n8\n\n\nPerm\n((AVAL-BASE)/BASE)*100\n\n\n19\nADLB\nAVALCAT1\nAnalysis Value Category 1\nChar\n200\n\n\nPerm\nCategorization of AVAL\n\n\n20\nADLB\nAVALCAT1N\nAnalysis Value Category 1 (N)\nNum\n8\n\n\nPerm\nNumeric representation of AVALCAT1\n\n\n21\nADLB\nPCHGCAT1\nPercent Chg from Baseline Category 1\nChar\n200\n\n\nPerm\nCategorization of PCHG\n\n\n22\nADLB\nPCHGCAT1N\nPercent Chg from Baseline Category 1 (N)\nNum\n8\n\n\nPerm\nNumeric representation of PCHGCAT1\n\n\n\n\n\n2.3.4 ADTTEのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADTTE\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADTTE\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADTTE\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADTTE\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADTTE\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADTTE\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADTTE\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADTTE\nPARAM\nParameter\nChar\n200\n\n\nReq\nAnalysis parameter description\n\n\n9\nADTTE\nPARAMCD\nParameter Code\nChar\n8\n\n\nReq\nAnalysis parameter short name\n\n\n10\nADTTE\nPARAMN\nParameter (N)\nNum\n8\n\n\nReq\nNumeric representation of PARAM\n\n\n11\nADTTE\nAVAL\nAnalysis Value\nNum\n8\n\n\nReq\nTime to event in days\n\n\n12\nADTTE\nSTARTDT\nTime to Event Origin Date\nNum\n8\ne8601da.\n\nReq\nAnalysis start date\n\n\n13\nADTTE\nADT\nAnalysis Date\nNum\n8\ne8601da.\n\nReq\nEvent or censoring date\n\n\n14\nADTTE\nCNSR\nCensor\nNum\n8\n\n\nReq\nCensoring flag (0=event, 1=censor)\n\n\n15\nADTTE\nEVNTDESC\nEvent or Censoring Description\nChar\n200\n\n\nPerm\nDescription of event or censoring\n\n\n16\nADTTE\nSRCDOM\nSource Data\nChar\n8\n\n\nPerm\nSource domain\n\n\n17\nADTTE\nSRCVAR\nSource Variable\nChar\n8\n\n\nPerm\nSource variable\n\n\n18\nADTTE\nSRCSEQ\nSource Sequence Number\nNum\n8\n\n\nPerm\nSource sequence number"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#paramシート",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#paramシート",
    "title": "解析用データセット仕様書",
    "section": "2.4 PARAMシート",
    "text": "2.4 PARAMシート\nADLB、ADTTEなどのBDS形式データセットでは、パラメータの定義情報を管理するための専用シートを作成します。\n\n2.4.1 ADLB_PARAMシート例\n\n\n\nPARAM\nPARAMCD\nPARAMN\nAVAL\n\n\n\n\nHbA1c(%)\nHBA1C\n1\ninput(LABデータ)\n\n\nBlood glucose (mg/dL)\nGLU\n2\ninput(LABデータ)\n\n\nBUN (mg/dL)\nBUN\n3\ninput(LABデータ)\n\n\nCreatinine (mg/dL)\nCREAT\n4\ninput(LABデータ)\n\n\nALT (U/L)\nALT\n5\ninput(LABデータ)\n\n\n\n\n\n2.4.2 ADTTE_PARAMシート例\n\n\n\n\n\n\n\n\n\nPARAM\nPARAMCD\nPARAMN\nAVAL\n\n\n\n\nWeight/Waist Circumference Loss\nWTWCLOSS\n1\nADT - STARTDT + 1\n\n\nOverall Survival\nOS\n2\nADT - STARTDT + 1\n\n\nProgression Free Survival\nPFS\n3\nADT - STARTDT + 1\n\n\nTime to Progression\nTTP\n4\nADT - STARTDT + 1"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#code-listのsheetについて",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#code-listのsheetについて",
    "title": "解析用データセット仕様書",
    "section": "2.5 Code ListのSheetについて",
    "text": "2.5 Code ListのSheetについて\nProc FormatでFormatを作るvalueとLabelを事前に仕様書に用意しておく。\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo.\nCodelist_Name\nValue\nLabel\nType\n説明\nSynonym\n備考\n\n\n\n\n1\nSEX\nM\nMale\nChar\n男性\n男\n\n\n\n2\nSEX\nF\nFemale\nChar\n女性\n女\n\n\n\n3\nSEX\nU\nUnknown\nChar\n不明\n未知\n\n\n\n4\nSEXN\n1\n男性\nNum\n男性\nMale\n\n\n\n5\nSEXN\n2\n女性\nNum\n女性\nFemale\n\n\n\n6\nNYFL\nY\nYes\nChar\nはい\nあり\n\n\n\n7\nNYFL\nN\nNo\nChar\nいいえ\nなし\n\n\n\n8\nAGEU\nYEARS\nYears\nChar\n年\n年\n\n\n\n9\nAGEU\nMONTHS\nMonths\nChar\n月\nヶ月"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#adlbデータセットの重要な変数",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#adlbデータセットの重要な変数",
    "title": "解析用データセット仕様書",
    "section": "2.6 ADLBデータセットの重要な変数",
    "text": "2.6 ADLBデータセットの重要な変数\n\n2.6.1 解析値とカテゴリ変数\nADLBでは数値解析値（AVAL）に基づいて、様々なカテゴリ変数を作成します：\n\n2.6.1.1 AVALCAT1 / AVALCAT1N\n解析値のカテゴリ化変数で、例えば正常範囲の判定などに使用： - “NORMAL” / “ABNORMAL” - “LOW” / “NORMAL” / “HIGH”\n\n\n2.6.1.2 PCHGCAT1 / PCHGCAT1N\nベースラインからの変化率のカテゴリ化変数： - “&gt;30% increase” / “±30%” / “&gt;30% decrease”\n\n\n\n2.6.2 時点変数（AVISIT / AVISITN）\n解析用の時点定義で、スケジュール通りの時点名： - “Baseline” (AVISITN=0) - “Week 4” (AVISITN=4) - “Week 12” (AVISITN=12) - “End of Treatment” (AVISITN=99)"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#adtteデータセットの詳細",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#adtteデータセットの詳細",
    "title": "解析用データセット仕様書",
    "section": "2.7 ADTTEデータセットの詳細",
    "text": "2.7 ADTTEデータセットの詳細\n\n2.7.1 ADTTEの特徴\nADTTEは生存時間解析用のデータセットで、以下の特徴があります：\n\n1被験者1パラメータにつき1レコードの構造\n事象の発生時間または打ち切り時間を記録\n複数の解析エンドポイントを1つのデータセットで管理\n\n\n\n2.7.2 ADTTE作成時の重要な考慮事項\n\n2.7.2.1 1. 事象の優先順位\n複数の事象や打ち切りが同日に発生した場合の優先順位を明確に定義する必要があります。\n\n\n2.7.2.2 2. AVALの計算方法\nAVALは通常、以下の式で計算されます：\nここで： - STARTDT：解析開始日（通常は治療開始日：ADSL.TRTSDT） - ADT：解析日（事象発生日または打ち切り日） - +1：0日目を避けるための調整\n\n\n2.7.2.3 3. 事象データの取得元\n\n事象発生：ADVS.ADTから日付を取得\n打ち切り：ADSL.EOSDTから日付を取得\n\n\n\n2.7.2.4 4. CNSRフラグの設定\n\nCNSR=0：事象発生\nCNSR=1：打ち切り\n\n\n\n2.7.2.5 5. ソースデータの追跡（SRCDOM, SRCVAR, SRCSEQ）\nADTTEでは元データの追跡可能性が重要です：\n事象採用時： - SRCDOM=“ADVS” - SRCVAR=“ADT” - SRCSEQ=ADVS.ASEQ\n打ち切り時： - SRCDOM=“ADSL” - SRCVAR=“EOSDT” - SRCSEQ=（ブランク）\n\n\n\n2.7.3 ADTTEプログラミングのポイント\n\nデータセットの組み合わせ：複数のデータセット（ADSL、ADVS等）を適切に結合\n日付の妥当性チェック：論理的に矛盾する日付の検出と処理\n追跡可能性の確保：各レコードの導出元を明確に記録\n複数事象の処理：同一被験者で複数の解析パラメータを生成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#データセット作成プロセス",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#データセット作成プロセス",
    "title": "解析用データセット仕様書",
    "section": "2.8 データセット作成プロセス",
    "text": "2.8 データセット作成プロセス\n\n2.8.1 仕様書に基づくプログラム作成\n解析用データセット仕様書を読み込み、Specificationシートの定義に従ってSASプログラムを作成します。ADxx_Conversionシートを参照してパラメータ変換処理も実装します。まずは、プロトコール、統計解析計画書、図表計画書、Rawデータ/SDTM仕様書を基に、解析用データ仕様書をテンプレートを基に手作業で作成する。ここは泥臭いが、手作業でやるしかない。\n\n\n2.8.2 チェックリストの作成\n解析用データセット仕様書について、事前に組織内で規定されているチェックリストに基づいて、目視チェックをする。ここが人的作業であるためミスが起こりえる！"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#section",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#section",
    "title": "解析用データセット仕様書",
    "section": "2.9 ",
    "text": "2.9"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html",
    "title": "解析用データセット作成の流れ2",
    "section": "",
    "text": "本記事では、以下の私のブログを踏まえて、より具体的な解析データセット作成の流れをまとめていく。\n\n\n\n\n\n\n\n\n\n\n\n\n\n坂本航太\n\n\n2025/06/14\n\n\n\n\n\n\n\n\n\n\n\n\n個人的な解析データセット作成方法をまとめます。\n\n\n\n坂本航太\n\n\n2025/06/14\n\n\n\n\n\n\n一致なし\n\n\n\n\nPharmaSUG2010 - Paper AD16 Automating the Link between Metadata and Analysis Dataset Misha Rittmann, Octagon Research Solutions, Inc., Wayne, PA\nPharmaSUG2010 - Paper TT06 SAS Programming Techniques for Manipulating Metadata on the Database Level Chris Speck, PAREXEL International, Durham, NC\nPharmaSUG2011 – Paper CD17 Making a List, Checking it Twice (Part 1): Techniques for Specifying and Validating Analysis Datasets\nPharmaSUG2011 - Paper CD12ADaM Standard Naming Conventions are Good to HaveChristine Teng, Merck Sharp & Dohme Corp, Rahway, NJ"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#参考文献",
    "title": "解析用データセット作成の流れ2",
    "section": "",
    "text": "PharmaSUG2010 - Paper AD16 Automating the Link between Metadata and Analysis Dataset Misha Rittmann, Octagon Research Solutions, Inc., Wayne, PA\nPharmaSUG2010 - Paper TT06 SAS Programming Techniques for Manipulating Metadata on the Database Level Chris Speck, PAREXEL International, Durham, NC\nPharmaSUG2011 – Paper CD17 Making a List, Checking it Twice (Part 1): Techniques for Specifying and Validating Analysis Datasets\nPharmaSUG2011 - Paper CD12ADaM Standard Naming Conventions are Good to HaveChristine Teng, Merck Sharp & Dohme Corp, Rahway, NJ"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#はじめに",
    "title": "解析用データセット作成の流れ2",
    "section": "2.1 はじめに",
    "text": "2.1 はじめに\n臨床研究でADaMデータセットを作成する際、仕様書通りの変数属性（長さ、ラベル）を確実に設定することは極めて重要です。しかし、実データを処理しながら属性を設定すると、元データの属性に引きずられてしまうリスクがあります。 今回は、Excelの仕様書から「空箱データセット」を自動生成し、確実に仕様書通りの構造を作る方法をご紹介します。\n\n2.1.1 よくある失敗パターン\n通常、ADSLデータセットを作成する際は以下のように手動でattrib文を記述します：\ndata adsl;\n    set dm;  /* 実データを先に読み込み */\n    \n    /* 後からattribを設定しても... */\n    attrib \n        STUDYID length=$20 label=\"Study Identifier\"\n        AGE     length=8   label=\"Age\";\n    \n    /* 元データの属性に引きずられる可能性 */\nrun;\n\n\n2.1.2 この方法の問題点\n\n元データの変数属性が優先される場合がある\n仕様書通りの長さに設定されない\nラベルが正しく設定されない場合がある\n\n\n\n2.1.3 解決方法：空箱データセットの活用\n\n\n2.1.4 コンセプト\n\n空箱データセット：仕様書通りの構造だけを持つ0観測のデータセット\n構造の継承：空箱の構造を継承して実データを処理\n確実性：仕様書の属性が必ず適用される"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#実践的な仕様書構造",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#実践的な仕様書構造",
    "title": "解析用データセット作成の流れ2",
    "section": "2.2 実践的な仕様書構造",
    "text": "2.2 実践的な仕様書構造\n\n2.2.1 Analysis Dataset Metadataシート\n\n\n\n\n\n\n\n\n\nDataset Name\nDataset Description\nDataset Structure\nKey Variables\n\n\n\n\nADSL\nSubject Population, demographic and baseline\none record per subject\nUSUBJID\n\n\nADAE\nAdverse Event Analysis Dataset\none record per subject per AE\nUSUBJID, AESEQ\n\n\nADEF\nAnalysis Dataset for Efficacy Disease Parameters\n1 record per subject parameter\nUSUBJID, PARAMCD\n\n\n\n\n\n2.2.2 個別データセットシート（ADSL例）\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nOrigin\nSource/Derivation\n\n\n\n\nADSL\nSTUDYID\nStudy Identifier\ntext\n200\n$20\nPredecessor\nDM.STUDYID\n\n\nADSL\nUSUBJID\nUnique Subject Identifier\ntext\n200\n$20\nPredecessor\nDM.USUBJID\n\n\nADSL\nAGE\nAge\ninteger\n8\n8.0\nPredecessor\nDM.AGE\n\n\nADSL\nSEX\nSex\ntext\n1\n$1\nPredecessor\nDM.SEX\n\n\nADSL\nSAFFL\nSafety Population Flag\ntext\n1\n$1\nDerived\n条件により設定"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#sasコードによる自動生成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#sasコードによる自動生成",
    "title": "解析用データセット作成の流れ2",
    "section": "2.3 SASコードによる自動生成",
    "text": "2.3 SASコードによる自動生成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#excel仕様書の読み込み",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#excel仕様書の読み込み",
    "title": "解析用データセット作成の流れ2",
    "section": "2.4 Excel仕様書の読み込み",
    "text": "2.4 Excel仕様書の読み込み\n/* ADaM仕様書を読み込み */\nproc import \n    datafile=\"C:\\specs\\ADaM_Specifications.xlsx\"  \n    out=work.spec_adsl\n    dbms=excel\n    replace;\n    sheet=\"ADSL\";\n    getnames=yes;\nrun;\n\n/* 内容確認 */\nproc print data=work.spec_adsl;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセット生成コードの作成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセット生成コードの作成",
    "title": "解析用データセット作成の流れ2",
    "section": "2.5 空箱データセット生成コードの作成",
    "text": "2.5 空箱データセット生成コードの作成\n/* 空箱データセット生成コードを作成 */\ndata _null_;\n    file \"C:\\temp\\ADSL_shell.sas\";\n    set work.spec_adsl end=last_obs;\n    \n    if _n_ = 1 then do;\n        put \"/* ADSL空箱データセット */\";\n        put \"data adsl_shell;\";\n        put \"    attrib\";\n    end;\n    \n    /* 各変数の属性を出力 */\n    put \"        \" Variable_Name @20 \"length=\" @;\n    if upcase(Type) = \"TEXT\" then put \"$\" @;\n    \n    /* Display Formatを使用 */\n    if Display_Format ne '' then \n        put Display_Format @35 \"label='\" Variable_Label \"'\";\n    else \n        put Length @35 \"label='\" Variable_Label \"'\";\n    \n    if last_obs then do;\n        put \"    ;\";\n        put \"    call missing(of _all_);  /* 全変数を欠損値に設定 */\";\n        put \"    stop;                    /* 0観測データセット */\";\n        put \"run;\";\n    end;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#生成されるコード例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#生成されるコード例",
    "title": "解析用データセット作成の流れ2",
    "section": "2.6 生成されるコード例",
    "text": "2.6 生成されるコード例\n実行後、C:\\temp\\ADSL_shell.sasに以下が生成されます：\n/* ADSL空箱データセット */\ndata adsl_shell;\n    attrib\n        STUDYID             length=$20              label='Study Identifier'\n        USUBJID             length=$20              label='Unique Subject Identifier'\n        AGE                 length=8                label='Age'\n        SEX                 length=$1               label='Sex'\n        SAFFL               length=$1               label='Safety Population Flag'\n    ;\n    call missing(of _all_);  /* 全変数を欠損値に設定 */\n    stop;                    /* 0観測データセット */\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセットを使った実データ処理",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセットを使った実データ処理",
    "title": "解析用データセット作成の流れ2",
    "section": "2.7 空箱データセットを使った実データ処理",
    "text": "2.7 空箱データセットを使った実データ処理\n/* 空箱データセットを作成 */\n%include \"C:\\temp\\ADSL_shell.sas\";\n\n/* 実際のADSL作成 */\ndata derived.adsl;\n    if 0 then set adsl_shell;  /* 構造のみ継承、実際は読み込まない */\n    set rawdata.dm;            /* 実データを処理 */\n    \n    /* データ処理 */\n    studyid = _studyid;\n    usubjid = _usubjid;\n    age = _age;\n    sex = _sex;\n    \n    /* 派生変数の作成 */\n    if /* 条件 */ then saffl = 'Y';\n    else saffl = 'N';\n    \n    keep studyid usubjid age sex saffl;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#重要なポイント",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#重要なポイント",
    "title": "解析用データセット作成の流れ2",
    "section": "2.8 重要なポイント",
    "text": "2.8 重要なポイント\n\n2.8.1 call missing(of all) の役割\n全ての変数を欠損値に設定し、データ型と長さのみを定義します。\ncall missing(of _all_);\n\n\n2.8.2 if 0 then set トリックの活用\nこのテクニックにより、空レコードを処理することなく、純粋に構造のみを継承できます。\nif 0 then set adsl_shell;  /* 決して実行されないが構造は継承 */\n\n\n2.8.3 stop ステートメントの必要性\nデータの読み込みを即座に停止し、構造のみのデータセットを作成します。\nstop;  /* 0観測データセットにする */"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#例",
    "title": "解析用データセット作成の流れ2",
    "section": "2.9 例",
    "text": "2.9 例\n%macro create_shell(dsname);\n    /* 仕様書読み込み */\n    proc import \n        datafile=\"C:\\specs\\ADaM_Specifications.xlsx\"  \n        out=work.spec_&dsname\n        dbms=excel\n        replace;\n        sheet=\"&dsname\";\n        getnames=yes;\n    run;\n    \ndata _null_;\n    file \"C:\\Users\\temp\\ADSL_shell.sas\";\n    set work.spec_clean end=last_obs;\n    \n    if _n_ = 1 then do;\n        put \"/* ADSL空箱データセット */\";\n        put \"data adsl_shell;\";\n        put \"    attrib\";\n    end;\n\n    put \"        \" Variable_Name \" length=\" @;\n    if upcase(Type) = \"CHAR\" then put \"$\" @;\n    put Length \" label='\" Variable_Label \"'\";\n    \n    if last_obs then do;\n        put \"    ;\";\n        put \"    call missing(of _all_);  \n        put \"    stop;                    \n        put \"run;\";\n    end;\nrun;\n%mend;\n\n/* 各データセットの空箱を生成 */\n%create_shell(ADSL);\n%create_shell(ADAE);\n%create_shell(ADEF);\n\n2.9.1 %includeによる読み込み\n生成されたSASコードは%include文で読み込み、任意のデータステップで使用できます。\nメリット\n1. 効率性: 手動でのattrib文記述が不要\n2. 正確性: コピペミスやタイプミスを防止\n3. 保守性: 仕様変更時はExcelファイルの更新のみで対応\n4. 再利用性: 複数のプログラムで同じattrib文を使用可能\n5. 検証支援: 独立プログラミングでも同じ仕様書を活用"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#excelコードリストの読み込みと-proc-format用データセット変換",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#excelコードリストの読み込みと-proc-format用データセット変換",
    "title": "解析用データセット作成の流れ2",
    "section": "3.1 Excelコードリストの読み込みと PROC FORMAT用データセット変換",
    "text": "3.1 Excelコードリストの読み込みと PROC FORMAT用データセット変換\nExcelコードリストの読み込み\n/* Excelファイルからコードリストを読み込み */\nproc import datafile=\"C:\\path\\to\\codelist.xlsx\"\n    out=Codelist\n    dbms=xlsx\n    replace;\n    sheet=\"Sheet1\";\n    getnames=yes;\nrun;\n\n/* CNTLIN形式に変換 */\ndata _Fmt;\n    set Codelist;\n    \n    FMTNAME = Codelist_Name;  /* フォーマット名 */\n    START = Value;            /* 開始値 */\n    LABEL = Label;            /* ラベル */\n    \n    /* 数値・文字型の判定 */\n    if Type = 'Num' then TYPE = 'N';\n    else TYPE = 'C';\n    \n    /* 不要な変数を除外 */\n    keep FMTNAME START LABEL TYPE;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#フォーマット作成出力",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#フォーマット作成出力",
    "title": "解析用データセット作成の流れ2",
    "section": "3.2 フォーマット作成・出力",
    "text": "3.2 フォーマット作成・出力\n/*-------------------------*/\n/*   作業用フォーマット作成           */\n/*-------------------------*/\nproc format lib=work cntlin=_Fmt;\nrun;\n\n/*-------------------------*/\n/*   フォーマットの出力               */\n/*-------------------------*/\nproc format lib=Output cntlin=_Fmt;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#用途例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#用途例",
    "title": "解析用データセット作成の流れ2",
    "section": "3.3 用途例",
    "text": "3.3 用途例\n/* 臨床試験の被験者背景表 */\nproc tabulate data=trial_data;\n    class sex agegrp;\n    table sex, agegrp*n*f=8.0;\n    format sex $SEX. agegrp $AGEGRP.;\n    title \"被験者背景（性別・年齢群別）\";\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#specificationシートでの記載例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#specificationシートでの記載例",
    "title": "解析用データセット作成の流れ2",
    "section": "3.4 Specificationシートでの記載例",
    "text": "3.4 Specificationシートでの記載例\n目的: Excelで管理されているコードリストマスターから自動的にSAS formatを生成し、データの標準化を図る 処理フロー:\n\nExcelコードリストをSASデータセットとして読み込み\nPROC FORMAT用のCNTLIN形式に変換（数値・文字型の自動判定含む）\n作業用ライブラリでフォーマット作成・検証\n本番ライブラリに最終出力\n\n入力ファイル: codelist.xlsxと出力フォーマットである。\n\nSEX（文字型）: M=Male, F=Female, U=Unknown\nSEXN（数値型）: 1=男性, 2=女性\nNYFL（文字型）: Y=Yes, N=No\nAGEU（文字型）: YEARS=Years, MONTHS=Months\n\n\n3.4.1 実装のメリット\n\nExcel管理の利便性: 非プログラマーでもコードリストの更新が容易で、チーム間での共有も簡単です。\n混在データ型対応: 数値型と文字型のフォーマットが混在していても、自動的に適切な形式で生成されます。\n自動化による効率性: 手動でのフォーマット定義が不要になり、Excelファイルの更新が即座にSASフォーマットに反映されます。\n品質向上: ヒューマンエラーが削減され、データの標準化が徹底されます。\n拡張性: 新しいコードリストの追加がExcelシートへの行追加だけで完了し、CDISC標準などへの準拠も効率的に行えます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#なぜアンダースコアを付けるのか",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#なぜアンダースコアを付けるのか",
    "title": "解析用データセット作成の流れ2",
    "section": "4.1 なぜアンダースコアを付けるのか？",
    "text": "4.1 なぜアンダースコアを付けるのか？\nSASでデータ処理をしていると、変数名の管理が重要になってきます。特に：\n\nデータマージ時の名前衝突を防ぐ\n生データと加工データの区別\n一時的な変数の識別\n\n例えば、ageという変数があるデータに対して、_ageのように接頭辞を付けることで、元の生データであることを明確にできます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#マクロの仕組み",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#マクロの仕組み",
    "title": "解析用データセット作成の流れ2",
    "section": "4.2 マクロの仕組み",
    "text": "4.2 マクロの仕組み\nこのマクロは3つのステップで動作します：\n\n4.2.1 ステップ1：変数情報の取得\n象データセットの変数一覧を取得します。\nproc contents data = work.&raw. out = work.VAR noprint ;\n\n\n4.2.2 ステップ2：マクロ変数の動的生成\n各変数名をマクロ変数として保存：\n\nVAR1_ → 1番目の変数名\nVAR2_ → 2番目の変数名\nMAXV → 総変数数\n\ndata _null_ ;\n  set work.VAR end = eof ;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G') ;\n  if eof then call symputx('MAXV', _N_) ;\nrun ;\n\n\n4.2.3 ステップ3：一括リネーム\nrename\n%do i = 1 %to &MAXV. ;\n  &&VAR&i._ = _&&VAR&i._\n%end ;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#実行例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#実行例",
    "title": "解析用データセット作成の流れ2",
    "section": "4.3 実行例",
    "text": "4.3 実行例\n%macro rawdata(raw=, sort=, out=&raw);\nproc contents data = work.&raw. out = work.VAR noprint ;\nrun ;\nproc sort data = work.VAR ; \n  by VARNUM ;\nrun ;\ndata _null_ ;\n  set work.VAR end = eof ;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G') ;\n  if eof then call symputx('MAXV', _N_) ;\nrun ;\ndata work.&out. ;\n  set work.&raw. ;\n  rename\n  %do i = 1 %to &MAXV. ;\n    &&VAR&i._ = _&&VAR&i._\n  %end ;\n  ;\nrun ;\n%mend rawdata ;\n\n/* まずirisデータをworkライブラリにコピー */\ndata work.iris;\n  set sashelp.iris;\nrun;\n\n/* マクロを実行 */\n%rawdata(raw=iris, out=iris_renamed)\n\n/* データの中身を確認 */\nproc print data=work.iris_renamed(obs=5);\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#adamデータセット作成における変数名管理の重要性",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#adamデータセット作成における変数名管理の重要性",
    "title": "解析用データセット作成の流れ2",
    "section": "4.4 ADaMデータセット作成における変数名管理の重要性",
    "text": "4.4 ADaMデータセット作成における変数名管理の重要性\nADaMにおける変数命名の課題 ADaM（Analysis Data Model）データセット作成では、複数のソースから様々な変数を統合する必要があります：\n\nSDTMデータ（生データ）\n派生変数（計算結果）\n解析用変数（統計処理用）\nメタデータ（フラグや分類変数）\nこれらが混在すると、データの出自が不明確になり、品質管理やバリデーションが困難になります。"
  }
]