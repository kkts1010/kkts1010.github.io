[
  {
    "objectID": "posts/Web_tools/Web_tools.html",
    "href": "posts/Web_tools/Web_tools.html",
    "title": "Web Tools",
    "section": "",
    "text": "ここでは、参考にさせていただいてるWeb URLを備忘録として保存する。"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#計量生物学会",
    "href": "posts/Web_tools/Web_tools.html#計量生物学会",
    "title": "Web Tools",
    "section": "1 計量生物学会",
    "text": "1 計量生物学会\n\n計量生物学会\n統計家の行動基準"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#論文雑誌",
    "href": "posts/Web_tools/Web_tools.html#論文雑誌",
    "title": "Web Tools",
    "section": "2 論文雑誌",
    "text": "2 論文雑誌\n\n計量生物学\n薬剤疫学\nJournal of Epideimology\nStatistics in Medicine\nPharmaceutical Statistics\nBiostatistics\nPharmacoepidemiology ＆ Drug Safety\nすうがくぶんか株式会社\nQuarto\nGit公式書籍（日本語"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#医薬品開発",
    "href": "posts/Web_tools/Web_tools.html#医薬品開発",
    "title": "Web Tools",
    "section": "3 医薬品開発",
    "text": "3 医薬品開発\n\nPMDA 審査関連業務の概要について\nICH Efficacyガイドライン\n製薬協データサイエンス部会 成果物\n製薬協 医薬品評価委員会シンポジウム\nFDA Clinical Trials Guidance Documents\nFDA Real-World Evidence Documents\nEMA Biostatistics guidelines\nEMA Real-world evidence guidelines\nCDISC ADaM\nStatistical Analysi Plan(Australian Clinical Trials)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#統計",
    "href": "posts/Web_tools/Web_tools.html#統計",
    "title": "Web Tools",
    "section": "4 統計",
    "text": "4 統計\n\nPankaj Kumar Choudhary先生\nFrank Harrell先生\nBayesian Data Analysis Course\n早稲田大学 村田先生 講義資料等\nCamden Lopez（海外の生物統計家ブログ）\nBiostatistics for Biomedical Research\n久保川達也先生 書籍関連"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#sasプログラミング",
    "href": "posts/Web_tools/Web_tools.html#sasプログラミング",
    "title": "Web Tools",
    "section": "5 SASプログラミング",
    "text": "5 SASプログラミング\n\nSAS備忘録\nPharmaceutical Software Users Group\nConference Proceedings (1976 - present) … and more\nSASユーザー会\nSASユーザー総会 論文集アーカイブ\nSAS Forumユーザー会 2006\n大阪SAS勉強会\nデータステップ100万回　SAS新手一生\n晴れ時々SAS\nSAS One Dash\n我輩はブロガーではない。ネタもまだない\n僕の頁 \nデータサイエンス100本ノック（構造化データ加工編）のSAS版\nRTFファイルをPDF化するDDEプログラム"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング書籍",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング書籍",
    "title": "Web Tools",
    "section": "6 Rプログラミング（書籍）",
    "text": "6 Rプログラミング（書籍）\n\nR for Data Science (2nd Edtion)\nAdvanced R (2nd Edition)\nR Cookbook, 2nd Edition\nQuarto 公式guide"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング海外サイト",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング海外サイト",
    "title": "Web Tools",
    "section": "7 Rプログラミング（海外サイト）",
    "text": "7 Rプログラミング（海外サイト）\n\nTidyverse style guide\nR Workflow for Reproducible Data Analysis and Reporting\nBuilding reproducible analytical pipelines with R\nR Rpharma\nR Workflow（Frank Harrell先生\nReproducible Medical Research with R\nR for Clinical Study Reports and Submission\nAn Introduction to Statistical Programming Methods with R\nTables in Clinical Trials with R\nIntroduction to tern\nWorkshops at rstudio::conf 2022\nTLG Catalog\nIntroduction to {rtables}\nReproducible Environments(Posit社)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#rプログラミング日本語",
    "href": "posts/Web_tools/Web_tools.html#rプログラミング日本語",
    "title": "Web Tools",
    "section": "8 Rプログラミング（日本語）",
    "text": "8 Rプログラミング（日本語）\n\nデータサイエンス100本ノック（構造化データ加工編）をRで解く\nRによる再現可能なデータ分析（瓜生真也先生）\nRによるデータ解析のための前処理（瓜生真也先生）\n次の一歩を踏み出すためのtidyverse入門（瓜生真也先生）\n今日からできる再現可能な論文執筆（国里愛彦先生・竹林由武先生）\nはじめよう！R（小杉考司先生）\n気軽にRでWebサイト\nRではじめようモダンなデータ分析\n私たちのR\nRプログラムの個人ブログ"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#研究関連",
    "href": "posts/Web_tools/Web_tools.html#研究関連",
    "title": "Web Tools",
    "section": "9 研究関連",
    "text": "9 研究関連\n\nWriting-Tips Series(Journal of Clinical Epidemiology)"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#論文",
    "href": "posts/Web_tools/Web_tools.html#論文",
    "title": "Web Tools",
    "section": "10 論文",
    "text": "10 論文\n\nTen Simple Rules for Reproducible Computational Research\n山本先生_LatexによるBibTeXにおけるbibファイルの書き方"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#ブログ関係",
    "href": "posts/Web_tools/Web_tools.html#ブログ関係",
    "title": "Web Tools",
    "section": "11 ブログ関係",
    "text": "11 ブログ関係\n\n長島健悟先生のブログ\nKRSK先生のブログ\n司馬先生のブログ\nYanagimoto先生のブログ\nすきとほるさんのブログ"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#quartoブログ",
    "href": "posts/Web_tools/Web_tools.html#quartoブログ",
    "title": "Web Tools",
    "section": "12 Quartoブログ",
    "text": "12 Quartoブログ\n\ntutorial\nBuilding a blog with Quarto\nMarkdown記法チート"
  },
  {
    "objectID": "posts/Web_tools/Web_tools.html#tips",
    "href": "posts/Web_tools/Web_tools.html#tips",
    "title": "Web Tools",
    "section": "13 Tips",
    "text": "13 Tips\n\nExcelシートの一括変換 note\nExcelファイルをまとめてPDFファイルに変換したい\n複数のExcelファイルを一括でPDFファイルに変換する方法\nメモ帳だけで作成！複数のExcelファイルをPDFに一括変換\nWinMerge日本語版"
  },
  {
    "objectID": "posts/statistics/研究メモ/20250702_メモ.html",
    "href": "posts/statistics/研究メモ/20250702_メモ.html",
    "title": "研究メモ",
    "section": "",
    "text": "Measurement Agreement Models, Methods, and Applicationsの書籍について、自己学習用にまとめる。\n書籍は以下の通り"
  },
  {
    "objectID": "posts/statistics/研究メモ/20250702_メモ.html#measurement-agreement",
    "href": "posts/statistics/研究メモ/20250702_メモ.html#measurement-agreement",
    "title": "研究メモ",
    "section": "",
    "text": "Measurement Agreement Models, Methods, and Applicationsの書籍について、自己学習用にまとめる。\n書籍は以下の通り"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html",
    "title": "解析用データセット作成の流れ2",
    "section": "",
    "text": "本記事では、以下の私のブログを踏まえて、より具体的な解析データセット作成の流れをまとめていく。\n\n\n\n\n\n\n\n\n\n\n\n\n\n坂本航太\n\n\n2025/06/14\n\n\n\n\n\n\n\n\n\n\n\n\n個人的な解析データセット作成方法をまとめます。\n\n\n\n坂本航太\n\n\n2025/06/14\n\n\n\n\n\n\n一致なし\n\n\n\n\nPharmaSUG2010 - Paper AD16 Automating the Link between Metadata and Analysis Dataset Misha Rittmann, Octagon Research Solutions, Inc., Wayne, PA\nPharmaSUG2010 - Paper TT06 SAS Programming Techniques for Manipulating Metadata on the Database Level Chris Speck, PAREXEL International, Durham, NC\nPharmaSUG2011 – Paper CD17 Making a List, Checking it Twice (Part 1): Techniques for Specifying and Validating Analysis Datasets\nPharmaSUG2011 - Paper CD12ADaM Standard Naming Conventions are Good to HaveChristine Teng, Merck Sharp & Dohme Corp, Rahway, NJ"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#参考文献",
    "title": "解析用データセット作成の流れ2",
    "section": "",
    "text": "PharmaSUG2010 - Paper AD16 Automating the Link between Metadata and Analysis Dataset Misha Rittmann, Octagon Research Solutions, Inc., Wayne, PA\nPharmaSUG2010 - Paper TT06 SAS Programming Techniques for Manipulating Metadata on the Database Level Chris Speck, PAREXEL International, Durham, NC\nPharmaSUG2011 – Paper CD17 Making a List, Checking it Twice (Part 1): Techniques for Specifying and Validating Analysis Datasets\nPharmaSUG2011 - Paper CD12ADaM Standard Naming Conventions are Good to HaveChristine Teng, Merck Sharp & Dohme Corp, Rahway, NJ"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#はじめに",
    "title": "解析用データセット作成の流れ2",
    "section": "2.1 はじめに",
    "text": "2.1 はじめに\n臨床研究でADaMデータセットを作成する際、仕様書通りの変数属性（長さ、ラベル）を確実に設定することは極めて重要です。しかし、実データを処理しながら属性を設定すると、元データの属性に引きずられてしまうリスクがあります。 今回は、Excelの仕様書から「空箱データセット」を自動生成し、確実に仕様書通りの構造を作る方法をご紹介します。\n\n2.1.1 よくある失敗パターン\n通常、ADSLデータセットを作成する際は以下のように手動でattrib文を記述します：\ndata adsl;\n    set dm;  /* 実データを先に読み込み */\n    \n    /* 後からattribを設定しても... */\n    attrib \n        STUDYID length=$20 label=\"Study Identifier\"\n        AGE     length=8   label=\"Age\";\n    \n    /* 元データの属性に引きずられる可能性 */\nrun;\n\n\n2.1.2 この方法の問題点\n\n元データの変数属性が優先される場合がある\n仕様書通りの長さに設定されない\nラベルが正しく設定されない場合がある\n\n\n\n2.1.3 解決方法：空箱データセットの活用\n\n\n2.1.4 コンセプト\n\n空箱データセット：仕様書通りの構造だけを持つ0観測のデータセット\n構造の継承：空箱の構造を継承して実データを処理\n確実性：仕様書の属性が必ず適用される"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#実践的な仕様書構造",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#実践的な仕様書構造",
    "title": "解析用データセット作成の流れ2",
    "section": "2.2 実践的な仕様書構造",
    "text": "2.2 実践的な仕様書構造\n\n2.2.1 Analysis Dataset Metadataシート\n\n\n\n\n\n\n\n\n\nDataset Name\nDataset Description\nDataset Structure\nKey Variables\n\n\n\n\nADSL\nSubject Population, demographic and baseline\none record per subject\nUSUBJID\n\n\nADAE\nAdverse Event Analysis Dataset\none record per subject per AE\nUSUBJID, AESEQ\n\n\nADEF\nAnalysis Dataset for Efficacy Disease Parameters\n1 record per subject parameter\nUSUBJID, PARAMCD\n\n\n\n\n\n2.2.2 個別データセットシート（ADSL例）\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nOrigin\nSource/Derivation\n\n\n\n\nADSL\nSTUDYID\nStudy Identifier\ntext\n200\n$20\nPredecessor\nDM.STUDYID\n\n\nADSL\nUSUBJID\nUnique Subject Identifier\ntext\n200\n$20\nPredecessor\nDM.USUBJID\n\n\nADSL\nAGE\nAge\ninteger\n8\n8.0\nPredecessor\nDM.AGE\n\n\nADSL\nSEX\nSex\ntext\n1\n$1\nPredecessor\nDM.SEX\n\n\nADSL\nSAFFL\nSafety Population Flag\ntext\n1\n$1\nDerived\n条件により設定"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#sasコードによる自動生成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#sasコードによる自動生成",
    "title": "解析用データセット作成の流れ2",
    "section": "2.3 SASコードによる自動生成",
    "text": "2.3 SASコードによる自動生成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#excel仕様書の読み込み",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#excel仕様書の読み込み",
    "title": "解析用データセット作成の流れ2",
    "section": "2.4 Excel仕様書の読み込み",
    "text": "2.4 Excel仕様書の読み込み\n/* ADaM仕様書を読み込み */\nproc import \n    datafile=\"C:\\specs\\ADaM_Specifications.xlsx\"  \n    out=work.spec_adsl\n    dbms=excel\n    replace;\n    sheet=\"ADSL\";\n    getnames=yes;\nrun;\n\n/* 内容確認 */\nproc print data=work.spec_adsl;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセット生成コードの作成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセット生成コードの作成",
    "title": "解析用データセット作成の流れ2",
    "section": "2.5 空箱データセット生成コードの作成",
    "text": "2.5 空箱データセット生成コードの作成\n/* 空箱データセット生成コードを作成 */\ndata _null_;\n    file \"C:\\temp\\ADSL_shell.sas\";\n    set work.spec_adsl end=last_obs;\n    \n    if _n_ = 1 then do;\n        put \"/* ADSL空箱データセット */\";\n        put \"data adsl_shell;\";\n        put \"    attrib\";\n    end;\n    \n    /* 各変数の属性を出力 */\n    put \"        \" Variable_Name @20 \"length=\" @;\n    if upcase(Type) = \"TEXT\" then put \"$\" @;\n    \n    /* Display Formatを使用 */\n    if Display_Format ne '' then \n        put Display_Format @35 \"label='\" Variable_Label \"'\";\n    else \n        put Length @35 \"label='\" Variable_Label \"'\";\n    \n    if last_obs then do;\n        put \"    ;\";\n        put \"    call missing(of _all_);  /* 全変数を欠損値に設定 */\";\n        put \"    stop;                    /* 0観測データセット */\";\n        put \"run;\";\n    end;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#生成されるコード例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#生成されるコード例",
    "title": "解析用データセット作成の流れ2",
    "section": "2.6 生成されるコード例",
    "text": "2.6 生成されるコード例\n実行後、C:\\temp\\ADSL_shell.sasに以下が生成されます：\n/* ADSL空箱データセット */\ndata adsl_shell;\n    attrib\n        STUDYID             length=$20              label='Study Identifier'\n        USUBJID             length=$20              label='Unique Subject Identifier'\n        AGE                 length=8                label='Age'\n        SEX                 length=$1               label='Sex'\n        SAFFL               length=$1               label='Safety Population Flag'\n    ;\n    call missing(of _all_);  /* 全変数を欠損値に設定 */\n    stop;                    /* 0観測データセット */\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセットを使った実データ処理",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#空箱データセットを使った実データ処理",
    "title": "解析用データセット作成の流れ2",
    "section": "2.7 空箱データセットを使った実データ処理",
    "text": "2.7 空箱データセットを使った実データ処理\n/* 空箱データセットを作成 */\n%include \"C:\\temp\\ADSL_shell.sas\";\n\n/* 実際のADSL作成 */\ndata derived.adsl;\n    if 0 then set adsl_shell;  /* 構造のみ継承、実際は読み込まない */\n    set rawdata.dm;            /* 実データを処理 */\n    \n    /* データ処理 */\n    studyid = _studyid;\n    usubjid = _usubjid;\n    age = _age;\n    sex = _sex;\n    \n    /* 派生変数の作成 */\n    if /* 条件 */ then saffl = 'Y';\n    else saffl = 'N';\n    \n    keep studyid usubjid age sex saffl;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#重要なポイント",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#重要なポイント",
    "title": "解析用データセット作成の流れ2",
    "section": "2.8 重要なポイント",
    "text": "2.8 重要なポイント\n\n2.8.1 call missing(of all) の役割\n全ての変数を欠損値に設定し、データ型と長さのみを定義します。\ncall missing(of _all_);\n\n\n2.8.2 if 0 then set トリックの活用\nこのテクニックにより、空レコードを処理することなく、純粋に構造のみを継承できます。\nif 0 then set adsl_shell;  /* 決して実行されないが構造は継承 */\n\n\n2.8.3 stop ステートメントの必要性\nデータの読み込みを即座に停止し、構造のみのデータセットを作成します。\nstop;  /* 0観測データセットにする */"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#例",
    "title": "解析用データセット作成の流れ2",
    "section": "2.9 例",
    "text": "2.9 例\n%macro create_shell(dsname);\n    /* 仕様書読み込み */\n    proc import \n        datafile=\"C:\\specs\\ADaM_Specifications.xlsx\"  \n        out=work.spec_&dsname\n        dbms=excel\n        replace;\n        sheet=\"&dsname\";\n        getnames=yes;\n    run;\n    \ndata _null_;\n    file \"C:\\Users\\temp\\ADSL_shell.sas\";\n    set work.spec_clean end=last_obs;\n    \n    if _n_ = 1 then do;\n        put \"/* ADSL空箱データセット */\";\n        put \"data adsl_shell;\";\n        put \"    attrib\";\n    end;\n\n    put \"        \" Variable_Name \" length=\" @;\n    if upcase(Type) = \"CHAR\" then put \"$\" @;\n    put Length \" label='\" Variable_Label \"'\";\n    \n    if last_obs then do;\n        put \"    ;\";\n        put \"    call missing(of _all_);  \n        put \"    stop;                    \n        put \"run;\";\n    end;\nrun;\n%mend;\n\n/* 各データセットの空箱を生成 */\n%create_shell(ADSL);\n%create_shell(ADAE);\n%create_shell(ADEF);\n\n2.9.1 %includeによる読み込み\n生成されたSASコードは%include文で読み込み、任意のデータステップで使用できます。\nメリット\n1. 効率性: 手動でのattrib文記述が不要\n2. 正確性: コピペミスやタイプミスを防止\n3. 保守性: 仕様変更時はExcelファイルの更新のみで対応\n4. 再利用性: 複数のプログラムで同じattrib文を使用可能\n5. 検証支援: 独立プログラミングでも同じ仕様書を活用"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#excelコードリストの読み込みと-proc-format用データセット変換",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#excelコードリストの読み込みと-proc-format用データセット変換",
    "title": "解析用データセット作成の流れ2",
    "section": "3.1 Excelコードリストの読み込みと PROC FORMAT用データセット変換",
    "text": "3.1 Excelコードリストの読み込みと PROC FORMAT用データセット変換\nExcelコードリストの読み込み\n/* Excelファイルからコードリストを読み込み */\nproc import datafile=\"C:\\path\\to\\codelist.xlsx\"\n    out=Codelist\n    dbms=xlsx\n    replace;\n    sheet=\"Sheet1\";\n    getnames=yes;\nrun;\n\n/* CNTLIN形式に変換 */\ndata _Fmt;\n    set Codelist;\n    \n    FMTNAME = Codelist_Name;  /* フォーマット名 */\n    START = Value;            /* 開始値 */\n    LABEL = Label;            /* ラベル */\n    \n    /* 数値・文字型の判定 */\n    if Type = 'Num' then TYPE = 'N';\n    else TYPE = 'C';\n    \n    /* 不要な変数を除外 */\n    keep FMTNAME START LABEL TYPE;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#フォーマット作成出力",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#フォーマット作成出力",
    "title": "解析用データセット作成の流れ2",
    "section": "3.2 フォーマット作成・出力",
    "text": "3.2 フォーマット作成・出力\n/*-------------------------*/\n/*   作業用フォーマット作成           */\n/*-------------------------*/\nproc format lib=work cntlin=_Fmt;\nrun;\n\n/*-------------------------*/\n/*   フォーマットの出力               */\n/*-------------------------*/\nproc format lib=Output cntlin=_Fmt;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#用途例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#用途例",
    "title": "解析用データセット作成の流れ2",
    "section": "3.3 用途例",
    "text": "3.3 用途例\n/* 臨床試験の被験者背景表 */\nproc tabulate data=trial_data;\n    class sex agegrp;\n    table sex, agegrp*n*f=8.0;\n    format sex $SEX. agegrp $AGEGRP.;\n    title \"被験者背景（性別・年齢群別）\";\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#specificationシートでの記載例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#specificationシートでの記載例",
    "title": "解析用データセット作成の流れ2",
    "section": "3.4 Specificationシートでの記載例",
    "text": "3.4 Specificationシートでの記載例\n目的: Excelで管理されているコードリストマスターから自動的にSAS formatを生成し、データの標準化を図る 処理フロー:\n\nExcelコードリストをSASデータセットとして読み込み\nPROC FORMAT用のCNTLIN形式に変換（数値・文字型の自動判定含む）\n作業用ライブラリでフォーマット作成・検証\n本番ライブラリに最終出力\n\n入力ファイル: codelist.xlsxと出力フォーマットである。\n\nSEX（文字型）: M=Male, F=Female, U=Unknown\nSEXN（数値型）: 1=男性, 2=女性\nNYFL（文字型）: Y=Yes, N=No\nAGEU（文字型）: YEARS=Years, MONTHS=Months\n\n\n3.4.1 実装のメリット\n\nExcel管理の利便性: 非プログラマーでもコードリストの更新が容易で、チーム間での共有も簡単です。\n混在データ型対応: 数値型と文字型のフォーマットが混在していても、自動的に適切な形式で生成されます。\n自動化による効率性: 手動でのフォーマット定義が不要になり、Excelファイルの更新が即座にSASフォーマットに反映されます。\n品質向上: ヒューマンエラーが削減され、データの標準化が徹底されます。\n拡張性: 新しいコードリストの追加がExcelシートへの行追加だけで完了し、CDISC標準などへの準拠も効率的に行えます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#なぜアンダースコアを付けるのか",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#なぜアンダースコアを付けるのか",
    "title": "解析用データセット作成の流れ2",
    "section": "4.1 なぜアンダースコアを付けるのか？",
    "text": "4.1 なぜアンダースコアを付けるのか？\nSASでデータ処理をしていると、変数名の管理が重要になってきます。特に：\n\nデータマージ時の名前衝突を防ぐ\n生データと加工データの区別\n一時的な変数の識別\n\n例えば、ageという変数があるデータに対して、_ageのように接頭辞を付けることで、元の生データであることを明確にできます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#マクロの仕組み",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#マクロの仕組み",
    "title": "解析用データセット作成の流れ2",
    "section": "4.2 マクロの仕組み",
    "text": "4.2 マクロの仕組み\nこのマクロは3つのステップで動作します：\n\n4.2.1 ステップ1：変数情報の取得\n象データセットの変数一覧を取得します。\nproc contents data = work.&raw. out = work.VAR noprint ;\n\n\n4.2.2 ステップ2：マクロ変数の動的生成\n各変数名をマクロ変数として保存：\n\nVAR1_ → 1番目の変数名\nVAR2_ → 2番目の変数名\nMAXV → 総変数数\n\ndata _null_ ;\n  set work.VAR end = eof ;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G') ;\n  if eof then call symputx('MAXV', _N_) ;\nrun ;\n\n\n4.2.3 ステップ3：一括リネーム\nrename\n%do i = 1 %to &MAXV. ;\n  &&VAR&i._ = _&&VAR&i._\n%end ;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#実行例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#実行例",
    "title": "解析用データセット作成の流れ2",
    "section": "4.3 実行例",
    "text": "4.3 実行例\n%macro rawdata(raw=, sort=, out=&raw);\nproc contents data = work.&raw. out = work.VAR noprint ;\nrun ;\nproc sort data = work.VAR ; \n  by VARNUM ;\nrun ;\ndata _null_ ;\n  set work.VAR end = eof ;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G') ;\n  if eof then call symputx('MAXV', _N_) ;\nrun ;\ndata work.&out. ;\n  set work.&raw. ;\n  rename\n  %do i = 1 %to &MAXV. ;\n    &&VAR&i._ = _&&VAR&i._\n  %end ;\n  ;\nrun ;\n%mend rawdata ;\n\n/* まずirisデータをworkライブラリにコピー */\ndata work.iris;\n  set sashelp.iris;\nrun;\n\n/* マクロを実行 */\n%rawdata(raw=iris, out=iris_renamed)\n\n/* データの中身を確認 */\nproc print data=work.iris_renamed(obs=5);\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ2.html#adamデータセット作成における変数名管理の重要性",
    "href": "posts/statistics/2025/解析用データセット作成の流れ2.html#adamデータセット作成における変数名管理の重要性",
    "title": "解析用データセット作成の流れ2",
    "section": "4.4 ADaMデータセット作成における変数名管理の重要性",
    "text": "4.4 ADaMデータセット作成における変数名管理の重要性\nADaMにおける変数命名の課題 ADaM（Analysis Data Model）データセット作成では、複数のソースから様々な変数を統合する必要があります：\n\nSDTMデータ（生データ）\n派生変数（計算結果）\n解析用変数（統計処理用）\nメタデータ（フラグや分類変数）\nこれらが混在すると、データの出自が不明確になり、品質管理やバリデーションが困難になります。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html",
    "href": "posts/statistics/2025/解析用データセット仕様書.html",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "臨床試験や統計解析プロジェクトにおいて、解析用データセット仕様書は分析の設計図とも言える重要な文書です。本記事では、実用的な解析用データセット仕様書の構成と記載内容について、主要な3つのデータセット（ADSL、ADLB、ADTTE）を例に解説し、さらに仕様書に基づくデータセット作成とバリデーションプロセスについても説明します。探索的解析であっても事前に解析用データセット仕様書を作成することを推奨する。\n\n\n\n\nSASユーザー総会2014年度：SASとExcelを用いたCDISCADaM標準における作業効率化の試み（武田薬品、高浪さん：PDFのP351）\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬：）\nSASユーザー総会2013年度：ライブラリ参照と名前の定義を利用して EXCELファイルへの柔軟なデータ入出力を実現する 解析結果のレポーティングからセルオートマトンまで\nSASユーザー総会2010年度：“Standard Template Programs”の開発\n生存時間解析用ADaMデータセット（ADTTE）のソースコード紹介"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#はじめに",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "臨床試験や統計解析プロジェクトにおいて、解析用データセット仕様書は分析の設計図とも言える重要な文書です。本記事では、実用的な解析用データセット仕様書の構成と記載内容について、主要な3つのデータセット（ADSL、ADLB、ADTTE）を例に解説し、さらに仕様書に基づくデータセット作成とバリデーションプロセスについても説明します。探索的解析であっても事前に解析用データセット仕様書を作成することを推奨する。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#参考文献",
    "title": "解析用データセット仕様書",
    "section": "",
    "text": "SASユーザー総会2014年度：SASとExcelを用いたCDISCADaM標準における作業効率化の試み（武田薬品、高浪さん：PDFのP351）\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬：）\nSASユーザー総会2013年度：ライブラリ参照と名前の定義を利用して EXCELファイルへの柔軟なデータ入出力を実現する 解析結果のレポーティングからセルオートマトンまで\nSASユーザー総会2010年度：“Standard Template Programs”の開発\n生存時間解析用ADaMデータセット（ADTTE）のソースコード紹介"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#例",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#例",
    "title": "解析用データセット仕様書",
    "section": "2.1 例",
    "text": "2.1 例\nAnalysis Dataset Metadata シート：データセットの一覧\n\n\n\n\n\n\n\n\n\n\n\n\nDataset Name\nDataset Description\nDataset Location\nDataset Structure\nKey Variables of Interest\nClass of Dataset\nDocumentation\n\n\n\n\nADSL\nSubject Population, demographic and baseline characteristics\nADSL.xpt\none record per subject\nUSUBJID\nADSL\nSAP, ADSL.sas\n\n\nADAE\nAdverse Event Analysis Dataset\nADAE.xpt\none record per subject per each AE recorded\nUSUBJID, AESEQ\nADAE\nADAE.sas\n\n\nADEF\nAnalysis Dataset for Efficacy Disease Parameters\nADEF.xpt\n1 record per subject parameter\nUSUBJID, PARAMCD\nBDS\nDictionary used in MedDRA VOL.X\n\n\n\nADSL シート：ADSL データセットの変数一覧（ADAE、ADEF も同様に作成）\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDataset\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist/Controlled Term\nCodelist Name\nOrigin\nSource/Derivation\n\n\n\n\nADSL\nSTUDYID\nStudy Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.STUDYID\n\n\nADSL\nUSUBJID\nUnique Subject Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.USUBJID\n\n\nADSL\nSUBJID\nSubject Identifier\ntext\n200\n$20\n\n\nPredecessor\nDM.SUBJID\n\n\nADSL\nSITEID\nStudy Site Identifier\ntext\n200\n$3\n\n\nPredecessor\nDM.SITEID\n\n\nADSL\nAGE\nAge\ninteger\n8\n8.0\nAGEU\nAGEU\nPredecessor\nDM.AGE\n\n\nADSL\nAGEU\nAge Units\ntext\n200\n$20\nAGEU\nAGEU\nPredecessor\nDM.AGEU\n\n\nADSL\nSEX\nSex\ntext\n1\n$1\nSEX\nSEX\nPredecessor\nDM.SEX\n\n\nADSL\nSEXN\nSex (N)\ntext\n8\n8.0\nSEXN\nSEXN\nPredecessor\n1=F,FEMALE=M,2=M\n\n\nADSL\nRACE\nRace\ntext\n200\n$200\nRACE\nRACE\nPredecessor\nDM.RACE\n\n\nADSL\nRACEN\nRace (N)\ninteger\n8\n8.0\nRACEN\nRACEN\nAssigned\n1=DM.RACE=“ASIAN”\n\n\n\nCodelist シート：コードリストの一覧\n\n\n\nName\nCodeValue\nCodeText\nData Type\n\n\n\n\nSEX\nF\nFemale\ntext\n\n\nSEX\nM\nMale\ntext\n\n\nSEXN\n1\nMale\ninteger\n\n\nSEXN\n2\nFemale\ninteger\n\n\nAGEU\nYEARS\n\ntext\n\n\nARM\nDrug A\nDrug A\ntext\n\n\nARM\nDrug B\nDrug B\ntext\n\n\nARM\nScreen Failure\nScreen Failure\ntext\n\n\nTRT\nDrug A\nDrug A\ntext\n\n\nTRT\nDrug B\nDrug B\ntext\n\n\nTRTN\n1\nDrug A\ninteger\n\n\nTRTN\n2\nDrug B\ninteger\n\n\n\nValue List シート：解析パラメータの一覧\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDataset Name\nVariable Name\nVariable Label\nParameter_variable\nComparator\nParameters\nVariable Type\nLength\nDisplay Format\n\n\n\n\n\nADEF\nAVAL\nAnalysis Value\nPARAMCD\nIN\nHEAL\ninteger\n8\n1.0\n\n\n\nAnalysis Results Metadata シート：解析結果メタデータ\n前向きの臨床試験であれば、ここまでAnalysis Result Metadataを作成することは可能であろう。ただし、探索的にデータを解析する場合は事前に解析方法を定義することは難しいように思われる。\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDisplay Identifier\nDisplay Name\nAnalysis\nPopulation\nDataset\nParameter\nReason\nSelection Criteria\nDocumentation\nProgramming Statements\n\n\n\n\nTable14.2.1\n主要評価項目\nFAS\nADEFF\nAVAL\nPre-specified in SAP\nFASFL=“Y” and PARAMCD = 1 and AVISTN = 4\nSAP\nproc format; value TRTFMT 1 = “Drug A” 2 = “Drug B”; run; proc freq data=ADSL ADEF; where FASFL = “Y” and PARAMCD = 1; table AVISTN　TRT AVAL/chisq nocol nopct format TRT01N TRT1FMT.;run;\n\n\nTable2\n副次評価項目\nFAS\nADEFF\nAVAL\nPre-specified in SAP\nPPROTFL=“Y” and PARAMCD = 1 and AVISTN = 4\nSAP\nproc format; value TRTFMT 1 = “Drug A” 2 = “Drug B”; run; proc freq data=ADSL ADEF; where PPROTFL = “Y” and PARAMCD = 1; table AVISTN TRT AVAL/chisq nocol nopct format TRT01N TRT1FMT.;run;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#解析用データセット仕様書の基本構成",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#解析用データセット仕様書の基本構成",
    "title": "解析用データセット仕様書",
    "section": "2.2 解析用データセット仕様書の基本構成",
    "text": "2.2 解析用データセット仕様書の基本構成\n解析用データセット仕様書は、主に以下の要素で構成されます：\n\n表紙・改訂履歴：文書管理情報\nDataset Definition：データセットの基本定義\nSpecification：変数の詳細仕様\nADLB_PARAM / ADTTE_PARAM：パラメータ定義表（ADLB、ADTTE用）\nCodelist：コード値の定義\n\nこれらの情報をExcelファイルの複数シートに整理することで、管理しやすく実用的な仕様書が作成できます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#specificationシートの構成",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#specificationシートの構成",
    "title": "解析用データセット仕様書",
    "section": "2.3 Specificationシートの構成",
    "text": "2.3 Specificationシートの構成\n変数仕様を記載するSpecificationシートでは、以下の項目を含めることを推奨します：\n\n2.3.1 基本項目\n\nVarnum：変数番号（並び順）\nDomain：データセット名（ADSL、ADLB、ADTTE等）\nVariable Name：変数名\nVariable Label：変数ラベル\nType：データタイプ（Char/Num）\nLength：変数長\nDisplay Format：表示フォーマット\nCodelist：コードリスト参照名\nCore：必須度（Req=必須、Perm=任意、Cond=条件付き）\nDefinition：定義・導出方法\n\n\n\n2.3.2 ADSLのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADSL\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADSL\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADSL\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADSL\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADSL\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADSL\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADSL\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADSL\nTRT01PN\nPlanned Treatment for Period 1 (N)\nNum\n8\n\n\nReq\nDerived from TRT01P\n\n\n9\nADSL\nTRT01AN\nActual Treatment for Period 1 (N)\nNum\n8\n\n\nReq\nDerived from TRT01A\n\n\n10\nADSL\nFASFL\nFull Analysis Set Flag\nChar\n1\n\nNYFL\nReq\nExternal derivation\n\n\n\n\n\n2.3.3 ADLBのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADLB\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADLB\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADLB\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADLB\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADLB\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADLB\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADLB\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADLB\nPARAM\nParameter\nChar\n200\n\n\nReq\nParameter description\n\n\n9\nADLB\nPARAMCD\nParameter Code\nChar\n8\n\n\nReq\nParameter short name\n\n\n10\nADLB\nPARAMN\nParameter (N)\nNum\n8\n\n\nReq\nNumeric representation of PARAM\n\n\n11\nADLB\nAVISIT\nAnalysis Visit\nChar\n200\n\n\nReq\nAnalysis visit description\n\n\n12\nADLB\nAVISITN\nAnalysis Visit (N)\nNum\n8\n\n\nReq\nNumeric representation of AVISIT\n\n\n13\nADLB\nAVAL\nAnalysis Value\nNum\n8\n\n\nReq\nNumeric analysis value\n\n\n14\nADLB\nAVALC\nAnalysis Value (C)\nChar\n200\n\n\nCond\nCharacter analysis value\n\n\n15\nADLB\nBASE\nBaseline Value\nNum\n8\n\n\nPerm\nBaseline analysis value\n\n\n16\nADLB\nBASEC\nBaseline Value (C)\nChar\n200\n\n\nPerm\nBaseline character value\n\n\n17\nADLB\nCHG\nChange from Baseline\nNum\n8\n\n\nPerm\nAVAL - BASE\n\n\n18\nADLB\nPCHG\nPercent Change from Baseline\nNum\n8\n\n\nPerm\n((AVAL-BASE)/BASE)*100\n\n\n19\nADLB\nAVALCAT1\nAnalysis Value Category 1\nChar\n200\n\n\nPerm\nCategorization of AVAL\n\n\n20\nADLB\nAVALCAT1N\nAnalysis Value Category 1 (N)\nNum\n8\n\n\nPerm\nNumeric representation of AVALCAT1\n\n\n21\nADLB\nPCHGCAT1\nPercent Chg from Baseline Category 1\nChar\n200\n\n\nPerm\nCategorization of PCHG\n\n\n22\nADLB\nPCHGCAT1N\nPercent Chg from Baseline Category 1 (N)\nNum\n8\n\n\nPerm\nNumeric representation of PCHGCAT1\n\n\n\n\n\n2.3.4 ADTTEのSpecificationシート例\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVarnum\nDomain\nVariable Name\nVariable Label\nType\nLength\nDisplay Format\nCodelist\nCore\nDefinition\n\n\n\n\n1\nADTTE\nSTUDYID\nStudy Identifier\nChar\n12\n\n\nReq\nDM.STUDYID\n\n\n2\nADTTE\nUSUBJID\nUnique Subject Identifier\nChar\n40\n\n\nReq\nDM.USUBJID\n\n\n3\nADTTE\nSUBJID\nSubject Identifier\nChar\n20\n\n\nReq\nDM.SUBJID\n\n\n4\nADTTE\nAGE\nAge\nNum\n8\n\n\nReq\nDM.AGE\n\n\n5\nADTTE\nSEX\nSex\nChar\n1\n\nSEX\nReq\nDM.SEX\n\n\n6\nADTTE\nTRT01P\nPlanned Treatment for Period 1\nChar\n200\n\n\nReq\nARM\n\n\n7\nADTTE\nTRT01A\nActual Treatment for Period 1\nChar\n200\n\n\nReq\nACTARM\n\n\n8\nADTTE\nPARAM\nParameter\nChar\n200\n\n\nReq\nAnalysis parameter description\n\n\n9\nADTTE\nPARAMCD\nParameter Code\nChar\n8\n\n\nReq\nAnalysis parameter short name\n\n\n10\nADTTE\nPARAMN\nParameter (N)\nNum\n8\n\n\nReq\nNumeric representation of PARAM\n\n\n11\nADTTE\nAVAL\nAnalysis Value\nNum\n8\n\n\nReq\nTime to event in days\n\n\n12\nADTTE\nSTARTDT\nTime to Event Origin Date\nNum\n8\ne8601da.\n\nReq\nAnalysis start date\n\n\n13\nADTTE\nADT\nAnalysis Date\nNum\n8\ne8601da.\n\nReq\nEvent or censoring date\n\n\n14\nADTTE\nCNSR\nCensor\nNum\n8\n\n\nReq\nCensoring flag (0=event, 1=censor)\n\n\n15\nADTTE\nEVNTDESC\nEvent or Censoring Description\nChar\n200\n\n\nPerm\nDescription of event or censoring\n\n\n16\nADTTE\nSRCDOM\nSource Data\nChar\n8\n\n\nPerm\nSource domain\n\n\n17\nADTTE\nSRCVAR\nSource Variable\nChar\n8\n\n\nPerm\nSource variable\n\n\n18\nADTTE\nSRCSEQ\nSource Sequence Number\nNum\n8\n\n\nPerm\nSource sequence number"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#paramシート",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#paramシート",
    "title": "解析用データセット仕様書",
    "section": "2.4 PARAMシート",
    "text": "2.4 PARAMシート\nADLB、ADTTEなどのBDS形式データセットでは、パラメータの定義情報を管理するための専用シートを作成します。\n\n2.4.1 ADLB_PARAMシート例\n\n\n\nPARAM\nPARAMCD\nPARAMN\nAVAL\n\n\n\n\nHbA1c(%)\nHBA1C\n1\ninput(LABデータ)\n\n\nBlood glucose (mg/dL)\nGLU\n2\ninput(LABデータ)\n\n\nBUN (mg/dL)\nBUN\n3\ninput(LABデータ)\n\n\nCreatinine (mg/dL)\nCREAT\n4\ninput(LABデータ)\n\n\nALT (U/L)\nALT\n5\ninput(LABデータ)\n\n\n\n\n\n2.4.2 ADTTE_PARAMシート例\n\n\n\n\n\n\n\n\n\nPARAM\nPARAMCD\nPARAMN\nAVAL\n\n\n\n\nWeight/Waist Circumference Loss\nWTWCLOSS\n1\nADT - STARTDT + 1\n\n\nOverall Survival\nOS\n2\nADT - STARTDT + 1\n\n\nProgression Free Survival\nPFS\n3\nADT - STARTDT + 1\n\n\nTime to Progression\nTTP\n4\nADT - STARTDT + 1"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#code-listのsheetについて",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#code-listのsheetについて",
    "title": "解析用データセット仕様書",
    "section": "2.5 Code ListのSheetについて",
    "text": "2.5 Code ListのSheetについて\nProc FormatでFormatを作るvalueとLabelを事前に仕様書に用意しておく。\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo.\nCodelist_Name\nValue\nLabel\nType\n説明\nSynonym\n備考\n\n\n\n\n1\nSEX\nM\nMale\nChar\n男性\n男\n\n\n\n2\nSEX\nF\nFemale\nChar\n女性\n女\n\n\n\n3\nSEX\nU\nUnknown\nChar\n不明\n未知\n\n\n\n4\nSEXN\n1\n男性\nNum\n男性\nMale\n\n\n\n5\nSEXN\n2\n女性\nNum\n女性\nFemale\n\n\n\n6\nNYFL\nY\nYes\nChar\nはい\nあり\n\n\n\n7\nNYFL\nN\nNo\nChar\nいいえ\nなし\n\n\n\n8\nAGEU\nYEARS\nYears\nChar\n年\n年\n\n\n\n9\nAGEU\nMONTHS\nMonths\nChar\n月\nヶ月"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#adlbデータセットの重要な変数",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#adlbデータセットの重要な変数",
    "title": "解析用データセット仕様書",
    "section": "2.6 ADLBデータセットの重要な変数",
    "text": "2.6 ADLBデータセットの重要な変数\n\n2.6.1 解析値とカテゴリ変数\nADLBでは数値解析値（AVAL）に基づいて、様々なカテゴリ変数を作成します：\n\n2.6.1.1 AVALCAT1 / AVALCAT1N\n解析値のカテゴリ化変数で、例えば正常範囲の判定などに使用： - “NORMAL” / “ABNORMAL” - “LOW” / “NORMAL” / “HIGH”\n\n\n2.6.1.2 PCHGCAT1 / PCHGCAT1N\nベースラインからの変化率のカテゴリ化変数： - “&gt;30% increase” / “±30%” / “&gt;30% decrease”\n\n\n\n2.6.2 時点変数（AVISIT / AVISITN）\n解析用の時点定義で、スケジュール通りの時点名： - “Baseline” (AVISITN=0) - “Week 4” (AVISITN=4) - “Week 12” (AVISITN=12) - “End of Treatment” (AVISITN=99)"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#adtteデータセットの詳細",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#adtteデータセットの詳細",
    "title": "解析用データセット仕様書",
    "section": "2.7 ADTTEデータセットの詳細",
    "text": "2.7 ADTTEデータセットの詳細\n\n2.7.1 ADTTEの特徴\nADTTEは生存時間解析用のデータセットで、以下の特徴があります：\n\n1被験者1パラメータにつき1レコードの構造\n事象の発生時間または打ち切り時間を記録\n複数の解析エンドポイントを1つのデータセットで管理\n\n\n\n2.7.2 ADTTE作成時の重要な考慮事項\n\n2.7.2.1 1. 事象の優先順位\n複数の事象や打ち切りが同日に発生した場合の優先順位を明確に定義する必要があります。\n\n\n2.7.2.2 2. AVALの計算方法\nAVALは通常、以下の式で計算されます：\nここで： - STARTDT：解析開始日（通常は治療開始日：ADSL.TRTSDT） - ADT：解析日（事象発生日または打ち切り日） - +1：0日目を避けるための調整\n\n\n2.7.2.3 3. 事象データの取得元\n\n事象発生：ADVS.ADTから日付を取得\n打ち切り：ADSL.EOSDTから日付を取得\n\n\n\n2.7.2.4 4. CNSRフラグの設定\n\nCNSR=0：事象発生\nCNSR=1：打ち切り\n\n\n\n2.7.2.5 5. ソースデータの追跡（SRCDOM, SRCVAR, SRCSEQ）\nADTTEでは元データの追跡可能性が重要です：\n事象採用時： - SRCDOM=“ADVS” - SRCVAR=“ADT” - SRCSEQ=ADVS.ASEQ\n打ち切り時： - SRCDOM=“ADSL” - SRCVAR=“EOSDT” - SRCSEQ=（ブランク）\n\n\n\n2.7.3 ADTTEプログラミングのポイント\n\nデータセットの組み合わせ：複数のデータセット（ADSL、ADVS等）を適切に結合\n日付の妥当性チェック：論理的に矛盾する日付の検出と処理\n追跡可能性の確保：各レコードの導出元を明確に記録\n複数事象の処理：同一被験者で複数の解析パラメータを生成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#データセット作成プロセス",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#データセット作成プロセス",
    "title": "解析用データセット仕様書",
    "section": "2.8 データセット作成プロセス",
    "text": "2.8 データセット作成プロセス\n\n2.8.1 仕様書に基づくプログラム作成\n解析用データセット仕様書を読み込み、Specificationシートの定義に従ってSASプログラムを作成します。ADxx_Conversionシートを参照してパラメータ変換処理も実装します。まずは、プロトコール、統計解析計画書、図表計画書、Rawデータ/SDTM仕様書を基に、解析用データ仕様書をテンプレートを基に手作業で作成する。ここは泥臭いが、手作業でやるしかない。\n\n\n2.8.2 チェックリストの作成\n解析用データセット仕様書について、事前に組織内で規定されているチェックリストに基づいて、目視チェックをする。ここが人的作業であるためミスが起こりえる！"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット仕様書.html#section",
    "href": "posts/statistics/2025/解析用データセット仕様書.html#section",
    "title": "解析用データセット仕様書",
    "section": "2.9 ",
    "text": "2.9"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html",
    "title": "SAS：要約統計量作成マクロ",
    "section": "",
    "text": "第3回：演題4「要約統計量マクロ」坂尻大樹さん\n\n要約統計量マクロ\n\n\n/* 疑似データの作成 */\ndata AAA;\n   input Name $ Age Height Treatment $;\n   datalines;\nアルフレッド 14 69.2 A群\nアリス 13 56.8 B群\nバーバラ 13 65.5 A群\nキャロル 14 62.9 B群\nヘンリー 14 63.7 A群\nジェームズ 12 . B群\nジェーン 12 59.9 A群\nジャネット 15 62.7 B群\nジェフリー 13 62.6 A群\nジョン 12 59.1 B群\n;\nrun;\n\n/* 分析設定 */\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = TREATMENT;\n\n/* ステップ1: 原データから桁数を取得 */\ndata SUMMARY_KETA1;\n   set &DS.;\n   if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n\nproc summary data=SUMMARY_KETA1;\n   var KETA;\n   output out=SUMMARY_KETA2 max=MAXKETA;\nrun;\n\ndata SUMMARY_KETA3;\n   set SUMMARY_KETA2;\n   if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n   else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n   \n   call symputx(\"KETA\", KETA);\nrun;\n\n/* ステップ2: クラスデータを作成 */\ndata SUMMARY_CLASS;\n   length &CVAR. $8.;\n   &CVAR. = \"A群\"; output;\n   &CVAR. = \"B群\"; output;\nrun;\n\n/* ステップ3: 要約統計量を算出 */\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n   class &CVAR.;\n   var &VAR.;\n   output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n\ndata SUMMARY_2;\n   length PREOUT1-PREOUT9 $12.;\n   set SUMMARY_1;\n   \n   /* 表示桁数の設定 */\n   PREOUT1 = cats(&VAR._N);\n   \n   /* 平均値 */\n   if &VAR._MEAN ^= . then \n       PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\n   else \n       PREOUT2 = \"-\";\n   \n   /* 標準偏差 */\n   if &VAR._STD ^= . then \n       PREOUT3 = cats(put(round(&VAR._STD, 0.01), 8.2));\n   else \n       PREOUT3 = \"-\";\n   \n   /* 最小値 */\n   if &VAR._MIN ^= . then \n       PREOUT4 = cats(put(round(&VAR._MIN, 1), 8.0));\n   else \n       PREOUT4 = \"-\";\n       \n   /* 第一四分位値 */\n   if &VAR._Q1 ^= . then \n       PREOUT5 = cats(put(round(&VAR._Q1, 0.1), 8.1));\n   else \n       PREOUT5 = \"-\";\n       \n   /* 中央値 */\n   if &VAR._MEDIAN ^= . then \n       PREOUT6 = cats(put(round(&VAR._MEDIAN, 0.1), 8.1));\n   else \n       PREOUT6 = \"-\";\n       \n   /* 第三四分位値 */\n   if &VAR._Q3 ^= . then \n       PREOUT7 = cats(put(round(&VAR._Q3, 0.1), 8.1));\n   else \n       PREOUT7 = \"-\";\n       \n   /* 最大値 */\n   if &VAR._MAX ^= . then \n       PREOUT8 = cats(put(round(&VAR._MAX, 1), 8.0));\n   else \n       PREOUT8 = \"-\";\n       \n   /* 欠測数 */\n   PREOUT9 = cats(&VAR._NMISS);\n   \n   /* ID変数 */\n   ID + 1;\n   keep ID &CVAR. PREOUT1-PREOUT9;\nrun;\n\n/* ステップ4: 整形&出力 */\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n   prefix=OUT;\n   var PREOUT1-PREOUT9;\n   id ID;\nrun;\n\n/* 統計項目ラベルを追加 */\ndata SUMMARY_FINAL;\n   length STAT_ITEM $12.;\n   set SUMMARY_3;\n   select(_N_);\n       when(1) STAT_ITEM = \"症例数\";\n       when(2) STAT_ITEM = \"平均値\";\n       when(3) STAT_ITEM = \"標準偏差\";\n       when(4) STAT_ITEM = \"最小値\";\n       when(5) STAT_ITEM = \"第一四分位値\";\n       when(6) STAT_ITEM = \"中央値\";\n       when(7) STAT_ITEM = \"第三四分位値\";\n       when(8) STAT_ITEM = \"最大値\";\n       when(9) STAT_ITEM = \"欠測数\";\n   end;\nrun;\n\n/* 結果出力 */\nproc print data=SUMMARY_FINAL noobs;\n   title \"統計量サマリー（&CVAR.別 - &VAR.）\";\n   var STAT_ITEM OUT1 OUT2;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#大阪sas-user総会にて紹介されていたプログラムの紹介",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#大阪sas-user総会にて紹介されていたプログラムの紹介",
    "title": "SAS：要約統計量作成マクロ",
    "section": "",
    "text": "第3回：演題4「要約統計量マクロ」坂尻大樹さん\n\n要約統計量マクロ\n\n\n/* 疑似データの作成 */\ndata AAA;\n   input Name $ Age Height Treatment $;\n   datalines;\nアルフレッド 14 69.2 A群\nアリス 13 56.8 B群\nバーバラ 13 65.5 A群\nキャロル 14 62.9 B群\nヘンリー 14 63.7 A群\nジェームズ 12 . B群\nジェーン 12 59.9 A群\nジャネット 15 62.7 B群\nジェフリー 13 62.6 A群\nジョン 12 59.1 B群\n;\nrun;\n\n/* 分析設定 */\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = TREATMENT;\n\n/* ステップ1: 原データから桁数を取得 */\ndata SUMMARY_KETA1;\n   set &DS.;\n   if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n\nproc summary data=SUMMARY_KETA1;\n   var KETA;\n   output out=SUMMARY_KETA2 max=MAXKETA;\nrun;\n\ndata SUMMARY_KETA3;\n   set SUMMARY_KETA2;\n   if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n   else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n   \n   call symputx(\"KETA\", KETA);\nrun;\n\n/* ステップ2: クラスデータを作成 */\ndata SUMMARY_CLASS;\n   length &CVAR. $8.;\n   &CVAR. = \"A群\"; output;\n   &CVAR. = \"B群\"; output;\nrun;\n\n/* ステップ3: 要約統計量を算出 */\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n   class &CVAR.;\n   var &VAR.;\n   output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n\ndata SUMMARY_2;\n   length PREOUT1-PREOUT9 $12.;\n   set SUMMARY_1;\n   \n   /* 表示桁数の設定 */\n   PREOUT1 = cats(&VAR._N);\n   \n   /* 平均値 */\n   if &VAR._MEAN ^= . then \n       PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\n   else \n       PREOUT2 = \"-\";\n   \n   /* 標準偏差 */\n   if &VAR._STD ^= . then \n       PREOUT3 = cats(put(round(&VAR._STD, 0.01), 8.2));\n   else \n       PREOUT3 = \"-\";\n   \n   /* 最小値 */\n   if &VAR._MIN ^= . then \n       PREOUT4 = cats(put(round(&VAR._MIN, 1), 8.0));\n   else \n       PREOUT4 = \"-\";\n       \n   /* 第一四分位値 */\n   if &VAR._Q1 ^= . then \n       PREOUT5 = cats(put(round(&VAR._Q1, 0.1), 8.1));\n   else \n       PREOUT5 = \"-\";\n       \n   /* 中央値 */\n   if &VAR._MEDIAN ^= . then \n       PREOUT6 = cats(put(round(&VAR._MEDIAN, 0.1), 8.1));\n   else \n       PREOUT6 = \"-\";\n       \n   /* 第三四分位値 */\n   if &VAR._Q3 ^= . then \n       PREOUT7 = cats(put(round(&VAR._Q3, 0.1), 8.1));\n   else \n       PREOUT7 = \"-\";\n       \n   /* 最大値 */\n   if &VAR._MAX ^= . then \n       PREOUT8 = cats(put(round(&VAR._MAX, 1), 8.0));\n   else \n       PREOUT8 = \"-\";\n       \n   /* 欠測数 */\n   PREOUT9 = cats(&VAR._NMISS);\n   \n   /* ID変数 */\n   ID + 1;\n   keep ID &CVAR. PREOUT1-PREOUT9;\nrun;\n\n/* ステップ4: 整形&出力 */\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n   prefix=OUT;\n   var PREOUT1-PREOUT9;\n   id ID;\nrun;\n\n/* 統計項目ラベルを追加 */\ndata SUMMARY_FINAL;\n   length STAT_ITEM $12.;\n   set SUMMARY_3;\n   select(_N_);\n       when(1) STAT_ITEM = \"症例数\";\n       when(2) STAT_ITEM = \"平均値\";\n       when(3) STAT_ITEM = \"標準偏差\";\n       when(4) STAT_ITEM = \"最小値\";\n       when(5) STAT_ITEM = \"第一四分位値\";\n       when(6) STAT_ITEM = \"中央値\";\n       when(7) STAT_ITEM = \"第三四分位値\";\n       when(8) STAT_ITEM = \"最大値\";\n       when(9) STAT_ITEM = \"欠測数\";\n   end;\nrun;\n\n/* 結果出力 */\nproc print data=SUMMARY_FINAL noobs;\n   title \"統計量サマリー（&CVAR.別 - &VAR.）\";\n   var STAT_ITEM OUT1 OUT2;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#各プログラムの工夫点",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#各プログラムの工夫点",
    "title": "SAS：要約統計量作成マクロ",
    "section": "2 各プログラムの工夫点",
    "text": "2 各プログラムの工夫点"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#桁数自動取得の工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#桁数自動取得の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "3 1. 桁数自動取得の工夫",
    "text": "3 1. 桁数自動取得の工夫\ndata SUMMARY_KETA1;\n    set &DS.;\n    if &VAR. ^= . then KETA = length(cats(&VAR. - int(&VAR.)));\nrun;\n工夫点:\n\n小数点以下の桁数を自動検出: &VAR. - int(&VAR.)で小数点以下のみを抽出\n文字列変換による桁数計算: cats()で文字列に変換し、length()で桁数を取得\n例: 62.75の場合 → 62.75 - 62 = 0.75 → “0.75” → length = 4文字 → 小数点第2位\n\ndata SUMMARY_KETA3;\n    set SUMMARY_KETA2;\n    if MAXKETA = 1 then KETA = 0;  /* 小数点第0桁=整数値 */\n    else KETA = MAXKETA - 2;        /* 小数点第X桁を格納 */\n    \n    call symputx(\"KETA\", KETA);\nrun;\n工夫点:\n\n整数判定: MAXKETA=1は”0”（整数）を意味するため、KETA=0に設定\n桁数計算: “0.75”なら4文字-2=“.”と”0”を除く=2桁\nマクロ変数への格納: call symputx()でグローバルマクロ変数に設定"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#クラスデータ作成の工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#クラスデータ作成の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "4 2. クラスデータ作成の工夫",
    "text": "4 2. クラスデータ作成の工夫\n\n4.1 数値変数（年齢）の場合:\ndata SUMMARY_CLASS;\n    if _N_ = 0 then set &DS.(keep=&CVAR.);\n    do &CVAR. = &CSTR. to &CEND.;\n        output;\n    end;\n    stop;\nrun;\n工夫点:\n\n変数定義の継承: if _N_ = 0 then setで元データの変数属性を継承\n連続値の生成: doループで指定範囲の全ての値を生成\n効率的な処理: stopで無限ループを防止\n\n\n\n4.2 文字変数（治療群）の場合:\ndata SUMMARY_CLASS;\n    length &CVAR. $8.;\n    &CVAR. = \"A群\"; output;\n    &CVAR. = \"B群\"; output;\nrun;\n工夫点:\n\n文字変数の明示的定義: lengthで文字変数の長さを指定\n必要な値のみ生成: 存在する治療群のみを明示的に作成"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#統計量計算での工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#統計量計算での工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "5 3. 統計量計算での工夫",
    "text": "5 3. 統計量計算での工夫\nproc summary data=&DS. classdata=SUMMARY_CLASS exclusive nway;\n    class &CVAR.;\n    var &VAR.;\n    output out=SUMMARY_1 N= MEAN= STD= MIN= MEDIAN= MAX= NMISS= Q1= Q3= /autoname;\nrun;\n工夫点:\n\nCLASSDATA使用: 存在しないクラス値も強制的に出力（0件でも表示）\nEXCLUSIVE: 元データにないクラス値も処理対象に含める\nNWAY: 最下位レベルのクロス集計のみ出力\nAUTONAME: 変数名を自動生成（HEIGHT_N, HEIGHT_MEAN等）"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#数値フォーマットの工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#数値フォーマットの工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "6 4. 数値フォーマットの工夫",
    "text": "6 4. 数値フォーマットの工夫\nif &VAR._MEAN ^= . then \n    PREOUT2 = cats(put(round(&VAR._MEAN, 0.1), 8.1));\nelse \n    PREOUT2 = \"-\";\n工夫点:\n\n統計量別の桁数制御:\n\n平均値: 小数点第1位（0.1で四捨五入、8.1で表示）\n標準偏差: 小数点第2位（0.01で四捨五入、8.2で表示）\n最小値・最大値: 整数（1で四捨五入、8.0で表示）\n\n欠損値の統一処理: 欠損値は全て”-“で表示\n文字列への変換: cats()で余分な空白を除去"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#データ構造変換の工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#データ構造変換の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "7 5. データ構造変換の工夫",
    "text": "7 5. データ構造変換の工夫\nproc transpose data=SUMMARY_2 out=SUMMARY_3 (drop=_NAME_)\n    prefix=OUT;\n    var PREOUT1-PREOUT9;\n    id ID;\nrun;\n工夫点:\n\n行列の転置: 統計量（行）×群（列）の表形式に変換\n列名の制御: prefix=OUTで列名をOUT1, OUT2…に統一\n不要変数の削除: drop=_NAME_で転置時の不要変数を除去"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#最終出力での工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#最終出力での工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "8 6. 最終出力での工夫",
    "text": "8 6. 最終出力での工夫\ndata SUMMARY_FINAL;\n    length STAT_ITEM $12.;\n    set SUMMARY_3;\n    select(_N_);\n        when(1) STAT_ITEM = \"症例数\";\n        when(2) STAT_ITEM = \"平均値\";\n        /* ... */\n    end;\nrun;\n工夫点:\n\n日本語ラベル: 統計量に分かりやすい日本語名を付与\n順序の制御: select(_N_)で行番号に基づいた処理\n表示用の最終調整: ユーザーフレンドリーな出力形式"
  },
  {
    "objectID": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#マクロ設計の工夫",
    "href": "posts/statistics/2025/要約統計量マクロ_大阪SAS_坂尻さん.html#マクロ設計の工夫",
    "title": "SAS：要約統計量作成マクロ",
    "section": "9 7. マクロ設計の工夫",
    "text": "9 7. マクロ設計の工夫\n%let DS = AAA;\n%let VAR = HEIGHT;\n%let CVAR = AGE;  /* または Treatment *\n工夫点:\n\nパラメータ化: データセット名、変数名を簡単に変更可能\n汎用性: 数値・文字変数どちらでも対応\n再利用性: マクロ変数を変更するだけで異なる分析に適用可能\n\nこれらの工夫により、元の複雑な%SUMMARYマクロの機能を再現しつつ、理解しやすく保守しやすいコードになっています。"
  },
  {
    "objectID": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html",
    "href": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "",
    "text": "本記事では、組織でSASプログラミングを実行する際に、注意すべきことをまとめます。また初学者向けにPitfall and Bad Habitsについてまとめます。\n引用：\n\nGood Programming Practices in Clinical Trial – a Check Program\nHow Not to SAS: Avoiding Common Pitfalls and Bad Habits\n\nAbstract\n\nLarge pharmaceutical companies typically have many programmers, data managers and statisticians producing trial analysis and reporting programs. Each of these has their own style in programming. Unfortunately, such a large variety in program styles can lead to problems in the quality, readability, verifiability and maintainability of the program code.\nEstablishing a central standard, or guideline, for good programming practices (GPP) is therefore a necessary first step for large companies. By requiring all programs to meet the GPP guideline, we can insure that we produce high quality programs that are easily readable by others, can be verified easily and can be easily maintained.\n\nということで、MUST DO、MUST NOT DO、AVOID、RECCOMENTを組織として決めたら良い。\n\n\n\n\n\n\n\nカテゴリ\n説明\n\n\n\n\nMUST DO\nThese requirements for coding style and techniques must be met in the program.\n\n\nMUST NOT DO\nThe styles and techniques in this category must not be used in the program.\n\n\nAVOID\nThe styles and techniques items in this category should not be used in the program.\n\n\nRECOMMEND\nThe styles and techniques items in this category should be used in order to promote good readability, verifiability, maintainability and efficiency"
  },
  {
    "objectID": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#sasプログラミングtipsについてまとめます",
    "href": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#sasプログラミングtipsについてまとめます",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "",
    "text": "本記事では、組織でSASプログラミングを実行する際に、注意すべきことをまとめます。また初学者向けにPitfall and Bad Habitsについてまとめます。\n引用：\n\nGood Programming Practices in Clinical Trial – a Check Program\nHow Not to SAS: Avoiding Common Pitfalls and Bad Habits\n\nAbstract\n\nLarge pharmaceutical companies typically have many programmers, data managers and statisticians producing trial analysis and reporting programs. Each of these has their own style in programming. Unfortunately, such a large variety in program styles can lead to problems in the quality, readability, verifiability and maintainability of the program code.\nEstablishing a central standard, or guideline, for good programming practices (GPP) is therefore a necessary first step for large companies. By requiring all programs to meet the GPP guideline, we can insure that we produce high quality programs that are easily readable by others, can be verified easily and can be easily maintained.\n\nということで、MUST DO、MUST NOT DO、AVOID、RECCOMENTを組織として決めたら良い。\n\n\n\n\n\n\n\nカテゴリ\n説明\n\n\n\n\nMUST DO\nThese requirements for coding style and techniques must be met in the program.\n\n\nMUST NOT DO\nThe styles and techniques in this category must not be used in the program.\n\n\nAVOID\nThe styles and techniques items in this category should not be used in the program.\n\n\nRECOMMEND\nThe styles and techniques items in this category should be used in order to promote good readability, verifiability, maintainability and efficiency"
  },
  {
    "objectID": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#must-do-and-must-not-do-categories",
    "href": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#must-do-and-must-not-do-categories",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "2 Must Do and Must Not Do Categories",
    "text": "2 Must Do and Must Not Do Categories\n\n2.1 MUST DO\n\n\n\n\n\n\n項目\n\n\n\n\nMake a backup copy of the program prior to updates (Not checked by the program).\nプログラムはフォルダとして、yyyymmddで日付管理をしましょう。1つのフォルダで管理するのは間違っています。\n都度、プログラムを実行する際にフォルダを移動させましょう。注意点：プロジェクトのプログラムが開発が終了したら、最後は1つのプログラムで全プログラムが実行されて、.rtfで解析帳票が出てくるようにしましょう。途中でExcelに吐き出してExcelで結果を加工するのはご法度です。ありえません。\n\n\nUse program documentation, e.g. Headers and Comments. Write documentation in English. Imbedded comments within the body of the program code should detail the modular flow.\nこれも大事です。手動でHeadersをつけるの大変ですので、自動化させましょう。ただし、プログラム内にはコメントを残すのが良いです。\n\n\nTypically, write only one SAS® statement per line.\n\n\nUse indentation to arrange the code clearly.\n\n\nUse unique names for datasets and files within the program / macro.\nこれも大事です。var、tmpが楽でよいですが、きちんと名前をつけましょう。\n\n\nReference datasets and/or files explicitly in each step or proc.\n1つの帳票に対して原則1つのプログラムです。\n\n\nDisplay ‘Draft’ in the output before program validation.\nこれもいいですね。1人でやるのは悩ましいが。\n\n\nReset global options to original settings – if changed by the program / macro.\nglobal optionsやproc datasetでwork フォルダを空にしたりlogをresetしましょう。\n\n\nDelete all temporary datasets after program execution.\n上と同じ考えですね。\n\n\nUse ‘RUN;’ or ‘QUIT;’ at the end of each data step / proc.\nこれは基本です。\n\n\nUse defensive coding.\nよく分かりません。\n\n\nDisplay the name of the program on the output when running outside of RAGE (our document control system).\n\n\nOptimize the data. Do not re-read data.\n\n\n\n\n\n2.2 MUST NOT DO\n\n\n\n\n\n\n項目\n\n\n\n\nHard-Code data.\n手で記載するのをやめましょう。表のheaderやグラフにおけるY軸、X軸のlength等はマクロ変数、Rであれば事前にベクトルにしておきましょう。\n/* ハードコードの悪い例 */ data work.sales_analysis; set mylib.sales_data; where year = 2024 and region = ‘Tokyo’; /* 年度と地域を直接記述 */\n/* 固定値を直接計算に使用 */ bonus = salary * 0.15; /* ボーナス率15%をハードコード */\n/* ファイルパスをハードコード */ if _n_ = 1 then call symputx(‘output_path’, ‘C:\\Reports\\sales_2024.xlsx’); run;\n/* マクロ変数で設定値を管理 */ %let target_year = 2024; %let target_region = Tokyo; %let bonus_rate = 0.15; %let output_dir = C:\\Reports; %let library_name = mylib;\n/* または外部設定ファイルから読み込み */ %include “C:\\Config\\sas_config.sas”;\ndata work.sales_analysis; set &library_name..sales_data; where year = &target_year and region = “&target_region”;\n/* マクロ変数を使用 */ bonus = salary * &bonus_rate; run;\n/* 動的なファイル名生成 */ %let output_file = &output_dir.\\sales_&target_year..xlsx;\nproc export data=work.sales_analysis outfile=“&output_file” dbms=xlsx replace; run;\n\n\nManually edit output.\nこれは論外です。どんな理由であれ解析結果を手で直すことはあってはなりません。\n上のHard codingと同様に事前にマクロ変数やベクトルで準備しておきましょう。\n\n\nOverwrite input data.\nこれはlibname statementにおいて、readonly optionをつけておきましょうか。\n\n\nUse macro names that are already used by CARE Standard macros (our standardized reporting macros)\n既にあるマクロと同じ名前は利用してはいけません。\n\n\nUse of SAS® keywords for dataset and variable names.\n\n\n\nAny programmers that have supported clinical trial analysis and reporting understand the complexity of derived datasets that are ready to produce tables and graphs for efficacy and safety analysis. Taking data from several domains, many-to-many merging, transposing data, imputing dates and values, averaging within visits for duplicate results, and creating intermediate datasets for the final ADaM are more complex than we expect."
  },
  {
    "objectID": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#参考",
    "href": "posts/statistics/2025/組織におけるSASプログラミングのMUST_DO_MUST_NOT_DO.html#参考",
    "title": "プログラミング一般的な考え方（MUST DO , MUST NOT DO)",
    "section": "3 参考",
    "text": "3 参考\n\nChallenges in Implementing ADaM datasets: Balancing the Analysis-Ready and Traceability Concepts"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html",
    "href": "posts/statistics/2025/中間解析.html",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "中間解析は、試験の進行中にデータを評価し、治療効果や安全性に関する情報を得るために行われます。これにより、試験の進行状況を把握し、必要に応じて試験デザインやプロトコルを調整することができます。 中間解析は、特に以下の目的で実施されます。\n\n治療効果の初期評価: 中間解析は、治療効果の初期評価を行うために使用されます。これにより、治療が有効であるかどうかを早期に判断することができます。\n安全性の評価: 中間解析は、安全性に関する情報を収集するためにも使用されます。これにより、治療が安全であるかどうかを早期に判断することができます。\n早期終了の判断: 中間解析の結果に基づいて、試験を早期に終了するかどうか（無効中止や有効中止）を判断することができます。これにより、無駄なリソースを節約することができます。\n倫理的な配慮: 中間解析は、倫理的な配慮からも重要です。治療が有効でない場合や安全性に問題がある場合、試験を早期に終了することで、被験者の安全を確保することができます。\nリソースの最適化: 中間解析は、試験の進行状況を把握し、リソースを最適化するためにも使用されます。これにより、試験の効率を向上させることができます。\n\n本記事では、以下の内容について説明します。\n\n抗がん剤第2相における2値アウトカムの中間解析\n\nSimonの最適法\nSimonのMinmax法\nFlemingデザイン\nBayes流の方法\n\n検証的試験における中間解析\n\nO’Brien-Flemingデザイン\nPocockデザイン\nLan-DeMetsデザイン（α spending function）\n\n\n\n\n\n抗がん剤第2相試験においては、治療効果を評価するために2値アウトカム（例: 完全奏効、部分奏効、無効など）が使用されます。中間解析は、これらのアウトカムを評価するために行われます。試験統計家として試験計画時に中間解析を実施する必要があるかを考えておく必要があります。\nこれらの資料が参考になります。\n\n山本先生：SASユーザー総会2010\n\nまた、基本的に本節での手法はSASのProc power等のプロシジャで簡単に実装されていません。SASで実行する場合は、ネットからマクロを活用するか、社内でSASマクロを開発しておく必要があります。若干ハードルが高いかもしれないですが、SASでサンプルサイズ設計マクロを開発しておき、RやWebサイトの計算結果との一致をもってQCを行うことができるので、開発しておくことをお勧めします。\n\n\n\nこの節での記法について導入します。検証的試験における中間解析では別途記法を定義します。\n\np : 奏効確率（主要評価項目）\np_0 : 閾値奏効確率（p が p_0 以下の場合，薬剤は無効と判断）\np_1 : 期待奏効確率（p が p_1 以上の場合，薬剤は有効かもしれないと判断）\n\\alpha : 第 I 種の過誤確率（一般的に0.05と規定）\n\\beta : 第 II 種の過誤確率（一般的に0.20と規定）\n\n\n\n\n仮説検定は片側検定として以下のように定義する。\n\nH_0 : p \\leq p_0\nH_1 : p &gt; p_1"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#中間解析の目的",
    "href": "posts/statistics/2025/中間解析.html#中間解析の目的",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "中間解析は、試験の進行中にデータを評価し、治療効果や安全性に関する情報を得るために行われます。これにより、試験の進行状況を把握し、必要に応じて試験デザインやプロトコルを調整することができます。 中間解析は、特に以下の目的で実施されます。\n\n治療効果の初期評価: 中間解析は、治療効果の初期評価を行うために使用されます。これにより、治療が有効であるかどうかを早期に判断することができます。\n安全性の評価: 中間解析は、安全性に関する情報を収集するためにも使用されます。これにより、治療が安全であるかどうかを早期に判断することができます。\n早期終了の判断: 中間解析の結果に基づいて、試験を早期に終了するかどうか（無効中止や有効中止）を判断することができます。これにより、無駄なリソースを節約することができます。\n倫理的な配慮: 中間解析は、倫理的な配慮からも重要です。治療が有効でない場合や安全性に問題がある場合、試験を早期に終了することで、被験者の安全を確保することができます。\nリソースの最適化: 中間解析は、試験の進行状況を把握し、リソースを最適化するためにも使用されます。これにより、試験の効率を向上させることができます。\n\n本記事では、以下の内容について説明します。\n\n抗がん剤第2相における2値アウトカムの中間解析\n\nSimonの最適法\nSimonのMinmax法\nFlemingデザイン\nBayes流の方法\n\n検証的試験における中間解析\n\nO’Brien-Flemingデザイン\nPocockデザイン\nLan-DeMetsデザイン（α spending function）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#抗がん剤第2相における2値アウトカムの中間解析",
    "href": "posts/statistics/2025/中間解析.html#抗がん剤第2相における2値アウトカムの中間解析",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "抗がん剤第2相試験においては、治療効果を評価するために2値アウトカム（例: 完全奏効、部分奏効、無効など）が使用されます。中間解析は、これらのアウトカムを評価するために行われます。試験統計家として試験計画時に中間解析を実施する必要があるかを考えておく必要があります。\nこれらの資料が参考になります。\n\n山本先生：SASユーザー総会2010\n\nまた、基本的に本節での手法はSASのProc power等のプロシジャで簡単に実装されていません。SASで実行する場合は、ネットからマクロを活用するか、社内でSASマクロを開発しておく必要があります。若干ハードルが高いかもしれないですが、SASでサンプルサイズ設計マクロを開発しておき、RやWebサイトの計算結果との一致をもってQCを行うことができるので、開発しておくことをお勧めします。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#パラメータの定義",
    "href": "posts/statistics/2025/中間解析.html#パラメータの定義",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "この節での記法について導入します。検証的試験における中間解析では別途記法を定義します。\n\np : 奏効確率（主要評価項目）\np_0 : 閾値奏効確率（p が p_0 以下の場合，薬剤は無効と判断）\np_1 : 期待奏効確率（p が p_1 以上の場合，薬剤は有効かもしれないと判断）\n\\alpha : 第 I 種の過誤確率（一般的に0.05と規定）\n\\beta : 第 II 種の過誤確率（一般的に0.20と規定）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#仮説検定",
    "href": "posts/statistics/2025/中間解析.html#仮説検定",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "",
    "text": "仮説検定は片側検定として以下のように定義する。\n\nH_0 : p \\leq p_0\nH_1 : p &gt; p_1"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#arguments",
    "href": "posts/statistics/2025/中間解析.html#arguments",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.1 Arguments",
    "text": "2.1 Arguments\n\n\n\n\n\n\n\nパラメータ\n説明\n\n\n\n\npu\nunacceptable response rate; baseline response rate that needs to be exceeded for treatment to be deemed promising\n\n\npa\nresponse rate that is desirable; should be larger than pu\n\n\nep1\nthreshold for the probability of declaring drug desirable under pu (target type 1 error rate); between 0 and 1\n\n\nep2\nthreshold for the probability of rejecting the drug under pa (target type 2 error rate); between 0 and 1\n\n\nnmax\nmaximum total sample size (default 100; can be at most 1000)\n\n\nx\nobject returned by ph2simon\n\n\n…\narguments to be passed onto plot and print commands called within"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#value",
    "href": "posts/statistics/2025/中間解析.html#value",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.2 Value",
    "text": "2.2 Value\nph2simon returns a list with pu, pa, alpha, beta and nmax as above and:\n\n\n\n\n\n\n\n出力\n説明\n\n\n\n\nout\nmatrix of best 2 stage designs for each value of total sample size n. The 6 columns in the matrix are:\n\n\n\n\n\n\nカラム\n説明\n\n\n\n\nr1\nnumber of responses needed to exceeded in first stage\n\n\nn1\nnumber of subjects treated in first stage\n\n\nr\nnumber of responses needed to exceeded at the end of trial\n\n\nn\ntotal number of subjects to be treated in the trial\n\n\nEN(pu)\nexpected number of patients in the trial under pu\n\n\nPET(pu)\nprobability of stopping after the first stage under pu\n\n\n\nTrial is stopped early if &lt;= r1 responses are seen in the first stage and treatment is considered desirable only when &gt;r responses seen."
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#methods",
    "href": "posts/statistics/2025/中間解析.html#methods",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.3 Methods",
    "text": "2.3 Methods\n\nprint(ph2simon): formats and returns the minimax, optimal and any admissible designs.\nplot(ph2simon): plots the expected sample size against the maximum sample size as in Jung et al., 2001"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#実務に応用する際において",
    "href": "posts/statistics/2025/中間解析.html#実務に応用する際において",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.4 実務に応用する際において",
    "text": "2.4 実務に応用する際において\nSimonのMinmax、SimonのOptimanデザインのいずれの方法においても、「薬剤が無効な場合に早期中止を判断するための2段階デザイン無効な場合の期待患者数/を最小にしたい」という無効中止のみを考えた試験デザインである。 すなわち、Rの出力結果から、第1段階目のn1人において、r1人未満の奏効例数であれば、試験を無効中止とするようなデザインである。Rのパッケージで症例数設計をする場合、この数値が正しいことを試験統計家としてValidationをしておく必要はある。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#数学的背景について",
    "href": "posts/statistics/2025/中間解析.html#数学的背景について",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "2.5 数学的背景について",
    "text": "2.5 数学的背景について\n別記事で解説します。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#試験概要",
    "href": "posts/statistics/2025/中間解析.html#試験概要",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.1 試験概要",
    "text": "6.1 試験概要\n今回設計した臨床試験の基本パラメータと解析計画をまとめました。この試験では2段階の逐次デザインを採用し、中間解析で早期中止の可能性を検討します。"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#試験設計パラメータ",
    "href": "posts/statistics/2025/中間解析.html#試験設計パラメータ",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.2 試験設計パラメータ",
    "text": "6.2 試験設計パラメータ\n\n\n\n項目\n設定値\n\n\n\n\n登録期間\n2年\n\n\n追跡期間\n5年\n\n\n目標症例数\n126.7例（2群計128例）63.25例/年\n\n\n期待イベント数\n96.5例（対照群: 55.4例、治療群: 41.1例）"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#解析スケジュール",
    "href": "posts/statistics/2025/中間解析.html#解析スケジュール",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.3 解析スケジュール",
    "text": "6.3 解析スケジュール\n\n6.3.1 中間解析（第1段階）\n\n実施時期: 試験開始から3年後（2.92年）\n期待イベント数: 48.3例（対照群: 30.4例、治療群: 17.9例）\n\n\n\n6.3.2 最終解析（第2段階）\n\n実施時期: 全症例の追跡完了後\n期待イベント数: 96.5例"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#統計的判定基準",
    "href": "posts/statistics/2025/中間解析.html#統計的判定基準",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.4 統計的判定基準",
    "text": "6.4 統計的判定基準\n\n\n\n\n\n\n\n\n\n解析段階\n統計量\n判定基準\n結論\n\n\n\n\n中間解析\nZ₁ &gt; 2.96259\n有効性境界を超過\n有効中止\n\n\n\nZ₁ &lt; 0.86994\n無効性境界を下回る\n無効中止\n\n\n\n0.86994 ≤ Z₁ ≤ 2.96259\n境界値の間\n試験継続\n\n\n最終解析\nZ₂ &gt; 1.89189\n有効性境界を超過\n有効"
  },
  {
    "objectID": "posts/statistics/2025/中間解析.html#まとめ",
    "href": "posts/statistics/2025/中間解析.html#まとめ",
    "title": "第2相抗がん剤開発及び検証的試験の中間解析",
    "section": "6.5 まとめ",
    "text": "6.5 まとめ\nこの逐次デザインにより、試験の途中で明確な結果が得られた場合には早期中止が可能となり、患者さんの負担軽減と試験の効率化が期待できます。特に、中間解析時点で強い有効性が示された場合や、逆に無効性が明らかになった場合には、倫理的観点からも適切な判断ができる設計となっている。\nこの後は、Proc lifetest Procedure等で実際に解析を行い推定値に基づくZ統計量を算出した上で、Proc Seqtest Procedureで中間解析の結果を評価することとなる。"
  },
  {
    "objectID": "posts/statistics/2025/TTE総説.html",
    "href": "posts/statistics/2025/TTE総説.html",
    "title": "TTE総説論文",
    "section": "",
    "text": "本記事では、薬剤疫学会で公開された下記2つの論文を勉強する。"
  },
  {
    "objectID": "posts/statistics/2025/TTE総説.html#要約",
    "href": "posts/statistics/2025/TTE総説.html#要約",
    "title": "TTE総説論文",
    "section": "1 要約",
    "text": "1 要約\n\n観察研究におけるバイアス\n\nランダム化の欠如による交絡\n不適切な研究デザインがもたらす選択バイアス\nImmortal Time bias"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html",
    "href": "posts/statistics/2025/SASマクロ入門1.html",
    "title": "SASマクロ入門1",
    "section": "",
    "text": "本記事では、2022年SASユーザー総会の森田氏の「マクロのすすめ～SASにプログラムをかいてもらおう～」の文章を写経したものである。個人の勉強記録であるため、基本的には元の資料を参考にしていただきたい。\n\n\n基礎的な事項で参考になるものはいつも通り、以下のブログである。特に実務上で重要だが知られていないデータステップで変数をマクロ化するcall syputx、データステップ外で関数を使えるようにする%sysfuncはきちんと理解したい。また、マクロ言語入門9で紹介されている&macro_variable.の.は常に記載する、もしくは記載しない等を組織/個人開発で統一しておくことが望ましい。\n\nマクロ言語入門1：マクロ変数とは【%LET】\nマクロ言語入門2：マクロの登録と実行【%MACRO、%MEND】\nマクロ言語入門3：パラメータの設定【定位置パラメータ】\nマクロ言語入門4：パラメータの設定【キーワードパラメータ】\nマクロ言語入門5：クォート処理【%STR関数】\nマクロ言語入門6：クォート処理【%BQUOTE関数】\nマクロ言語入門7：マクロ内でのループ処理【%DO】\nマクロ言語入門8：マクロ内での条件分岐処理【%IF】\nマクロ言語入門9：マクロ変数とドット\nマクロ言語入門10：マクロ変数と&&\nマクロ言語入門11：演算評価 【%EVAL、%SYSEVALF】\n値をマクロ変数に格納する「CALL SYMPUTX」その1\nデータステップ外で関数を使えるようにする「%SYSFUNC」その１\n森岡 裕, %if-%then-%doのオープンコードでの利用と9.4以降のSASマクロ拡張点について, SASユーザー総会論文集, 2021.\n本本 早紀, クォート処理及びスコープへの理解を深める, SASユーザー総会論文集, 2019, p141-150\n竹田 真, 佐藤 智美, 社内マクロライブラリの構築について, SASユーザー総会論文集, 2001, p37-44\n柳沢 健太郎, 常吉 華奈, 山本 典子, 臨床試験における集計解析用 SASプログラムの標準化, SASユーザー総会論文集, 2004, p37-44\n田村 洋介, SASマクロライブラリの開発/管理/運用, SASユーザー総会論文集, 2007, p123-134\n“How to organize your SAS projects in Git”, SAS Blogs, 2020-11-10\n“Good Programming Practice In Macro Development”, PhUSE Advance Hub, 2021-09-21\nRon Cody, Cody’s Data Cleaning Techniques Using SAS, SAS Press, 2017, 234p\n市橋 里絵, 江口 幸子, 渡邊 大丞, 月田 あづき, “Standard Template Programs”の開発, SASユーザー総会論文集, 2010, p381-383\n\nまた、他にも応用上の使い方等は以下が参考になる。 - Compareプロシジャの結果が一致か不一致か、何が不一致かをマクロ変数で取得する話 なお、私が知る限りProc Compare Procedureの解説文献は、2022年度のSASユーザー総会資料のCOMPAREプロシジャの便利な使い方がおすすめである。Proc Compare Procedureについては別記事で解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#参考ブログ",
    "href": "posts/statistics/2025/SASマクロ入門1.html#参考ブログ",
    "title": "SASマクロ入門1",
    "section": "",
    "text": "基礎的な事項で参考になるものはいつも通り、以下のブログである。特に実務上で重要だが知られていないデータステップで変数をマクロ化するcall syputx、データステップ外で関数を使えるようにする%sysfuncはきちんと理解したい。また、マクロ言語入門9で紹介されている&macro_variable.の.は常に記載する、もしくは記載しない等を組織/個人開発で統一しておくことが望ましい。\n\nマクロ言語入門1：マクロ変数とは【%LET】\nマクロ言語入門2：マクロの登録と実行【%MACRO、%MEND】\nマクロ言語入門3：パラメータの設定【定位置パラメータ】\nマクロ言語入門4：パラメータの設定【キーワードパラメータ】\nマクロ言語入門5：クォート処理【%STR関数】\nマクロ言語入門6：クォート処理【%BQUOTE関数】\nマクロ言語入門7：マクロ内でのループ処理【%DO】\nマクロ言語入門8：マクロ内での条件分岐処理【%IF】\nマクロ言語入門9：マクロ変数とドット\nマクロ言語入門10：マクロ変数と&&\nマクロ言語入門11：演算評価 【%EVAL、%SYSEVALF】\n値をマクロ変数に格納する「CALL SYMPUTX」その1\nデータステップ外で関数を使えるようにする「%SYSFUNC」その１\n森岡 裕, %if-%then-%doのオープンコードでの利用と9.4以降のSASマクロ拡張点について, SASユーザー総会論文集, 2021.\n本本 早紀, クォート処理及びスコープへの理解を深める, SASユーザー総会論文集, 2019, p141-150\n竹田 真, 佐藤 智美, 社内マクロライブラリの構築について, SASユーザー総会論文集, 2001, p37-44\n柳沢 健太郎, 常吉 華奈, 山本 典子, 臨床試験における集計解析用 SASプログラムの標準化, SASユーザー総会論文集, 2004, p37-44\n田村 洋介, SASマクロライブラリの開発/管理/運用, SASユーザー総会論文集, 2007, p123-134\n“How to organize your SAS projects in Git”, SAS Blogs, 2020-11-10\n“Good Programming Practice In Macro Development”, PhUSE Advance Hub, 2021-09-21\nRon Cody, Cody’s Data Cleaning Techniques Using SAS, SAS Press, 2017, 234p\n市橋 里絵, 江口 幸子, 渡邊 大丞, 月田 あづき, “Standard Template Programs”の開発, SASユーザー総会論文集, 2010, p381-383\n\nまた、他にも応用上の使い方等は以下が参考になる。 - Compareプロシジャの結果が一致か不一致か、何が不一致かをマクロ変数で取得する話 なお、私が知る限りProc Compare Procedureの解説文献は、2022年度のSASユーザー総会資料のCOMPAREプロシジャの便利な使い方がおすすめである。Proc Compare Procedureについては別記事で解説する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロはsasにプログラムを書いてもらうための機能",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロはsasにプログラムを書いてもらうための機能",
    "title": "SASマクロ入門1",
    "section": "2.1 マクロはSASにプログラムを書いてもらうための機能",
    "text": "2.1 マクロはSASにプログラムを書いてもらうための機能\nマクロは、簡単に言うとテキストの置換機能である。Aという文字列をBという文字列に置き換える機能である。そして、このテキスト置換機能がたいへん役に立つ。なぜなら、プログラミング業務では、似たような解析やデータハンドリングを繰り返し行っている場合が多いからである。例えば、他のプロジェクトと同じ解析を行う、対象のデータセット名だけが異なる、対象データの抽出条件だけが異なる、処理対象の変数だけが異なる、設定値やオプション指定だけが異なる、出力形式（行数や列数、ファイル形式など）だけが異なる。こういった場合、各解析のSASプログラムの大部分が重複することになり、差異が生じるのは、ほんの一部となる。つまり、基準となるプログラムをコピー&ペーストで複製して、変更が必要な箇所だけをテキスト置換すれば済む場合が多い。この基準となるプログラムの設定とテキスト置換をSASプログラムで実現するための機能がマクロである。マクロがプログラムを書いてくれるのである。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロの仕組み",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロの仕組み",
    "title": "SASマクロ入門1",
    "section": "2.2 マクロの仕組み",
    "text": "2.2 マクロの仕組み\n私たちの書いたSASプログラムは、SASのコンパイラによって解釈され、実行される。このとき、実はSASには二種類のコンパイラがある。\n1. マクロを解析・実行するマクロプロセッサ、\n2. DATAステップおよびPROCステップを解析・実行するコンパイラである。\nSASプログラムをサブミットすると、まず、①マクロプロセッサがマクロ部分だけを解析・実行し、DATAステップまたはPROCステップの命令だけのプログラムを作成する。その後、②のコンパイラによって、マクロ部分が解析された後のプログラムを実行する。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロ変数を使う",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロ変数を使う",
    "title": "SASマクロ入門1",
    "section": "2.3 マクロ変数を使う",
    "text": "2.3 マクロ変数を使う\n本章では、マクロの基本的な機能であるマクロ変数について概説する。シンプルな機能ながら応用場面は多い。マクロ変数を習得するだけでもプログラミングの効率化や品質向上が期待できる。\n\n2.3.1 マクロ変数とは\nマクロ変数はテキストを格納する容れものである。マクロ変数に格納したテキストはプログラム中で参照できる。マクロプロセッサは、SASプログラム内でマクロ変数の参照箇所を見つけると、そのマクロ変数に格納したテキストに置き換える。テキストファイルで行う一括置換をSASに実行してもらうイメージである。\n\n\n2.3.2 マクロ変数の作成と参照\nマクロ変数は%letステートメントを利用して作成する。\n%let マクロ変数名 = 格納したい値;\nマクロ変数名は最大32文字、最初の文字は英字またはアンダースコア、その後の文字は英字・数字・アンダースコアが使用可能である。また大文字と小文字は区別されない。設定値AF、DMS、SQL、SYSは該当する自動マクロ変数と名前が重複する可能性があるため、避けたほうがよい。\n%let greeting = Hello World;\n%put &greeting.;\n%put 「Hello World」と表示;\n\n%let year = 40;\n%let comment = おめでとうございます;\n%put SASユーザー総会&year.周年&comment.;\n%put 「SASユーザー総会40周年おめでとうございます」と表示;\n\n%let anavar = age; /* マクロ変数&anavarを定義し、ageという値を格納 */\n\n/* 単変量解析; */\nproc univariate data = sashelp.class;\nvar &anavar.; /* マクロプロセッサによって&age.に置換される */\nclass sex;\nrun;\n\n/* 単変量解析(bee-swarm plot)を作成; */\nproc sgplot data = sashelp.class;\nvbox &anavar. / category = sex nofill nooutliers;\nscatter y = &anavar. x = sex / jitter;\nrun;\nマクロ変数により、プログラムに一貫性を持たせることができる。例えば、追加解析や仕様変更により、年齢(age)ではなく体重(weight)の解析を行いたい場合は、%let anavarの定義部分だけを変更するだけで済む。人の手を介することで修正漏れやミスタイプのリスクがある。\nまた、CALL SYMPUTXルーチンを利用すれば、DATAステップでデータセットの変数の内容をマクロ変数に格納できる。次章で説明する制御構文と併せて、データセットの内容に応じて、プログラムを変更させることが可能になり、プログラムに柔軟性を与えられる。\ncall symputx('マクロ変数名', 格納したい値(DATAステップの変数名));\n\n/* 男女別の生徒数を数えて、それぞれをマクロ変数に格納する; */\nproc freq data = sashelp.class noprint;\ntables sex / out = out1;\nrun;\n\ndata _null_;\nset out1;\nif sex = \"男子\" then call symputx('N_Male', count);\nif sex = \"女子\" then call symputx('N_Female', count);\nrun;\n\n/* マクロ変数の値をログに出力して確認; */\n%put N_Male = &N_Male N_Female = &N_Female;/* 「N_Male : 10 N_Female : 9」と出力; */\nまた、SQLプロシジャのINTO句を利用して、データセットの変数の内容をマクロ変数に格納することも可能である。\nproc sql;\nselect 変数名1, 変数名2, ..., 変数名N\ninto :マクロ変数名1, :マクロ変数名2, ..., :マクロ変数名N\nfrom データセット名;\nquit;\n\nproc sql noprint;\ncreate table work.class as\nselect *\nfrom sashelp.class\nrun;\nquit;\n\n%put &sqlobs.; /* proc sqlで直近に処理したデータ(OBS数)を格納; */\n\n\n2.3.3 マクロ変数は文字型変数\nマクロ変数は、DATAステップと違って、すべて文字型変数として扱われる。このため、マクロプロセッサに数値演算をさせるような場面では、注意が必要である。数値の場合は%eval関数、小数を含む場合は%sysevalf関数に演算式を渡す必要がある。（ただし、%evalと%sysevalfは、演算のおよそについても調査した上で利用しないと）\n%let not5 = 1 + 4;\n%put &not5.; /* 「1 + 4」と表示; */\n\n%let equal5 = %eval(1 + 4);\n%put &equal5.; /* 「5」と表示; */\n\n%let not5 = 1.5 + 3.5;\n%put &not5.; /* 「1.5 + 3.5」と表示; */\n\n%let equal5 = %sysevalf(1.5 + 3.5);\n%put &equal5.; /* 「5」と表示; */\n\n%let not5 = %eval(1.5 + 3.5); /* %evalは整数計算だけなのでエラーとなる */\nなお、格納されるテキストによってマクロ変数の変数は自動的に調整されるため、データセットの文字型変数のように長さを気にする必要はない（ただし、SAS9.4の最大長は65,534文字である）。\n\n\n2.3.4 自動マクロ変数\nマクロプロセッサが自動的に作成する自動マクロ変数もある。自動マクロ変数は、実行環境の確認、プログラム実行時の表示などに利用できる。いくつか例を示す。\n\n\n\n\n\n\n\n自動マクロ変数名\n内容\n\n\n\n\nSYSVER\nSASのバージョンを格納（例：9.4）\n\n\nSYSDATEP\nSAS セッションの開始日をDATEフォーマットで格納（例：01SEP2022）\n\n\nSYSLAST\nSAS セッションで直近に作成したデータセットを格納（例：WORK.CLASS）\n\n\nSYSUSERID\n現在のSAS プロセスのユーザーIDを格納（例：morita.yusuke）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロプログラムを使う",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロプログラムを使う",
    "title": "SASマクロ入門1",
    "section": "2.4 マクロプログラムを使う",
    "text": "2.4 マクロプログラムを使う\n本章では、マクロの主要機能であるマクロプログラムについて概説する。前章のマクロ変数とマクロプログラムを組み合わせることで、より複雑なプログラムをマクロプロセッサに書いてもらうことができる。\n\n2.4.1 マクロプログラムとは\nマクロプログラムもマクロ変数と同様に、テキスト置換を行う機能である。マクロ変数は、プログラム中の変数名、データセット名、オプションまたは短いテキストの置換に用いられる場合が多い。一方、マクロプログラムは、あるまとまった単位のSAS プログラムへの置換に利用されるものであり、マクロ変数と組み合わせることで、また、制御構文を使用することで、さまざまなプログラムをマクロプロセッサに手軽に作成してもらうことができる。\n\n\n2.4.2 マクロプログラムの作成・呼び出し方法\nマクロプログラムは%macroおよび%mendステートメントを利用して作成する。\n%macro マクロプログラム名; （簡略したいテキスト） %mend マクロプログラム名;\nマクロプログラム名は最大32文字、最初の文字は英字またはアンダースコア、その後の文字は英字・数字・アンダースコアが使用可能である。\n\n\n2.4.3 マクロプログラムの特徴\n\n2.4.3.1 呼び出し時にマクロ変数を受け取ることができる\n基準となるプログラムをコピー&ペーストして、一部分を書き換えたい場合があ る。この基準となるプログラムをマクロプログラム内に格納して、書き換えたい箇所を呼び出し時に受け取れるマクロ変数として、マクロプログラムに指定できる。このマクロプログラム呼び出し時に受け取るマクロ変数をマクロパラメータという。マクロパラメータも、ユーザーが任意の名前を設定可能で、そのマクロプログラム内で参照可能なマクロ変数となる。マクロパラメータとしてデータセット名(dsn)および変数名(var)を指定する例を以下に示す。\n/* 呼び出し時にマクロパラメータを指定; */\n%macro univariate2(dsn, var); /* マクロ名の後にマクロパラメータを設定; */\n\nproc univariate data = &dsn.;\nvar &var.;\nclass sex;\nrun;\n\n%mend;\n\n/* 呼び出し時にマクロパラメータを指定して実行; */\n%univariate2(dsn=sashelp.class, var=age)\n%univariate2(dsn=sashelp.class, var=weight)\n%univariate2(dsn=sashelp.class, var=height)\nまた、マクロパラメータに予め既定値を与えることもできる。この既定値をもつマクロパラメータをキーワードパラメータという。キーワードパラメータは呼び出し時に指定しなければ、既定値が自動的に設定される。したがって、ほぼ毎回同じパラメータで実行する可能性があるパラメータはキーワードパラメータとして宣言すとよい。\n\n\n2.4.3.2 制御構文が使える\nDATAステップでは、条件分岐のIFステートメント、反復処理のDOステートメントが使用できる。マクロ言語にも同様に%ifステートメント、%doステートメントが用意されており、データセットの内容やマクロパラメータの内容に応じて、マクロプロセッサの動作を変更できる。これら制御構文はマクロ変数にはない機能で、マクロプログラムに柔軟性を与える機能の一つとなっている。\n制御構文の例として、条件分岐の%ifステートメントについて説明する。\n%if 条件文 %then %do;\n(条件文がTrueの場合の処理)\n%end;\n%else %if 条件文 %then %do;\n(条件文がTrueの場合の処理)\n%end;\n%else %do;\n(全条件文をも不満足している場合の処理)\n%end;\nなお、上記のdsn および var のように、既定値を持たないマクロパラメータを位置パラメータという。\nまた、DATAステップでは、条件分岐から反復処理の%doステートメントについて説明する。\n%macro list_by_4years(startyr, endyr);\n    title1 \"Customer List of &yr. to &endyr.\";\n    proc print data = work.customer;\n        where &yr. &lt;= year &lt;= &endyr., &by 4;\n        var year customer_revenue;\n    run;\n    title1 \"Customer List of 2000 to 2003\";\n    proc print data = work.customer;\n        where 2000 &lt;= year &lt;= 2003;\n        var year customer_revenue;\n    run;\n    title1 \"Customer List of 2004 to 2007\";\n    proc print data = work.customer;\n        where 2004 &lt;= year &lt;= 2007;\n        var year customer_revenue;\n    run;\n%mend;\n\n%list_by_4years(startyr=1996, endyr=2007)\nマクロの制御構文には、他にも%do-%while、%do-%until等がある。しかし、初心者のうちは%ifと%doの2つを事実としても余りがない。%ifと%doもマクロプロセッサに対する命令である。一方、DATAステップのコンパイラに対する命令であり、データセットの変数の内容を変更することになる。ただし、%ifと%do%sysevalfは、SAS9.4 M5からマクロプログラム内部でなくても（オープンコードで）%if%then%else等を使えるようになった。2021年のSASユーザー総会の発表資料に詳細が記載されている。\n\n\n\n2.4.4 マクロ関数\n字句SASで用意されたマクロ関数を利用できる。これらのマクロ関数は、マクロプロセッサによって実行されるマクロプログラムである。DATAステップでデータセットを編集するために利用される関数と同名・同機能であっても異なるものであることに留意されたい。以下にマクロ関数の一例を示す。\n\n\n\n\n\n\n\nマクロ関数名\n説明\n\n\n\n\n%upcase(文字列) / %lowcase(文字列)\n文字列を大文字/小文字に変換する\n\n\n%trim(文字列)\n文字列の末尾の余分なスペース文字を取り除く\n\n\n%index(文字列1, 文字列2)\n文字列1の中に文字列2が含まれていれば、最初の位置(何文字目)を返す。文字列2が含まれていなければ0を返す\n\n\n%sysfunc(関数名)\nDATAステップの関数をマクロプロセッサから使用する\n\n\n\n\n\n2.4.5 マクロ変数のスコープ\nマクロ変数にもスコープ、つまりプログラム中で参照可能な範囲がある。スコープによってglobal マクロ変数とlocal マクロ変数に区分される。global マクロ変数は、プログラムのどこからでも値を参照可能である。一方、local 変数は、その変数が宣言されたマクロプログラム内部でのみ値を参照可能である。\n/* マクロ変数のスコープ; */\n%global global_var; /* グローバルマクロ変数を宣言; */\n\n%macro global_local;\n    %let local_var = ローカル変数です; /* このマクロ内部だけで有効期間; */\n    %let global_var = グローバル変数です;\n%mend;\n\n%global_local /* マクロを実行; */\n\n%put &global_var.; /* グローバル変数なので、マクロ外でも参照可能; */\n%put &local_var.; /* マクロ外なでマイナ一ルで、変数を参照できない; */\n初心者のうちは、スコープを意識する機会はさほど無いかもしれない。しかし、チームでマクロプログラムを分担して構築する場合、マクロプログラムで構築されるシステムを利用する際は、マクロ変数の衝突を避けるため、マクロ変数のスコープに留意が必要となる。（local マクロ変数を明示的に作成するためのlocal ステートメントが用意されている。）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロをデバッグする",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロをデバッグする",
    "title": "SASマクロ入門1",
    "section": "2.5 5. マクロをデバッグする",
    "text": "2.5 5. マクロをデバッグする\n本節で同じ章にまとめ」で、マクロを書けばバグが生じる。したがって、マクロを効率的にデバッグする技術を重要である。以下に、マクロプロセッサが、マクロプログラムを生じさせたのかを知ることが有用である。このため、マクロのデバッグを効率的に行うためのオプションが用意されている。以下に、よく使用するオプションの例を示す。\n\n\n\n\n\n\n\nオプション名\n内容\n\n\n\n\nMPRINT\nマクロプロセッサによって生成されるSAS プログラムをSAS ログに表示する\n\n\nMLOGIC\nマクロプロセッサがマクロパラメータにどのような値を受け取ったか、%if条件分岐を True/Falseのどちらに判断したか、マクロの開始点と終了点をSASログに表示する\n\n\nSYMBOLGEN\nマクロプロセッサが、マクロ変数をどの値に置き換えたかSAS ログに表示する\n\n\n\nこれらのオプションを指定することで、SAS ログにマクロプロセッサからの情報が出力されるようになる。しかし、上記オプションを指定してもSAS ログを読み解くのが困難な場合もある。その場合、mfileオプションでマクロプロセッサが出力したプログラム全体を別ファイルとして出力することも可能である。（マクロの学習にも活用できる。）"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロをライブラリとして整理して活用する",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロをライブラリとして整理して活用する",
    "title": "SASマクロ入門1",
    "section": "2.6 6. マクロをライブラリとして整理して活用する",
    "text": "2.6 6. マクロをライブラリとして整理して活用する\n作成したマクロは積極的に活用したほうがよい。一度制作したマクロプログラム、別の活用場面では思いがけずれなく再現全文が現在の場合がある。つまり、マクロはほとんど常設され、品質も向上していく。そこで本章では、作成したマクロプログラムをライブラリとして整理し、プログラムから呼び出し可能にする方法について説明する。\n以下にマクロライブラリを作成する手順を示す。\n\nマクロを格納するフォルダを用意する。（フォルダは複数あってもよい）\n各マクロプログラムを個別ファイルに格納していうフォルダに保存する。 このとき、ファイル名はマクロ名と同じにする必要がある。（マクロ名.sas とする）\nマクロを呼び出す側のプログラムで、以下のMAUTOSOURCE及びSASAUTOSの2つのオプションを指定する。このとき、SASAUTOSに（1）のフォルダを指定する。\n\n/* マクロをライブラリとして活用する; */\noptions mautosource sasautos=(sasautos, \"C:\\sasYearlyMacros\");\n/* （1）の sasautos内容ないこと; */\noptions mautosource sasautos=(sasautos, \"C:\\sasYearlyMacros\" \"C:\\sasYearMacros\");\nこれで、マクロライブラリ中のマクロプログラムが呼び出し可能になる。\nまた、本章では触れないが、継続として共有するライブラリを整備・活用した事例は、過去のSASユーザー総会の複数の発表がある。\nまた、SAS9.4 M6 以降、WebページのバージョンProgramming Tool であるGitHub との連携機能が搭載されている。GitHub上でマクロファイルのバージョン管理を行い、SASから直接GitHub上のマクロプログラムをinclude可能になっている。多くのオープンソースマクロがGitHub上で管理・公開されており、GitHub上での連携機能について今後の発展が注目される。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロのコツ",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロのコツ",
    "title": "SASマクロ入門1",
    "section": "2.7 マクロのコツ",
    "text": "2.7 マクロのコツ\nどんな項目もで正しく場合ほど拡張を発想する。本章ではマクロを作成する際に留意したいポイントを説明する。筆者にして筆者の経験に価値たけ書もあるかもしれない。PhUSE6が「Good Programming Practice In Macro Development」を公開しており、マクロ開発に関する考査ずべきポイントを学ぶことができる。なお、機械のコーディングルールやガイドラインがある場合には、それらを優先されたい。\n\n2.7.1 マクロでコードの重複を排除する\nマクロによりコードの重複部分を削減し、プログラム全体をコンパクトに保つのがポイントである。そのために、マクロ化する際には、どのようなポイントで構成するか、マクロのパラメータをどこに配置するかマクロ作成時の設計が大式である。しかし、このためには、一定の実装経験を積んで、マクロプロセッサに作成させたコードのイメージが持てるように下はないと無難い趣もある。まずはマクロを含まないプログラムを作成してから、重複部分をマクロ化していくというアプローチがある。いずれにせよコードの重複部分はマクロ化を考慮するポイントである。\n\n\n2.7.2 マクロの機能と入出力を明示する\nそのマクロプログラムが、どんな機能を提供するマクロか、出力は何か、入力は何かの3点を明示することは、便利でマクロを作成するうえで重要である。そのマクロプログラムのマクロパラメータとして明示する。そのマクロパラメータも馴染みやすいネーミングを心掛けたい。また、コメントも適切に活用して必要な情報を補記するべき利用を使用して説明する。以下に、データクリーニングの名前(Cody’s Data Cleaning Techniques Using SAS）に掲載されたもののマクロプログラムの冒頭部分である。\n\n\n2.7.3 マクロの機能と入出力を明示する\nそのマクロプログラムが、どんな機能を提供するマクロか、出力は何か、入力は何かの3点を明示することは、便利でマクロを作成するうえで重要である。そのマクロプログラムのマクロパラメータとして明示する。そのマクロパラメータも馴染みやすいネーミングを心掛けたい。また、コメントも適切に活用して必要な情報を補記するべき利用を使用して説明する。以下に、データクリーニングの名前(Cody’s Data Cleaning Techniques Using SAS）に掲載されたもののマクロプログラムの冒頭部分である。\n%macro auto_outliers(\n    Dsn=,       /* Data set name */\n    ID=,        /* Name of ID variable */ \n    Var_list=,  /* List of variables to check */\n    Trim=1,     /* Trim criterion */\n    N_sd=2      /* Number of standard deviations */\n);\nコメントの細部もあるがAuto_Outliersマクロは外れ値を検出するマクロであることが読み取れる。入力として、対象データセット名(Dsn)、オブザベーションのID変数名(ID)、外れ値を抽出したい対象変数名(Var_list)、統計的な判断基準であるTrim_N_sd)を指定すればよいことがわかる。数章では、外れ値の統計基準やプログラムの詳細より、当初マクロプログラムからできることがわかる。したがって方がユーザーにより使いやすかっただいられる（Auto,はプログラム内部からできること）。\n\n\n2.7.4 マクロの内部をブラックボックス化し、抽象化する\n細部は基本原理は「プログラムの内部アルゴリズムを知らずとも、マクロプログラムの機能を利用可能にすること」である。これはプロシジャで用いるイメージに近い。例えば、私たちは SORT プロシジャに入力かのデータセット名とソート変数を指定すれば、プロシジャ内部のソートアルゴリズムを意識することなく目的を達成できる。このように、マクロプログラムを作成する際は、ユーザーにマクロの内部を意識させない形式をイメージすべきである。\nやや哲学的な内容になるが、優れたマクロは、その出力だけを実行された課題が魅力を呈しない。マクロの内部にソート順を含めてカテゴリーゼットは変更しないようにする。また、マクロの内部だけで作成する一時的なデータセットを削除しなければ、ユーザーは、そのマクロ内部の構造する必要がないらならない。また、「文今後、新を適時」の結構で、マクロの終了時にマクロ内部で作成したworkデータセットを削除することもある。\n\n\n2.7.5 マクロプログラムはなるべくシンプルを保つ\nプログラム設計の原則に「分割して統治する」および「Keep it simple, stupid」があり、マクロプログラムもなるべくシンプルに保つことを推奨する。これは、マクロプログラムの汎用性を高めることと方針テンションスピ方向にあることも分かいている。また、新たにマクロプログラムを作成する際は、既存のマクロプログラムの入力方法を工夫すれば詳細なプロ先はせずとも済まない、あるいは既存のシンプルなマクロプログラムを利用して（呼び出して）作成できないか構想すべき場合がある。品質は既存されたシンプルのマクロプログラムを利用すれば、マクロプログラム全体のコードを予備し、かつ新たに作成するマクロプログラムの品質も維持しようといううがい対象である。\n\n\n2.7.6 コードの読みやすさや理解のしやすさにも配慮する\nマクロを書けば、いろいろな場面で活用できるようになるが、SASにプログラムを書いてもらうのが楽しくなり、%や&が使いびう複雑なプログラムになる場合がある。もちろん、そのことは体はマクロを理解している範囲であり、マクロプロセッサも文法的に問題ないよう限りは説明に動いてくれる。一方で、保存する他のプログラマや求人の自分がプログラムを読み機会もあり、コードの読みやすさや理解のしやすさを保持して、あえてマクロ化しない（マクロ化しすぎない）という判断場合もある。\nまた、マクロプログラミングでも、DATAステップ同様にネーミングが重要である。インデント（字下げ）を適切に行い、マクロの条件分岐や反復構造などを把握しやすくする、効果的にコメントを入れるなど、コードの読みやすさについても心掛けたい。\n\n\n2.7.7 小さく始める\n小さく始めて、少しずつ理解するのが習得のコツである。最初はマクロ変数を使うところからでもよい。基本プログラムによく変更する部分だけをマクロ変数化して、プラクマの電用管理を設定可能にする、先行するすプロジェクトの設定を改めてせることも多いし、実はここまででも十分な効果が着込まれる場合がある。また、簡単なマクロプログラムを作成する際給与も設ける。マクロを作成する手順として、まずマクロを含まないプログラムを作成し、少しずつマクロ化していくアプローチが推奨されている。これによりマクロプロセッサに命令があるかが明り分けすされる。"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#マクロの実例",
    "href": "posts/statistics/2025/SASマクロ入門1.html#マクロの実例",
    "title": "SASマクロ入門1",
    "section": "2.8 マクロの実例",
    "text": "2.8 マクロの実例\n筆者らが業務で実際に作成したマクロプログラムを紹介する。筆者で簡切と練習する事例であり、なるべく小題のプログラム編集で対応できるよう意図している。\n\n2.8.1 特定のフォルダ内のSASデータセットを1つのExcelファイルに変換する\nSASデータセットをデータセット別にシートを分けてExcelファイルに変換してほしいと依頼を受ける。もちろんデータセットの教だけprocexportまたはsetステートメントを記述してもよいのだが、そのような縮り返し処理はマクロ化したときに自動転するのがよい。なお、以下でマクロプログラムが直後されたフォルダ内のSASデータセットを、同フォルダに既定のExcelファイルを指定する必要がある。\n%macro sas2xlsx;\n\n    /* データセット一覧を取得する */\n    proc sql noprint;\n        select memname into :dsname1-\n        from dictionary.tables\n        where libname = \"SAS\";\n    quit;\n\n    do i = 1 to &sqlobs.;\n\n        data work.&&&dsname&i..;\n            set sas.&&&dsname&i..;\n        run;\n\n    %end;\n\n%mend;\n上記マクロでは、現在でデータセットのあるフォルダを出力先のExcelファイルに指定する必要がある。そこで、上記マクロプログラムが配置されたフォルダ内のSASデータセットを、同フォルダに既定のExcelファイルとして出力するようにプログラムを変更すれば、条件ごとにプログラムを編集する必要がなくなる。（もちろん不測の事象が生じする能性があるため、SASログ確認および出力ファイルの確認は時う。）\n\n\n2.8.2 特定のフォルダ内のSASデータセットをXPTファイルに一括変換する\n医療機関医療品の承認申請では、原則として申請電子データ提出が求められており、既導データをXPT形式で提出する必要がある。このためSASデータセットをXPT形式に変換する機会がよくある。なお、以下ではfilel.sasという名前でマクロプログラムを保存し、指定したデータセットが配置されたフォルダに配置してくれる。細部の具い事例である。\n/* 指定フォルダ内のSASデータセットをXPTファイルに一括変換する; */\noption nofmterr nologic print symbol;\n%let xpt = %str(C:\\workXpt);  \n%let sas = %str(C:\\workXsas); \n\nlibname _sas \"&sas.\";\nlibname _xpt xport \"&sas.\";\n\n%macro sas2xpt(sptdir, sasdir);\n\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n/* ファイル一覧を取得する; */\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n%filelist(\n    directory=%superq(sasdir), /* Directory to read */\n    out=_sas,                  /* Output data set to create */\n    extensions=sas7bdat        /* Space delimited extensions to include. Not case\n                                sensitive. Leave blank or set other based on extension */\n)\n\n/* ファイル一覧を読み込む; */\nproc sql noprint;\n    select dsname into :_dsname1 - \n    from _sas;\nquit;\n\n/* 各ファイルがない場合は終了する; */\n%if &sqlobs. = 0 %then %return;\n\nlibname _sas %superq(sasdir)\" access=readonly;\n\n%do i = 1 to &sqlobs.;\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\n/* SAS7BDATをXPTに変換する; */\n/* ～～～～～～～～～～～～～～～～～～～～～～～～～～～～～～; */\nlibname _xpt xport \"&sptdir\\&&&_dsname&i..&_xpt\";\ndata _xpt.&&&_dsname&i..;\n    set _sas.&&&_dsname&i..;\nrun;\n%end;\n\n/* ～～～～～～終了処理～～～～～～; */\nlibname _sas clear;\nlibname _xpt clear;\nproc datasets library=work nolist;\n    delete _sas;\nquit;\nrun;\nquit;\n\n%mend;\n\n%sas2xpt(sptdir=%superq(xpt), sasdir=%superq(sas))"
  },
  {
    "objectID": "posts/statistics/2025/SASマクロ入門1.html#終わりに",
    "href": "posts/statistics/2025/SASマクロ入門1.html#終わりに",
    "title": "SASマクロ入門1",
    "section": "2.9 終わりに",
    "text": "2.9 終わりに\nマクロ言語を対象にマクロの基礎から応用、そして利用のコツを概説した。マクロプロセッサにプログラムを書いてもらうライブラリ化により大量軸な共通化に及ぶまで、マクロは様々な場面で雄用いと感じてもらえれば幸いしたい。しかし、一度にすべてを理解する必要はなく、筆者ももともくさんのトライ&エラーを経験し、必要に迫られながら時間をかけてレットたという自分求むのが実情である。やがり理解できる自然に身につくき交鎖に考え、引用文献もご参照頂ければ幸いである。マクロプロセッサは、そこと出番を待っている。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "",
    "text": "本記事では、以下の2つの文献をまとめる。\n参考文献"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#はじめに",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#はじめに",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.1 はじめに",
    "text": "1.1 はじめに\n「保守しやすいコードは少ない人員で管理できる。つまり、あなたの雇用が危険にさらされる」\nこの皮肉な視点から、意図的に読みにくく、保守困難なSASコードを書く「技法」を紹介します。もちろん、これは反面教師として学ぶべき内容です。\n\n“Don’t be irreplaceable, if you can’t be replaced, you can’t be promoted.” - Dilbert’s Laws of Work"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#プログラミングスタイルやってはいけないこと",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#プログラミングスタイルやってはいけないこと",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.2 🚫 プログラミングスタイル（やってはいけないこと）",
    "text": "1.2 🚫 プログラミングスタイル（やってはいけないこと）\n\n1.2.1 論理的分離の回避\n/* 悪い例：本来分けるべき処理を無理やり1つにまとめる */\ndata result;\n   set patients;\n   if age &lt; 18 then group='pediatric'; else group='adult';\n   weight_kg = weight_lb / 2.2;\n   bmi = weight_kg / (height_m * height_m);\n   if bmi &gt; 30 then obese_flag = 1; else obese_flag = 0;\n   /* 複数の異なる処理が混在 */\nrun;\n解説: このコードは年齢分類、重量変換、BMI計算、肥満判定という4つの異なる処理を1つのデータステップに混在させています。本来なら機能ごとに分割すべきですが、すべてを混ぜることで何をしているのか分かりにくくしています。\n\n\n1.2.2 過度なネスト化（3層以上で複雑さ倍増）\n/* 悪い例：無意味に深いネスト */\ndate = mdy(month(date), day(date), year(date));\ndepth2 = input(substr(station, index(station,'-')+1), 3.);\nname = substr(name, index(name,',')+1, length(name));\n解説:\n\n1行目：既にSAS日付値の変数を、わざわざ分解して再構築する無意味な処理\n2行目：文字列から数値抽出を3つの関数で複雑にネスト\n3行目：名前の後半部分を取得する処理を複雑化 これらは全て、より単純な方法で書けるものを意図的に複雑にしています。\n\n\n\n1.2.3 関数の不適切な使用\n/* 悪い例：関数で置き換え可能な処理を冗長に記述 */\nif a &lt; 0 then b = a*-1;\nelse b = a;\n/* ABS(a)で済む処理 */\n\n/* 悪い例：非標準的な書き方 */\nab = (a*(a&gt;0) + b*(b&gt;0))/((a&gt;0)+(b&gt;0));\n/* 2つの正数の平均を求める処理 */\n解説:\n\n1つ目：ABS(a)関数で済む絶対値計算を、わざわざIF文で書いている\n2つ目：2つの正数の平均を求めるのに、論理値を数値として使う複雑な式を使用。(a+b)/2で済むところを意図的に分かりにくくしている\n\n\n\n1.2.4 マクロの悪用\n/* 悪い例：ローカル・グローバル変数の混乱 */\n%macro inside(aa);\n    %put inside &aa;\n%mend inside;\n\n%macro outside;\n    %let aa = 5;\n    %inside(3)\n    %put outside &aa;\n%mend outside;\n\n%outside\n/* 出力: inside 3, outside 5 */\n解説: マクロパラメータとマクロ変数の名前を同じにして混乱を誘発。%inside(3)では引数として3が渡されるため「inside 3」と出力されますが、%outsideマクロ内の&aaは依然として5のままです。これによりマクロ変数のスコープについて混乱を招きます。\n\n\n1.2.5 不必要な複雑化\n/* 悪い例：PROC SQLを無理やり複数ステップに分解 */\nproc sort data=sales;\n    by region;\nproc summary data=sales nway;\n    by region;\n    var saleprce;\n    output out=stats mean=meansale;\ndata report;\n    merge stats sales;\n    by region;\n    if saleprce gt meansale;\n\n/* 本来は以下の1ステップで済む */\nproc sql;\n    create table report as\n    select * from sales\n    having saleprce gt mean(saleprce)\n    group by region;\n解説: 1つのSQL文で書ける処理を、わざわざSORT→SUMMARY→DATA stepの3段階に分けています。これにより一時データセット（stats）が作成され、処理が複雑になり、エラーの可能性も増加します。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#システムオプションの悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#システムオプションの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.3 🎭 システムオプションの悪用",
    "text": "1.3 🎭 システムオプションの悪用\n\n1.3.1 デバッグ機能の無効化\n/* 悪い例：重要な情報を隠す */\noptions NOSOURCE NOSOURCE2 NONOTES NOLABEL NOMACRO;\n解説:\n\nNOSOURCE: 実行されたSASコードをログに表示しない\nNOSOURCE2: %INCLUDEで読み込まれたコードも表示しない\nNONOTES: 通常のNOTEメッセージを非表示\nNOLABEL: 変数ラベルを無効化\nNOMACRO: マクロ機能自体を無効化 これらによりデバッグが困難になります。\n\n\n\n1.3.2 観測数制御の悪用\n/* 悪い例：事前告知なしでのデータ制限 */\noptions obs=100 firstobs=50;  /* 隠して設定 */\n解説: データセットの50-100番目の観測値のみを処理対象にしていますが、これを他の人に知らせていません。全データを処理していると思い込ませる悪質な手法です。\n\n\n1.3.3 ワークエリアの操作\n/* 悪い例：一時ファイルの場所を変更 */\noptions user=sasuser;\ndata new;  /* 実際はSASUSER.NEWに保存される */\n    set project.master;\n解説: USER=オプションにより、一時的なデータセットNEWがSASUSERライブラリに保存されます。セッション終了後も残存し、ディスク容量の問題や混乱を引き起こします。\n\n\n1.3.4 危険なオプション\n/* 悪い例：エラー時即座終了 */\noptions ERRORABEND;\n\n/* 悪い例：年の解釈を混乱させる */\noptions YEARCUTOFF=1800;\ndata a;\n    date = '23mar98'd;\n    year = year(date);  /* 1897になる */\n解説:\n\nERRORABEND: エラー発生時にSASセッションが即座に終了し、ログも確認できない\nYEARCUTOFF=1800: 2桁年表記の解釈基準を1800年に設定。’98’が1998年ではなく1898年と解釈される\n\n\n\n1.3.5 S=オプションによる列数制限\n/* 悪い例：最初の10桁のみ読み取り */\noptions s=10;\ndata new;\n    set olddata    /* OLDDATになる */\n        master\n        adj;\n    profit =\n        sales + tax;  /* TAXが使われない */\n    cnt+1;  /* PROFITの計算に含まれる */\n解説: S=10により、各行の最初の10文字のみが読み取られます。olddataはolddatに、sales + taxはsales +のみが読まれ、変数taxは無視されます。また、cnt+1;が前の行に繋がってしまいます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#編集スタイル可読性を破壊する方法",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#編集スタイル可読性を破壊する方法",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.4 📝 編集スタイル（可読性を破壊する方法）",
    "text": "1.4 📝 編集スタイル（可読性を破壊する方法）\n\n1.4.1 インデントの無視\n/* 悪い例：インデントなし */\ndata sasclass.biomass;\ninfile rawdat missover;\ninput @1 STATION $\n@12 DATE DATE7.\n@20 BMPOLY\n@25 BMCRUS\n@31 BMMOL\n@36 BMOTHR\n@41 BMTOTL ;\n解説: インデントがないため、どの行がどのステートメントに属するかが分かりにくくなっています。特にINPUTステートメントの変数リストが見づらく、修正時にミスを誘発しやすくなります。\n\n\n1.4.2 複数ステートメントの詰め込み\n/* 悪い例：1行に複数ステートメント */\ndata new;set old;if age&gt;65 then senior=1;else senior=0;weight_kg=weight_lb/2.2;output;\n解説: 5つのステートメントを1行に詰め込んでいます。どこで1つのステートメントが終わり、次が始まるのかが分からず、デバッグや修正が困難になります。\n\n\n1.4.3 行の途中での改行\n/* 悪い例：意味のない場所での改行 */\ndata sasclass.biomass;infile rawdat\nmissover;\ninput @1 STATION $ @12 DATE DATE7.\n@20 BMPOLY @25 BMCRUS @31 BMMOL @36\nBMOTHR @41 BMTOTL ;\n解説: 文法的に意味のない場所で改行しています。infile rawdatとmissoverオプションが分離され、inputステートメントも不自然に分割されています。\n\n\n1.4.4 画面外への重要コード配置\n/* 悪い例：80桁以降に重要な変数を配置 */\n                                                                              /*80桁*/\ndata newdata;\n    set olddata (drop=name                                                   fname\n                     address city state);  /* 重要な変数が見えない */\n解説: 80桁以降に重要な変数名を配置しています。多くのエディタでは80桁以降が表示されないか、画面外に隠れるため、重要な処理内容が見えなくなります。\n\n\n1.4.5 会社ロゴ形式のコード\n/* 悪い例：見た目重視のコード配置 */\n         data\n      sasclass.biomass;\n      infile cards missover;\n      input @1 STATION $\n      @12 DATE DATE7.\n      @20 BMPOLY\n   @25 BMCRUS @31 BMMOL\n  @36 BMOTHR @41 BMTOTL\n      ; format\n      date date7.\n      ;label BMCRUS=\n   'CRUSTACEAN BIOMASS'\n         BMMOL=\n   'MOLLUSC BIOMASS'\n      ;\n      run;\n解説: 機能性を完全に無視して、見た目の形（おそらく会社ロゴや図形）を優先してコードを配置しています。読みやすさが完全に犠牲になっています。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#コメントの悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#コメントの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.5 💬 コメントの悪用",
    "text": "1.5 💬 コメントの悪用\n\n1.5.1 実行可能コメント\n/* 悪い例：コメント内に実行文を隠す */\n* The comments in this section do more ;\n* than it seems ;\n* ;\n* modify data to prep for; proc means ;\n* after adjusting the data using ;\n* the; var for weight ;\n解説: 一見コメントに見えますが、実際にはproc means; var for weight;という実行可能なコードが隠されています。3行目の* ;でコメントが終了し、4-6行目が実際に実行されます。\n\n\n1.5.2 ネストできないコメントの悪用\n/* 悪い例：未完了コメントでコード全体を隠す */\n/* *****************\n* Apply the\n* ***very ***\n* important adjustment;\ndata yearly;\n    set yearly;\n    income = income*adjust;\nrun;\n/* Plot the adjusted income */\nproc gplot data=yearly......\n解説: 最初の/*コメントが閉じられていないため、その後のコード全体がコメント扱いになります。/* Plot the adjusted income */の*/で最初のコメントが閉じられ、それ以降のコードが実行されます。\n\n\n1.5.3 埋め込みコメントによる部分実行\n/* 悪い例：コメント内の一部のみ実行 */\n/* *****************\nREMOVE FOR PRODUCTION\nproc print data=big obs=25;\n    title1 'Test print of BIG';\n    var company dept mgr /*clerk*/;\ndata big;\n    set big;\n    if name='me' then salary=salary+5;\n*END OF REMOVED SECTION;\n****************** */\n解説: 全体がコメントで囲まれているように見えますが、/*clerk*/の部分で一時的にコメントが閉じ、その後のdataステップが実行されます。給与を不正に操作するコードが隠されて実行されてしまいます。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#命名規則の悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#命名規則の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.6 🔤 命名規則の悪用",
    "text": "1.6 🔤 命名規則の悪用\n\n1.6.1 混乱を招く命名\n/* 悪い例：意味不明な変数名 */\ndata analysis;\n    set patient_data;\n    /* デバッグ時は meaningful names を使い、後でCHANGEコマンドで変更 */\n    /* ===&gt; c 'age' 'qwrtxzqr' all */\n    QWRTXZQR = age;           /* 年齢なのに意味不明な名前 */\n    QWRTZXQR = weight;        /* 似たような名前で混乱 */\n    QWRZTXQR = height;        /* 微妙な違いで判別困難 */\n    HHHIIHIH = height;        /* HとIの区別が困難 */\n    WVWVWVVW = weight;        /* VとWの区別が困難 */\n    testnuml = test_result;   /* 1（数字）とl（小文字L）の混用 */\n    test0001 = test_id;       /* 0（ゼロ）とO（オー）の混用 */\n    QWRT2XQR = group;         /* ZとNの混用 */\n解説:\n\n母音を避けた無意味な文字列を使用\n似たような文字の組み合わせで視覚的混乱を誘発\n数字と文字の見た目が似ているものを混用（1とl、0とO、2とZ）\nコメントで「デバッグ時には意味のある名前を使い、後で置換する」という悪質な手法を示唆\n\n\n\n1.6.2 SASキーワードの変数名使用\n/* 悪い例：SASキーワードを変数名に使用 */\nDATA SET; \nSET DATA;\nDO = 5+ TO -15;  /* DO loopに見えるが変数代入 */\n解説: DATA、SET、DO、TOなどのSASキーワードを変数名として使用しています。DO = 5+ TO -15;は一見DO loopに見えますが、実際は変数DOに5 + TO - 15を代入するステートメントです。\n\n\n1.6.3 誤解を招く命名\n/* 悪い例：変数名と内容が一致しない */\ndata patients;\n    set raw_data;\n    SEX = fish_count;        /* SEXという名前だが魚の数 */\n    WEIGHT = height_cm;      /* WEIGHTという名前だが身長 */\n    INCHES = height_cm;      /* INCHESだがセンチメートル */\n    \n    /* 出力先も混乱させる */\n    IF SEX = 'MALES' THEN OUTPUT FEMALES;\n    \n    /* ラベルでさらに混乱 */\n    LABEL sex = 'Sex of the Patient';  /* 実際は魚の数 */\n解説:\n\n変数名と実際の内容が完全に異なる（SEXに魚の数、WEIGHTに身長など）\nOUTPUT文で条件と出力先が逆転（MALESの条件でFEMALESデータセットに出力）\nLABELでさらに混乱を助長（魚の数に「患者の性別」というラベル）\n\n\n\n1.6.4 一貫性のない命名\n/* 悪い例：YES/NOの値が一貫しない */\ndata flags;\n    set survey;\n    /* 通常: YES=0, NO=1 */\n    response1 = (answer='YES') * 0 + (answer='NO') * 1;\n    \n    /* どこかで例外: YES=1, NO=0 */\n    response2 = (answer='YES') * 1 + (answer='NO') * 0;\n    \n    /* さらに混乱: Y=NOの意味、N=YESの意味 */\n    if answer='YES' then code='N';\n    else if answer='NO' then code='Y';\n解説:\n\n同じプログラム内でYES/NOのコーディングが一貫していない\n通常の論理（YES=1, NO=0）とは逆の設定\n最後は完全に逆転（YESなのにN、NOなのにY）"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#データステップの境界をぼかす技法",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#データステップの境界をぼかす技法",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.7 🌀 データステップの境界をぼかす技法",
    "text": "1.7 🌀 データステップの境界をぼかす技法\n\n1.7.1 コメントによる境界隠し\n/* 悪い例：セミコロンなしコメントで次ステップを隠す */\ndata new; \n    set old;\n    x = 5 * y;\n    /* この行で次のステップが始まっている\n    data second; \n    set gudstuff;\n    x = zzstuff;\n/* 結果：NEWにはzsstuffの値が入る */\n解説: 4行目のコメントにセミコロンがないため、5-7行目がコメント扱いになりません。実際には1つのDATAステップで2つのSETステートメントが実行され、最後のx = zzstuff;の値が最終的に変数xに残ります。\n\n\n1.7.2 コロンによる巧妙な隠蔽\n/* 悪い例：セミコロンの代わりにコロンを使用 */\ndata new; \n    set old;\n    x = 5 * y;\n    /* この行で次のステップが始まっている:\n    data second; \n    set gudstuff;\n    x = zzstuff;\n解説: コメント行の最後がセミコロンではなくコロンになっています。SASではコロンはコメントの終了記号として認識されないため、次のdataステップが隠されて実行されます。\n\n\n1.7.3 不完全な引用符による隠蔽\n/* 悪い例：不完全な引用符で後続コードを隠す */\ndata new;\n    y = 5;\n    frankwt = 0;\n    x = 5 * y;\n    length name $6;\n    name = 'weight;\n    data second; set gudstuff;  /* この行が隠されている */\n    *for weight use Franks';\n    x = frankwt;\nproc print; run;\n/* 結果：xは常に0（25ではない） */\n解説:\n\n6行目で開始された文字列リテラル'weight;が閉じられていない\nそのため7-8行目が文字列の一部として扱われ、実行されない\n9行目の'で文字列が閉じられ、その後のコードが実行される\n結果としてx = frankwt;（0）が実行され、期待されたx = 5 * y;（25）は無効になる"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#さらに極端な技法上級者向け悪魔術",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#さらに極端な技法上級者向け悪魔術",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.8 🔥 さらに極端な技法（上級者向け悪魔術）",
    "text": "1.8 🔥 さらに極端な技法（上級者向け悪魔術）\n\n1.8.1 ソースコードの隠蔽・削除\n/* 悪い例：コンパイル後にソースを削除・改名 */\n/* SCL source code for SAS/AF applications */\n/* Compiled DATA steps */\n/* Compiled stored macros */\n/* DATA step views */\n/* SQL views（DESCRIBE optionで復元可能だが...） */\n\n/* エディタの文字色を背景色と同じにして隠す */\n解説:\n\nコンパイル済みのSAS/AFアプリケーション、ストアドマクロなどの元ソースコードを削除\nDATA step viewやSQL viewのソースも隠蔽\nエディタで文字色を背景色と同じにして視覚的に見えなくする これらにより、動作するプログラムがあっても、どのように動作しているかが分からなくなります。\n\n\n\n1.8.2 AUTOEXEC.SASとCONFIG.SASの悪用\n/* 悪い例：AUTOEXEC.SASでセッション終了 */\nENDSAS;\n/* または */\nABORT;\n/* または */\n%MACRO DUMMY;  /* %MENDまでのすべてのコードを無効化 */\n\n/* 悪い例：CONFIG.SASで隠れたERRORABEND設定 */\n-ERRORABEND\n\n/* 悪い例：AUTOEXEC.SASの最後に未完了コメント */\n/* 以降のすべてのコードがコメント扱いに */\n解説:\n\nENDSASやABORTをAUTOEXEC.SASに入れると、ユーザーのプログラムが実行される前にセッションが終了\n%MACRO DUMMY;を入れると、%MENDが現れるまでのすべてのコードがマクロ定義として扱われ実行されない\nCONFIG.SASでのERRORABEND設定は非常に見つけにくい\nAUTOEXEC.SASの最後に/*を入れると、以降のすべての投入コードがコメント扱いになる\n\n\n\n1.8.3 危険なデータステップ技法\n/* 悪い例：BYステートメント変数の途中変更 */\ndata merged;\n    merge data1 data2;\n    by id;\n    id = id + 1;  /* BYステートメント変数を変更 */\n解説: MERGEステートメントのBY変数idを、マージ処理の途中で変更しています。これにより予期しないマージ結果が生成され、データの整合性が失われます。\n\n\n1.8.4 POINT/NOBSオプションの落とし穴\n/* 悪い例：削除された観測値との相互作用 */\ndata a;\n    do i = 1 to 5;\n        output;\n    end;\nrun;\n/* FSEDITでi=2の観測値を削除 */\n\ndata b;\n    do point=1 to nobs;\n        set a point=point nobs=nobs;\n        output;\n    end;\n    stop;\nrun;\n/* 結果：削除された観測値が読まれ、iの値が不正になる */\n解説:\n\nデータセットAから観測値2（i=2）を削除\nPOINT/NOBSオプションで順次読み取ると、削除された位置でも読み取りが行われる\n削除された観測値を読み取ると、変数iには予期しない値（この場合は1）が入る\n結果として観測値2の位置でi=1が読まれ、データの整合性が失われる\n\n\n\n1.8.5 マクロクォート関数の悪用\n/* 悪い例：マクロ変数の解決を阻害 */\n%macro doit(city);\n    %put &city;\n    %let city=%nrstr(&city);  /* 文字列として固定 */\n    %put &city;\n    %if &city = LA %then\n        %put CITY is LOS ANGELES;\n    %else \n        %put city is not LA;  /* 常にこちらが実行される */\n%mend doit;\n\n%doit(LA)\n/* 出力: LA, &city, city is not LA */\n解説:\n\n%nrstr(&city)により、マクロ変数&cityが文字列リテラル「&city」として固定される\n以降の比較&city = LAでは、「&city」と「LA」が比較されるため、常にfalseになる\n引数として「LA」を渡しても、条件判定では常に「not LA」の結果になる\n\n\n\n1.8.6 特殊システムオプションの悪用\n/* 悪い例：エラーメッセージ抑制 */\noptions DKRICOND=NOWARN;  /* DROP/KEEP/RENAME文のエラーを隠す */\n\n/* 悪い例：データセット置き換え防止 */\noptions NOREPLACE;  /* 永続データセットの置き換えを阻止 */\n\n/* 悪い例：WORK領域のクリーンアップ抑制 */\noptions NOWORKINIT NOWORKTERM;  /* セッション終了後もファイル残存 */\n解説:\n\nDKRICOND=NOWARN: DROP/KEEP/RENAMEステートメントで存在しない変数を指定してもエラーが出ない\nNOREPLACE: 既存の永続データセットを上書きしようとするとエラーになる（一見良いが、予期しない場所で設定されると混乱）\nNOWORKINIT/NOWORKTERM: SASセッション終了後もWORKライブラリのファイルが残り、ディスク容量やセキュリティの問題を引き起こす"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#正しいプログラミング実践推奨事項",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#正しいプログラミング実践推奨事項",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.9 ✅ 正しいプログラミング実践（推奨事項）",
    "text": "1.9 ✅ 正しいプログラミング実践（推奨事項）\n\n1.9.1 良いコードの原則\n/* 良い例：読みやすく保守しやすいコード */\noptions MSGLEVEL=I SOURCE FMTERR DSNFERR NOREPLACE;\n\n/* Step 1: Demographics data preparation */\ndata adam.adsl;\n    set raw.demographics;\n    \n    /* Treatment group coding */\n    if trt01a = 'Placebo' then trt01pn = 1;\n    else if trt01a = 'Active 10mg' then trt01pn = 2;\n    else if trt01a = 'Active 20mg' then trt01pn = 3;\n    \n    /* Age group classification */\n    if age &lt; 65 then agegroup = 'Under 65';\n    else agegroup = '65 and Over';\n    \n    /* Safety population flag */\n    if cmstdt ne . then saffl = 'Y';\n    else saffl = 'N';\n    \n    /* Variable labels */\n    label trt01pn = 'Treatment Group (Numeric)'\n          agegroup = 'Age Group'\n          saffl = 'Safety Population Flag';\nrun;\n\n/* Step 2: Data validation */\nproc freq data=adam.adsl;\n    tables trt01pn*trt01a / missing;\n    title1 'Treatment Group Verification';\nrun;\n\nproc means data=adam.adsl n nmiss min max;\n    var age;\n    title1 'Age Distribution Check';\nrun;\n解説:\n\n明確なコメントで各ステップの目的を説明\n意味のある変数名とラベルを使用\n処理を論理的に分離（データ準備→検証）\n品質管理オプションを適切に設定\n一貫したインデントとフォーマット\n\n\n\n1.9.2 臨床試験での品質管理\n/* Step 3: Efficacy endpoint derivation */\ndata adam.adeff;\n    set adam.adsl(keep=usubjid trt01pn saffl);\n    \n    /* Merge with vital signs */\n    merge adam.adsl(in=demo)\n          raw.vitals(in=vital \n                     keep=usubjid visitnum aval param);\n    by usubjid;\n    \n    /* Only include subjects with baseline and post-baseline values */\n    if demo and vital;\n    \n    /* Derive change from baseline */\n    retain baseline;\n    if visitnum = 1 then baseline = aval;\n    else if visitnum &gt; 1 and baseline ne . then do;\n        chg = aval - baseline;\n        pchg = (chg / baseline) * 100;\n    end;\n    \n    /* Quality checks */\n    if baseline = . then put \"WARNING: Missing baseline for \" usubjid=;\n    if aval = . and visitnum &gt; 1 then put \"WARNING: Missing post-baseline value for \" usubjid= visitnum=;\n    \n    label chg = 'Change from Baseline'\n          pchg = 'Percent Change from Baseline'\n          baseline = 'Baseline Value';\nrun;\n解説:\n\nデータセットの結合条件を明確に指定（in=demo and vital）\nベースライン値の適切な保持と計算\n品質チェックを組み込み、問題があればログに出力\n計算ロジックを段階的に記述し、理解しやすくする\n派生変数には適切なラベルを付与"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#心理的トリックと認知バイアスの悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#心理的トリックと認知バイアスの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.10 🧠 心理的トリックと認知バイアスの悪用",
    "text": "1.10 🧠 心理的トリックと認知バイアスの悪用\n\n1.10.1 先入観を利用した混乱\n/* 悪い例：一般的な変数名で全く違う内容を格納 */\ndata demographics;\n    set patient_roster;\n    \n    /* 通常なら患者情報だが... */\n    age = protocol_version;      /* 年齢ではなくプロトコル番号 */\n    sex = randomization_seed;    /* 性別ではなく乱数シード */\n    height = study_duration;     /* 身長ではなく研究期間 */\n    weight = site_number;        /* 体重ではなく施設番号 */\n    \n    /* ラベルで更なる混乱を誘発 */\n    label age = 'Patient Age (Years)'\n          sex = 'Patient Gender'\n          height = 'Height (cm)'\n          weight = 'Weight (kg)';\nrun;\n解説: プログラマーの先入観を悪用した極めて悪質な手法。変数名から期待される内容と実際の内容が完全に異なり、さらにラベルでも嘘の情報を提供しています。これにより重大な解析エラーを引き起こす可能性があります。\n\n\n1.10.2 視覚的類似性を利用した混乱\n/* 悪い例：見た目が似ている文字・数字の混用 */\ndata confusion;\n    /* 数字の1と小文字のl */\n    testnum1 = score_1;\n    testnuml = score_l;  /* 実際は小文字のL */\n    \n    /* 数字の0と大文字のO */\n    patient0 = id_zero;\n    patientO = id_oh;    /* 実際は大文字のO */\n    \n    /* 数字の2とアルファベットのZ */\n    group2 = treatment_2;\n    groupZ = treatment_z; /* 実際はZ */\n    \n    /* IとlとlIの組み合わせ */\n    IlllIlIl = result_a;  /* 何がIで何がlか判別不可能 */\n    lIlIlIll = result_b;\nrun;\n解説: フォントによっては区別が困難な文字を意図的に混用しています。特にプログラミング用でないフォントでは、これらの違いを見分けることは非常に困難になります。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#プロシージャの悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#プロシージャの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.11 🔄 プロシージャの悪用",
    "text": "1.11 🔄 プロシージャの悪用\n\n1.11.1 PROC SQLの危険な使用法\n/* 悪い例：副作用のあるSQL */\nproc sql;\n    /* 一見単純な選択に見えるが... */\n    create table summary as\n    select *,\n           (select count(*) from work.temp_calc \n            where temp_calc.id = main.id) as calc_count\n    from main_data as main;\n    \n    /* work.temp_calcは実際には存在せず、\n       このクエリ実行中に副作用で作成される隠しプロセスがある */\nquit;\n\n/* 隠された前処理（別の場所に配置） */\ndata work.temp_calc / view=work.temp_calc;\n    set main_data;\n    /* 複雑な計算でmain_dataを変更 */\n    call execute('data main_data; modify main_data; id = id + 1000; run;');\nrun;\n解説:\n\n一見単純なSELECTクエリに見えるが、サブクエリが隠された副作用を持つ\nVIEWを使って実行時に元データを変更する隠れた処理を組み込む\nCALL EXECUTEにより、クエリ実行中に予期しないデータ変更が発生\n\n\n\n1.11.2 PROC SORTの落とし穴\n/* 悪い例：NODUPKEY vs NODUPLICATESの混乱 */\n/* 同じファイル名で異なる結果を生成 */\nproc sort data=patients out=clean_data NODUPKEY;\n    by patient_id visit_date;\nrun;\n/* patient_idとvisit_dateの組み合わせで重複削除 */\n\n/* どこか別の場所で... */\nproc sort data=patients out=clean_data NODUPLICATES;\n    by patient_id visit_date;\nrun;\n/* 完全に同一の行のみ重複削除（結果が異なる） */\n解説:\n\nNODUPKEYとNODUPLICATESは似ているが動作が異なる\n同じ出力データセット名を使うことで、どちらが実行されたかが分からなくなる\n結果として異なるデータセットが同じ名前で作成される"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#マクロプログラミングの悪魔術",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#マクロプログラミングの悪魔術",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.12 🎭 マクロプログラミングの悪魔術",
    "text": "1.12 🎭 マクロプログラミングの悪魔術\n\n1.12.1 動的マクロ生成の混乱\n/* 悪い例：実行時にマクロを動的生成して混乱させる */\n%macro generate_confusion(type);\n    %if &type = A %then %do;\n        %macro process_data;\n            data result; set input; value = value * 2; run;\n        %mend;\n    %end;\n    %else %if &type = B %then %do;\n        %macro process_data;\n            data result; set input; value = value / 2; run;\n        %mend;\n    %end;\n    %else %do;\n        %macro process_data;\n            data result; set input; value = .; run;\n        %mend;\n    %end;\n%mend;\n\n/* 実行時に決定される処理内容 */\n%generate_confusion(A)\n%process_data  /* 何が実行されるかは実行時まで不明 */\n解説:\n\n実行時に条件によって異なるマクロ定義を生成\n同名のマクロprocess_dataが異なる処理を行う\nプログラムを読んだだけでは実際の処理内容が予測できない\n\n\n\n1.12.2 マクロ変数の隠蔽と再定義\n/* 悪い例：グローバル変数を局所的に再定義 */\n%let important_factor = 1.5;  /* グローバル設定 */\n\n%macro sneaky_calculation(data);\n    %local important_factor;  /* 局所的に再定義 */\n    %let important_factor = 0.1;  /* 全く違う値 */\n    \n    data &data._adjusted;\n        set &data;\n        adjusted_value = original_value * &important_factor;\n    run;\n    \n    %put NOTE: Applied factor &important_factor to &data;\n%mend;\n\n/* 使用者は1.5倍されると期待するが... */\n%sneaky_calculation(patient_data)  /* 実際は0.1倍 */\n解説:\n\nグローバル変数と同名の局所変数を定義\n使用者はグローバル値（1.5）が使われると期待\n実際は局所変数の値（0.1）が使用される\nPUTステートメントで正しい値を表示するため、ログを見ても気づきにくい\n\n\n\n1.12.3 マクロクォート関数の連鎖\n/* 悪い例：複数のクォート関数を連鎖させて混乱 */\n%macro quote_chaos(input);\n    %let step1 = %nrstr(&input);\n    %let step2 = %superq(step1);\n    %let step3 = %nrbquote(&step2);\n    %let step4 = %unquote(&step3);\n    \n    %if &step4 = &input %then\n        %put SUCCESS: Values match;\n    %else\n        %put ERROR: Values do not match - &step4 vs &input;\n%mend;\n\n%quote_chaos(test_value)\n解説:\n\n複数のマクロクォート関数を意味もなく連鎖\n各ステップで文字列の扱いが微妙に変化\n最終的な比較結果が予測困難\nデバッグが非常に困難"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#データアクセスとライブラリの混乱",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#データアクセスとライブラリの混乱",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.13 🗃️ データアクセスとライブラリの混乱",
    "text": "1.13 🗃️ データアクセスとライブラリの混乱\n\n1.13.1 ライブラリ参照の動的変更\n/* 悪い例：実行中にライブラリ参照を変更 */\nlibname mydata \"/path/to/original/data\";\n\ndata important_analysis;\n    set mydata.patients;  /* 最初のデータソース */\n    \n    /* 途中で同じライブラリ名を別パスに変更 */\n    call execute('libname mydata \"/path/to/different/data\";');\n    \n    /* この後のmydata参照は別のデータを指す */\n    merge mydata.treatments mydata.outcomes;  /* 異なるデータソース */\n    by patient_id;\nrun;\n解説:\n\nCALL EXECUTEを使って実行中にライブラリ参照を変更\n同一プログラム内で同じライブラリ名が異なるデータを指すことになる\nデータの整合性が完全に失われる可能性\n\n\n\n1.13.2 隠れたデータ変更\n/* 悪い例：読み取り専用に見えるが実際は変更している */\ndata summary_report;\n    set master_data;  /* 読み取りのみに見える */\n    \n    /* 隠されたMODIFYステートメント */\n    if _n_ = 1 then do;\n        call execute('\n            data master_data;\n                modify master_data;\n                if patient_id = \"DUMMY001\" then delete;\n            run;\n        ');\n    end;\n    \n    /* 集計処理 */\n    summary_stat = mean(value);\n    output;\nrun;\n解説:\n\n一見データを読み取りのみしているように見える\n実際はCALL EXECUTEで元データを変更している\n集計レポート作成時に元データが変更されるという予期しない副作用"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#統計プロシージャの悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#統計プロシージャの悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.14 📊 統計プロシージャの悪用",
    "text": "1.14 📊 統計プロシージャの悪用\n\n1.14.1 PROC REGの隠れた前提条件違反\n/* 悪い例：前提条件を満たさないデータで回帰分析 */\nproc reg data=patient_data;\n    model outcome = treatment age weight;  /* 一見正常な回帰式 */\n    \n    /* 隠された問題：\n       - outcomeには欠測値が50%\n       - treatmentは完全に共線性のある3つのダミー変数\n       - ageとweightは完全相関（r=1.0）\n       - データには外れ値が意図的に挿入済み\n    */\nrun;\n解説:\n\n統計的前提条件を全く満たさないデータで分析実行\n多重共線性、欠測値、外れ値などの問題を隠蔽\n結果は統計的に無意味だが、出力は正常に見える\n\n\n\n1.14.2 PROC FREQの誤解を招く使用\n/* 悪い例：意図的に誤解を招くクロス集計 */\nproc freq data=clinical_data;\n    /* 一見、治療効果の評価に見えるが... */\n    tables treatment*outcome / chisq;\n    \n    /* 実際のデータには重大な問題：\n       - outcomeは治療開始前の状態\n       - treatmentは別の研究での割り付け\n       - 同一患者が複数回カウントされている\n    */\n    \n    title \"Treatment Effect Analysis\";  /* 誤解を招くタイトル */\nrun;\n解説:\n\n変数名から因果関係があるように見せかける\n実際は時系列が逆転していたり、関係のないデータ\nタイトルで意図的に誤解を招く"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#セキュリティと権限の悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#セキュリティと権限の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.15 🔒 セキュリティと権限の悪用",
    "text": "1.15 🔒 セキュリティと権限の悪用\n\n1.15.1 パスワードとアクセス制御の隠蔽\n/* 悪い例：隠されたデータベース接続 */\n%let hidden_pw = %substr(%sysfunc(compress('pass1word2',,'kd')),1,8);\n\nlibname secret oracle user=admin password=\"&hidden_pw\" \n                   path=\"//hidden.server.com:1521/secret_db\"\n                   schema=confidential;\n\n/* 一見通常のデータ処理 */\ndata public_summary;\n    set secret.classified_data;  /* 実際は機密データにアクセス */\n    /* パスワードは暗号化されて見えない */\nrun;\n解説:\n\nパスワードを関数で暗号化・難読化\n機密データベースへの隠れたアクセス\n表面上は通常のデータ処理に見せかけ"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#オペレーティングシステム固有の悪用",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#オペレーティングシステム固有の悪用",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.16 🌐 オペレーティングシステム固有の悪用",
    "text": "1.16 🌐 オペレーティングシステム固有の悪用\n\n1.16.1 Windows環境での隠れた設定\n/* 悪い例：アイコンのプロパティで隠れたオプション設定 */\n/* SASアイコンのプロパティで以下を設定（見えない場所） */\n/*\nTarget: \"C:\\SAS\\sas.exe\" -CONFIG \"C:\\hidden\\malicious.cfg\" \n                          -AUTOEXEC \"C:\\hidden\\autoexec.sas\"\n                          -SYSIN \"C:\\decoy\\normal_program.sas\"\n                          -ARCH=BIT16\n*/\n\n/* 実際に実行されるのは hidden/autoexec.sas の内容 */\n/* ユーザーは normal_program.sas が実行されると思っている */\n解説:\n\nWindowsのアイコンプロパティで隠れた設定を行う\nユーザーには見えない設定ファイルや自動実行ファイルを指定\n16ビットモードで実行して性能を意図的に低下\nユーザーが期待するプログラムとは異なるものを実行\n\n\n\n1.16.2 外部DLLとシステムコールの悪用\n/* 悪い例：外部ライブラリで隠れた処理 */\nfilename hidden 'hidden_malicious.dll';\n\ndata _null_;\n    /* 表面上は時刻の取得 */\n    current_time = datetime();\n    \n    /* 実際は外部DLLで隠れた処理を実行 */\n    call module(hidden, 'secret_function', current_time, result);\n    \n    /* DLLの中身：\n       - ファイルシステムの操作\n       - ネットワーク通信\n       - データの外部送信\n       - ログの改竄\n    */\nrun;\n解説:\n\n外部DLLを使って隠れた処理を実行\nSASのログには通常の処理のみ記録\n実際の悪意ある処理はDLL内に隠蔽\nシステム権限を悪用した危険な操作"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#実際の被害例と教訓",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#実際の被害例と教訓",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.17 ⚠️ 実際の被害例と教訓",
    "text": "1.17 ⚠️ 実際の被害例と教訓\n\n1.17.1 臨床試験での重大インシデント\n/* 実際にあった危険な例（教育目的で再現） */\n\n/* 悪い例：効果量の計算で隠れたバイアス */\ndata efficacy_analysis;\n    set clinical_data;\n    \n    /* 表面的には標準的な効果量計算 */\n    if treatment = 'Active' then trt_num = 1;\n    else if treatment = 'Placebo' then trt_num = 0;\n    \n    /* 隠されたバイアス：特定の患者のみ除外 */\n    if patient_id in ('001', '047', '089') and trt_num = 0 then delete;\n    /* これらは偶然プラセボ群で改善した患者 */\n    \n    /* 通常の統計計算 */\n    effect_size = (active_mean - placebo_mean) / pooled_sd;\nrun;\n\n/* 結果：人為的に効果が過大評価される */\n解説:\n\n一見正常な効果量計算に見える\n実際は特定の患者（プラセボ群で改善した例）を意図的に除外\n結果として薬剤効果が過大評価される\n規制当局への提出データに重大な問題を作り出す\n\n\n\n1.17.2 データ管理での混乱事例\n/* 実際にあった混乱例 */\n\n/* 悪い例：バックアップのつもりが本番データを破壊 */\n%let backup_date = %sysfunc(today(), yymmddd6.);\n\n/* 本番データの「バックアップ」 */\ndata backup.patient_data_&backup_date;\n    set production.patient_data;\nrun;\n\n/* 隠れた問題：productionとbackupが同じ場所を指している */\n/* libname production \"//server/data/current\"; */\n/* libname backup    \"//server/data/current\"; */\n\n/* 結果：バックアップではなく上書きが発生 */\n解説:\n\nバックアップ処理のつもりで実装\n実際は両方のライブラリが同じ場所を指している\nバックアップではなく本番データの上書きが発生\nデータロストの原因となる"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングの風刺.html#まとめ",
    "href": "posts/statistics/2025/SASプログラミングの風刺.html#まとめ",
    "title": "PROGRAMMING FOR JOB SECURITY REVISITED",
    "section": "1.18 まとめ",
    "text": "1.18 まとめ\nこの記事で紹介した「技法」は、実際のプログラムでは絶対に使用してはいけません。これらは全て、実際に遭遇する可能性のある問題パターンです。\n\n“In reality there is a constant demand for SAS programmers. Just knowing how to write good, clean, and tight SAS code provides a high level of job security.”\n\n良いSASプログラマーになるためには：\n\n可読性を重視したコード作成\n適切な命名規則の遵守\n十分なドキュメント化とコメント\n論理的な構造の維持\n品質管理オプションの適切な使用\n一貫したプログラミングスタイル\n他者が保守しやすいコード設計\n\n特に臨床試験の統計解析では、コードの品質が直接患者の安全性と規制当局への信頼性に関わるため、これらの原則を厳格に守ることが重要です。\nこの記事は、Arthur L. Carpenter氏とTony Payne氏の「Programming for Job Security」シリーズを基に作成されました。元の論文は風刺的な内容ですが、実際のプログラミングにおいて避けるべき問題を明確にする優れた教材として、SAS界隈で長く愛され続けています。\n参考文献:\n\nCarpenter, Arthur L. (1993, 1996). “Programming For Job Security: Tips and techniques to Maximize Your Indispensability”\nCarpenter, Arthur L. & Payne, Tony. “Programming For Job Security Revisited: Even More Tips and Techniques to Maximize Your Indispensability”"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "",
    "text": "本記事では、実務上便利なSASプログラミングのTipsを紹介する。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "2.1 プログラム解説",
    "text": "2.1 プログラム解説\nこのSASプログラムは現在の日時を取得し、異なる形式でマクロ変数に格納するコードです。\n処理の流れ：\n\n%sysfunc(datetime())で現在日時を数値形式で取得\ndate()とtime()で日付・時刻を個別に取得\nput()関数でフォーマット適用（日付：YYYY/MM/DD、時刻：HH:MM:SS）\ncompress()で区切り文字を除去（日付：YYYYMMDD、時刻：HHMMSS）\ncall symputx()で4つのマクロ変数を作成\n\n作成されるマクロ変数：\n\n&StDates：2025/06/16（スラッシュ付き日付）\n&StDate：20250616（スラッシュなし日付）\n&StTimes：14:30:25（コロン付き時刻）\n&StTime：143025（コロンなし時刻）\n\n用途： ログファイル名生成、バックアップのタイムスタンプ、処理開始時刻の記録など、バッチ処理でよく使用される汎用的なコードです。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-1",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-1",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "3.1 プログラム解説",
    "text": "3.1 プログラム解説\nこのSASプログラムは、実行中のプログラムの場所を自動判定し、プロジェクトの標準フォルダ構造に基づいて各種パスを動的に設定する汎用的なパス管理コードです。\n\n3.1.1 実行パス取得マクロ\n最初の部分では、現在実行中のSASプログラムの完全パスを取得するマクロを定義しています。このマクロは実行環境に関係なく動作するよう設計されており、バッチ実行時はGETOPTION(SYSIN)関数を、対話的実行時はSAS_EXECFILEPATH環境変数を使用します。IF文による条件分岐により、どちらの環境でも確実にプログラムパスを取得できる仕組みになっています。\n\n\n3.1.2 階層パス解析\n次に、取得したフルパスから階層構造を解析し、プロジェクト内での相対位置を把握する処理を行います。SCAN関数とQSUBSTR関数を組み合わせて、パスを階層別に分解します。PROGRAM_NAMEには実行中のプログラム名（拡張子なし）、CURRENT_DIRには現在のディレクトリの完全パス、PARENT_DIRには1つ上の階層ディレクトリのパス、PROJECT_ROOTにはプロジェクトルートディレクトリのパス（2つ上の階層）がそれぞれ格納されます。\n\n各変数の役割：\n\nPROGRAM_NAME：実行中のプログラム名（拡張子なし）\nCURRENT_DIR：現在のディレクトリの完全パス\nPARENT_DIR：1つ上の階層ディレクトリのパス\nPROJECT_ROOT：プロジェクトルートディレクトリのパス（2つ上の階層）\n\n\n\n\n3.1.3 標準パス自動生成\n最後のデータステップでは、プロジェクト標準フォルダ構造に基づいて必要なパスを自動生成します。CAT関数でPROJECT_ROOTを基準として各フォルダパスを結合し、CALL SYMPUTX文でマクロ変数として定義します。生データ格納用のINPUT_RAW、外部データ格納用のINPUT_EXT、出力ファイル格納用のOUTPUT_PATH、ログファイル格納用のLOG_PATH、マクロファイル格納用のMACRO_PATH、設定ファイル格納用のSETTING_PATH、仕様書格納用のSPEC_PATHが設定されます。\n設定されるパス：\n\nINPUT_RAW：生データ（Raw data）格納パス\nINPUT_EXT：外部データ（External data）格納パス\nOUTPUT_PATH：出力ファイル格納パス\nLOG_PATH：ログファイル格納パス\nMACRO_PATH：マクロファイル格納パス\nSETTING_PATH：設定ファイル格納パス\nSPEC_PATH：仕様書格納パス\n\n\n\n3.1.4 活用メリット\nこのコードをプロジェクトの各SASプログラム冒頭に配置することで、プロジェクトフォルダの移動や環境変更時にパス設定の修正が不要になります。チーム開発での設定統一と保守性向上を実現でき、どのサブフォルダからプログラムを実行しても、常に正しいプロジェクトルートを基準とした一貫したパス管理が可能になります。手動でのパス設定ミスを防ぎ、開発効率の向上にも寄与します。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-2",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-2",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "4.1 プログラム解説",
    "text": "4.1 プログラム解説\nこのSASマクロは、指定されたディレクトリパスが存在しない場合に、必要な階層構造を含めて自動的にフォルダを作成する汎用的なディレクトリ作成マクロです。\n\n4.1.1 マクロの動作原理\nマクロは再帰的なアルゴリズムを採用しており、深い階層のフォルダ構造でも一度の呼び出しで全ての必要なディレクトリを作成できます。まず入力されたパスを親ディレクトリ部分と最終フォルダ名に分解し、指定されたパスが存在するかをチェックします。存在しない場合、親ディレクトリの存在も確認し、親ディレクトリが存在しなければマクロが自分自身を呼び出して上位階層から順次作成していきます。\n\n\n4.1.2 パス解析のロジック\nSTRIP関数で入力パスの前後空白を除去した後、SUBSTR関数とSCAN関数を組み合わせてパスを分解します。SCAN関数でパス区切り文字（バックスラッシュ）を基準に最終フォルダ名を抽出し、SUBSTR関数で親ディレクトリ部分を切り出します。この処理により、どのような深さのパスでも正確に階層構造を解析できます。\n\n\n4.1.3 条件分岐による効率的な処理\nFILEEXIST関数による存在チェックを各段階で実行し、既に存在するディレクトリに対しては何も処理を行いません。これにより無駄な処理を避け、既存の構造を保護しながら必要な部分のみを作成します。実際のフォルダ作成はDCREATE関数で実行され、作成結果は戻り値で確認できます。\n\n\n4.1.4 プロジェクト管理での活用\nこのマクロを前回のパス設定コードと組み合わせることで、プロジェクト開始時のフォルダ構造セットアップを完全自動化できます。新しい環境でプロジェクトを開始する際や、チームメンバーが初めてプロジェクトに参加する際に、手動でフォルダを作成する手間を省き、標準的なフォルダ構造を確実に構築できます。\n\n\n4.1.5 エラー処理と保守性\nマクロはエラーハンドリングも考慮されており、作成に失敗した場合でも処理が停止することなく、次の処理に進みます。また、既存のフォルダ構造に影響を与えることなく、必要な部分のみを安全に追加できる設計になっています。プロジェクトの成長に合わせて新しいフォルダが必要になった場合も、このマクロを呼び出すだけで簡単に対応できます"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-3",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-3",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "5.1 プログラム解説",
    "text": "5.1 プログラム解説\nこのSASプログラムは、実行日ベースのプログラム管理フォルダを自動作成する汎用的なコードです。\n\n5.1.1 基本的な仕組み\nまず現在の日付をYYYYMMDD形式で取得し、実行中のプログラムパスからプロジェクトルートを自動判定します。その後、プロジェクトルート配下のPrgフォルダ内に実行日付のサブフォルダ（例：Prg\\20250616）を作成します。\n\n\n5.1.2 日付ベースフォルダ管理の利点\nこのシステムにより、プログラムの実行履歴を日付別に整理できます。同じプログラムを異なる日に実行しても結果が混在せず、過去の実行内容を簡単に追跡できます。特に開発段階では、日々の変更内容を時系列で管理できるため、問題発生時の原因特定や以前のバージョンへの戻しが容易になります。\n\n\n5.1.3 自動ディレクトリ作成の活用\ncreate_dir_structureマクロの再帰処理により、深い階層構造でも一度の呼び出しで必要なフォルダが全て作成されます。既存フォルダの存在チェック機能により、重複実行しても安全で、チーム開発での環境差異も自動的に解決されます。\nこのコードをプログラム冒頭に配置することで、実行のたびに適切な作業フォルダが準備され、プロジェクトの標準化と履歴管理を同時に実現できます。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-4",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-4",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "6.1 プログラム解説",
    "text": "6.1 プログラム解説\nこのコードは、FILENAME文とINCLUDE文を組み合わせて、特定フォルダ内の複数のSASファイルを効率的に読み込む汎用的な手法です。\n\n6.1.1 FILENAME文による論理参照の設定\nFILENAME文で論理名「MACROLIB」を定義し、マクロ変数で指定されたフォルダパスを割り当てます。これにより、以降の処理では物理的なフォルダパスではなく、論理名を使用してファイルにアクセスできるようになります。\n\n\n6.1.2 INCLUDE文による選択的ファイル読み込み\n各INCLUDE文では、論理名に続けて括弧内にファイル名を指定することで、指定フォルダ内の特定ファイルを読み込みます。この記法により、フォルダ内の全ファイルではなく、必要なファイルのみを選択的に読み込むことが可能です。\n\n\n6.1.3 この手法の優位性\n従来の絶対パス指定と比較して、コードの保守性と可読性が大幅に向上します。フォルダパスの変更時は最初のFILENAME文のみを修正すれば良く、同一フォルダ内の複数ファイルを扱う際の記述量も削減されます。また、論理名を使用することで、プラットフォーム間でのパス記法の違いも吸収できます。\n\n\n6.1.4 応用範囲\nこの手法は、マクロライブラリの管理以外にも、設定ファイルの読み込み、データセットの一括処理、プログラムの分割実行など、様々な場面で活用できます。プロジェクトの規模が大きくなり、複数のファイルを体系的に管理する必要がある場合に特に有効な手法です。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-5",
    "href": "posts/statistics/2025/SASによる解析業務開始時のフォルダ整理・作成.html#プログラム解説-5",
    "title": "SASによる解析業務開始時のフォルダ整理・作成",
    "section": "7.1 プログラム解説",
    "text": "7.1 プログラム解説\nこのSASプログラムは、メタデータを基にして解析プログラムのテンプレートを動的に生成する自動化システムです。\n\n7.1.1 プログラム生成マクロの構造\ncreate_pgマクロは、プログラム名、テーブル名、解析対象集団の3つのパラメータを受け取り、指定されたフォルダに新しいSASプログラムファイルを作成します。FILENAME文で出力先ファイルを指定し、FILE文とPUT文を使用してプログラムのヘッダー部分を標準化されたフォーマットで出力します。\n\n\n7.1.2 標準化されたヘッダー生成\n各生成プログラムには、プロジェクト情報、プログラム説明、解析対象集団、バージョン情報、履歴管理欄を含む統一フォーマットのヘッダーが自動挿入されます。これにより、手動作成時に発生しがちな記載漏れや形式の不統一を防ぎ、プロジェクト全体でのドキュメント品質を保証します。\n\n\n7.1.3 メタデータ駆動型の一括生成\n最後のデータステップでは、OUT2データセットに格納されたメタデータを読み込み、CALL EXECUTE文を使用してマクロを動的に実行します。CATS関数でマクロ呼び出し文を構築し、データセットの各レコードに対して個別のプログラムファイルを生成します。\n\n\n7.1.4 自動化の利点とメリット\nこの手法により、数十から数百の解析プログラムを一度に生成できるため、大規模プロジェクトでの開発効率が大幅に向上します。メタデータの変更時も該当部分のみを修正して再実行すれば、全プログラムに変更が反映されるため、保守性も高くなります。また、ヒューマンエラーの削減と品質の均一化も実現できます。"
  },
  {
    "objectID": "posts/statistics/2025/SAS_PROC_SGPLOT.html",
    "href": "posts/statistics/2025/SAS_PROC_SGPLOT.html",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "",
    "text": "参考文献\n\n2023年SAS User総会：太田さん資料：\n\n小さく始めるSGPLOT／SGPANEL ～データに語らせよう～\n\nSAS One DashのSGplotブログ\n武田薬品：舟尾先生、SAS Sgplot超入門\n\nTips\n\nvlineにおいて最終時点のみ線で結ばないⅡ\nSGPlotのカプランマイヤー図にログランク検定のp値を書き入れる\nSGPlot内に記述統計量を書き込む方法"
  },
  {
    "objectID": "posts/statistics/2025/SAS_PROC_SGPLOT.html#sgplotに関する基礎的事項と発展的な内容をまとめる",
    "href": "posts/statistics/2025/SAS_PROC_SGPLOT.html#sgplotに関する基礎的事項と発展的な内容をまとめる",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "",
    "text": "参考文献\n\n2023年SAS User総会：太田さん資料：\n\n小さく始めるSGPLOT／SGPANEL ～データに語らせよう～\n\nSAS One DashのSGplotブログ\n武田薬品：舟尾先生、SAS Sgplot超入門\n\nTips\n\nvlineにおいて最終時点のみ線で結ばないⅡ\nSGPlotのカプランマイヤー図にログランク検定のp値を書き入れる\nSGPlot内に記述統計量を書き込む方法"
  },
  {
    "objectID": "posts/statistics/2025/SAS_PROC_SGPLOT.html#introduction",
    "href": "posts/statistics/2025/SAS_PROC_SGPLOT.html#introduction",
    "title": "SASのProc SGPLOTに関するTips",
    "section": "2 Introduction",
    "text": "2 Introduction\nSGPLOTプロシジャとは、ODS Graphics機能で使用できるStatistical Graphics Proceduresに分類されるプロシジャ。解析用データセットや他Procedureにて計算した統計量データを用いて、様々なグラフを生成することができる。\nODS Graphics機能\n代表的な作成できるグラフ\n\n散布図\n折れ線グラフ"
  },
  {
    "objectID": "posts/statistics/2025/RWD研究におけるADS仕様書.html",
    "href": "posts/statistics/2025/RWD研究におけるADS仕様書.html",
    "title": "RWD研究における解析用データセット仕様書",
    "section": "",
    "text": "臨床試験では厳格な統計解析計画書（SAP）とそれに紐づくADS仕様書が必須ですが、観察研究やリアルワールドデータ（RWD）を用いた研究では、その柔軟性ゆえに解析データセットの管理が曖昧になりがちです。しかし、これは結果の再現性や解析効率の低下、さらには研究の信頼性に関わるリスクを孕んでいます。\n本記事では、生物統計家の視点から、観察研究・RWDにおいてもなぜ解析データセット（ADS）仕様書の作成が重要なのかを解説し、その効果的な運用戦略を提案します。\n\n\n「探索的」な要素が強い観察研究やRWD解析において、ADS仕様書は一見すると手間のように思えるかもしれません。しかし、以下の点でその作成は不可欠です。\n\n\nADS仕様書は、解析に使用する変数の定義、欠損値の処理方法、変数変換のロジックなどを明確に文書化します。これにより、誰がいつ解析を行っても同じデータセットが生成されることが保証され、結果の再現性が担保されます。これは、研究の科学的信頼性を高める上で非常に重要です。\n\n\n\n解析の基盤となるデータセットの構造が明確であれば、プログラマーは無駄なく効率的に解析プログラムを開発できます。途中で変数の追加や定義変更が発生した場合でも、ADS仕様書があれば影響範囲を素早く特定し、手戻りを最小限に抑えることが可能です。\n\n\n\n医師や研究者との間で「どのデータがどのように使われているか」という共通認識を持つことは、スムーズな研究推進に不可欠です。「このカットオフを変えてみたら？」といった要望に対しても、ADS仕様書を基に議論することで、影響や実現可能性を具体的に検討できます。\n\n\n\n研究成果の発表や薬事承認プロセスにおいては、解析の透明性とトレーサビリティが求められます。ADS仕様書は、データ処理のプロセスを客観的に示す証拠となり、将来的な監査や検証に耐えうる研究基盤を構築します。\n\n\n\n\n臨床試験のSAPのような厳密さではなく、観察研究の特性に合わせた柔軟なアプローチが求められます。\n\n\n研究の初期段階で完璧なADS仕様書を作成するのは困難です。まずは現時点での仮説に基づき、最低限の情報を盛り込んだドラフトを作成しましょう。そして、研究の進捗や医師からのフィードバックに応じて、継続的に改訂していきます。\nポイント: すべての改訂には改訂履歴（バージョン、日付、内容、担当者）を明確に記録し、変更の経緯を追跡できるようにすることが重要です。\n\n\n\n「この変数を追加してみたら？」といった要望があった際、すぐにデータセットやプログラムを変更するのではなく、ADS仕様書の変更プロセスを設けましょう。変更の必要性、影響範囲、そして最終的な合意形成（誰が承認したか）を文書化することで、無秩序な変更を防ぎ、管理を強化できます。\n\n\n\n以下のような項目を網羅することで、実用的なADS仕様書を作成できます。\n\nデータソース: 元となる生データの出所\n変数定義:\n\n元の変数名とADS上の変数名\nデータ型（例: 数値、文字列、日付）\n単位\n欠損値の扱い: どのようなルールで処理するか（例: 欠損として扱う、特定値で補完）\nカテゴリカル変数の場合は、コードとラベルの対応\n新規作成変数の定義: 計算式やロジック（例: BMI = 体重(kg) / 身長(m)2、特定のカットオフ値の定義）\n\nデータ結合・マージの定義: 複数データソースを結合する場合のキーや結合方法\n除外基準: ADS作成段階で除外する対象（例: 特定の疾患群、データ不備の症例）\n\n\n\n\n可能であれば、SAS、R、Pythonなどの統計プログラミング言語を用いて、ADSの生成プロセスを自動化しましょう。これにより、手動でのデータ操作によるヒューマンエラーを防ぎ、ADS仕様書の変更にも柔軟かつ迅速に対応できるようになります。プログラム自体もバージョン管理することで、より高い再現性を実現できます。\n\n\n\n\n初期段階での合意形成: 研究開始時に、解析の主要な目的とそれに必要な変数について医師と合意し、ADS仕様書の初稿を共有します。\n変更依頼への対応: 変更依頼があった際には、単に実行するだけでなく、ADS仕様書への反映とその影響（解析結果への影響、多重比較の問題など）を説明し、変更プロセスに乗せることを促します。これにより、科学的妥当性を保ちながら柔軟に対応できます。\n\n\n\n\n\n観察研究やRWDを用いた解析において、ADS仕様書は単なる文書作成の手間ではありません。それは、研究の質と信頼性を高め、解析効率を最大化するための強力なツールです。\n臨床試験ほど厳密である必要はありませんが、段階的な作成と改訂、明確な変更管理プロセス、そしてプログラミングによる自動化を組み合わせることで、観察研究の柔軟性を保ちつつ、再現性と信頼性の高い統計解析業務を実現できます。生物統計家として、これらの戦略を積極的に導入し、より質の高い研究成果に貢献していきましょう。"
  },
  {
    "objectID": "posts/statistics/2025/RWD研究におけるADS仕様書.html#なぜ観察研究rwdにads仕様書が必要なのか",
    "href": "posts/statistics/2025/RWD研究におけるADS仕様書.html#なぜ観察研究rwdにads仕様書が必要なのか",
    "title": "RWD研究における解析用データセット仕様書",
    "section": "",
    "text": "「探索的」な要素が強い観察研究やRWD解析において、ADS仕様書は一見すると手間のように思えるかもしれません。しかし、以下の点でその作成は不可欠です。\n\n\nADS仕様書は、解析に使用する変数の定義、欠損値の処理方法、変数変換のロジックなどを明確に文書化します。これにより、誰がいつ解析を行っても同じデータセットが生成されることが保証され、結果の再現性が担保されます。これは、研究の科学的信頼性を高める上で非常に重要です。\n\n\n\n解析の基盤となるデータセットの構造が明確であれば、プログラマーは無駄なく効率的に解析プログラムを開発できます。途中で変数の追加や定義変更が発生した場合でも、ADS仕様書があれば影響範囲を素早く特定し、手戻りを最小限に抑えることが可能です。\n\n\n\n医師や研究者との間で「どのデータがどのように使われているか」という共通認識を持つことは、スムーズな研究推進に不可欠です。「このカットオフを変えてみたら？」といった要望に対しても、ADS仕様書を基に議論することで、影響や実現可能性を具体的に検討できます。\n\n\n\n研究成果の発表や薬事承認プロセスにおいては、解析の透明性とトレーサビリティが求められます。ADS仕様書は、データ処理のプロセスを客観的に示す証拠となり、将来的な監査や検証に耐えうる研究基盤を構築します。"
  },
  {
    "objectID": "posts/statistics/2025/RWD研究におけるADS仕様書.html#観察研究rwdにおけるads仕様書の運用戦略",
    "href": "posts/statistics/2025/RWD研究におけるADS仕様書.html#観察研究rwdにおけるads仕様書の運用戦略",
    "title": "RWD研究における解析用データセット仕様書",
    "section": "",
    "text": "臨床試験のSAPのような厳密さではなく、観察研究の特性に合わせた柔軟なアプローチが求められます。\n\n\n研究の初期段階で完璧なADS仕様書を作成するのは困難です。まずは現時点での仮説に基づき、最低限の情報を盛り込んだドラフトを作成しましょう。そして、研究の進捗や医師からのフィードバックに応じて、継続的に改訂していきます。\nポイント: すべての改訂には改訂履歴（バージョン、日付、内容、担当者）を明確に記録し、変更の経緯を追跡できるようにすることが重要です。\n\n\n\n「この変数を追加してみたら？」といった要望があった際、すぐにデータセットやプログラムを変更するのではなく、ADS仕様書の変更プロセスを設けましょう。変更の必要性、影響範囲、そして最終的な合意形成（誰が承認したか）を文書化することで、無秩序な変更を防ぎ、管理を強化できます。\n\n\n\n以下のような項目を網羅することで、実用的なADS仕様書を作成できます。\n\nデータソース: 元となる生データの出所\n変数定義:\n\n元の変数名とADS上の変数名\nデータ型（例: 数値、文字列、日付）\n単位\n欠損値の扱い: どのようなルールで処理するか（例: 欠損として扱う、特定値で補完）\nカテゴリカル変数の場合は、コードとラベルの対応\n新規作成変数の定義: 計算式やロジック（例: BMI = 体重(kg) / 身長(m)2、特定のカットオフ値の定義）\n\nデータ結合・マージの定義: 複数データソースを結合する場合のキーや結合方法\n除外基準: ADS作成段階で除外する対象（例: 特定の疾患群、データ不備の症例）\n\n\n\n\n可能であれば、SAS、R、Pythonなどの統計プログラミング言語を用いて、ADSの生成プロセスを自動化しましょう。これにより、手動でのデータ操作によるヒューマンエラーを防ぎ、ADS仕様書の変更にも柔軟かつ迅速に対応できるようになります。プログラム自体もバージョン管理することで、より高い再現性を実現できます。\n\n\n\n\n初期段階での合意形成: 研究開始時に、解析の主要な目的とそれに必要な変数について医師と合意し、ADS仕様書の初稿を共有します。\n変更依頼への対応: 変更依頼があった際には、単に実行するだけでなく、ADS仕様書への反映とその影響（解析結果への影響、多重比較の問題など）を説明し、変更プロセスに乗せることを促します。これにより、科学的妥当性を保ちながら柔軟に対応できます。"
  },
  {
    "objectID": "posts/statistics/2025/RWD研究におけるADS仕様書.html#まとめ",
    "href": "posts/statistics/2025/RWD研究におけるADS仕様書.html#まとめ",
    "title": "RWD研究における解析用データセット仕様書",
    "section": "",
    "text": "観察研究やRWDを用いた解析において、ADS仕様書は単なる文書作成の手間ではありません。それは、研究の質と信頼性を高め、解析効率を最大化するための強力なツールです。\n臨床試験ほど厳密である必要はありませんが、段階的な作成と改訂、明確な変更管理プロセス、そしてプログラミングによる自動化を組み合わせることで、観察研究の柔軟性を保ちつつ、再現性と信頼性の高い統計解析業務を実現できます。生物統計家として、これらの戦略を積極的に導入し、より質の高い研究成果に貢献していきましょう。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "臨床試験における有害事象（Adverse Event: AE）の集計は、薬剤の安全性評価において最も重要な分析の一つです。特に治療群間での比較は、薬剤の安全性プロファイルを理解する上で欠かせません。本記事では、標準的なADSL（Subject-Level Analysis Dataset）とADAE（Adverse Event Analysis Dataset）を使用して、Treatment群、Control群、Total の3つの観点からSOC（System Organ Class）/PT（Preferred Term）別の有害事象集計を実装する方法を詳しく解説します。\n標準データセットの作成 ADSLデータセット（被験者レベル）\n/* ADSL（被験者レベル分析データセット）の作成 */\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\nDATA STEPの基本解説：\n\ndata adsl; - 新しいデータセット「adsl」を作成開始\nlength - 変数の型と最大長を事前定義（$は文字型、数値は文字数）\ndo i = 1 to 50; - 1から50まで繰り返し処理（50人の被験者作成）\ncats() - 複数の文字列を結合する関数（空白なしで連結）\nput(i, z3.) - 数値iを3桁のゼロパディング文字列に変換（001, 002, …）\nmod(i, 3) - iを3で割った余りを計算（0, 1, 2のサイクル）\noutput; - 現在の変数値でレコードを出力\ndrop i; - 作業用変数iを最終データセットから除外\nrun; - DATA STEPの実行\n\n\n\n/* ADAE（有害事象分析データセット）の作成 - より豊富なデータ */\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\nStatement解説：\n\nADAEデータの特徴：\n\naesoc: 器官別大分類（MedDRA SOC相当）\naedecod: 基本語（MedDRA PT相当）\naerel: 因果関係（Y=あり, N=なし）\naeser: 重篤性（Y=重篤, N=非重篤）\naestdy: 投与開始からの日数\n\n\n\n\n\n\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\nPROC SQLの基本解説：\n1. PROC SQLの開始と終了：\n\nproc sql; - SQLプロシジャの開始\nquit; - SQLプロシジャの終了（他のプロシジャはrun;だがSQLはquit;）\n\n2. CREATE TABLE文：\n\ncreate table ae_safety_arm as - 新しいテーブル「ae_safety_arm」を作成\nselect ... from ... where ...; の結果でテーブルを作成\n\n3. SELECT文の基本構造：\nselect 列名1, 列名2, 計算式 as 新しい列名 from テーブル名 where 条件;\n4. CASE文（条件分岐）：\ncase when 条件1 then 値1\n     else 値2 end as 新列名\n\nIF-THEN-ELSEのSQL版\ncase when s.arm = \"Placebo\" then \"Control\" - PlaceboをControlに表示変更\n\n5. INNER JOIN（内部結合）：\nfrom adae a\ninner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\"\n\n2つのテーブルを結合\na, s はテーブルエイリアス（短縮名）\non の条件を満たすレコードのみ結果に含める\nand s.saffl = \"Y\" で安全性解析対象のみ抽出\n\n6. INTO句（マクロ変数への格納）：\nselect count(*) into :total_n\nfrom adsl\nwhere saffl = \"Y\";\n\ncount(*) - レコード数をカウント\ninto :total_n - 結果をマクロ変数&total_nに格納\n後で分母として使用\n\n\n\n\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n1. サブクエリ（副問い合わせ）：\nfrom (select aesoc, usubjid, arm\n      from ae_safety_arm\n      group by aesoc, usubjid, arm) as subj_arm\n\n() 内のSELECT文が先に実行される\nその結果をsubj_armという名前のテーブルとして使用\n重要な目的: 同一被験者の同一SOCで複数AEがある場合の重複除去\n\n2. GROUP BY句：\ngroup by aesoc, usubjid, arm\n\n指定した列の組み合わせでデータをグループ化\n各グループに対して集計関数（COUNT, SUMなど）を適用\n例：被験者001の心臓障害は1つのグループとして扱われる\n\n3. 集計関数：\ncount(distinct usubjid)  -- ユニークな被験者数をカウント\n4. 文字列処理：\ncompress(put(count(distinct usubjid), 8.)) || '(' || \ncompress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c\n\nput() - 数値を文字列に変換\ncompress() - 不要な空白を除去\n|| - 文字列結合演算子\n結果例：「5(10.0)」形式の文字列作成\n\n5. OUTER UNION CORRESPONDING：\nselect ... from ...\nunion all  \nselect ... from ...\n\n複数のSELECT結果を縦に結合\n\n\n\nall - 重複行も含めて全て結合\n\n\n\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n重要なポイント：\n1. PROC SORTの必要性：\n\nPROC TRANSPOSEはBY変数で指定した順序でデータが並んでいることを要求\n事前にソートしないとエラーが発生\n\n2. PROC TRANSPOSEの解説：\n\ndata=ae_comprehensive - 入力データセット\nout=ae_arm_pivot - 出力データセット名\nby aesoc aept; - グループ化変数（これらの組み合わせごとに転置）\nid arm_group; - 新しい列名になる変数（Treatment, Control, Totalが列名になる）\nvar c; - 転置する値の変数\n\n転置前:\naesoc    aept  arm_group  c\n心臓障害  \"\"   Treatment  2(6.7)\n心臓障害  \"\"   Control    1(3.3)\n心臓障害  \"\"   Total      3(6.0)\n\n転置後:\naesoc    aept  Treatment  Control  Total\n心臓障害  \"\"   2(6.7)     1(3.3)   3(6.0)\n//* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\nDATA STEPでの後処理解説：\n\nset ae_arm_pivot; - 入力データセットを読み込み\nif Y = \"\" then Y = \"0(0.0)\"; - 空文字列を”0(0.0)“に置換\n\"  \" || aept - PTの前に2つのスペースでインデント追加\n階層表示の仕組み:\n\n-    SOCレベル: `display_term = aesoc`（例：「心臓障害」）\n\n-    PTレベル: `display_term = \"  \" || aept`（例：「 完全房室ブロック」）\n\n\n\n\n/*======================================================================================*/\n/* プログラム名: 治療群別有害事象集計 (SOC/PT別) - シンプル版                           */\n/* 作成者: [作成者名]                                                                   */\n/* 作成日: [作成日]                                                                     */\n/* 目的: 臨床試験における有害事象データの治療群別集計                                   */\n/*      Treatment群、Control群、Total の3つの観点からSOC/PT別に集計                   */\n/*======================================================================================*/\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 1: ADSLデータセット（被験者レベル）の作成                                       */\n/*---------------------------------------------------------------------------------------*/\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 2: ADAEデータセット（有害事象レベル）の作成                                     */\n/*---------------------------------------------------------------------------------------*/\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 3: 治療群別有害事象集計の実行                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\n\n/* Step 3-2: 治療群別SOC/PT集計の実行 */\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 4: データの転置と整形                                                           */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n\n/* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    retain display_term Treatment Control Total;  /* 列順序の明示的制御 */\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\n\n/* Step 4-4: 最終ソート */\nproc sort data=final_display_ordered;\n    by aesoc sort_level aept;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 5: 結果表示                                                                     */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 5-1: 最終結果の表示 */\nproc print data=final_display_ordered noobs;\n    title1 \"有害事象集計表（治療群別）\";\n    title3 \"被験者数 (%)\";\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 6: 検証用出力                                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 6-1: 基本統計の確認 */\nproc sql;\n    title \"データ整合性チェック\";\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value from (select 1 as dummy);\nquit;\n\n/* Step 6-2: SOC別詳細検証 */\nproc sql;\n   title \"SOC別被験者数検証\";\n   select aesoc,\n          count(distinct case when arm = \"Treatment\" then usubjid else null end) as treatment_subj,\n          count(distinct case when arm = \"Control\" then usubjid else null end) as control_subj,\n          count(distinct usubjid) as total_subj\n   from ae_safety_arm\n   group by aesoc\n   order by total_subj desc;\nquit;\n\n/* Step 6-3: 治療群配分の確認 */\nproc freq data=adsl;\n   tables arm / nocum;\n   title \"治療群配分\";\nrun;\n\n\n\n/*---------------------------------------------------------------------------------------*/\n/* プログラム終了                                                                       */\n/*---------------------------------------------------------------------------------------*/\n\n/* タイトルクリア */\ntitle;\n\n/* マクロ変数の確認（ログ出力） */\n%put NOTE: Treatment群被験者数 = &treatment_n;\n%put NOTE: Control群被験者数 = &control_n;\n%put NOTE: Total被験者数 = &total_n;\n\n%put NOTE: 治療群別有害事象集計プログラム実行完了;\n\n/*======================================================================================*/\n/* プログラム終了                                                                       */\n/* 出力データセット:                                                                    */\n/*   - final_display_ordered: 最終的な治療群別集計表                                   */\n/*   - ae_safety_arm: 安全性解析対象AEデータ                                           */\n/*   - ae_comprehensive: 中間集計データ                                                */\n/*======================================================================================*/\n\n\n\n/* 集計結果の検証 */\nproc sql;\n    /* 元データとの整合性チェック */\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value;\nquit;\n検証SQLの解説：\n\nunion all - 複数のSELECT結果を縦に結合（重複も含める）\n&treatment_n - 事前に計算したマクロ変数の値を表示\n検証の重要性: 各ステップで期待する件数が得られているか確認\n\n/* SOC別被験者数の詳細検証 */\nproc sql;\n    select aesoc,\n           count(distinct case when arm = \"Treatment\" then usubjid end) as treatment_subj,\n           count(distinct case when arm = \"Control\" then usubjid end) as control_subj,\n           count(distinct usubjid) as total_subj\n    from ae_safety_arm\n    where aerel = \"Y\"  /* 因果関係ありのみ */\n    group by aesoc\n    order by total_subj desc;\nquit;\nCASE文の高度な使用：\ncount(distinct case when arm = \"Treatment\" then usubjid end)\n\ncase when ... then ... end - 条件を満たす場合のみ値を返す\nTreatment群の場合のみusubjidをカウント対象にする\n1つのクエリで治療群別の集計が可能\n\n\n\n\n\n\nSELECT 何を選ぶか\nFROM どのテーブルから  \nWHERE どんな条件で\nGROUP BY どうグループ化するか\nORDER BY どう並び替えるか\n\n\n\n/* 内部結合の例 */\nfrom adae a                    -- メインテーブル\ninner join adsl s              -- 結合するテーブル  \non a.usubjid = s.usubjid       -- 結合条件\nand s.saffl = \"Y\"              -- 追加フィルタ\n\n\n\n\ncount(*) - 全行数\ncount(distinct 列名) - ユニークな値の数\nsum() - 合計\nmin(), max() - 最小値、最大値\n\n\n\n\nfrom (select ... from ... group by ...) as 別名\n\n内側のクエリから読む\n外側のクエリは内側の結果を使用\n\n\n\n\n\n本記事では、臨床試験における有害事象データの治療群別集計を、PROC SQLを用いて段階的に実装しました。初心者の方にとって重要なポイントは：\n\n\n\n小さく始める: 複雑なクエリは段階的に構築\n中間結果確認: 各ステップでPROC PRINTで結果確認\nエラー対処: エラーメッセージから問題箇所を特定\nコメント活用: 処理の目的を明記\n\nこの段階的アプローチにより、初心者でも確実に治療群別有害事象集計をマスターできます。重要なのは、各ステップの目的を理解しながら進めることです。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#治療群別有害事象集計の実装",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#治療群別有害事象集計の実装",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\nPROC SQLの基本解説：\n1. PROC SQLの開始と終了：\n\nproc sql; - SQLプロシジャの開始\nquit; - SQLプロシジャの終了（他のプロシジャはrun;だがSQLはquit;）\n\n2. CREATE TABLE文：\n\ncreate table ae_safety_arm as - 新しいテーブル「ae_safety_arm」を作成\nselect ... from ... where ...; の結果でテーブルを作成\n\n3. SELECT文の基本構造：\nselect 列名1, 列名2, 計算式 as 新しい列名 from テーブル名 where 条件;\n4. CASE文（条件分岐）：\ncase when 条件1 then 値1\n     else 値2 end as 新列名\n\nIF-THEN-ELSEのSQL版\ncase when s.arm = \"Placebo\" then \"Control\" - PlaceboをControlに表示変更\n\n5. INNER JOIN（内部結合）：\nfrom adae a\ninner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\"\n\n2つのテーブルを結合\na, s はテーブルエイリアス（短縮名）\non の条件を満たすレコードのみ結果に含める\nand s.saffl = \"Y\" で安全性解析対象のみ抽出\n\n6. INTO句（マクロ変数への格納）：\nselect count(*) into :total_n\nfrom adsl\nwhere saffl = \"Y\";\n\ncount(*) - レコード数をカウント\ninto :total_n - 結果をマクロ変数&total_nに格納\n後で分母として使用\n\n\n\n\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n1. サブクエリ（副問い合わせ）：\nfrom (select aesoc, usubjid, arm\n      from ae_safety_arm\n      group by aesoc, usubjid, arm) as subj_arm\n\n() 内のSELECT文が先に実行される\nその結果をsubj_armという名前のテーブルとして使用\n重要な目的: 同一被験者の同一SOCで複数AEがある場合の重複除去\n\n2. GROUP BY句：\ngroup by aesoc, usubjid, arm\n\n指定した列の組み合わせでデータをグループ化\n各グループに対して集計関数（COUNT, SUMなど）を適用\n例：被験者001の心臓障害は1つのグループとして扱われる\n\n3. 集計関数：\ncount(distinct usubjid)  -- ユニークな被験者数をカウント\n4. 文字列処理：\ncompress(put(count(distinct usubjid), 8.)) || '(' || \ncompress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c\n\nput() - 数値を文字列に変換\ncompress() - 不要な空白を除去\n|| - 文字列結合演算子\n結果例：「5(10.0)」形式の文字列作成\n\n5. OUTER UNION CORRESPONDING：\nselect ... from ...\nunion all  \nselect ... from ...\n\n複数のSELECT結果を縦に結合\n\n\n\nall - 重複行も含めて全て結合\n\n\n\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n重要なポイント：\n1. PROC SORTの必要性：\n\nPROC TRANSPOSEはBY変数で指定した順序でデータが並んでいることを要求\n事前にソートしないとエラーが発生\n\n2. PROC TRANSPOSEの解説：\n\ndata=ae_comprehensive - 入力データセット\nout=ae_arm_pivot - 出力データセット名\nby aesoc aept; - グループ化変数（これらの組み合わせごとに転置）\nid arm_group; - 新しい列名になる変数（Treatment, Control, Totalが列名になる）\nvar c; - 転置する値の変数\n\n転置前:\naesoc    aept  arm_group  c\n心臓障害  \"\"   Treatment  2(6.7)\n心臓障害  \"\"   Control    1(3.3)\n心臓障害  \"\"   Total      3(6.0)\n\n転置後:\naesoc    aept  Treatment  Control  Total\n心臓障害  \"\"   2(6.7)     1(3.3)   3(6.0)\n//* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\nDATA STEPでの後処理解説：\n\nset ae_arm_pivot; - 入力データセットを読み込み\nif Y = \"\" then Y = \"0(0.0)\"; - 空文字列を”0(0.0)“に置換\n\"  \" || aept - PTの前に2つのスペースでインデント追加\n階層表示の仕組み:\n\n-    SOCレベル: `display_term = aesoc`（例：「心臓障害」）\n\n-    PTレベル: `display_term = \"  \" || aept`（例：「 完全房室ブロック」）"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#修正されたappendixプログラム列順序修正版",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#修正されたappendixプログラム列順序修正版",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/*======================================================================================*/\n/* プログラム名: 治療群別有害事象集計 (SOC/PT別) - シンプル版                           */\n/* 作成者: [作成者名]                                                                   */\n/* 作成日: [作成日]                                                                     */\n/* 目的: 臨床試験における有害事象データの治療群別集計                                   */\n/*      Treatment群、Control群、Total の3つの観点からSOC/PT別に集計                   */\n/*======================================================================================*/\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 1: ADSLデータセット（被験者レベル）の作成                                       */\n/*---------------------------------------------------------------------------------------*/\ndata adsl;\n    length usubjid $20 subjid $10 arm $20 saffl $1;\n    \n    /* 50名の被験者データを作成 */\n    do i = 1 to 50;\n        usubjid = cats(\"STUDY001-\", put(i, z3.));\n        subjid = put(i, z3.);\n        \n        /* 治療群の割り当て（2:1でTreatment:Placebo） */\n        if mod(i, 3) = 0 then arm = \"Placebo\";\n        else arm = \"Treatment\";\n        \n        /* 安全性解析対象フラグ */\n        saffl = \"Y\";\n        \n        output;\n    end;\n    drop i;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 2: ADAEデータセット（有害事象レベル）の作成                                     */\n/*---------------------------------------------------------------------------------------*/\ndata adae;\n    length usubjid $20 subjid $10 aesoc $50 aedecod $100 aeser $1 aerel $1 aestdy 8;\n    \n    /* 心臓障害の有害事象 */\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 15; output;\n    usubjid = \"STUDY001-001\"; subjid = \"001\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 22; output;\n    \n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全慢性\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 8; output;\n    usubjid = \"STUDY001-002\"; subjid = \"002\"; aesoc = \"心臓障害\"; aedecod = \"心不全\"; aeser = \"N\"; aerel = \"N\"; aestdy = 45; output;\n    \n    usubjid = \"STUDY001-004\"; subjid = \"004\"; aesoc = \"心臓障害\"; aedecod = \"動悸\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 3; output;\n    usubjid = \"STUDY001-007\"; subjid = \"007\"; aesoc = \"心臓障害\"; aedecod = \"洞停止\"; aeser = \"N\"; aerel = \"N\"; aestdy = 34; output;\n    usubjid = \"STUDY001-010\"; subjid = \"010\"; aesoc = \"心臓障害\"; aedecod = \"完全房室ブロック\"; aeser = \"Y\"; aerel = \"Y\"; aestdy = 25; output;\n    usubjid = \"STUDY001-013\"; subjid = \"013\"; aesoc = \"心臓障害\"; aedecod = \"徐脈\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 11; output;\n    usubjid = \"STUDY001-016\"; subjid = \"016\"; aesoc = \"心臓障害\"; aedecod = \"心房細動\"; aeser = \"Y\"; aerel = \"N\"; aestdy = 67; output;\n    usubjid = \"STUDY001-019\"; subjid = \"019\"; aesoc = \"心臓障害\"; aedecod = \"狭心症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 44; output;\n    \n    /* 胃腸障害の有害事象 */\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 2; output;\n    usubjid = \"STUDY001-005\"; subjid = \"005\"; aesoc = \"胃腸障害\"; aedecod = \"嘔吐\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-008\"; subjid = \"008\"; aesoc = \"胃腸障害\"; aedecod = \"下痢\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 18; output;\n    usubjid = \"STUDY001-011\"; subjid = \"011\"; aesoc = \"胃腸障害\"; aedecod = \"便秘\"; aeser = \"N\"; aerel = \"N\"; aestdy = 28; output;\n    usubjid = \"STUDY001-014\"; subjid = \"014\"; aesoc = \"胃腸障害\"; aedecod = \"悪心\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 4; output;\n    usubjid = \"STUDY001-017\"; subjid = \"017\"; aesoc = \"胃腸障害\"; aedecod = \"腹痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 32; output;\n    usubjid = \"STUDY001-020\"; subjid = \"020\"; aesoc = \"胃腸障害\"; aedecod = \"消化不良\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 12; output;\n    \n    /* 神経系障害の有害事象 */\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 1; output;\n    usubjid = \"STUDY001-006\"; subjid = \"006\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 14; output;\n    usubjid = \"STUDY001-009\"; subjid = \"009\"; aesoc = \"神経系障害\"; aedecod = \"傾眠\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 7; output;\n    usubjid = \"STUDY001-012\"; subjid = \"012\"; aesoc = \"神経系障害\"; aedecod = \"頭痛\"; aeser = \"N\"; aerel = \"N\"; aestdy = 21; output;\n    usubjid = \"STUDY001-015\"; subjid = \"015\"; aesoc = \"神経系障害\"; aedecod = \"めまい\"; aeser = \"N\"; aerel = \"N\"; aestdy = 19; output;\n    usubjid = \"STUDY001-018\"; subjid = \"018\"; aesoc = \"神経系障害\"; aedecod = \"振戦\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 29; output;\n    \n    /* 皮膚および皮下組織障害 */\n    usubjid = \"STUDY001-021\"; subjid = \"021\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"発疹\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 9; output;\n    usubjid = \"STUDY001-022\"; subjid = \"022\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"そう痒症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 16; output;\n    usubjid = \"STUDY001-023\"; subjid = \"023\"; aesoc = \"皮膚および皮下組織障害\"; aedecod = \"紅斑\"; aeser = \"N\"; aerel = \"N\"; aestdy = 23; output;\n    \n    /* 一般・全身障害および投与部位の状態 */\n    usubjid = \"STUDY001-024\"; subjid = \"024\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"疲労\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 5; output;\n    usubjid = \"STUDY001-025\"; subjid = \"025\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"発熱\"; aeser = \"N\"; aerel = \"N\"; aestdy = 13; output;\n    usubjid = \"STUDY001-026\"; subjid = \"026\"; aesoc = \"一般・全身障害および投与部位の状態\"; aedecod = \"無力症\"; aeser = \"N\"; aerel = \"Y\"; aestdy = 27; output;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 3: 治療群別有害事象集計の実行                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 3-1: 安全性解析対象データの準備と母集団サイズ取得 */\nproc sql;\n    /* 安全性解析対象のAEデータ抽出（ARM情報付き） */\n    create table ae_safety_arm as\n    select a.usubjid, a.aesoc, a.aedecod, a.aerel, a.aeser, \n           case when s.arm = \"Placebo\" then \"Control\" \n                else s.arm end as arm\n    from adae a\n    inner join adsl s on a.usubjid = s.usubjid and s.saffl = \"Y\";\n    \n    /* 各ARM別とTOTALの母集団サイズ取得 */\n    select count(*) into :total_n\n    from adsl\n    where saffl = \"Y\";\n    \n    select count(*) into :treatment_n\n    from adsl  \n    where saffl = \"Y\" and arm = \"Treatment\";\n    \n    select count(*) into :control_n\n    from adsl\n    where saffl = \"Y\" and arm = \"Placebo\";  /* 元データではPlacebo */\nquit;\n\n/* Step 3-2: 治療群別SOC/PT集計の実行 */\nproc sql;\n    create table ae_comprehensive as\n    \n    /* SOCレベル - ARM別 */\n    select aesoc, \"\" as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, usubjid, arm) as subj_arm\n    group by aesoc, arm\n    \n    union all\n    \n    /* SOCレベル - Total */\n    select aesoc, \"\" as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, usubjid\n          from ae_safety_arm\n          group by aesoc, usubjid) as subj_total\n    group by aesoc\n    \n    union all\n    \n    /* PTレベル - ARM別 */\n    select aesoc, aedecod as aept, arm as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/\n               case when arm = \"Treatment\" then &treatment_n\n                    when arm = \"Control\" then &control_n\n                    else &total_n end)*100, 8.1)) || ')' as c,\n           case when arm = \"Treatment\" then 1\n                when arm = \"Control\" then 2\n                else 3 end as arm_order\n    from (select aesoc, aedecod, usubjid, arm\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid, arm) as subj_arm\n    group by aesoc, aedecod, arm\n    \n    union all\n    \n    /* PTレベル - Total */\n    select aesoc, aedecod as aept, \"Total\" as arm_group,\n           compress(put(count(distinct usubjid), 8.)) || '(' || \n           compress(put((count(distinct usubjid)/&total_n)*100, 8.1)) || ')' as c,\n           3 as arm_order\n    from (select aesoc, aedecod, usubjid\n          from ae_safety_arm\n          group by aesoc, aedecod, usubjid) as subj_total\n    group by aesoc, aedecod;\nquit;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 4: データの転置と整形                                                           */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 4-1: ソート処理（転置前に必要） */\nproc sort data=ae_comprehensive;\n    by aesoc aept arm_order arm_group;\nrun;\n\n/* Step 4-2: 転置処理 */\nproc transpose data=ae_comprehensive out=ae_arm_pivot;\n    by aesoc aept;\n    id arm_group;\n    var c;\nrun;\n\n/* Step 4-3: 表示用整形 */\ndata final_display_ordered;\n    retain display_term Treatment Control Total;  /* 列順序の明示的制御 */\n    set ae_arm_pivot;\n    \n    /* 欠損値処理 */\n    if Treatment = \"\" then Treatment = \"0(0.0)\";\n    if Control = \"\" then Control = \"0(0.0)\";\n    if Total = \"\" then Total = \"0(0.0)\";\n    \n    /* 階層表示 */\n    length display_term $100;\n    if aept = \"\" then display_term = aesoc;\n    else display_term = \"  \" || aept;\n    \n    /* ソート用変数 */\n    if aept = \"\" then sort_level = 1;  /* SOCレベル */\n    else sort_level = 2;               /* PTレベル */\n    \n    drop _name_;\nrun;\n\n/* Step 4-4: 最終ソート */\nproc sort data=final_display_ordered;\n    by aesoc sort_level aept;\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 5: 結果表示                                                                     */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 5-1: 最終結果の表示 */\nproc print data=final_display_ordered noobs;\n    title1 \"有害事象集計表（治療群別）\";\n    title3 \"被験者数 (%)\";\nrun;\n\n/*---------------------------------------------------------------------------------------*/\n/* Step 6: 検証用出力                                                                   */\n/*---------------------------------------------------------------------------------------*/\n\n/* Step 6-1: 基本統計の確認 */\nproc sql;\n    title \"データ整合性チェック\";\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value from (select 1 as dummy)\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value from (select 1 as dummy);\nquit;\n\n/* Step 6-2: SOC別詳細検証 */\nproc sql;\n   title \"SOC別被験者数検証\";\n   select aesoc,\n          count(distinct case when arm = \"Treatment\" then usubjid else null end) as treatment_subj,\n          count(distinct case when arm = \"Control\" then usubjid else null end) as control_subj,\n          count(distinct usubjid) as total_subj\n   from ae_safety_arm\n   group by aesoc\n   order by total_subj desc;\nquit;\n\n/* Step 6-3: 治療群配分の確認 */\nproc freq data=adsl;\n   tables arm / nocum;\n   title \"治療群配分\";\nrun;\n\n\n\n/*---------------------------------------------------------------------------------------*/\n/* プログラム終了                                                                       */\n/*---------------------------------------------------------------------------------------*/\n\n/* タイトルクリア */\ntitle;\n\n/* マクロ変数の確認（ログ出力） */\n%put NOTE: Treatment群被験者数 = &treatment_n;\n%put NOTE: Control群被験者数 = &control_n;\n%put NOTE: Total被験者数 = &total_n;\n\n%put NOTE: 治療群別有害事象集計プログラム実行完了;\n\n/*======================================================================================*/\n/* プログラム終了                                                                       */\n/* 出力データセット:                                                                    */\n/*   - final_display_ordered: 最終的な治療群別集計表                                   */\n/*   - ae_safety_arm: 安全性解析対象AEデータ                                           */\n/*   - ae_comprehensive: 中間集計データ                                                */\n/*======================================================================================*/"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#結果の検証とデバッグ",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#結果の検証とデバッグ",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "/* 集計結果の検証 */\nproc sql;\n    /* 元データとの整合性チェック */\n    select \"元AE総件数\" as check_point, \n           count(*) as count_value\n    from adae\n    \n    union all\n    \n    select \"安全性解析対象AE件数\" as check_point,\n           count(*) as count_value\n    from ae_safety_arm\n    \n    union all\n    \n    select \"Treatment群被験者数\" as check_point,\n           &treatment_n as count_value\n           \n    union all\n    \n    select \"Control群被験者数\" as check_point,\n           &control_n as count_value\n           \n    union all\n    \n    select \"Total被験者数\" as check_point,\n           &total_n as count_value;\nquit;\n検証SQLの解説：\n\nunion all - 複数のSELECT結果を縦に結合（重複も含める）\n&treatment_n - 事前に計算したマクロ変数の値を表示\n検証の重要性: 各ステップで期待する件数が得られているか確認\n\n/* SOC別被験者数の詳細検証 */\nproc sql;\n    select aesoc,\n           count(distinct case when arm = \"Treatment\" then usubjid end) as treatment_subj,\n           count(distinct case when arm = \"Control\" then usubjid end) as control_subj,\n           count(distinct usubjid) as total_subj\n    from ae_safety_arm\n    where aerel = \"Y\"  /* 因果関係ありのみ */\n    group by aesoc\n    order by total_subj desc;\nquit;\nCASE文の高度な使用：\ncount(distinct case when arm = \"Treatment\" then usubjid end)\n\ncase when ... then ... end - 条件を満たす場合のみ値を返す\nTreatment群の場合のみusubjidをカウント対象にする\n1つのクエリで治療群別の集計が可能"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#初心者向けsql学習のポイント",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#初心者向けsql学習のポイント",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "SELECT 何を選ぶか\nFROM どのテーブルから  \nWHERE どんな条件で\nGROUP BY どうグループ化するか\nORDER BY どう並び替えるか\n\n\n\n/* 内部結合の例 */\nfrom adae a                    -- メインテーブル\ninner join adsl s              -- 結合するテーブル  \non a.usubjid = s.usubjid       -- 結合条件\nand s.saffl = \"Y\"              -- 追加フィルタ\n\n\n\n\ncount(*) - 全行数\ncount(distinct 列名) - ユニークな値の数\nsum() - 合計\nmin(), max() - 最小値、最大値\n\n\n\n\nfrom (select ... from ... group by ...) as 別名\n\n内側のクエリから読む\n外側のクエリは内側の結果を使用"
  },
  {
    "objectID": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#まとめ",
    "href": "posts/statistics/2025/Proc_SQL_SOC_PT別の集計.html#まとめ",
    "title": "臨床試験における有害事象データの集計：PROC SQL",
    "section": "",
    "text": "本記事では、臨床試験における有害事象データの治療群別集計を、PROC SQLを用いて段階的に実装しました。初心者の方にとって重要なポイントは：\n\n\n\n小さく始める: 複雑なクエリは段階的に構築\n中間結果確認: 各ステップでPROC PRINTで結果確認\nエラー対処: エラーメッセージから問題箇所を特定\nコメント活用: 処理の目的を明記\n\nこの段階的アプローチにより、初心者でも確実に治療群別有害事象集計をマスターできます。重要なのは、各ステップの目的を理解しながら進めることです。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contentsによる_nameの作成.html",
    "href": "posts/statistics/2025/Proc_Contentsによる_nameの作成.html",
    "title": "Proc Contentsを利用したRawデータの変数を_varにするマクロ",
    "section": "",
    "text": "SASで解析プロジェクトを進める際、最初に行う作業の一つが生データの加工です。特に、生データの変数名がSASの命名規則に厳密に準拠していなかったり、特定のプレフィックスやサフィックスを追加・削除したい場合が多くあります。\n今回ご紹介するSASマクロ%rawdataは、この「生データの変数名を自動で一括変換する」という、非常に実用的な処理を実現します。このテクニックをマスターすれば、手作業での変数名変更の手間を大幅に削減し、より効率的なデータ準備が可能になります。\n\n\nこのマクロの主な目的は、入力データセットの全変数に対して、以下のような処理を自動で適用することです。\n\nデータセットの変数情報（定義情報）を取得する\n変数情報を基に、各変数の古い名前と新しい名前のペアを作成する\nそのペアを使って、データセットの全変数名を一括で変更する\n\n特に注目すべきは、変数名の変更ロジックが_subjidのように、元の変数名にアンダースコア（_）をプレフィックスとして追加している点です。これは、特定の命名規則を強制したい場合に非常に有効です。\nそれでは、各セクションを詳しく見ていきましょう。\n\n\n\n%macro rawdata(raw=, sort=, out=&raw);\n\n/* データセット定義情報の DS を作成 */\nproc contents data=work.&raw. out = work.VAR noprints;\nrun;\n\n%macro rawdata(raw=, sort=, out=&raw);: %rawdataという名前のマクロを定義しています。引数は以下の3つです。\n\nraw=: 処理対象となる生データセット名を指定します。\nsort=: （このコードでは直接使用されていませんが、将来的な拡張性を示唆しています。）\nout=&raw: 処理結果の出力データセット名を指定します。デフォルトでは入力と同じ&rawになります。\n\nproc contents data=work.&raw. out = work.VAR noprints; run;: PROC CONTENTSプロシジャは、指定されたデータセット（work.&raw）の構造や変数に関する情報を取得し、その結果を新しいデータセット（work.VAR）に出力します。\n\nnoprints: 通常、PROC CONTENTSは結果をSAS出力ウィンドウに出力しますが、noprintsオプションを指定することで、この出力を抑制し、データセットへの出力のみを行います。 work.VARデータセットには、VARNUM（変数番号）、NAME（変数名）、LENGTH（変数長）、TYPE（変数型）などの情報が格納されます。このうち、今回は特にVARNUMとNAMEが重要になります。\n\n\n\n\n\n/* 変数番号でソート */\nproc sort data=work.VAR ;\nby VARNUM ;\nrun;\nPROC SORTプロシジャを使って、先ほど作成したwork.VARデータセットをVARNUM（変数番号）の昇順でソートします。これにより、後続の処理で変数を順番に扱うことが容易になります。SASは内部的に変数に番号を割り当てており、この番号順で処理することで、元のデータセットにおける変数の並び順を反映できます。\n\n\n\n/* マクロ変数(VARn_)に変数を格納 */\ndata _null_;\n  set work.VAR end = eof;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');\n  /* マクロ変数(MAXV)にオブザベーション数（変数の数）を格納 */\n  if eof then call symputx('MAXV',_N_);\nrun;\nこのDATA _NULL_ステップは、このマクロの肝となる部分の一つです。work.VARデータセットの各行（つまり各変数）を読み込み、それに対応するマクロ変数を動的に生成します。\n\nset work.VAR end = eof;: work.VARデータセットを読み込みます。end=eofオプションは、データセットの最後のオブザベーションを読み込んだときに、eofという一時的な変数を1に設定します。\ncall symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');: CALL SYMPUTXルーチンは、データステップ内でSASマクロ変数を定義するために使用します。\n\n\"VAR\"||strip(put(VARNUM, 8.))||\"_\": ここでマクロ変数名が生成されます。\n\nVAR: プレフィックス\nstrip(put(VARNUM, 8.)): VARNUM（変数番号）を文字列に変換し、前後の空白を除去します。例えばVARNUMが1なら\"1\"になります。\n_: サフィックス 結果として、VAR1_, VAR2_, …, VARn_のようなマクロ変数が作成されます。\n\nNAME: これがマクロ変数に割り当てられる値、つまり元の変数名です。例えば、VAR1_には最初の変数名、VAR2_には2番目の変数名が格納されます。\n'G': スコープを指定します。'G'はグローバルマクロ変数として定義することを意味します。\n\nif eof then call symputx('MAXV',_N_);: データセットの最後のオブザベーションに到達したとき（eofが1のとき）に、MAXVというマクロ変数に_N_（データステップの現在のオブザベーション番号、ここでは変数番号の最大値）を格納します。これにより、データセット内の変数総数を取得できます。\n\nこのステップが完了すると、例えば元のデータセットにSUBJID, AGE, SEXという変数があった場合、以下のようなマクロ変数が生成されます。\n\n&VAR1_ = SUBJID\n&VAR2_ = AGE\n&VAR3_ = SEX\n&MAXV = 3\n\n\n\n\n/* 全変数の変数名を変更 (ex: subjid ⇒ _subjid) */\ndata work.&out. ;\n  set work.&raw. ;\n  rename %do i = 1 %to &MAXV.;\n  &&VAR&i._ = _&&VAR&i._\n  %end;\n  ;\nrun;\nいよいよ変数名の変更を行うコア部分です。DATAステップのRENAMEステートメントを、動的に生成されたマクロ変数を使って構築します。\n\ndata work.&out. ; set work.&raw. ;: 入力データセットwork.&rawを読み込み、work.&outとして新しいデータセットを作成します。\nrename %do i = 1 %to &MAXV.; ... %end;: この部分が、RENAMEステートメントをループ処理で動的に生成する肝です。\n\n%do i = 1 %to &MAXV.; ... %end;: iを1から&MAXV（変数総数）までループさせます。\n&&VAR&i._ = _&&VAR&i._:\n\n&&VAR&i._: これは二重間接参照です。\n\nまず&iが評価され、例えば1になります。\n次に&VAR1_が評価され、その値（例：SUBJID）が取得されます。 結果として、元の変数名（例：SUBJID）を指します。\n\n_&&VAR&i._: これが新しい変数名です。元の変数名の前にアンダースコア_を付けています。 結果として、SUBJID = _SUBJID、AGE = _AGE、SEX = _SEXといったRENAMEステートメントのリストがループによって生成されます。\nrename SUBJID = _SUBJID AGE = _AGE SEX = _SEX; のように展開されます。\n\n\n\nこの処理により、元のデータセットのすべての変数名が、定義されたルール（この場合は先頭に_を追加）に従って一括で変更されます。\n\n\n\nこの%rawdataマクロは、以下の点でSASプログラミングの効率と堅牢性を高めます。\n\n自動化と効率化: 手動で大量の変数名を変更する手間を省き、エラーのリスクを減らします。\n再利用性: どのようなデータセットに対しても、同じロジックで変数名を変換できます。\n命名規則の統一: プロジェクト全体で一貫した変数命名規則を強制するのに役立ちます。\n柔軟な対応: &&VAR&i._ = _&&VAR&i._ の部分を変更することで、NEWNAME = OLDNAME、OLDNAME = NEWNAMEなど、様々な変数名変換ロジックを適用できます。例えば、特定のサフィックスを追加したり、特定の文字列を置換したりすることも可能です。\n\n生データの前処理は解析の基盤です。このような自動化ツールを積極的に活用し、より質の高いデータ準備を目指しましょう。\n\n\n\n%macro rawdata(raw=, sort=, out=&raw);\n\n/* データセット定義情報の DS を作成 */\nproc contents data=work.&raw. out = work.VAR noprints;\nrun;\n\n/* 変数番号でソート */\nproc sort data=work.VAR ;\nby VARNUM ;\nrun;\n\n/* マクロ変数(VARn_)に変数を格納 */\ndata _null_;\n  set work.VAR end = eof;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');\n  /* マクロ変数(MAXV)にオブザベーション数（変数の数）を格納 */\n  if eof then call symputx('MAXV',_N_);\nrun;\n\n/* 全変数の変数名を変更 (ex: subjid ⇒ _subjid) */\ndata work.&out. ;\n  set work.&raw. ;\n  rename %do i = 1 %to &MAXV.;\n  &&VAR&i._ = _&&VAR&i._\n  %end;\n  ;\nrun;\n\n%mend rawdata;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contentsによる_nameの作成.html#sasマクロで生データをスマートに整形変数名変換の自動化テクニック",
    "href": "posts/statistics/2025/Proc_Contentsによる_nameの作成.html#sasマクロで生データをスマートに整形変数名変換の自動化テクニック",
    "title": "Proc Contentsを利用したRawデータの変数を_varにするマクロ",
    "section": "",
    "text": "SASで解析プロジェクトを進める際、最初に行う作業の一つが生データの加工です。特に、生データの変数名がSASの命名規則に厳密に準拠していなかったり、特定のプレフィックスやサフィックスを追加・削除したい場合が多くあります。\n今回ご紹介するSASマクロ%rawdataは、この「生データの変数名を自動で一括変換する」という、非常に実用的な処理を実現します。このテクニックをマスターすれば、手作業での変数名変更の手間を大幅に削減し、より効率的なデータ準備が可能になります。\n\n\nこのマクロの主な目的は、入力データセットの全変数に対して、以下のような処理を自動で適用することです。\n\nデータセットの変数情報（定義情報）を取得する\n変数情報を基に、各変数の古い名前と新しい名前のペアを作成する\nそのペアを使って、データセットの全変数名を一括で変更する\n\n特に注目すべきは、変数名の変更ロジックが_subjidのように、元の変数名にアンダースコア（_）をプレフィックスとして追加している点です。これは、特定の命名規則を強制したい場合に非常に有効です。\nそれでは、各セクションを詳しく見ていきましょう。\n\n\n\n%macro rawdata(raw=, sort=, out=&raw);\n\n/* データセット定義情報の DS を作成 */\nproc contents data=work.&raw. out = work.VAR noprints;\nrun;\n\n%macro rawdata(raw=, sort=, out=&raw);: %rawdataという名前のマクロを定義しています。引数は以下の3つです。\n\nraw=: 処理対象となる生データセット名を指定します。\nsort=: （このコードでは直接使用されていませんが、将来的な拡張性を示唆しています。）\nout=&raw: 処理結果の出力データセット名を指定します。デフォルトでは入力と同じ&rawになります。\n\nproc contents data=work.&raw. out = work.VAR noprints; run;: PROC CONTENTSプロシジャは、指定されたデータセット（work.&raw）の構造や変数に関する情報を取得し、その結果を新しいデータセット（work.VAR）に出力します。\n\nnoprints: 通常、PROC CONTENTSは結果をSAS出力ウィンドウに出力しますが、noprintsオプションを指定することで、この出力を抑制し、データセットへの出力のみを行います。 work.VARデータセットには、VARNUM（変数番号）、NAME（変数名）、LENGTH（変数長）、TYPE（変数型）などの情報が格納されます。このうち、今回は特にVARNUMとNAMEが重要になります。\n\n\n\n\n\n/* 変数番号でソート */\nproc sort data=work.VAR ;\nby VARNUM ;\nrun;\nPROC SORTプロシジャを使って、先ほど作成したwork.VARデータセットをVARNUM（変数番号）の昇順でソートします。これにより、後続の処理で変数を順番に扱うことが容易になります。SASは内部的に変数に番号を割り当てており、この番号順で処理することで、元のデータセットにおける変数の並び順を反映できます。\n\n\n\n/* マクロ変数(VARn_)に変数を格納 */\ndata _null_;\n  set work.VAR end = eof;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');\n  /* マクロ変数(MAXV)にオブザベーション数（変数の数）を格納 */\n  if eof then call symputx('MAXV',_N_);\nrun;\nこのDATA _NULL_ステップは、このマクロの肝となる部分の一つです。work.VARデータセットの各行（つまり各変数）を読み込み、それに対応するマクロ変数を動的に生成します。\n\nset work.VAR end = eof;: work.VARデータセットを読み込みます。end=eofオプションは、データセットの最後のオブザベーションを読み込んだときに、eofという一時的な変数を1に設定します。\ncall symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');: CALL SYMPUTXルーチンは、データステップ内でSASマクロ変数を定義するために使用します。\n\n\"VAR\"||strip(put(VARNUM, 8.))||\"_\": ここでマクロ変数名が生成されます。\n\nVAR: プレフィックス\nstrip(put(VARNUM, 8.)): VARNUM（変数番号）を文字列に変換し、前後の空白を除去します。例えばVARNUMが1なら\"1\"になります。\n_: サフィックス 結果として、VAR1_, VAR2_, …, VARn_のようなマクロ変数が作成されます。\n\nNAME: これがマクロ変数に割り当てられる値、つまり元の変数名です。例えば、VAR1_には最初の変数名、VAR2_には2番目の変数名が格納されます。\n'G': スコープを指定します。'G'はグローバルマクロ変数として定義することを意味します。\n\nif eof then call symputx('MAXV',_N_);: データセットの最後のオブザベーションに到達したとき（eofが1のとき）に、MAXVというマクロ変数に_N_（データステップの現在のオブザベーション番号、ここでは変数番号の最大値）を格納します。これにより、データセット内の変数総数を取得できます。\n\nこのステップが完了すると、例えば元のデータセットにSUBJID, AGE, SEXという変数があった場合、以下のようなマクロ変数が生成されます。\n\n&VAR1_ = SUBJID\n&VAR2_ = AGE\n&VAR3_ = SEX\n&MAXV = 3\n\n\n\n\n/* 全変数の変数名を変更 (ex: subjid ⇒ _subjid) */\ndata work.&out. ;\n  set work.&raw. ;\n  rename %do i = 1 %to &MAXV.;\n  &&VAR&i._ = _&&VAR&i._\n  %end;\n  ;\nrun;\nいよいよ変数名の変更を行うコア部分です。DATAステップのRENAMEステートメントを、動的に生成されたマクロ変数を使って構築します。\n\ndata work.&out. ; set work.&raw. ;: 入力データセットwork.&rawを読み込み、work.&outとして新しいデータセットを作成します。\nrename %do i = 1 %to &MAXV.; ... %end;: この部分が、RENAMEステートメントをループ処理で動的に生成する肝です。\n\n%do i = 1 %to &MAXV.; ... %end;: iを1から&MAXV（変数総数）までループさせます。\n&&VAR&i._ = _&&VAR&i._:\n\n&&VAR&i._: これは二重間接参照です。\n\nまず&iが評価され、例えば1になります。\n次に&VAR1_が評価され、その値（例：SUBJID）が取得されます。 結果として、元の変数名（例：SUBJID）を指します。\n\n_&&VAR&i._: これが新しい変数名です。元の変数名の前にアンダースコア_を付けています。 結果として、SUBJID = _SUBJID、AGE = _AGE、SEX = _SEXといったRENAMEステートメントのリストがループによって生成されます。\nrename SUBJID = _SUBJID AGE = _AGE SEX = _SEX; のように展開されます。\n\n\n\nこの処理により、元のデータセットのすべての変数名が、定義されたルール（この場合は先頭に_を追加）に従って一括で変更されます。\n\n\n\nこの%rawdataマクロは、以下の点でSASプログラミングの効率と堅牢性を高めます。\n\n自動化と効率化: 手動で大量の変数名を変更する手間を省き、エラーのリスクを減らします。\n再利用性: どのようなデータセットに対しても、同じロジックで変数名を変換できます。\n命名規則の統一: プロジェクト全体で一貫した変数命名規則を強制するのに役立ちます。\n柔軟な対応: &&VAR&i._ = _&&VAR&i._ の部分を変更することで、NEWNAME = OLDNAME、OLDNAME = NEWNAMEなど、様々な変数名変換ロジックを適用できます。例えば、特定のサフィックスを追加したり、特定の文字列を置換したりすることも可能です。\n\n生データの前処理は解析の基盤です。このような自動化ツールを積極的に活用し、より質の高いデータ準備を目指しましょう。\n\n\n\n%macro rawdata(raw=, sort=, out=&raw);\n\n/* データセット定義情報の DS を作成 */\nproc contents data=work.&raw. out = work.VAR noprints;\nrun;\n\n/* 変数番号でソート */\nproc sort data=work.VAR ;\nby VARNUM ;\nrun;\n\n/* マクロ変数(VARn_)に変数を格納 */\ndata _null_;\n  set work.VAR end = eof;\n  call symputx(\"VAR\"||strip(put(VARNUM, 8.))||\"_\", NAME, 'G');\n  /* マクロ変数(MAXV)にオブザベーション数（変数の数）を格納 */\n  if eof then call symputx('MAXV',_N_);\nrun;\n\n/* 全変数の変数名を変更 (ex: subjid ⇒ _subjid) */\ndata work.&out. ;\n  set work.&raw. ;\n  rename %do i = 1 %to &MAXV.;\n  &&VAR&i._ = _&&VAR&i._\n  %end;\n  ;\nrun;\n\n%mend rawdata;"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html",
    "href": "posts/statistics/2025/Markdown記法1.html",
    "title": "Markdown記法について",
    "section": "",
    "text": "R Quartoでは、Markdownを使って文書を作成し、Rコードと組み合わせて美しいレポートや論文を生成できます。本記事では、Quarto環境で効果的に使えるMarkdown記法を体系的に解説します。\n\n\n\n私たちのR　再現可能な研究24.Quarto［基礎］\n私たちのR　再現可能な研究25.Quarto［文書］\n私たちのR　再現可能な研究25.Quarto［スライド］\n私たちのR　Appendix F — R Markdown [基礎]\n私たちのR　Appendix G — R Markdown [応用]\n私たちのR　Appendix H — Quarto入門\n\n\n\n\nMarkdownは、プレーンテキストで記述した文書を構造化された文書に変換するためのマークアップ言語です。R Quartoでは、このMarkdownとRコードを組み合わせて、データ分析レポートや学術論文を作成できます。\n\n\n\n可読性が高い：マークアップが最小限で、プレーンテキストでも内容が理解しやすい\n学習コストが低い：基本的な記法は数時間で習得可能\nQuartoとの親和性：Rコードチャンクとシームレスに統合\n多様な出力形式：HTML、PDF、Word、PowerPointなど\n\n\n\n\n\n\n\nコードを美しく表示するには、バッククオート3つ（```）でコードを囲みます。 これだけだとSAS/Rに限らず、プログラムは実行はされないが、サンプルとして提示する際に便利である。\n# Rコードの例\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# データの読み込みと前処理\ndata &lt;- mtcars %&gt;%\n  mutate(efficiency = ifelse(mpg &gt; 20, \"High\", \"Low\"))\n\n# 散布図の作成\nggplot(data, aes(x = wt, y = mpg, color = efficiency)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"車重と燃費の関係\",\n       x = \"車重 (1000 lbs)\",\n       y = \"燃費 (mpg)\")\nQuartoでRプログラムも実行させたい場合は以下のように記載する。なお、SASは実行させない前提とする。 なお、SASの設定環境をQuartoに構築したらSASも実行可能である。\nプログラムも実行させるには、バッククオート3つ（```）でコードを囲み、{r}と書く。そうすると、Rプログラムの実行できる。\nオプションとしてRプログラムを非表示にしたり、表や図を表示する際は、2つの図表を横に並べたりとオプションは様々ある。それらは、こちらのブログを参考にしていただきたい。デフォルトではプログラムが表示されてしまうので、非表示にする場合は、\n\n\nコード\n1+1\n\n\n[1] 2\n\n\nQuartoでの頻用するであろうオプション記法：\n\n\n\n\n実行制御：このコードを実際に実行するかを指定\ntrue：コードを実行する（デフォルト）\nfalse：コードを実行せず、表示のみ\n\n\n\n\n\n出力形式：コードの実行結果をそのまま（as-is）出力\n通常はコードの出力結果が整形されますが、asisでは生の形式で出力\nHTMLタグやMarkdown記法をそのまま文書に挿入したい場合に使用\n\n\n\n\n\nコード表示制御：コードブロックを折りたたみ状態で表示する\ntrue：コードを折りたたんで、クリック可能なボタンで展開\nfalse：コードを通常通り表示（デフォルト）\n読者が必要に応じてコードの詳細を確認できる柔軟性を提供\n\n\n\n\n\n折りたたみボタンのラベル：折りたたまれたコードを展開するボタンのテキストを設定\nデフォルトでは「Show code」や「コードを表示」が表示される\nカスタムテキストで、そのコードブロックの内容を説明できる\n絵文字や詳細な説明文を使用して、読みやすさを向上させる\n\n以下のプログラムを回すと、その下の結果が得らえる。プログラムが表示されないので結果だけを提示する際には有用である。\n#| eval: true\n#| output: asis\n#| code-fold: true\n#| code-summary: \"Show Code\"\n\n1 + 1\n\nShow Code\n1 + 1\n\n[1] 2\n\n\n\n本文中にRの結果を直接入れることができます！これをインラインコードと呼びます。 “r 引数”で本文中に簡単にRの出力結果を入れることができる。これは論文作成の文章案を作成するときに便利であろう。\n以下のように書くことでできます。普通はRチャンクで計算したものを引用するのがよいだろう。\n年齢の平均は r mean(mtcars$mpg) です。\nサンプルサイズは r nrow(mtcars) でした。\n最大値は r max(mtcars$hp) 馬力です。\n年齢の平均は 20.090625 です。 サンプルサイズは 32 でした。 最大値は 335 馬力です。\n\n\n\n\n\nコード\n# データの事前計算\nmean_age &lt;- round(mean(mtcars$mpg), 1)\nsd_age &lt;- round(sd(mtcars$mpg), 2)\nn_cars &lt;- nrow(mtcars)\n\n\nここで、上で事前にRチャンクで計算をしておく。今回は練習のためプログラムを表示しているが、Rプログラムを非表示にしてもよいだろう。記載としては以下のように書けばよい。\n\n\nコード\n本研究では `r n_cars` 台の自動車を分析しました。\n燃費の平均は `r mean_age`mpg（標準偏差 = `r sd_age`）でした。\n\n\n上記のように書くとこのように出力できる。\n本研究では 32 台の自動車を分析しました。\n燃費の平均は 20.1mpg（標準偏差 = 6.03）でした。\n\n\n\n\nMarkdownにおける改行はやや特殊だ。特殊といっても難しいことはない。普段よりもう一行改行するだけだ。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識する。結構難しい。\n文章1 文章2\n文章1\n文章2\n\n\n\nWebページを作成する際、ブラウザが理解できる言語がHTMLです。例えば、ブログ記事でリンクを作成したい場合、HTMLでは以下のように記述します：文章中に簡単にURLを参照できます。\n例：私のブログ\n[私のブログ](https://example-blog.com)\nまた、以下のように{}内に.externalを付けると、リンクのテキストの右側にアイコンを付く。\n[私のブログ](https://example-blog.com){.external target=\"_blank\"}\n例：私のブログ\n\n\n\n文章中でコードや関数名を表示する場合は、バッククオート1つで囲みます。単純にかっこいい。\n例：ggplot()関数やdplyr::filter()を使用してデータを処理します。平均値はmean()で計算できます。\n\n\n\n\n\n見出しは#の数で階層を表現します。学術文書では、適切な階層構造が重要です。 ちなみに#は6つまで使える。\n# 1. はじめに（H1）\n## 1.1 研究背景（H2）\n### 1.1.1 先行研究（H3）\n#### データの特徴（H4）\n##### 変数の詳細（H5）\n###### 補足事項（H6）\n\n\n\n\n\n\n\n重要な結果：**重要な結果**\n統計的有意：*統計的有意*\n仮説は棄却：~~仮説は棄却~~\nアンダーライン：アンダーラインはHTMLタグを使う。\n\n\n\n\n\n\n\n`-`を書いて、blankを入れるだけで順序なしリストができます。\n- データ収集\n  - アンケート調査\n  - 実験データ\n  - 公開データセット\n- データ前処理\n  - 欠損値処理\n  - 外れ値検出\n  - 変数変換\n- 分析手法\n  - 記述統計\n  - 回帰分析\n  - 機械学習\n結果：\n\nデータ収集\n\nアンケート調査\n実験データ\n公開データセット\n\nデータ前処理\n\n欠損値処理\n外れ値検出\n変数変換\n\n分析手法\n\n記述統計\n回帰分析\n機械学習\n\n\n\n\n\n普通に1.みたいにかけばよいだけ。単純。.の付け忘れに注意しよう！\n1. 研究目的の設定\n2. データ収集計画の策定\n   1. サンプルサイズの決定\n   2. 測定項目の選択\n   3. 倫理的配慮\n3. データ収集の実施\n4. 統計解析\n5. 結果の解釈\n6. 考察と結論\n\n\n\n\nQuartoで画像を入れるには![代替テキスト](ファイルのパス名 or URL)と入力します。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもあるが、視覚障害者用のウェブブラウザーのためにも使われる。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれる。\n例えば、Figsフォルダー内のex.pngというファイルを読み込むとしたら以下のように書く。\n![画像](Figs/ex.png)\n\n\n相対パス（推奨）が最も一般的で推奨される方法です。Quartoファイル（.qmd）からの相対位置で指定します。以下のように結果の図を記載するのが楽であろう。絶対パスでも可能であるが、あまりお勧めはできない。\n#相対パス\n![図1: データの分布](images/distribution.png)\n![図2: 回帰分析結果](figs/regression_plot.png)\n![図3: 比較グラフ](../shared_images/comparison.png)\n\n#絶対パス\n![画像](/Users/username/Documents/project/images/plot.png)\n![Windows例](C:\\Users\\username\\Documents\\project\\images\\plot.png)\n\n\n\n\n脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要だ。まず、文末脚注を入れる箇所に[^xxxx]を挿入する。xxxxは任意の文字列で構わない。しかし、同じQuarto文書内においてこの識別子は被らないようにすること。実際の脚注の内容は[^xxxx]: 内容のように入力する。これはどこに位置しても構わない。文書の途中でも、最後に入れても、脚注の内容は文末に位置する。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいだろう。\n統計的有意性[^1]は重要な概念ですが、効果量[^2]も同様に考慮すべきです。\n\n[^1]: p値が設定した有意水準（通常0.05）を下回ること。\n\n[^2]: 統計的有意性とは独立した、実際的な重要性を示す指標。\n統計的有意性1は重要な概念ですが、効果量2も同様に考慮すべきです。\n\n\n\nテーブルを自分で書くことはないと思う。生成AIに書いてもらおう。Rでもkableを使えば出てくる。\n\n\n| 変数名 | データ型 | 欠損値 | 説明 |\n|:-------|:---------|:------:|:-----|\n| age | numeric | 0 | 年齢（歳） |\n| gender | factor | 2 | 性別（M/F） |\n| income | numeric | 15 | 年収（万円） |\n| education | factor | 3 | 教育レベル |\n結果：\n\n\n\n変数名\nデータ型\n欠損値\n説明\n\n\n\n\nage\nnumeric\n0\n年齢（歳）\n\n\ngender\nfactor\n2\n性別（M/F）\n\n\nincome\nnumeric\n15\n年収（万円）\n\n\neducation\nfactor\n3\n教育レベル\n\n\n\nRでの例\n\n\nコード\nlibrary(knitr)\nkable(head(mtcars))\n\n\n\n\n表 1: mtcarsデータの基本統計量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&gt; 統計学における最も重要な概念の一つは、\n&gt; サンプルから母集団について推論を行うことである。\n&gt; この過程では、不確実性を適切に評価することが不可欠である。\n&gt; \n&gt; &gt; データは語るが、解釈は人間が行うものである。\n結果：\n\n統計学における最も重要な概念の一つは、 サンプルから母集団について推論を行うことである。 この過程では、不確実性を適切に評価することが不可欠である。\n\nデータは語るが、解釈は人間が行うものである。\n\n\n\n\n\n\nGFMは数式に対応していないが、$数式$でインライン数式を埋め込むことができる。Quartoの数式はMathJaxと呼ばれるJavaScriptのライブラリによってレンダリングされる。このMathJaxライブラリはHTMLにデフォルトで埋め込まれるわけではではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されないため、インターネット接続を忘れないこと。MathJaxの記法は とほぼ変わらない。Texでの数式の書き方は別途まとめる。\n\n\n回帰係数は $\\beta_1 = 0.73$ で統計的に有意でした（$p &lt; 0.001$）。 決定係数は $R^2 = 0.85$ でした。\n表示は以下の通り。\n回帰係数は \\beta_1 = 0.73 で統計的に有意でした（p &lt; 0.001）。 決定係数は R^2 = 0.85 でした。\n\n\n\n数式を独立した行として出力する場合は、の代わりに$を使用する。\n$$\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n$$\n\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n\n\n\n\nもし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用する。むろん、 Latexと記法は同じだ。\n\\begin{align}\nY_i &= \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_i \\\\\n\\epsilon_i &\\sim N(0, \\sigma^2) \\\\\n\\hat{\\beta}_1 &= \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\end{align}\n複数の行にわたる数式の書き方\n\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n\n\n\n\n\nRの場合、#でコメントを付けられるように、Quartoでもコメントを付けることができる。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法だろう。ただし、Rのように#は使えない。なぜなら#は見出しを意味する体。QuartoのコメントはHTMLと同様、で囲まれた領域がコメント扱いとなり、レンダリングに影響を与えない。\n例\n文章1\n\n&lt;!--\nここはコメントです。\n--&gt;\n\n文章2\n\n\n\nQuartoを使う意義 以上の内容まで抑えると、Quartoを使って、簡単な文法のみで構造化された文書が作成できるでしょう。しかし、これまでの内容はQuartoの良さではなく、Markdownの良さです。別にQuartoでなくても、TyporaやGhostwriterのようなMarkdownエディターを使えば良いでしょう。Quartoを使う真の意義は、文章とコード、結果が統合されることです。それではQuarto文書にRコードを入れる方法について解説します。 チャンク（Chunk） Quarto文書にRコードを入れる方法は2つあります：\n\nチャンクにRコードを入れる方法\nインラインコードを入れる方法\n\nチャンク内のRコードは独立した段落にコードと結果が両方出力されます。一方、インラインコードは文中に結果のみ出力されます。\n\n\nチャンクが始まるとの宣言は {r}、終わるとの宣言は です。つまり、{r} と ちょんちょんの間にRコードを入れるだけです。前の方にも書きました。\n“Hello World!”を出力するコード\n\n\nコード\nprint(\"Hello World!\")\n\n\n[1] \"Hello World!\"\n\n\n\n\n\nインラインコードの基本概念 他にもインラインコードを使って文中にRコードを埋め込むことも可能です。ただし、Rコードは出力されず、結果のみが出力されます。例えば、ベクトル X &lt;- c(2, 3, 5, 7, 12) があり、この平均値を文中で示したいとしましょう。むろん、文中に「5.8」と直接書いても問題ありません。しかし、Xの入力ミスが見つかり、実は c(2, 3, 5, 7, 11) になったらどうでしょうか。この「5.8」と書いた箇所を見つけて「5.6」と修正しなければいけません。これは非常に面倒な作業であり、ミスも起こりやすいです。絶対やめましょう。\n\nインラインコードの利点\n\n文中に mean(X) の結果を埋め込めるならこういったミスを未然に防ぐことができ、文書のメンテナンスも楽になるでしょう。インラインコードの記法文中でRコードを入れるためには r と ` の間にRコードを入力すれば良いです。\nこうかけばいいのです。\n\n\nコード\nmean(X)の実行結果：`r mean(X)`\n\n\n出力は以下\nmean(X)の実行結果：5.6\nコードスパンとインラインコードの違い mean(X) のように r でなく、単に `` だけで囲まれたコードは実行されません。文中に短いコードを入れたり、オブジェクト名を表記する際などに使う機能です。つまり、\n\n`コード` = コードを文字として見せるだけ\n`R コード` = コードを実行して結果を表示 （r コード）\n\n\n\n\n\nオプションの基本構文\nここではチャンクに指定可能なオプションについて紹介します。実際は本記事で紹介する内容の十数倍のオプションが用意されていますが、あまりにも膨大すぎるため、ここではよく使う機能のみを紹介します。 チャンクオプションはチャンク内の最上段に #| 仮引数: 実引数 のように表記します。 基本例：\n\n\nコード\n#| eval: false\n1+1\n\n\n[1] 2\n\n\neval は true か false の値が指定できます。evalは「コードを実行するかどうか」を決めるオプションです。\n\n\n\n\nチャンク名は #| label: チャンク名 で指定します。これはチャンクに名前を付けるオプションですが、多くの場合分析に影響を与えることはありません（それでもチャンク名は指定することを強く推奨します）。\nラベルの例は以下の通り。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\n\nこのチャンク名が重要となるのは cache オプションを付ける場合です。\ncache オプションは処理結果を保存しておくことを意味します。チャンク内のコードはrenderする度に計算されますが、演算にかなりの時間を必要とするコードが含まれている場合、renderの時間も長くなります。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n時間のかかる処理cache: true オプションを付けておくと、最初のrender時に結果を別途のファイルとして保存しておき、次回からはその結果を読み込むだけとなります。基本的にはこのオプションはおすすめしない。\n\n\n\n\n次は「コードだけ見せたい」、「結果だけ見せたい」場合に使うオプションを紹介します。これは技術書、授業用資料、スライドでよく使う機能です。\n\n\n\n\n\nオプション\n説明\nデフォルト値\n\n\n\n\necho\nコードの出力有無\ntrue\n\n\neval\nコードの実行有無\ntrue\n\n\ninclude\nコードと結果両方の表示有無\ntrue\n\n\n\n\n\n\nコードのみ出力（実行なし）：\n\n\nコード\nこのコードは表示されるが実行されない\n\n\n結果のみ出力（コード非表示）：\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nコードと結果を両方隠す：\nパッケージの読み込みコードやメタ変数の作成の際に include: false は有用なオプションです。\n\n\n\n\n既に見てきた通り、Quartoは作図の結果も出力してくれます。図のサイズや解像度を変えることもできます。\n\n\n\n\n\nオプション名\n説明\n値の例\n\n\n\n\nfig-height\n図の高さ（インチ）\n数値\n\n\nfig-width\n図の幅（インチ）\n数値\n\n\nfig-align\n図の位置\n“left”, “center”, “right”\n\n\nfig-cap\n図のキャプション\n文字列\n\n\ndpi\n図の解像度（印刷用なら300以上を推奨）\n数値\n\n\n\n\n\n\n\n\nコード\nlibrary(ggplot2)\nlibrary(dplyr)\n\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal()\n\n\n\n\n\nirisデータセットの可視化\n\n\n\n\n\n\n\n\n\n\n自分だけが見るコードなら別に推奨されない書き方でも問題ないかもしれませんが、Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事でしょう。\nここで便利なオプションが tidy オプションです。tidy: true を加えると、自動的にコードを読みやすい形に調整してくれます。\n\n\n\ntidy: false（デフォルト）の場合：\n\n\nコード\nfor(i in 1:10){\nprint(i*2)\n}\n\n\ntidy: TRUEの場合： Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事だろう。ここで便利なオプションがtidyオプションだ。tidy: trueを加えると、自動的にコードを読みやすい形に調整してくれる。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないダメなコードだが、tidy: trueを付けた場合と付けなかった場合の出力結果の違いを見てみよう。tidy: trueを付けただけで、読みやすいコードになった。ちなみにtidyオプションを使うためには事前に{formatR}パッケージをインストールしておく必要がある。ただし、{formatR}パッケージはQuarto文書内にて読み込んでおく必要はない。また、{formatR}パッケージは万能ではないため、普段から読みやすいコードを書くように心がけよう。\n\n\nコード\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n\nR Quartoでのデータ分析レポート作成において、Markdownの適切な使用は以下のメリットをもたらします：\n\n構造化された文書：見出しとセクションで論理的な流れを作成\n美しい数式表示：LaTeX記法による専門的な数式表現\n効果的な表現：テーブル、リスト、引用による情報整理\n再現可能性：コードと文章の統合による透明性の確保\n\nこれらの記法を活用して、読みやすく、理解しやすいデータ分析レポートを作成しましょう。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#参考文献",
    "href": "posts/statistics/2025/Markdown記法1.html#参考文献",
    "title": "Markdown記法について",
    "section": "",
    "text": "私たちのR　再現可能な研究24.Quarto［基礎］\n私たちのR　再現可能な研究25.Quarto［文書］\n私たちのR　再現可能な研究25.Quarto［スライド］\n私たちのR　Appendix F — R Markdown [基礎]\n私たちのR　Appendix G — R Markdown [応用]\n私たちのR　Appendix H — Quarto入門"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#markdownとは何か",
    "href": "posts/statistics/2025/Markdown記法1.html#markdownとは何か",
    "title": "Markdown記法について",
    "section": "",
    "text": "Markdownは、プレーンテキストで記述した文書を構造化された文書に変換するためのマークアップ言語です。R Quartoでは、このMarkdownとRコードを組み合わせて、データ分析レポートや学術論文を作成できます。\n\n\n\n可読性が高い：マークアップが最小限で、プレーンテキストでも内容が理解しやすい\n学習コストが低い：基本的な記法は数時間で習得可能\nQuartoとの親和性：Rコードチャンクとシームレスに統合\n多様な出力形式：HTML、PDF、Word、PowerPointなど"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#コードの記述方法",
    "href": "posts/statistics/2025/Markdown記法1.html#コードの記述方法",
    "title": "Markdown記法について",
    "section": "",
    "text": "コードを美しく表示するには、バッククオート3つ（```）でコードを囲みます。 これだけだとSAS/Rに限らず、プログラムは実行はされないが、サンプルとして提示する際に便利である。\n# Rコードの例\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# データの読み込みと前処理\ndata &lt;- mtcars %&gt;%\n  mutate(efficiency = ifelse(mpg &gt; 20, \"High\", \"Low\"))\n\n# 散布図の作成\nggplot(data, aes(x = wt, y = mpg, color = efficiency)) +\n  geom_point(size = 3) +\n  geom_smooth(method = \"lm\") +\n  labs(title = \"車重と燃費の関係\",\n       x = \"車重 (1000 lbs)\",\n       y = \"燃費 (mpg)\")\nQuartoでRプログラムも実行させたい場合は以下のように記載する。なお、SASは実行させない前提とする。 なお、SASの設定環境をQuartoに構築したらSASも実行可能である。\nプログラムも実行させるには、バッククオート3つ（```）でコードを囲み、{r}と書く。そうすると、Rプログラムの実行できる。\nオプションとしてRプログラムを非表示にしたり、表や図を表示する際は、2つの図表を横に並べたりとオプションは様々ある。それらは、こちらのブログを参考にしていただきたい。デフォルトではプログラムが表示されてしまうので、非表示にする場合は、\n\n\nコード\n1+1\n\n\n[1] 2\n\n\nQuartoでの頻用するであろうオプション記法：\n\n\n\n\n実行制御：このコードを実際に実行するかを指定\ntrue：コードを実行する（デフォルト）\nfalse：コードを実行せず、表示のみ\n\n\n\n\n\n出力形式：コードの実行結果をそのまま（as-is）出力\n通常はコードの出力結果が整形されますが、asisでは生の形式で出力\nHTMLタグやMarkdown記法をそのまま文書に挿入したい場合に使用\n\n\n\n\n\nコード表示制御：コードブロックを折りたたみ状態で表示する\ntrue：コードを折りたたんで、クリック可能なボタンで展開\nfalse：コードを通常通り表示（デフォルト）\n読者が必要に応じてコードの詳細を確認できる柔軟性を提供\n\n\n\n\n\n折りたたみボタンのラベル：折りたたまれたコードを展開するボタンのテキストを設定\nデフォルトでは「Show code」や「コードを表示」が表示される\nカスタムテキストで、そのコードブロックの内容を説明できる\n絵文字や詳細な説明文を使用して、読みやすさを向上させる\n\n以下のプログラムを回すと、その下の結果が得らえる。プログラムが表示されないので結果だけを提示する際には有用である。\n#| eval: true\n#| output: asis\n#| code-fold: true\n#| code-summary: \"Show Code\"\n\n1 + 1\n\nShow Code\n1 + 1\n\n[1] 2\n\n\n\n本文中にRの結果を直接入れることができます！これをインラインコードと呼びます。 “r 引数”で本文中に簡単にRの出力結果を入れることができる。これは論文作成の文章案を作成するときに便利であろう。\n以下のように書くことでできます。普通はRチャンクで計算したものを引用するのがよいだろう。\n年齢の平均は r mean(mtcars$mpg) です。\nサンプルサイズは r nrow(mtcars) でした。\n最大値は r max(mtcars$hp) 馬力です。\n年齢の平均は 20.090625 です。 サンプルサイズは 32 でした。 最大値は 335 馬力です。\n\n\n\n\n\nコード\n# データの事前計算\nmean_age &lt;- round(mean(mtcars$mpg), 1)\nsd_age &lt;- round(sd(mtcars$mpg), 2)\nn_cars &lt;- nrow(mtcars)\n\n\nここで、上で事前にRチャンクで計算をしておく。今回は練習のためプログラムを表示しているが、Rプログラムを非表示にしてもよいだろう。記載としては以下のように書けばよい。\n\n\nコード\n本研究では `r n_cars` 台の自動車を分析しました。\n燃費の平均は `r mean_age`mpg（標準偏差 = `r sd_age`）でした。\n\n\n上記のように書くとこのように出力できる。\n本研究では 32 台の自動車を分析しました。\n燃費の平均は 20.1mpg（標準偏差 = 6.03）でした。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#改行",
    "href": "posts/statistics/2025/Markdown記法1.html#改行",
    "title": "Markdown記法について",
    "section": "",
    "text": "Markdownにおける改行はやや特殊だ。特殊といっても難しいことはない。普段よりもう一行改行するだけだ。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識する。結構難しい。\n文章1 文章2\n文章1\n文章2"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#urlの挿入",
    "href": "posts/statistics/2025/Markdown記法1.html#urlの挿入",
    "title": "Markdown記法について",
    "section": "",
    "text": "Webページを作成する際、ブラウザが理解できる言語がHTMLです。例えば、ブログ記事でリンクを作成したい場合、HTMLでは以下のように記述します：文章中に簡単にURLを参照できます。\n例：私のブログ\n[私のブログ](https://example-blog.com)\nまた、以下のように{}内に.externalを付けると、リンクのテキストの右側にアイコンを付く。\n[私のブログ](https://example-blog.com){.external target=\"_blank\"}\n例：私のブログ"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#インラインコード",
    "href": "posts/statistics/2025/Markdown記法1.html#インラインコード",
    "title": "Markdown記法について",
    "section": "",
    "text": "文章中でコードや関数名を表示する場合は、バッククオート1つで囲みます。単純にかっこいい。\n例：ggplot()関数やdplyr::filter()を使用してデータを処理します。平均値はmean()で計算できます。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#見出しと文書構造",
    "href": "posts/statistics/2025/Markdown記法1.html#見出しと文書構造",
    "title": "Markdown記法について",
    "section": "",
    "text": "見出しは#の数で階層を表現します。学術文書では、適切な階層構造が重要です。 ちなみに#は6つまで使える。\n# 1. はじめに（H1）\n## 1.1 研究背景（H2）\n### 1.1.1 先行研究（H3）\n#### データの特徴（H4）\n##### 変数の詳細（H5）\n###### 補足事項（H6）"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#テキストの装飾とフォーマット",
    "href": "posts/statistics/2025/Markdown記法1.html#テキストの装飾とフォーマット",
    "title": "Markdown記法について",
    "section": "",
    "text": "重要な結果：**重要な結果**\n統計的有意：*統計的有意*\n仮説は棄却：~~仮説は棄却~~\nアンダーライン：アンダーラインはHTMLタグを使う。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#リストとチェックボックス",
    "href": "posts/statistics/2025/Markdown記法1.html#リストとチェックボックス",
    "title": "Markdown記法について",
    "section": "",
    "text": "`-`を書いて、blankを入れるだけで順序なしリストができます。\n- データ収集\n  - アンケート調査\n  - 実験データ\n  - 公開データセット\n- データ前処理\n  - 欠損値処理\n  - 外れ値検出\n  - 変数変換\n- 分析手法\n  - 記述統計\n  - 回帰分析\n  - 機械学習\n結果：\n\nデータ収集\n\nアンケート調査\n実験データ\n公開データセット\n\nデータ前処理\n\n欠損値処理\n外れ値検出\n変数変換\n\n分析手法\n\n記述統計\n回帰分析\n機械学習\n\n\n\n\n\n普通に1.みたいにかけばよいだけ。単純。.の付け忘れに注意しよう！\n1. 研究目的の設定\n2. データ収集計画の策定\n   1. サンプルサイズの決定\n   2. 測定項目の選択\n   3. 倫理的配慮\n3. データ収集の実施\n4. 統計解析\n5. 結果の解釈\n6. 考察と結論"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#画像の挿入",
    "href": "posts/statistics/2025/Markdown記法1.html#画像の挿入",
    "title": "Markdown記法について",
    "section": "",
    "text": "Quartoで画像を入れるには![代替テキスト](ファイルのパス名 or URL)と入力します。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもあるが、視覚障害者用のウェブブラウザーのためにも使われる。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれる。\n例えば、Figsフォルダー内のex.pngというファイルを読み込むとしたら以下のように書く。\n![画像](Figs/ex.png)\n\n\n相対パス（推奨）が最も一般的で推奨される方法です。Quartoファイル（.qmd）からの相対位置で指定します。以下のように結果の図を記載するのが楽であろう。絶対パスでも可能であるが、あまりお勧めはできない。\n#相対パス\n![図1: データの分布](images/distribution.png)\n![図2: 回帰分析結果](figs/regression_plot.png)\n![図3: 比較グラフ](../shared_images/comparison.png)\n\n#絶対パス\n![画像](/Users/username/Documents/project/images/plot.png)\n![Windows例](C:\\Users\\username\\Documents\\project\\images\\plot.png)"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#脚注",
    "href": "posts/statistics/2025/Markdown記法1.html#脚注",
    "title": "Markdown記法について",
    "section": "",
    "text": "脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要だ。まず、文末脚注を入れる箇所に[^xxxx]を挿入する。xxxxは任意の文字列で構わない。しかし、同じQuarto文書内においてこの識別子は被らないようにすること。実際の脚注の内容は[^xxxx]: 内容のように入力する。これはどこに位置しても構わない。文書の途中でも、最後に入れても、脚注の内容は文末に位置する。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいだろう。\n統計的有意性[^1]は重要な概念ですが、効果量[^2]も同様に考慮すべきです。\n\n[^1]: p値が設定した有意水準（通常0.05）を下回ること。\n\n[^2]: 統計的有意性とは独立した、実際的な重要性を示す指標。\n統計的有意性1は重要な概念ですが、効果量2も同様に考慮すべきです。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#テーブルの活用",
    "href": "posts/statistics/2025/Markdown記法1.html#テーブルの活用",
    "title": "Markdown記法について",
    "section": "",
    "text": "テーブルを自分で書くことはないと思う。生成AIに書いてもらおう。Rでもkableを使えば出てくる。\n\n\n| 変数名 | データ型 | 欠損値 | 説明 |\n|:-------|:---------|:------:|:-----|\n| age | numeric | 0 | 年齢（歳） |\n| gender | factor | 2 | 性別（M/F） |\n| income | numeric | 15 | 年収（万円） |\n| education | factor | 3 | 教育レベル |\n結果：\n\n\n\n変数名\nデータ型\n欠損値\n説明\n\n\n\n\nage\nnumeric\n0\n年齢（歳）\n\n\ngender\nfactor\n2\n性別（M/F）\n\n\nincome\nnumeric\n15\n年収（万円）\n\n\neducation\nfactor\n3\n教育レベル\n\n\n\nRでの例\n\n\nコード\nlibrary(knitr)\nkable(head(mtcars))\n\n\n\n\n表 1: mtcarsデータの基本統計量\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmpg\ncyl\ndisp\nhp\ndrat\nwt\nqsec\nvs\nam\ngear\ncarb\n\n\n\n\nMazda RX4\n21.0\n6\n160\n110\n3.90\n2.620\n16.46\n0\n1\n4\n4\n\n\nMazda RX4 Wag\n21.0\n6\n160\n110\n3.90\n2.875\n17.02\n0\n1\n4\n4\n\n\nDatsun 710\n22.8\n4\n108\n93\n3.85\n2.320\n18.61\n1\n1\n4\n1\n\n\nHornet 4 Drive\n21.4\n6\n258\n110\n3.08\n3.215\n19.44\n1\n0\n3\n1\n\n\nHornet Sportabout\n18.7\n8\n360\n175\n3.15\n3.440\n17.02\n0\n0\n3\n2\n\n\nValiant\n18.1\n6\n225\n105\n2.76\n3.460\n20.22\n1\n0\n3\n1"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#引用とノート",
    "href": "posts/statistics/2025/Markdown記法1.html#引用とノート",
    "title": "Markdown記法について",
    "section": "",
    "text": "&gt; 統計学における最も重要な概念の一つは、\n&gt; サンプルから母集団について推論を行うことである。\n&gt; この過程では、不確実性を適切に評価することが不可欠である。\n&gt; \n&gt; &gt; データは語るが、解釈は人間が行うものである。\n結果：\n\n統計学における最も重要な概念の一つは、 サンプルから母集団について推論を行うことである。 この過程では、不確実性を適切に評価することが不可欠である。\n\nデータは語るが、解釈は人間が行うものである。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#数式の表示",
    "href": "posts/statistics/2025/Markdown記法1.html#数式の表示",
    "title": "Markdown記法について",
    "section": "",
    "text": "GFMは数式に対応していないが、$数式$でインライン数式を埋め込むことができる。Quartoの数式はMathJaxと呼ばれるJavaScriptのライブラリによってレンダリングされる。このMathJaxライブラリはHTMLにデフォルトで埋め込まれるわけではではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されないため、インターネット接続を忘れないこと。MathJaxの記法は とほぼ変わらない。Texでの数式の書き方は別途まとめる。\n\n\n回帰係数は $\\beta_1 = 0.73$ で統計的に有意でした（$p &lt; 0.001$）。 決定係数は $R^2 = 0.85$ でした。\n表示は以下の通り。\n回帰係数は \\beta_1 = 0.73 で統計的に有意でした（p &lt; 0.001）。 決定係数は R^2 = 0.85 でした。\n\n\n\n数式を独立した行として出力する場合は、の代わりに$を使用する。\n$$\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n$$\n\ny_i \\sim \\mbox{Normal}(X \\beta, \\sigma).\n\n\n\n\nもし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用する。むろん、 Latexと記法は同じだ。\n\\begin{align}\nY_i &= \\beta_0 + \\beta_1 X_{1i} + \\beta_2 X_{2i} + \\epsilon_i \\\\\n\\epsilon_i &\\sim N(0, \\sigma^2) \\\\\n\\hat{\\beta}_1 &= \\frac{\\sum_{i=1}^{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^{n}(X_i - \\bar{X})^2}\n\\end{align}\n複数の行にわたる数式の書き方\n\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#quart内でのコメントアウト",
    "href": "posts/statistics/2025/Markdown記法1.html#quart内でのコメントアウト",
    "title": "Markdown記法について",
    "section": "",
    "text": "Rの場合、#でコメントを付けられるように、Quartoでもコメントを付けることができる。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法だろう。ただし、Rのように#は使えない。なぜなら#は見出しを意味する体。QuartoのコメントはHTMLと同様、で囲まれた領域がコメント扱いとなり、レンダリングに影響を与えない。\n例\n文章1\n\n&lt;!--\nここはコメントです。\n--&gt;\n\n文章2"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#quartoにおけるrコードの挿入と活用法",
    "href": "posts/statistics/2025/Markdown記法1.html#quartoにおけるrコードの挿入と活用法",
    "title": "Markdown記法について",
    "section": "",
    "text": "Quartoを使う意義 以上の内容まで抑えると、Quartoを使って、簡単な文法のみで構造化された文書が作成できるでしょう。しかし、これまでの内容はQuartoの良さではなく、Markdownの良さです。別にQuartoでなくても、TyporaやGhostwriterのようなMarkdownエディターを使えば良いでしょう。Quartoを使う真の意義は、文章とコード、結果が統合されることです。それではQuarto文書にRコードを入れる方法について解説します。 チャンク（Chunk） Quarto文書にRコードを入れる方法は2つあります：\n\nチャンクにRコードを入れる方法\nインラインコードを入れる方法\n\nチャンク内のRコードは独立した段落にコードと結果が両方出力されます。一方、インラインコードは文中に結果のみ出力されます。\n\n\nチャンクが始まるとの宣言は {r}、終わるとの宣言は です。つまり、{r} と ちょんちょんの間にRコードを入れるだけです。前の方にも書きました。\n“Hello World!”を出力するコード\n\n\nコード\nprint(\"Hello World!\")\n\n\n[1] \"Hello World!\"\n\n\n\n\n\nインラインコードの基本概念 他にもインラインコードを使って文中にRコードを埋め込むことも可能です。ただし、Rコードは出力されず、結果のみが出力されます。例えば、ベクトル X &lt;- c(2, 3, 5, 7, 12) があり、この平均値を文中で示したいとしましょう。むろん、文中に「5.8」と直接書いても問題ありません。しかし、Xの入力ミスが見つかり、実は c(2, 3, 5, 7, 11) になったらどうでしょうか。この「5.8」と書いた箇所を見つけて「5.6」と修正しなければいけません。これは非常に面倒な作業であり、ミスも起こりやすいです。絶対やめましょう。\n\nインラインコードの利点\n\n文中に mean(X) の結果を埋め込めるならこういったミスを未然に防ぐことができ、文書のメンテナンスも楽になるでしょう。インラインコードの記法文中でRコードを入れるためには r と ` の間にRコードを入力すれば良いです。\nこうかけばいいのです。\n\n\nコード\nmean(X)の実行結果：`r mean(X)`\n\n\n出力は以下\nmean(X)の実行結果：5.6\nコードスパンとインラインコードの違い mean(X) のように r でなく、単に `` だけで囲まれたコードは実行されません。文中に短いコードを入れたり、オブジェクト名を表記する際などに使う機能です。つまり、\n\n`コード` = コードを文字として見せるだけ\n`R コード` = コードを実行して結果を表示 （r コード）"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#チャンクオプション2",
    "href": "posts/statistics/2025/Markdown記法1.html#チャンクオプション2",
    "title": "Markdown記法について",
    "section": "",
    "text": "オプションの基本構文\nここではチャンクに指定可能なオプションについて紹介します。実際は本記事で紹介する内容の十数倍のオプションが用意されていますが、あまりにも膨大すぎるため、ここではよく使う機能のみを紹介します。 チャンクオプションはチャンク内の最上段に #| 仮引数: 実引数 のように表記します。 基本例：\n\n\nコード\n#| eval: false\n1+1\n\n\n[1] 2\n\n\neval は true か false の値が指定できます。evalは「コードを実行するかどうか」を決めるオプションです。\n\n\n\n\nチャンク名は #| label: チャンク名 で指定します。これはチャンクに名前を付けるオプションですが、多くの場合分析に影響を与えることはありません（それでもチャンク名は指定することを強く推奨します）。\nラベルの例は以下の通り。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n\n\n\nこのチャンク名が重要となるのは cache オプションを付ける場合です。\ncache オプションは処理結果を保存しておくことを意味します。チャンク内のコードはrenderする度に計算されますが、演算にかなりの時間を必要とするコードが含まれている場合、renderの時間も長くなります。\n\n\nコード\n1+1\n\n\n[1] 2\n\n\n時間のかかる処理cache: true オプションを付けておくと、最初のrender時に結果を別途のファイルとして保存しておき、次回からはその結果を読み込むだけとなります。基本的にはこのオプションはおすすめしない。\n\n\n\n\n次は「コードだけ見せたい」、「結果だけ見せたい」場合に使うオプションを紹介します。これは技術書、授業用資料、スライドでよく使う機能です。\n\n\n\n\n\nオプション\n説明\nデフォルト値\n\n\n\n\necho\nコードの出力有無\ntrue\n\n\neval\nコードの実行有無\ntrue\n\n\ninclude\nコードと結果両方の表示有無\ntrue\n\n\n\n\n\n\nコードのみ出力（実行なし）：\n\n\nコード\nこのコードは表示されるが実行されない\n\n\n結果のみ出力（コード非表示）：\n\n\n  Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   \n Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  \n 1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  \n Median :5.800   Median :3.000   Median :4.350   Median :1.300  \n Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  \n 3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  \n Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  \n       Species  \n setosa    :50  \n versicolor:50  \n virginica :50  \n                \n                \n                \n\n\nコードと結果を両方隠す：\nパッケージの読み込みコードやメタ変数の作成の際に include: false は有用なオプションです。\n\n\n\n\n既に見てきた通り、Quartoは作図の結果も出力してくれます。図のサイズや解像度を変えることもできます。\n\n\n\n\n\nオプション名\n説明\n値の例\n\n\n\n\nfig-height\n図の高さ（インチ）\n数値\n\n\nfig-width\n図の幅（インチ）\n数値\n\n\nfig-align\n図の位置\n“left”, “center”, “right”\n\n\nfig-cap\n図のキャプション\n文字列\n\n\ndpi\n図の解像度（印刷用なら300以上を推奨）\n数値\n\n\n\n\n\n\n\n\nコード\nlibrary(ggplot2)\nlibrary(dplyr)\n\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal()\n\n\n\n\n\nirisデータセットの可視化\n\n\n\n\n\n\n\n\n\n\n自分だけが見るコードなら別に推奨されない書き方でも問題ないかもしれませんが、Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事でしょう。\nここで便利なオプションが tidy オプションです。tidy: true を加えると、自動的にコードを読みやすい形に調整してくれます。\n\n\n\ntidy: false（デフォルト）の場合：\n\n\nコード\nfor(i in 1:10){\nprint(i*2)\n}\n\n\ntidy: TRUEの場合： Quarto文書は他人と共有するケースが多いため、読みやすいコードを書くのも大事だろう。ここで便利なオプションがtidyオプションだ。tidy: trueを加えると、自動的にコードを読みやすい形に調整してくれる。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないダメなコードだが、tidy: trueを付けた場合と付けなかった場合の出力結果の違いを見てみよう。tidy: trueを付けただけで、読みやすいコードになった。ちなみにtidyオプションを使うためには事前に{formatR}パッケージをインストールしておく必要がある。ただし、{formatR}パッケージはQuarto文書内にて読み込んでおく必要はない。また、{formatR}パッケージは万能ではないため、普段から読みやすいコードを書くように心がけよう。\n\n\nコード\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n\nR Quartoでのデータ分析レポート作成において、Markdownの適切な使用は以下のメリットをもたらします：\n\n構造化された文書：見出しとセクションで論理的な流れを作成\n美しい数式表示：LaTeX記法による専門的な数式表現\n効果的な表現：テーブル、リスト、引用による情報整理\n再現可能性：コードと文章の統合による透明性の確保\n\nこれらの記法を活用して、読みやすく、理解しやすいデータ分析レポートを作成しましょう。"
  },
  {
    "objectID": "posts/statistics/2025/Markdown記法1.html#footnotes",
    "href": "posts/statistics/2025/Markdown記法1.html#footnotes",
    "title": "Markdown記法について",
    "section": "脚注",
    "text": "脚注\n\n\np値が設定した有意水準（通常0.05）を下回ること。↩︎\n統計的有意性とは独立した、実際的な重要性を示す指標。↩︎"
  },
  {
    "objectID": "posts/statistics/2025/github.html",
    "href": "posts/statistics/2025/github.html",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "GitHubでブログを更新する際の標準的な手順は以下の通りです。\n\n\nquarto render\ngit add .\ngit commit -m \"新記事追加/編集\"\ngit push origin main\n\n\n\nなお、quartoが多くなってきた場合、特定のファイルのみでrenderすることも可能である。\nquarto render\nquarto render post.qmd\n\n\n\ngit add .\n\n\n\ngit commit -m \"コミットメッセージ\"\n\n\n\ngit push origin main"
  },
  {
    "objectID": "posts/statistics/2025/github.html#一括実行",
    "href": "posts/statistics/2025/github.html#一括実行",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "quarto render\ngit add .\ngit commit -m \"新記事追加/編集\"\ngit push origin main"
  },
  {
    "objectID": "posts/statistics/2025/github.html#quartoサイトをレンダリング",
    "href": "posts/statistics/2025/github.html#quartoサイトをレンダリング",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "なお、quartoが多くなってきた場合、特定のファイルのみでrenderすることも可能である。\nquarto render\nquarto render post.qmd"
  },
  {
    "objectID": "posts/statistics/2025/github.html#変更内容をステージングエリアに追加",
    "href": "posts/statistics/2025/github.html#変更内容をステージングエリアに追加",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git add ."
  },
  {
    "objectID": "posts/statistics/2025/github.html#変更をコミット",
    "href": "posts/statistics/2025/github.html#変更をコミット",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git commit -m \"コミットメッセージ\""
  },
  {
    "objectID": "posts/statistics/2025/github.html#リモートリポジトリにプッシュ",
    "href": "posts/statistics/2025/github.html#リモートリポジトリにプッシュ",
    "title": "1 githubのブログ更新手順について",
    "section": "",
    "text": "git push origin main"
  },
  {
    "objectID": "posts/statistics/2025/DDEによるExcelデータの読み込み.html",
    "href": "posts/statistics/2025/DDEによるExcelデータの読み込み.html",
    "title": "DDEによるExcelデータの読み込み",
    "section": "",
    "text": "SASを使ってExcelファイルからデータを読み込む方法はいくつかありますが、今回は**DDE（Dynamic Data Exchange）**という少しレガシーながらも強力な手法をご紹介します。DDEを使えば、ExcelアプリケーションをSASから制御し、必要な範囲のデータを柔軟に読み込むことができます。これは、特に「Excelファイルを開いて特定のシートの特定のセル範囲だけを読みたい」といった場合に非常に便利です。\n\n\nDDEは、Microsoft Windowsアプリケーション間でデータを共有・交換するためのプロトコルです。SASからDDEを利用することで、Excelアプリケーションを直接操作し、ファイルを開く、特定のセル範囲を選択する、データを読み込む、ファイルを閉じる、といった一連の動作を自動化できます。\n\n\n\nDDEでExcelファイルを操作する前に、読み込みたいExcelファイルのパスとファイル名をマクロ変数で定義しておくと便利です。これは、プログラムの可読性を高め、パスの変更があった際に対応を容易にするためです。\nSAS\n%put &SettingsPath.;\n%put &&SettingsFile.;\nここでは、すでに定義されている&SettingsPath.（Excelファイルが格納されているディレクトリ）と&SettingsFile.（Excelファイル名）というマクロ変数の内容をログに出力しています。これはデバッグ時に、意図したパスとファイル名が設定されているかを確認するのに役立ちます。\n\n\n\nExcelファイルをDDEで操作するには、まずそのExcelアプリケーションを起動しておく必要があります。\n/*---------------------------*/\n/* 設定ファイルの読込         */\n/*---------------------------*/\n*--- Excel起動 ---*;\n%sysexec  \"&SettingsPath.\\&SettingsFile.\";\n\ndata _null_;\n  rc = sleep(5);\nrun;\n\n%sysexec \"&SettingsPath.\\&SettingsFile.\";: %SYSEXECマクロステートメントは、SASセッションから外部のコマンドを実行するために使用します。ここでは、指定されたパスにあるExcelファイルを直接実行しています。これにより、Excelアプリケーションが起動し、指定されたファイルが開かれます。\ndata _null_; rc = sleep(5); run;: Excelが完全に起動してファイルを開くには少し時間がかかる場合があります。SLEEP関数は、指定された秒数（この例では5秒）だけプログラムの実行を一時停止させます。これにより、SASがExcelにDDE接続する前に、Excelが準備を完了するのを待つことができます。\n\n\n\n\nExcelが起動したら、FILENAME DDEステートメントを使ってDDE接続を確立し、データを読み込みます。\n*--- Excelデータの読込 ---*;\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";\n\ndata work._SettingList;\n    length Title $100. Path $1000. FileName $500. SheetName $50.;\n    infile EXC notab dlm=\"09\"x dsd missover lrecl=1000 firstobs=2;\n    input Title Path FileName SheetName;\n\n    if Title ne \"\";\nrun;\n\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";: これがDDE接続の核心です。\n\nfilename EXC: EXCという**fileref（ファイル参照名）**を定義します。\ndde: DDEプロトコルを使用することをSASに伝えます。\n\"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\": DDEの**会話文字列（conversation string）**です。\n\nExcel: サービス名（アプリケーション名）です。\n|: サービス名とトピック名を区切ります。\n[&SettingsFile.]: トピック名（アプリケーションが提供するデータセット）です。ここでは開いているExcelファイル名を指定します。[]で囲むのがExcel DDEの慣習です。\n&SettingsSheet.!C1:C4: アイテム名（特定のデータ項目）です。&SettingsSheet.で指定されたシートのC1からC4までのセル範囲をDDE経由で読み込むことを指示しています。\n\n\ndata work._SettingList; ... run;: 通常のDATAステップとINFILEステートメントを使って、DDEで接続したExcelのデータ範囲からデータを読み込みます。\n\ninfile EXC: 上で定義したDDE接続のfileref EXCを指定します。\nnotab: タブ文字をデータの一部として扱わないようにします。\ndlm=\"09\"x: **デリミタ（区切り文字）**としてタブ文字（09xはタブの16進数表現）を指定します。Excelのセルデータは通常タブで区切られて転送されます。\ndsd: Delimited Standard Data。連続するデリミタを欠損値として扱い、引用符で囲まれた値の中のデリミタをデータの一部として扱います。\nmissover: 行の終わりに変数のデータが不足している場合、残りの変数を欠損値にします。\nlrecl=1000: 論理レコード長を1000バイトに設定します。行が長い場合に必要です。\nfirstobs=2: 読み込みを開始する行を指定します。この例ではExcelの1行目がヘッダーであるため、2行目から読み込みを開始しています。\ninput Title Path FileName SheetName;: 読み込む変数を定義します。lengthステートメントで適切な長さを設定しておくことが重要です。\nif Title ne \"\";: Titleが空でない行のみを読み込むことで、データの終端や不要な行をスキップできます。\n\n\n\n\n\nデータ読み込みが終わったら、開いたExcelファイルを閉じ、DDE接続を解放します。\n*--- Excelクローズ ---*;\nfilename SYS dde 'Excel|system';\n\ndata _null_;\nfile SYS;\nput \"[quit()]\";\nrun;\n\ndata _null_;\n    rc = sleep(3);\nrun;\n\n*--- ファイル参照を解放 ---*;\nfilename EXC clear;\nfilename SYS clear;\n\nfilename SYS dde 'Excel|system';: Excelアプリケーション全体を制御するためのDDE接続を確立します。サービス名がExcel、トピック名がsystemです。このsystemトピックを通じて、Excelにコマンドを送信できます。\ndata _null_; file SYS; put \"[quit()]\"; run;: FILE SYSでこのDDE接続に出力することで、Excelアプリケーションに対して[quit()]というコマンドを送信しています。これはExcelに終了を指示するDDEコマンドです。\ndata _null_; rc = sleep(3); run;: Excelが終了するのを待つために、再びSLEEP関数を使用します。これにより、Excelが完全に閉じられる前に次の処理が実行されるのを防ぎます。\nfilename EXC clear; filename SYS clear;: 最後に、定義したすべてのfilerefをクリアし、DDE接続を完全に解放します。これにより、リソースのリークを防ぎ、次の処理に影響を与えないようにします。\n\n\n\n\n\nGUI環境でのみ動作: DDEは、SASが稼働しているマシンにExcelがインストールされており、かつGUIモード（インタラクティブなSASセッション）で実行されている場合にのみ機能します。バッチモードやSAS Gridなどのサーバー環境では直接使用できません。\nファイルが開かれた状態: DDEで操作するExcelファイルは、SASプログラムが実行される時点で開かれていない必要があります。もし開いている場合、排他ロックによりエラーになる可能性があります。\nエラーハンドリング: DDE接続やExcel操作中にエラーが発生した場合のハンドリングが複雑になることがあります。SYSEXECやDDEの構文エラーはSASログに表示されますが、Excel内部のエラーを詳細に捕捉するのは難しい場合があります。\n代替手段: 現在では、より堅牢でクロスプラットフォームなデータ読み込み方法として、PROC IMPORT（特にDBMS=XLSXオプション）、SAS/ACCESS to PC Files、またはSAS ViyaのCASエンジン経由でのデータ読み込みが推奨されます。DDEは特定のユースケース（例：Excelのマクロ実行後データの取得）を除いて、第一選択肢とはならないかもしれません。\n\n\n\n\nDDEを使ったExcelデータの読み込みは、SASからExcelを直接制御できる強力な方法です。特に、動的に特定の範囲のデータを取得したい場合や、Excelの特定の機能を利用する必要がある場合にその真価を発揮します。ただし、その特性と注意点を理解した上で、適切に活用することが重要です。\n\n\n\n%put &SettingsPath.;\n%put &&SettingsFile.;\n\n/*---------------------------*/\n/* 設定ファイルの読込       */\n/*---------------------------*/\n*--- Excel起動 ---*;\n%sysexec  \"&SettingsPath.\\&SettingsFile.\";\n\ndata _null_;\n  rc = sleep(5);\nrun;\n\n*--- Excelデータの読込 ---*;\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";\n\ndata work._SettingList;\n    length Title $100. Path $1000. FileName $500. SheetName $50.;\n    infile EXC notab dlm=\"09\"x dsd missover lrecl=1000 firstobs=2;\n    input Title Path FileName SheetName;\n\n    if Title ne \"\";\nrun;\n\n*--- Excelクローズ ---*;\nfilename SYS dde 'Excel|system';\n\ndata _null_;\nfile SYS;\nput \"[quit()]\";\nrun;\n\ndata _null_;\n    rc = sleep(3);\nrun;\n\n*--- ファイル参照を解放 ---*;\nfilename EXC clear;\nfilename SYS clear;"
  },
  {
    "objectID": "posts/statistics/2025/DDEによるExcelデータの読み込み.html#sasでexcelデータを自在に操るddeを活用したデータ読み込み術",
    "href": "posts/statistics/2025/DDEによるExcelデータの読み込み.html#sasでexcelデータを自在に操るddeを活用したデータ読み込み術",
    "title": "DDEによるExcelデータの読み込み",
    "section": "",
    "text": "SASを使ってExcelファイルからデータを読み込む方法はいくつかありますが、今回は**DDE（Dynamic Data Exchange）**という少しレガシーながらも強力な手法をご紹介します。DDEを使えば、ExcelアプリケーションをSASから制御し、必要な範囲のデータを柔軟に読み込むことができます。これは、特に「Excelファイルを開いて特定のシートの特定のセル範囲だけを読みたい」といった場合に非常に便利です。\n\n\nDDEは、Microsoft Windowsアプリケーション間でデータを共有・交換するためのプロトコルです。SASからDDEを利用することで、Excelアプリケーションを直接操作し、ファイルを開く、特定のセル範囲を選択する、データを読み込む、ファイルを閉じる、といった一連の動作を自動化できます。\n\n\n\nDDEでExcelファイルを操作する前に、読み込みたいExcelファイルのパスとファイル名をマクロ変数で定義しておくと便利です。これは、プログラムの可読性を高め、パスの変更があった際に対応を容易にするためです。\nSAS\n%put &SettingsPath.;\n%put &&SettingsFile.;\nここでは、すでに定義されている&SettingsPath.（Excelファイルが格納されているディレクトリ）と&SettingsFile.（Excelファイル名）というマクロ変数の内容をログに出力しています。これはデバッグ時に、意図したパスとファイル名が設定されているかを確認するのに役立ちます。\n\n\n\nExcelファイルをDDEで操作するには、まずそのExcelアプリケーションを起動しておく必要があります。\n/*---------------------------*/\n/* 設定ファイルの読込         */\n/*---------------------------*/\n*--- Excel起動 ---*;\n%sysexec  \"&SettingsPath.\\&SettingsFile.\";\n\ndata _null_;\n  rc = sleep(5);\nrun;\n\n%sysexec \"&SettingsPath.\\&SettingsFile.\";: %SYSEXECマクロステートメントは、SASセッションから外部のコマンドを実行するために使用します。ここでは、指定されたパスにあるExcelファイルを直接実行しています。これにより、Excelアプリケーションが起動し、指定されたファイルが開かれます。\ndata _null_; rc = sleep(5); run;: Excelが完全に起動してファイルを開くには少し時間がかかる場合があります。SLEEP関数は、指定された秒数（この例では5秒）だけプログラムの実行を一時停止させます。これにより、SASがExcelにDDE接続する前に、Excelが準備を完了するのを待つことができます。\n\n\n\n\nExcelが起動したら、FILENAME DDEステートメントを使ってDDE接続を確立し、データを読み込みます。\n*--- Excelデータの読込 ---*;\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";\n\ndata work._SettingList;\n    length Title $100. Path $1000. FileName $500. SheetName $50.;\n    infile EXC notab dlm=\"09\"x dsd missover lrecl=1000 firstobs=2;\n    input Title Path FileName SheetName;\n\n    if Title ne \"\";\nrun;\n\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";: これがDDE接続の核心です。\n\nfilename EXC: EXCという**fileref（ファイル参照名）**を定義します。\ndde: DDEプロトコルを使用することをSASに伝えます。\n\"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\": DDEの**会話文字列（conversation string）**です。\n\nExcel: サービス名（アプリケーション名）です。\n|: サービス名とトピック名を区切ります。\n[&SettingsFile.]: トピック名（アプリケーションが提供するデータセット）です。ここでは開いているExcelファイル名を指定します。[]で囲むのがExcel DDEの慣習です。\n&SettingsSheet.!C1:C4: アイテム名（特定のデータ項目）です。&SettingsSheet.で指定されたシートのC1からC4までのセル範囲をDDE経由で読み込むことを指示しています。\n\n\ndata work._SettingList; ... run;: 通常のDATAステップとINFILEステートメントを使って、DDEで接続したExcelのデータ範囲からデータを読み込みます。\n\ninfile EXC: 上で定義したDDE接続のfileref EXCを指定します。\nnotab: タブ文字をデータの一部として扱わないようにします。\ndlm=\"09\"x: **デリミタ（区切り文字）**としてタブ文字（09xはタブの16進数表現）を指定します。Excelのセルデータは通常タブで区切られて転送されます。\ndsd: Delimited Standard Data。連続するデリミタを欠損値として扱い、引用符で囲まれた値の中のデリミタをデータの一部として扱います。\nmissover: 行の終わりに変数のデータが不足している場合、残りの変数を欠損値にします。\nlrecl=1000: 論理レコード長を1000バイトに設定します。行が長い場合に必要です。\nfirstobs=2: 読み込みを開始する行を指定します。この例ではExcelの1行目がヘッダーであるため、2行目から読み込みを開始しています。\ninput Title Path FileName SheetName;: 読み込む変数を定義します。lengthステートメントで適切な長さを設定しておくことが重要です。\nif Title ne \"\";: Titleが空でない行のみを読み込むことで、データの終端や不要な行をスキップできます。\n\n\n\n\n\nデータ読み込みが終わったら、開いたExcelファイルを閉じ、DDE接続を解放します。\n*--- Excelクローズ ---*;\nfilename SYS dde 'Excel|system';\n\ndata _null_;\nfile SYS;\nput \"[quit()]\";\nrun;\n\ndata _null_;\n    rc = sleep(3);\nrun;\n\n*--- ファイル参照を解放 ---*;\nfilename EXC clear;\nfilename SYS clear;\n\nfilename SYS dde 'Excel|system';: Excelアプリケーション全体を制御するためのDDE接続を確立します。サービス名がExcel、トピック名がsystemです。このsystemトピックを通じて、Excelにコマンドを送信できます。\ndata _null_; file SYS; put \"[quit()]\"; run;: FILE SYSでこのDDE接続に出力することで、Excelアプリケーションに対して[quit()]というコマンドを送信しています。これはExcelに終了を指示するDDEコマンドです。\ndata _null_; rc = sleep(3); run;: Excelが終了するのを待つために、再びSLEEP関数を使用します。これにより、Excelが完全に閉じられる前に次の処理が実行されるのを防ぎます。\nfilename EXC clear; filename SYS clear;: 最後に、定義したすべてのfilerefをクリアし、DDE接続を完全に解放します。これにより、リソースのリークを防ぎ、次の処理に影響を与えないようにします。\n\n\n\n\n\nGUI環境でのみ動作: DDEは、SASが稼働しているマシンにExcelがインストールされており、かつGUIモード（インタラクティブなSASセッション）で実行されている場合にのみ機能します。バッチモードやSAS Gridなどのサーバー環境では直接使用できません。\nファイルが開かれた状態: DDEで操作するExcelファイルは、SASプログラムが実行される時点で開かれていない必要があります。もし開いている場合、排他ロックによりエラーになる可能性があります。\nエラーハンドリング: DDE接続やExcel操作中にエラーが発生した場合のハンドリングが複雑になることがあります。SYSEXECやDDEの構文エラーはSASログに表示されますが、Excel内部のエラーを詳細に捕捉するのは難しい場合があります。\n代替手段: 現在では、より堅牢でクロスプラットフォームなデータ読み込み方法として、PROC IMPORT（特にDBMS=XLSXオプション）、SAS/ACCESS to PC Files、またはSAS ViyaのCASエンジン経由でのデータ読み込みが推奨されます。DDEは特定のユースケース（例：Excelのマクロ実行後データの取得）を除いて、第一選択肢とはならないかもしれません。\n\n\n\n\nDDEを使ったExcelデータの読み込みは、SASからExcelを直接制御できる強力な方法です。特に、動的に特定の範囲のデータを取得したい場合や、Excelの特定の機能を利用する必要がある場合にその真価を発揮します。ただし、その特性と注意点を理解した上で、適切に活用することが重要です。\n\n\n\n%put &SettingsPath.;\n%put &&SettingsFile.;\n\n/*---------------------------*/\n/* 設定ファイルの読込       */\n/*---------------------------*/\n*--- Excel起動 ---*;\n%sysexec  \"&SettingsPath.\\&SettingsFile.\";\n\ndata _null_;\n  rc = sleep(5);\nrun;\n\n*--- Excelデータの読込 ---*;\nfilename EXC dde \"Excel|[&SettingsFile.]&SettingsSheet.!C1:C4\";\n\ndata work._SettingList;\n    length Title $100. Path $1000. FileName $500. SheetName $50.;\n    infile EXC notab dlm=\"09\"x dsd missover lrecl=1000 firstobs=2;\n    input Title Path FileName SheetName;\n\n    if Title ne \"\";\nrun;\n\n*--- Excelクローズ ---*;\nfilename SYS dde 'Excel|system';\n\ndata _null_;\nfile SYS;\nput \"[quit()]\";\nrun;\n\ndata _null_;\n    rc = sleep(3);\nrun;\n\n*--- ファイル参照を解放 ---*;\nfilename EXC clear;\nfilename SYS clear;"
  },
  {
    "objectID": "posts/statistics/2025/ADaM作成においてDataステップにおける便利な関数.html",
    "href": "posts/statistics/2025/ADaM作成においてDataステップにおける便利な関数.html",
    "title": "ADaM作成においてDataステップにおける便利な関数",
    "section": "",
    "text": "0.1 SASプログラマ必見！ADaM作成を効率化するデータステップ重要機能6選\nこんにちは！臨床試験のSASプログラマの皆さん、日々の業務でADaMデータセットの作成に多くの時間を費やしていませんか？\nADaMの仕様は複雑で、元となるSDTMデータから多くの新しい変数を導出したり、レコードを跨いだ計算を行ったりする必要があります。こうした処理を愚直にコーディングすると、プログラムが長くなり、ミスも起こりがちです。\nしかし、SASデータステップには、こうした複雑なデータ加工を驚くほどスマートに解決するための強力な機能が備わっています。\nこの記事では、あなたのADaM作成業務を劇的に効率化する、6つの重要な関数とステートメントを厳選し、具体的な活用例とともに徹底解説します。\n\n\n0.2 【第1部】データステップの基本機能とADaM作成への応用\nまずは、データ加工の基本となる6つの機能の役割と、ADaM作成における具体的な使い方を見ていきましょう。\n\n0.2.1 1 & 2. LENGTH関数とSUBSTR関数 - 文字列操作の基本\n\nLENGTH関数: 文字列の長さを返します。\nSUBSTR関数: 文字列の一部を抜き出（抽出）します。\n\n\n0.2.1.1 実行可能なサンプルコード\nPROC TRANSPOSEで生成されるようなデータ（変数名_NAME_を持つ）から、パラメータ(PARAM)と訪問番号(VISITNUM)を分割する例です。\n/* 1. サンプルデータ作成 */\ndata transposed_data;\n  input _NAME_ $ AVAL;\n  cards;\nTC_1 212\nHDL_1 50\nTC_2 224\nHDL_2 64\n;\nrun;\n\n/* 2. LENGTHとSUBSTRを使った処理 */\ndata parsed_data;\n  set transposed_data;\n\n  /* LENGTH関数で全体の長さを取得 */\n  NAME_LEN = length(_NAME_); \n\n  /* SUBSTR関数で文字列を分割 */\n  PARAM    = substr(_NAME_, 1, NAME_LEN - 2); \n  VISITNUM = input(substr(_NAME_, NAME_LEN, 1), 8.); \n\n  drop NAME_LEN;\nrun;\n\n/* 3. 結果表示 */\ntitle \"LENGTHとSUBSTRによる変数名分割の結果\";\nproc print data=parsed_data;\nrun;\ntitle;\n\n\n\n\n0.3 3. RETAINステートメント - 値を次の行へ引き継ぐ魔法\n\n0.3.0.1 「RETAIN」とは？\nRETAINステートメントで指定された変数は、データステップのループを越えて値を保持します。 通常、変数はループの開始時に欠損値にリセットされますが、\nRETAINを使うと前の行の値を引き継ぐことができます。\n\n\n0.3.0.2 実行可能なサンプルコード\n1から5までの累積和（1, 1+2, 1+2+3, …）を計算する例です。\n/* 1. サンプルデータ作成 (入力データは不要) */\n\n/* 2. RETAINを使った処理 */\ndata sample_sum;\n  retain SUM 0; /* SUM変数の値を保持し、初期値を0に設定 */ \n\n  do i = 1 to 5;\n    SUM = SUM + i; /* 前のループのSUMに現在のiを足す */ \n    output;\n  end;\nrun;\n\n/* 3. 結果表示 */\ntitle \"RETAINによる累積和の計算結果\";\nproc print data=sample_sum;\nrun;\ntitle;\n\n\n\n0.4 4 & 5. first.by / last.by変数 - グループ処理の案内人\n\n0.4.0.1 「first.by」「last.by」とは？\nBYステートメントと一緒に使う特殊な一時変数です。 BYグループ内で、\n\nfirst.by変数: グループの最初の行である場合に 1 になります。\nlast.by変数: グループの最後の行である場合に 1 になります。\n\n\n\n0.4.0.2 実行可能なサンプルコード\nBDSデータセットで、被験者ごと、パラメータごとにレコード番号（ASEQ）を振る例です。\n/* 1. サンプルデータ作成 */\ndata ADVS;\n  input USUBJID $ PARAMCD $ AVAL;\n  cards;\nP01 HR 70\nP01 HR 72\nP01 DIABP 80\nP02 HR 65\nP02 HR 68\nP02 DIABP 75\n;\nrun;\n\n/* 2. first.byを使った処理 */\nproc sort data=ADVS;\n  by USUBJID PARAMCD;\nrun;\n\ndata ADVS_ASEQ;\n  set ADVS;\n  by USUBJID PARAMCD;\n\n  if first.PARAMCD then ASEQ = 0; /* パラメータが切り替わったらASEQを0にリセット */\n  ASEQ = ASEQ + 1;\nrun;\n\n/* 3. 結果表示 */\ntitle \"first.byによるグループ内連番(ASEQ)の作成結果\";\nproc print data=ADVS_ASEQ;\nrun;\ntitle;\n\n\n\n0.5 6. VNAME関数 - 変数名を文字列として取得\n\n0.5.0.1 「VNAME」とは？\nVNAME関数は、引数に指定した変数の名前を文字列として返します。\n\n\n0.5.0.2 実行可能なサンプルコード\nARRAYステートメントと組み合わせて、横持ちデータから縦持ちデータを作成する際に、PARAMCDを動的に生成する例です。\n/* 1. サンプルデータ作成 (横持ち) */\ndata source_data;\n  input USUBJID $ TC_1 HDL_1 TC_2 HDL_2;\n  cards;\nP01 212 50 224 64\n;\nrun;\n\n/* 2. VNAMEを使った処理 */\ndata vertical_data;\n  set source_data;\n  array aval_group[*] TC_1 HDL_1 TC_2 HDL_2; /* アスタリスク(*)で変数を指定 */\n\n  do i = 1 to dim(aval_group);\n    AVAL = aval_group{i};\n\n    /* VNAMEで変数名(例: \"TC_1\")を取得 */\n    VAR_NAME = VNAME(aval_group{i});\n\n    /* 変数名からPARAMCDとVISITNUMを動的に生成 */\n    PARAMCD  = scan(VAR_NAME, 1, '_');\n    VISITNUM = input(scan(VAR_NAME, 2, '_'), 8.);\n    \n    output;\n  end;\n  keep USUBJID PARAMCD VISITNUM AVAL;\nrun;\n\n/* 3. 結果表示 */\ntitle \"VNAMEによる動的な縦持ち変換の結果\";\nproc print data=vertical_data;\nrun;\ntitle;\n\n\n\n0.6 【第2部】さらにステップアップ！各機能の応用テクニック\n基本を理解したところで、次はいよいよ実践です。これらの機能を組み合わせることで、どのような強力な処理が実現できるか見ていきましょう。\n\n0.6.1 応用例1：RETAINとfirst.byによるグループ情報の引き継ぎ（Fill Down）\nシナリオ: ADSLにしかない被験者レベルの情報（例: 治験薬群 ARM）を、ADVSのような測定データセットの全レコードにコピーします。これにより、ADVSデータセット単体で、治験薬群による層別解析が可能になります。\n解説: MERGEでデータを結合しただけでは、ARMの値は各被験者の最初のレコードにしか入りません。そこでRETAINを使い、first.USUBJID（被験者の最初の行）のタイミングでARMの値を一度キャッチし、その値をlast.USUBJID（被験者の最後の行）まで保持し続けることで、グループ内の全レコードに値を「引き継ぐ」ことができます。\n/* ADSLとADVSをマージし、RETAINでARM情報を引き継ぐ */\ndata ADVS_with_ARM;\n  merge ADSL(keep=USUBJID ARM) ADVS(in=in_vs);\n  by USUBJID;\n\n  retain RETAINED_ARM;\n  if first.USUBJID then RETAINED_ARM = ARM;\n  ARM = RETAINED_ARM;\n  \n  if in_vs;\n  drop RETAINED_ARM;\nrun;\n\n\n0.6.2 応用例2：RETAINとfirst.byによるAUCの計算\nシナリオ: 薬物動態データ（ADPC）において、台形公式を用いて血中濃度時間曲線下面積（AUC）を算出します。これは重要な薬物動態パラメータの一つです。\n解説: 台形公式 (値1 + 値2) * (時間2 - 時間1) / 2 を計算するには、現在行の値/時間に加え、前の行の値/時間が必要です。RETAINを使って前の行の時間（PREV_ATPT）と値（PREV_AVAL）を保持します。first.byでパラメータが切り替わるタイミングを検知し、累積AUCや保持している変数を初期化することで、パラメータごとに正しく計算を実行できます。\n/* ADPCデータでAUCを計算 */\ndata ADPC_AUC;\n  set ADPC;\n  by USUBJID PARAMCD;\n\n  retain PREV_ATPT PREV_AVAL AUC_CUM;\n\n  if first.PARAMCD then do;\n    AUC_CUM = 0;\n    call missing(PREV_ATPT, PREV_AVAL);\n  end;\n\n  if not missing(PREV_AVAL) then do;\n    AUC_INTERVAL = (AVAL + PREV_AVAL) * (ATPT - PREV_ATPT) / 2;\n    AUC_CUM + AUC_INTERVAL;\n  end;\n\n  PREV_ATPT = ATPT;\n  PREV_AVAL = AVAL;\nrun;\n\n\n0.6.3 応用例3：last.byとRETAINによるグループ集計\nシナリオ: PROC MEANSやPROC SQLとMERGEを組み合わせる複数ステップの処理を、1回のDATAステップで実現し、各被験者のバイタルサイン（AVAL）の最大値を求めます。\n解説: このテクニックのキモはlast.byです。RETAINとmax関数を使い、各レコードを読み進めるごと に、その時点での最大値を計算し保持し続けます。そして、if last.USUBJID then output;とすることで、計算は全レコードで行いつつ、最終的な集計結果は各被験者の最後のレコードを処理したタイミングで一度だけ出力します。これにより、プログラムのステップを削減し、処理を効率化できます。\n/* 各被験者のバイタルサインの最大値を求める */\ndata VS_MAX;\n  set ADVS_SORTED; /* 事前にUSUBJIDでソート済み */\n  by USUBJID;\n  retain MAX_AVAL;\n\n  if first.USUBJID then MAX_AVAL = .;\n  \n  MAX_AVAL = max(MAX_AVAL, AVAL);\n  \n  if last.USUBJID then output;\nrun;\n\n\n0.6.4 応用例4：VNAMEによる汎用的なデータ品質チェック（QC）\nシナリオ: 複数の変数（AVAL, BASE, CHG）に負の値が含まれていないかチェックし、問題があれば具体的な変数名と情報をログに出力します。\n解説: データ品質チェック（QC）では、同じロジックを多くの変数に適用することが多々あります。ARRAYでチェック対象の変数をグループ化し、VNAMEでエラーが発生した変数名を動的に取得することで、保守性の高いプログラムを作成できます。もし将来、チェック対象の変数が追加されても、ARRAYステートメントに変数名を加えるだけで対応でき、ログ出力部分のコードを修正する必要がありません。\n/* 汎用的なQCプログラム */\ndata _NULL_; /* データセットを作成しない場合は _NULL_ を使う */\n  set ADVS;\n  array checks[*] AVAL BASE CHG;\n\n  do i = 1 to dim(checks);\n    if checks[i] &lt; 0 then do;\n      VAR_NAME = VNAME(checks[i]);\n      put \"ERROR: Negative value found in \" VAR_NAME= \"at OBS=\" _N_ \"for USUBJID=\" USUBJID;\n    end;\n  end;\nrun;\n\n\n\n0.7 まとめ：機能を組み合わせて、データ加工の達人へ\n今回ご紹介した6つの機能は、それぞれが強力ですが、真価は組み合わせることで発揮されます。BYステートメント、RETAIN、first.byを組み合わせれば、複雑なグループ処理が1つのデータステップで完結します。ARRAY、VNAME、SUBSTRを組み合わせれば、保守性の高い動的なプログラムが実現できます。\nこれらの武器を使いこなし、日々のADaM作成業務をより速く、より正確に進めていきましょう！\n\n\n0.8 Appendix: 応用テクニックのサンプルプログラム集\n記事の第2部で紹介した応用テクニックを、実際に動作させて試せる完全なサンプルプログラムです。\n\n0.8.1 応用例1：RETAINによるグループ情報の引き継ぎ（Fill Down）\n/* 1. サンプルデータ作成 */\ndata ADSL;\n  input USUBJID $ ARM $;\n  cards;\nP01 Drug A\nP02 Drug B\n;\nrun;\ndata ADVS;\n  input USUBJID $ VISIT $ AVAL;\n  cards;\nP01 VISIT 1 120\nP01 VISIT 2 125\nP02 VISIT 1 110\nP02 VISIT 2 112\n;\nrun;\n/* 2. メイン処理 */\nproc sort data=ADVS; by USUBJID; run;\nproc sort data=ADSL; by USUBJID; run;\ndata ADVS_with_ARM;\n  merge ADSL(keep=USUBJID ARM) ADVS(in=in_vs);\n  by USUBJID;\n  retain RETAINED_ARM;\n  if first.USUBJID then RETAINED_ARM = ARM;\n  ARM = RETAINED_ARM;\n  if in_vs;\n  drop RETAINED_ARM;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例1: ARM情報を全レコードに引き継いだ結果\";\nproc print data=ADVS_with_ARM;\nrun;\ntitle;\n\n\n0.8.2 応用例2：RETAINとfirst.byによるAUCの計算\n/* 1. サンプルデータ作成 */\ndata ADPC;\n  input USUBJID $ PARAMCD $ ATPT AVAL;\n  cards;\nPK-01 AUC 0 0\nPK-01 AUC 1 50\nPK-01 AUC 2 40\nPK-01 AUC 4 20\nPK-01 AUC 8 5\n;\nrun;\n/* 2. メイン処理 */\ndata ADPC_AUC;\n  set ADPC;\n  by USUBJID PARAMCD;\n  retain PREV_ATPT PREV_AVAL AUC_CUM;\n  if first.PARAMCD then do;\n    AUC_CUM = 0;\n    call missing(PREV_ATPT, PREV_AVAL);\n  end;\n  if not missing(PREV_AVAL) then do;\n    AUC_INTERVAL = (AVAL + PREV_AVAL) * (ATPT - PREV_ATPT) / 2;\n    AUC_CUM + AUC_INTERVAL;\n  end;\n  PREV_ATPT = ATPT;\n  PREV_AVAL = AVAL;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例2: AUCを計算した結果\";\nproc print data=ADPC_AUC;\nrun;\ntitle;\n\n\n0.8.3 応用例3：last.byとRETAINによるグループ集計\n/* 1. サンプルデータ作成 */\ndata ADVS_SORTED;\n  input USUBJID $ AVAL;\n  cards;\nP01 120\nP01 135\nP01 128\nP02 110\nP02 105\n;\nrun;\n/* 2. メイン処理 */\ndata VS_MAX;\n  set ADVS_SORTED;\n  by USUBJID;\n  retain MAX_AVAL;\n  if first.USUBJID then MAX_AVAL = .;\n  MAX_AVAL = max(MAX_AVAL, AVAL);\n  if last.USUBJID then output;\n  drop AVAL;\nrun;\n/* 3. 結果表示 */\ntitle \"応用例3: 各被験者の最大値を求めた結果\";\nproc print data=VS_MAX;\nrun;\ntitle;\n\n\n0.8.4 応用例4：VNAMEによる汎用的なデータ品質チェック（QC）\n/* 1. サンプルデータ作成 (意図的に負の値を含む) */\ndata ADVS_QC;\n  input USUBJID $ AVAL BASE CHG;\n  cards;\nP01 120 120 0\nP01 110 120 -10\nP02 100 105 -5\n;\nrun;\n/* 2. メイン処理 (結果はデータセットではなくログに出力) */\ntitle \"応用例4: QCチェックの結果 (SASログを確認してください)\";\ndata _NULL_;\n  set ADVS_QC;\n  array checks[*] AVAL BASE CHG;\n  do i = 1 to dim(checks);\n    if checks[i] &lt; 0 then do;\n      VAR_NAME = VNAME(checks[i]);\n      put \"ERROR: Negative value found in \" VAR_NAME= \"at OBS=\" _N_ \"for USUBJID=\" USUBJID;\n    end;\n  end;\nrun;\ntitle;"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kota Sakamoto",
    "section": "",
    "text": "本サイトは個人の学習記録であり、内容の正確性は保証いたしません。所属組織とは無関係の個人的見解です。\n当サイトのご利用により生じたいかなる損害・トラブルについて当サイトでは一切の責任を負いかねます事をご了承ください。\n所属先\n\n岡山大学病院 新医療研究開発センター データサイエンス部\n\n連絡先\n本ブログ等について、誤り/疑問点がありましたら以下までご連絡ください。\n\nkota.sakamoto0514@gmail.com"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "坂本航太（さかもと こうた）です。私は岡山大学病院 新医療研究開発センター データサイエンス部 統計解析室にて、生物統計家を目指して勤務しています。\n私の関心・興味は以下の通りです。"
  },
  {
    "objectID": "about.html#学歴",
    "href": "about.html#学歴",
    "title": "About",
    "section": "1 学歴",
    "text": "1 学歴\n\n2015.3 私立中央大学杉並高校卒業\n2015.4 中央大学理工学部人間総合理工学科入学\n2017.8 香港城市大学 交換留学開始\n2018.5 香港城市大学 交換留学終了\n2019.3 中央大学理工学部人間総合理工学科卒業\n2019.4 東京大学学際情報学府学際情報学専攻 生物統計情報学コース 入学\n2021.3 東京大学学際情報学府学際情報学専攻 生物統計情報学コース 修了\n2024.4 岡山大学大学院医歯薬学研究科医歯薬学専攻入学\n2028.3 岡山大学大学院医歯薬学研究科医歯薬学専攻修了予定"
  },
  {
    "objectID": "about.html#学位",
    "href": "about.html#学位",
    "title": "About",
    "section": "2 学位",
    "text": "2 学位\n\n博士（医学）（2028.3 岡山大学（取得予定））\n修士（学際情報学）（2021.3 東京大学）\n学士（理工学）（2019.3 中央大学）"
  },
  {
    "objectID": "about.html#職歴",
    "href": "about.html#職歴",
    "title": "About",
    "section": "3 職歴",
    "text": "3 職歴\n\n2021.4 - 現在 岡山大学病院新医療研究開発センター データサイエンス部 統計解析室 助教"
  },
  {
    "objectID": "about.html#資格",
    "href": "about.html#資格",
    "title": "About",
    "section": "4 資格",
    "text": "4 資格\n\n日本統計学会 統計検定1級（統計数理、統計応用（医薬生物学）） 2024.11"
  },
  {
    "objectID": "about.html#所属学会",
    "href": "about.html#所属学会",
    "title": "About",
    "section": "5 所属学会",
    "text": "5 所属学会\n\n日本計量生物学会"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html",
    "href": "posts/statistics/2025/ADaM1.html",
    "title": "ADaM IG1.3",
    "section": "",
    "text": "本記事では、自己学習用にADaM IGの文書を和訳する。基本的には以下の文献を読んでいただきたい。\n\n\n\nADaMIG v1.3"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#文献",
    "href": "posts/statistics/2025/ADaM1.html#文献",
    "title": "ADaM IG1.3",
    "section": "",
    "text": "ADaMIG v1.3"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#basic-data-structure-definitions",
    "href": "posts/statistics/2025/ADaM1.html#basic-data-structure-definitions",
    "title": "ADaM IG1.3",
    "section": "2.1 1.5.2 Basic Data Structure Definitions",
    "text": "2.1 1.5.2 Basic Data Structure Definitions\n\nAnalysis parameter – 共通の定義を持つ値のグループを一意に特徴づけるために使用される行識別子。ADaM解析パラメータには、関連する解析値のグループを一意に識別するために必要なすべての情報が含まれていることに注意してください。対照的に、SDTM –TEST列は、関連する値のグループを識別するために–STRESU、–POS、–LOC、–SPECなどの修飾子列と組み合わせる必要がある場合があります。本文書では、「パラメータ」という語は「解析パラメータ」の同義語として使用されています。例：主要有効性解析パラメータは「座位収縮期血圧（mmHg）」です。\nAnalysis timepoint – 解析パラメータ内の値を解析に使用される時間的または概念的グループに分類するために使用される行識別子。これらのグループ化は、観測された、計画された、または導出されたものである可能性があります。例：主要有効性解析は、第2週、第6週、およびエンドポイント解析タイムポイントで実施されました。\nAnalysis value – （1）解析パラメータによって記述される数値（AVAL）または文字（AVALC）値。解析値は、入力データに存在する、入力データ値のカテゴリ化、または導出されたものである可能性があります。例：パラメータ「体格指数」の解析値は、収集された身長と体重からADaMデータセットで導出されました。（2）さらに、特定の関数の値は解析値とみなされます。例：ベースライン値（BASE）、ベースラインからの変化量（CHG）。 Parameter-variant – AVAL（またはAVALC）の関数として導出される列で、データセットで変数が設定される一部のパラメータに対して異なって計算される場合、パラメータ可変となります。したがって、列がパラメータ可変であるのは、その導出方法が行にあるパラメータに依存する場合です。例えば、AVALCATyはAVAL（またはAVALC）をカテゴリ化します。カテゴリはパラメータによって異なる可能性があり、これによりAVALCATyがパラメータ可変となります。\nParameter-invariant – AVAL（またはAVALC）の関数として導出される列で、データセットで変数が設定されるすべてのパラメータに対して同じ方法で計算される場合、パラメータ不変となります。したがって、列がパラメータ不変であるのは、その導出方法が行にあるパラメータに依存しない場合です。パラメータ不変の導出は、適用されないパラメータに対してはnullのままにされる可能性がありますが、すべてのパラメータにわたって同じままです。例えば、ベースラインからの変化量変数の導出はCHG = AVAL-BASEであり、これはすべてのパラメータで同じ式です。したがって、CHGはパラメータ不変変数です。パラメータ不変性の概念は、BDSの整合性にとって不可欠であり、第4.2節「導出列の作成対導出行の作成」で定義されたルールの不可欠な構成要素であり、モデルが代わりに新しい行が必要であることを示している場合にプロデューサーによる「水平化」（新しい列の作成）を禁止するものです。"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#analysis-datasets-and-adam-datasets",
    "href": "posts/statistics/2025/ADaM1.html#analysis-datasets-and-adam-datasets",
    "title": "ADaM IG1.3",
    "section": "2.2 Analysis Datasets and ADaM Datasets",
    "text": "2.2 Analysis Datasets and ADaM Datasets\n現在、ADaMには3つの構造があります： - ADSL（SUBJECT LEVEL ANALYSIS DATASET） - BDS　（BASIC DATA STRUCTURE） - OCCDS（OCCURRENCE DATA STRUCTURE）\nADaMの基本原則およびその他のADaM規則に従うが、定義された3つの構造（ADSL、BDS、OCCDS）のいずれにも従わない解析データセットは、ADAM OTHERクラスのADaMデータセットと見なされます。解析データセットメタデータのクラス要素の統制用語は、http://www.cdisc.org/terminology でダウンロードできます。\n解析データセットのカテゴリを示す図では、最上位レベルで「Analysis Datasets」があり、その下に「ADaM Datasets」と「Non-ADaM Analysis Datasets」に分かれています。 - ADaM Datasets ADaM Datasetsは以下の4つのカテゴリに分類されます：\n\nADSL: ADSL（被験者レベル解析データセット）\nBDS: ADLB、ADEFF、ADTTE*（基本データ構造の例）\nOCCDS: ADAE、ADCM（発生データ構造の例）\nOTHER: ADMV*（その他のADaMデータセットの例）\n\n\nNon-ADaM Analysis Datasets Non-ADaM Analysis Datasetsには：PATP、AXEVT（ADaMの基本原則に従わずに開発されたデータセットの例）"
  },
  {
    "objectID": "posts/statistics/2025/ADaM1.html#fundamental-principles",
    "href": "posts/statistics/2025/ADaM1.html#fundamental-principles",
    "title": "ADaM IG1.3",
    "section": "2.3 Fundamental Principles",
    "text": "2.3 Fundamental Principles\nADaMデータセットは、ADaMモデル文書に記載されている特定の基本原則に従う必要があります：\n\nADaMデータセットおよび関連するメタデータは、臨床試験で実施される統計解析を支援するデータセットの内容とソースを明確かつ曖昧さなく伝達しなければなりません。\nADaMデータセットおよび関連するメタデータは、値または変数のソースまたは導出を示すトレーサビリティを提供しなければなりません（すなわち、データの系譜または値とその前身との関係）。メタデータは、解析データがいつ、どのように導出または補完されたかを特定しなければなりません。\nADaMデータセットは、一般的に利用可能なソフトウェアツールで容易に使用できなければなりません。\nADaMデータセットは、明確で曖昧さのないコミュニケーションを促進するためのメタデータと関連付けられなければなりません。理想的には、メタデータは機械可読であることが望ましいです。\nADaMデータセットは、最小限のプログラミングで統計解析を実行できる構造と内容を持つべきです。このようなデータセットは「Analysi Ready」と表現されます。ADaMデータセットには、特定の統計解析のレビューと再作成に必要なデータが含まれています。データリスティングやその他の非解析的な表示をサポートするためだけに、データを解析準備完了データセットに照合する必要はありません。"
  },
  {
    "objectID": "posts/statistics/2025/ADSL_trial.html",
    "href": "posts/statistics/2025/ADSL_trial.html",
    "title": "臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック",
    "section": "",
    "text": "臨床試験において、被験者の基本情報をまとめた人口統計データ（ADSL: Analysis Data Subject Level）の作成は、全ての解析の基盤となる重要な作業です。今回は、実際の現場で使われているSASプログラミングテクニックを詳しく解説します。"
  },
  {
    "objectID": "posts/statistics/2025/ADSL_trial.html#adslデータ作成の2つのプログラム例",
    "href": "posts/statistics/2025/ADSL_trial.html#adslデータ作成の2つのプログラム例",
    "title": "臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック",
    "section": "1 ADSLデータ作成の2つのプログラム例",
    "text": "1 ADSLデータ作成の2つのプログラム例\n\n1.1 1. 人口統計データ（Demographics）の作成\ndata work.DT01 ;\n  length STUDYID $10 USUBJID $17 SUBJID ORSUBJID $6 AGE 8 AGEU $5 SEX $1 SEXN 8 RFICDTC $100 ;\n  set work.en ;\n  STUDYID = \"STUDY-XXX\" ;\n  if length(scan(_subjid, 2, '-')) = 1 then SUBJID = cats(scan(_subjid, 1, '-'), \"-0\", scan(_subjid, 2, '-')) ;\n  else SUBJID = _subjid ;\n  ORSUBJID = _subjid ;\n  USUBJID = catx(\"-\", STUDYID, SUBJID) ;\n  AGE = _age ;\n  AGEU = \"YEARS\" ;\n  if _sex = 1 then SEX = \"M\" ;\n  else if _sex = 2 then SEX = \"F\" ;\n  SEXN = _sex ;\n  RFICDTC = put(_icdat, yymmdd10.) ;\n  keep STUDYID -- RFICDTC ;\n\n\n1.2 2. プロトコルイベント（Protocol Events）データの作成\ndata work.PE01 ;\n  length SUBJID ORSUBJID $6 RFSTDTC RFXSTDTC $100 TRTSDT 8 ;\n  set work.pe ;\n  if length(scan(_subjid, 2, '-')) = 1 then SUBJID = cats(scan(_subjid, 1, '-'), \"-0\", scan(_subjid, 2, '-')) ;\n  else SUBJID = _subjid ;\n  ORSUBJID = _subjid ;\n  RFSTDTC = strip(put(_tretdat, yymmdd10.)) ;\n  RFXSTDTC = strip(put(_tretdat, yymmdd10.)) ;\n  if length(RFXSTDTC) = 10 then TRTSDT = input(RFXSTDTC, yymmdd10.) ;\n  keep SUBJID -- TRTSDT ;"
  },
  {
    "objectID": "posts/statistics/2025/ADSL_trial.html#注目すべきテクニック解説",
    "href": "posts/statistics/2025/ADSL_trial.html#注目すべきテクニック解説",
    "title": "臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック",
    "section": "2 注目すべきテクニック解説",
    "text": "2 注目すべきテクニック解説\n\n2.1 1. 被験者ID標準化の統一処理\nif length(scan(_subjid, 2, '-')) = 1 then \n    SUBJID = cats(scan(_subjid, 1, '-'), \"-0\", scan(_subjid, 2, '-')) ;\nelse SUBJID = _subjid ;\nポイント：\n\nscan関数でハイフン区切りのIDを分割\n2番目の部分が1桁の場合、ゼロパディングを実施\n「01-1」→「01-01」のような統一化\n両プログラムで完全に同じロジックを使用\n\n効果：\n\nデータの一貫性確保\n後の解析でのID照合エラー防止\n見た目の統一性向上\n\n\n\n2.2 2. 階層的ID管理システム\nORSUBJID = _subjid ;           // 元のID\nSUBJID = [標準化されたID] ;    // 標準化後のID  \nUSUBJID = catx(\"-\", STUDYID, SUBJID) ; // 試験全体でユニークなID\n設計思想：\n\nORSUBJID: 元データのトレーサビリティ確保\nSUBJID: 試験内での標準化されたID\nUSUBJID: 複数試験統合時のユニークID\n\n\n\n2.3 3. 数値・文字コードの両方保持\nif _sex = 1 then SEX = \"M\" ;\nelse if _sex = 2 then SEX = \"F\" ;\nSEXN = _sex ;\n利点：\n\nSEX: レポート表示用（M/F）\nSEXN: 統計解析用（1/2）\n用途に応じた使い分けが可能\n\n\n\n2.4 4. 日付データの多角的準備\n\n2.4.1 Demographics側：\nRFICDTC = put(_icdat, yymmdd10.) ;\nインフォームドコンセント日をISO 8601形式に変換\n\n\n2.4.2 Protocol Events側：\nRFSTDTC = strip(put(_tretdat, yymmdd10.)) ;\nRFXSTDTC = strip(put(_tretdat, yymmdd10.)) ;\nif length(RFXSTDTC) = 10 then TRTSDT = input(RFXSTDTC, yymmdd10.) ;\n巧妙な処理：\n\n同じ治療日を開始日・終了日両方に設定\nstrip関数で余分な空白を除去\n完全な日付（10桁）のみ数値変換する安全な処理\n\n\n\n\n2.5 5. CDISC準拠の変数命名\n\nSTUDYID: 試験識別子\nUSUBJID: ユニーク被験者ID\nSUBJID: 被験者ID\nRFSTDTC: 参照開始日（文字形式）\nRFXSTDTC: 参照終了日（文字形式）\nTRTSDT: 治療開始日（数値形式）"
  },
  {
    "objectID": "posts/statistics/2025/ADSL_trial.html#実用的な設計の利点",
    "href": "posts/statistics/2025/ADSL_trial.html#実用的な設計の利点",
    "title": "臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック",
    "section": "3 実用的な設計の利点",
    "text": "3 実用的な設計の利点\n\n3.1 1. 一貫性の確保\n両プログラムで同じID標準化ロジックを使用し、システム全体の整合性を保つ\n\n\n3.2 2. 用途別最適化\n\nレポート用（文字形式）\n計算用（数値形式）\n表示用（見やすい形式）\n\n\n\n3.3 3. データ品質の向上\n\n元データの保持によるトレーサビリティ\n条件分岐による安全な変換処理\n不完全データの適切な処理\n\n\n\n3.4 4. 保守性の向上\n\n統一されたコーディング規則\n変数名の体系化\n処理ロジックの標準化"
  },
  {
    "objectID": "posts/statistics/2025/ADSL_trial.html#まとめ",
    "href": "posts/statistics/2025/ADSL_trial.html#まとめ",
    "title": "臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック",
    "section": "4 まとめ",
    "text": "4 まとめ\nADSLデータの作成では、単なるデータ変換ではなく、後の解析作業全体を見据えた設計が重要です。今回紹介したテクニックにより：\n\nデータの一貫性が確保される\n国際標準に準拠したデータ構造が構築される\n効率的な解析が可能になる\nデータ品質が向上する\n\nこれらの実践的なアプローチにより、信頼性の高い臨床試験データベースの基盤を構築することができます。\n注：実際のプログラム使用の際は、各施設のSOPや規制要件に従って適切に実装してください。"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "疫学研究において、2つの二値曝露（A₁, A₂）がアウトカムに与える共同効果（Joint Effect）を評価する場面は頻繁にあります。その際のモデリング戦略として、一般的に以下の2つのアプローチが考えられます。\n\n4カテゴリーのダミー変数モデル: 参照群（例: A₁=0, A₂=0）を基準に、3つのダミー変数を作成する\n交互作用モデル: 主効果（A₁, A₂）と交互作用項（A₁ × A₂）をモデルに投入する\n\n本稿では、まず線形回帰モデルにおける両者の数学的な等価性を詳細に示し、Rを用いた数値シミュレーションでその結果を実証します。さらに、この関係がロジスティック回帰モデルにも拡張できることを確認します。\n\n\n\n線形回帰の枠組みでは、2つのモデルが数学的に全く同じものであることを明確に示せます。\n\n\nアウトカムをY、曝露グループごとのサンプル平均を Ȳₐ₁ₐ₂ とします。\n\n\n参照群を (A₁=0, A₂=0) とします。\nE[Y] = β₀ + β₁D₁₀ + β₂D₀₁ + β₃D₁₁\n最小二乗法（OLS）による係数βの推定量は、サンプル平均との差で直感的に表現できます。\n\nβ̂₀ = Ȳ₀₀\nβ̂₁ = Ȳ₁₀ − Ȳ₀₀\nβ̂₂ = Ȳ₀₁ − Ȳ₀₀\nβ̂₃ = Ȳ₁₁ − Ȳ₀₀\n\nここで、β̂₃が参照群に対する共同効果の直接的な推定量となります。\n\n\n\nE[Y] = γ₀ + γ₁A₁ + γ₂A₂ + γ₃(A₁ × A₂)\nこのモデルの係数γも同様にサンプル平均から導出できます。\n\nγ̂₀ = Ȳ₀₀\nγ̂₁ = Ȳ₁₀ − Ȳ₀₀ （A₁の主効果）\nγ̂₂ = Ȳ₀₁ − Ȳ₀₀ （A₂の主効果）\nγ̂₃ = Ȳ₁₁ − Ȳ₁₀ − Ȳ₀₁ + Ȳ₀₀ （交互作用）\n\nModel Iにおける共同効果は、係数の線形和 γ̂₁ + γ̂₂ + γ̂₃ で表されます。これを展開すると、\n(Ȳ₁₀ − Ȳ₀₀) + (Ȳ₀₁ − Ȳ₀₀) + (Ȳ₁₁ − Ȳ₁₀ − Ȳ₀₁ + Ȳ₀₀) = Ȳ₁₁ − Ȳ₀₀\nとなり、これはModel Dのβ̂₃と代数的に完全に一致します。\n\n\n\n\n点推定量の正体が同じ（どちらも Ȳ₁₁ − Ȳ₀₀）であるため、標準誤差も必然的に同じになります。\nVar(β̂₃) = Var(γ̂₁ + γ̂₂ + γ̂₃) = Var(Ȳ₁₁ − Ȳ₀₀) = σ²/n₁₁ + σ²/n₀₀\nしたがって、両モデルは同じ情報を異なるパラメータで表現した**再パラメータ化（re-parameterization）**の関係にあり、導き出される結論は同一です。\n\n\n\n\n理論的な等価性を、シミュレーションデータを用いてRで確認します。\n# パッケージの読み込み（必要に応じてインストール）\n# install.packages(\"emmeans\")\nlibrary(emmeans)\n\n# 再現性のためのシード設定\nset.seed(123)\n\n# 1. データ生成\nn &lt;- 400\ndf &lt;- data.frame(\n  A1 = rbinom(n, 1, 0.5),\n  A2 = rbinom(n, 1, 0.4)\n)\n\n# Yを生成 (A1=1, A2=1のときに強い効果を持たせる)\ndf$Y_linear &lt;- 10 + 2*df$A1 + 3*df$A2 + 5*df$A1*df$A2 + rnorm(n, 0, 4)\n\n# 2. 4カテゴリーのダミー変数を作成\n# 参照群を A1=0, A2=0 に設定\ndf$group &lt;- factor(paste0(\"A1=\", df$A1, \", A2=\", df$A2))\ndf$group &lt;- relevel(df$group, ref = \"A1=0, A2=0\")\n\n# 3. モデルのフィッティング\n# Model D: ダミー変数モデル\nmodel_D_lm &lt;- lm(Y_linear ~ group, data = df)\ncat(\"--- ダミー変数モデル (Model D) の結果 ---\\n\")\nprint(summary(model_D_lm))\n\n# Model I: 交互作用モデル\nmodel_I_lm &lt;- lm(Y_linear ~ A1 * A2, data = df)\ncat(\"\\n--- 交互作用モデル (Model I) の結果 ---\\n\")\nprint(summary(model_I_lm))\n\n# 4. 共同効果の比較\ncat(\"\\n--- 共同効果の点推定値と標準誤差の比較 ---\\n\")\n\n# Model Dから共同効果を直接取得\nbeta3 &lt;- summary(model_D_lm)$coefficients[\"groupA1=1, A2=1\",]\ncat(sprintf(\"Model D (ダミー) の共同効果: Estimate = %.4f, SE = %.4f\\n\", beta3[1], beta3[2]))\n\n# Model Iから共同効果を計算\n# 方法1: emmeansパッケージを使用\njoint_effect &lt;- emmeans(model_I_lm, ~ A1*A2)\ncontrast_result &lt;- contrast(joint_effect, method = list(\"Joint Effect (1,1 vs 0,0)\" = c(-1, 0, 0, 1)))\ncontrast_summary &lt;- summary(contrast_result)\ncat(sprintf(\"Model I (交互作用) の共同効果: Estimate = %.4f, SE = %.4f (emmeansを使用)\\n\",\n            contrast_summary$estimate[1], contrast_summary$SE[1]))\n\n# 方法2: 手動計算による確認\n# γ1 + γ2 + γ3 = 共同効果\ncoef_I &lt;- summary(model_I_lm)$coefficients\njoint_manual &lt;- coef_I[\"A1\", \"Estimate\"] + coef_I[\"A2\", \"Estimate\"] + coef_I[\"A1:A2\", \"Estimate\"]\ncat(sprintf(\"Model I (交互作用) の共同効果: Estimate = %.4f (手動計算)\\n\", joint_manual))\n\n# 標準誤差の手動計算（共分散行列を使用）\nvcov_matrix &lt;- vcov(model_I_lm)\n# γ1 + γ2 + γ3 の分散を計算\ncontrast_vector &lt;- c(0, 1, 1, 1)  # (Intercept, A1, A2, A1:A2)\njoint_var &lt;- t(contrast_vector) %*% vcov_matrix %*% contrast_vector\njoint_se_manual &lt;- sqrt(joint_var)\ncat(sprintf(\"Model I (交互作用) の共同効果: SE = %.4f (手動計算)\\n\", joint_se_manual))\n\n\n上記のRコードを実行すると、以下の結果が得られます。\nModel D の groupA1=1, A2=1 の係数：\n\nEstimate: 10.1044\nStd. Error: 0.5856\n\nModel I から計算したJoint Effect：\n\nemmeansを使用: Estimate = 10.1044, SE = 0.5856\n手動計算: Estimate = 10.1044, SE = 0.5856\n\nこの結果は、共同効果の点推定値と標準誤差が、小数点以下4桁まで完全に一致することを示しており、理論的な等価性を実証しています。\n\n\n\n\nこの等価性の原則は、ロジスティック回帰にもそのまま適用される。再パラメータ化の関係は、この線形予測子の部分で成立するため、共同効果の対数オッズ比とその標準誤差も、2つのモデルで完全に一致します。\n\n\n# 再現性のためのシード設定\nset.seed(456)\n\n# 1. ロジスティック回帰用のデータ生成\nlogit_p &lt;- -2 + 0.5*df$A1 + 0.8*df$A2 + 1.2*df$A1*df$A2\nprob &lt;- exp(logit_p) / (1 + exp(logit_p))\ndf$Y_logistic &lt;- rbinom(n, 1, prob)\n\n# 2. モデルのフィッティング\n# Model D: ダミー変数モデル\nmodel_D_glm &lt;- glm(Y_logistic ~ group, data = df, family = \"binomial\")\n# Model I: 交互作用モデル\nmodel_I_glm &lt;- glm(Y_logistic ~ A1 * A2, data = df, family = \"binomial\")\n\n# 3. 共同効果（対数オッズ比）の比較\ncat(\"\\n--- ロジスティック回帰における共同効果の比較 ---\\n\")\n\n# Model Dから直接取得\nbeta3_glm &lt;- summary(model_D_glm)$coefficients[\"groupA1=1, A2=1\",]\ncat(sprintf(\"Model D (ダミー) の共同効果(LOR): Estimate = %.4f, SE = %.4f\\n\", beta3_glm[1], beta3_glm[2]))\n\n# Model Iから計算\njoint_effect_glm &lt;- emmeans(model_I_glm, ~ A1*A2)\ncontrast_glm &lt;- contrast(joint_effect_glm, method = list(\"Joint Effect (1,1 vs 0,0)\" = c(-1, 0, 0, 1)))\ncontrast_glm_summary &lt;- summary(contrast_glm)\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): Estimate = %.4f, SE = %.4f (emmeansを使用)\\n\",\n            contrast_glm_summary$estimate[1], contrast_glm_summary$SE[1]))\n\n# 手動計算による確認\ncoef_glm &lt;- summary(model_I_glm)$coefficients\njoint_manual_glm &lt;- coef_glm[\"A1\", \"Estimate\"] + coef_glm[\"A2\", \"Estimate\"] + coef_glm[\"A1:A2\", \"Estimate\"]\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): Estimate = %.4f (手動計算)\\n\", joint_manual_glm))\n\n# 標準誤差の手動計算\nvcov_matrix_glm &lt;- vcov(model_I_glm)\ncontrast_vector &lt;- c(0, 1, 1, 1)  # (Intercept, A1, A2, A1:A2)\njoint_var_glm &lt;- t(contrast_vector) %*% vcov_matrix_glm %*% contrast_vector\njoint_se_manual_glm &lt;- sqrt(joint_var_glm)\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): SE = %.4f (手動計算)\\n\", joint_se_manual_glm))\n\n\n\nModel D (logistic) の groupA1=1, A2=1 の係数：\n\nEstimate: 1.6801\nStd. Error: 0.3567\n\nModel I (logistic) から計算したJoint Effect：\n\nemmeansを使用: Estimate = 1.6801, SE = 0.3567\n手動計算: Estimate = 1.6801, SE = 0.3567\n\nロジスティック回帰においても、共同効果の対数オッズ比とその標準誤差が完全に一致することが確認できました。\n\n\n\n\n2つの二値曝露を扱う際、4カテゴリーのダミー変数モデルと交互作用モデルは、単なる再パラメータ化の関係にあります。そのため、線形回帰・ロジスティック回帰を問わず、適切に計算すれば共同効果の点推定値と標準誤差は完全に一致します。\n実証結果のポイント：\n\n線形回帰、ロジスティック回帰ともに、ダミー変数モデルを使おうが交互作用モデルを使おうが同じ結果\n点推定値だけでなく標準誤差も小数点以下4桁まで完全に一致\n\nモデルの選択は、研究の目的に応じて行うべきです。\n\nダミー変数モデル: 各曝露パターンの効果を、共通の参照群と比較して直接的に解釈したい場合に直感的です\n交互作用モデル: 主効果からの逸脱、つまり交互作用の大きさとその有意性を直接評価したい場合に適しています\n\nJoint Intervention Exposureにおいてはどちらのモデルを使おうが結果は同じとなる。あくまで解析には興味がなく、"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#はじめに",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#はじめに",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "疫学研究において、2つの二値曝露（A₁, A₂）がアウトカムに与える共同効果（Joint Effect）を評価する場面は頻繁にあります。その際のモデリング戦略として、一般的に以下の2つのアプローチが考えられます。\n\n4カテゴリーのダミー変数モデル: 参照群（例: A₁=0, A₂=0）を基準に、3つのダミー変数を作成する\n交互作用モデル: 主効果（A₁, A₂）と交互作用項（A₁ × A₂）をモデルに投入する\n\n本稿では、まず線形回帰モデルにおける両者の数学的な等価性を詳細に示し、Rを用いた数値シミュレーションでその結果を実証します。さらに、この関係がロジスティック回帰モデルにも拡張できることを確認します。"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#線形回帰モデルにおける等価性の証明",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#線形回帰モデルにおける等価性の証明",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "線形回帰の枠組みでは、2つのモデルが数学的に全く同じものであることを明確に示せます。\n\n\nアウトカムをY、曝露グループごとのサンプル平均を Ȳₐ₁ₐ₂ とします。\n\n\n参照群を (A₁=0, A₂=0) とします。\nE[Y] = β₀ + β₁D₁₀ + β₂D₀₁ + β₃D₁₁\n最小二乗法（OLS）による係数βの推定量は、サンプル平均との差で直感的に表現できます。\n\nβ̂₀ = Ȳ₀₀\nβ̂₁ = Ȳ₁₀ − Ȳ₀₀\nβ̂₂ = Ȳ₀₁ − Ȳ₀₀\nβ̂₃ = Ȳ₁₁ − Ȳ₀₀\n\nここで、β̂₃が参照群に対する共同効果の直接的な推定量となります。\n\n\n\nE[Y] = γ₀ + γ₁A₁ + γ₂A₂ + γ₃(A₁ × A₂)\nこのモデルの係数γも同様にサンプル平均から導出できます。\n\nγ̂₀ = Ȳ₀₀\nγ̂₁ = Ȳ₁₀ − Ȳ₀₀ （A₁の主効果）\nγ̂₂ = Ȳ₀₁ − Ȳ₀₀ （A₂の主効果）\nγ̂₃ = Ȳ₁₁ − Ȳ₁₀ − Ȳ₀₁ + Ȳ₀₀ （交互作用）\n\nModel Iにおける共同効果は、係数の線形和 γ̂₁ + γ̂₂ + γ̂₃ で表されます。これを展開すると、\n(Ȳ₁₀ − Ȳ₀₀) + (Ȳ₀₁ − Ȳ₀₀) + (Ȳ₁₁ − Ȳ₁₀ − Ȳ₀₁ + Ȳ₀₀) = Ȳ₁₁ − Ȳ₀₀\nとなり、これはModel Dのβ̂₃と代数的に完全に一致します。\n\n\n\n\n点推定量の正体が同じ（どちらも Ȳ₁₁ − Ȳ₀₀）であるため、標準誤差も必然的に同じになります。\nVar(β̂₃) = Var(γ̂₁ + γ̂₂ + γ̂₃) = Var(Ȳ₁₁ − Ȳ₀₀) = σ²/n₁₁ + σ²/n₀₀\nしたがって、両モデルは同じ情報を異なるパラメータで表現した**再パラメータ化（re-parameterization）**の関係にあり、導き出される結論は同一です。"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#rによる実証線形回帰",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#rによる実証線形回帰",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "理論的な等価性を、シミュレーションデータを用いてRで確認します。\n# パッケージの読み込み（必要に応じてインストール）\n# install.packages(\"emmeans\")\nlibrary(emmeans)\n\n# 再現性のためのシード設定\nset.seed(123)\n\n# 1. データ生成\nn &lt;- 400\ndf &lt;- data.frame(\n  A1 = rbinom(n, 1, 0.5),\n  A2 = rbinom(n, 1, 0.4)\n)\n\n# Yを生成 (A1=1, A2=1のときに強い効果を持たせる)\ndf$Y_linear &lt;- 10 + 2*df$A1 + 3*df$A2 + 5*df$A1*df$A2 + rnorm(n, 0, 4)\n\n# 2. 4カテゴリーのダミー変数を作成\n# 参照群を A1=0, A2=0 に設定\ndf$group &lt;- factor(paste0(\"A1=\", df$A1, \", A2=\", df$A2))\ndf$group &lt;- relevel(df$group, ref = \"A1=0, A2=0\")\n\n# 3. モデルのフィッティング\n# Model D: ダミー変数モデル\nmodel_D_lm &lt;- lm(Y_linear ~ group, data = df)\ncat(\"--- ダミー変数モデル (Model D) の結果 ---\\n\")\nprint(summary(model_D_lm))\n\n# Model I: 交互作用モデル\nmodel_I_lm &lt;- lm(Y_linear ~ A1 * A2, data = df)\ncat(\"\\n--- 交互作用モデル (Model I) の結果 ---\\n\")\nprint(summary(model_I_lm))\n\n# 4. 共同効果の比較\ncat(\"\\n--- 共同効果の点推定値と標準誤差の比較 ---\\n\")\n\n# Model Dから共同効果を直接取得\nbeta3 &lt;- summary(model_D_lm)$coefficients[\"groupA1=1, A2=1\",]\ncat(sprintf(\"Model D (ダミー) の共同効果: Estimate = %.4f, SE = %.4f\\n\", beta3[1], beta3[2]))\n\n# Model Iから共同効果を計算\n# 方法1: emmeansパッケージを使用\njoint_effect &lt;- emmeans(model_I_lm, ~ A1*A2)\ncontrast_result &lt;- contrast(joint_effect, method = list(\"Joint Effect (1,1 vs 0,0)\" = c(-1, 0, 0, 1)))\ncontrast_summary &lt;- summary(contrast_result)\ncat(sprintf(\"Model I (交互作用) の共同効果: Estimate = %.4f, SE = %.4f (emmeansを使用)\\n\",\n            contrast_summary$estimate[1], contrast_summary$SE[1]))\n\n# 方法2: 手動計算による確認\n# γ1 + γ2 + γ3 = 共同効果\ncoef_I &lt;- summary(model_I_lm)$coefficients\njoint_manual &lt;- coef_I[\"A1\", \"Estimate\"] + coef_I[\"A2\", \"Estimate\"] + coef_I[\"A1:A2\", \"Estimate\"]\ncat(sprintf(\"Model I (交互作用) の共同効果: Estimate = %.4f (手動計算)\\n\", joint_manual))\n\n# 標準誤差の手動計算（共分散行列を使用）\nvcov_matrix &lt;- vcov(model_I_lm)\n# γ1 + γ2 + γ3 の分散を計算\ncontrast_vector &lt;- c(0, 1, 1, 1)  # (Intercept, A1, A2, A1:A2)\njoint_var &lt;- t(contrast_vector) %*% vcov_matrix %*% contrast_vector\njoint_se_manual &lt;- sqrt(joint_var)\ncat(sprintf(\"Model I (交互作用) の共同効果: SE = %.4f (手動計算)\\n\", joint_se_manual))\n\n\n上記のRコードを実行すると、以下の結果が得られます。\nModel D の groupA1=1, A2=1 の係数：\n\nEstimate: 10.1044\nStd. Error: 0.5856\n\nModel I から計算したJoint Effect：\n\nemmeansを使用: Estimate = 10.1044, SE = 0.5856\n手動計算: Estimate = 10.1044, SE = 0.5856\n\nこの結果は、共同効果の点推定値と標準誤差が、小数点以下4桁まで完全に一致することを示しており、理論的な等価性を実証しています。"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#ロジスティック回帰モデルへの拡張",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#ロジスティック回帰モデルへの拡張",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "この等価性の原則は、ロジスティック回帰にもそのまま適用される。再パラメータ化の関係は、この線形予測子の部分で成立するため、共同効果の対数オッズ比とその標準誤差も、2つのモデルで完全に一致します。\n\n\n# 再現性のためのシード設定\nset.seed(456)\n\n# 1. ロジスティック回帰用のデータ生成\nlogit_p &lt;- -2 + 0.5*df$A1 + 0.8*df$A2 + 1.2*df$A1*df$A2\nprob &lt;- exp(logit_p) / (1 + exp(logit_p))\ndf$Y_logistic &lt;- rbinom(n, 1, prob)\n\n# 2. モデルのフィッティング\n# Model D: ダミー変数モデル\nmodel_D_glm &lt;- glm(Y_logistic ~ group, data = df, family = \"binomial\")\n# Model I: 交互作用モデル\nmodel_I_glm &lt;- glm(Y_logistic ~ A1 * A2, data = df, family = \"binomial\")\n\n# 3. 共同効果（対数オッズ比）の比較\ncat(\"\\n--- ロジスティック回帰における共同効果の比較 ---\\n\")\n\n# Model Dから直接取得\nbeta3_glm &lt;- summary(model_D_glm)$coefficients[\"groupA1=1, A2=1\",]\ncat(sprintf(\"Model D (ダミー) の共同効果(LOR): Estimate = %.4f, SE = %.4f\\n\", beta3_glm[1], beta3_glm[2]))\n\n# Model Iから計算\njoint_effect_glm &lt;- emmeans(model_I_glm, ~ A1*A2)\ncontrast_glm &lt;- contrast(joint_effect_glm, method = list(\"Joint Effect (1,1 vs 0,0)\" = c(-1, 0, 0, 1)))\ncontrast_glm_summary &lt;- summary(contrast_glm)\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): Estimate = %.4f, SE = %.4f (emmeansを使用)\\n\",\n            contrast_glm_summary$estimate[1], contrast_glm_summary$SE[1]))\n\n# 手動計算による確認\ncoef_glm &lt;- summary(model_I_glm)$coefficients\njoint_manual_glm &lt;- coef_glm[\"A1\", \"Estimate\"] + coef_glm[\"A2\", \"Estimate\"] + coef_glm[\"A1:A2\", \"Estimate\"]\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): Estimate = %.4f (手動計算)\\n\", joint_manual_glm))\n\n# 標準誤差の手動計算\nvcov_matrix_glm &lt;- vcov(model_I_glm)\ncontrast_vector &lt;- c(0, 1, 1, 1)  # (Intercept, A1, A2, A1:A2)\njoint_var_glm &lt;- t(contrast_vector) %*% vcov_matrix_glm %*% contrast_vector\njoint_se_manual_glm &lt;- sqrt(joint_var_glm)\ncat(sprintf(\"Model I (交互作用) の共同効果(LOR): SE = %.4f (手動計算)\\n\", joint_se_manual_glm))\n\n\n\nModel D (logistic) の groupA1=1, A2=1 の係数：\n\nEstimate: 1.6801\nStd. Error: 0.3567\n\nModel I (logistic) から計算したJoint Effect：\n\nemmeansを使用: Estimate = 1.6801, SE = 0.3567\n手動計算: Estimate = 1.6801, SE = 0.3567\n\nロジスティック回帰においても、共同効果の対数オッズ比とその標準誤差が完全に一致することが確認できました。"
  },
  {
    "objectID": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#結論",
    "href": "posts/statistics/2025/Joint_interventionにおけるモデル構築.html#結論",
    "title": "Joint Interventionにおけるモデル構築",
    "section": "",
    "text": "2つの二値曝露を扱う際、4カテゴリーのダミー変数モデルと交互作用モデルは、単なる再パラメータ化の関係にあります。そのため、線形回帰・ロジスティック回帰を問わず、適切に計算すれば共同効果の点推定値と標準誤差は完全に一致します。\n実証結果のポイント：\n\n線形回帰、ロジスティック回帰ともに、ダミー変数モデルを使おうが交互作用モデルを使おうが同じ結果\n点推定値だけでなく標準誤差も小数点以下4桁まで完全に一致\n\nモデルの選択は、研究の目的に応じて行うべきです。\n\nダミー変数モデル: 各曝露パターンの効果を、共通の参照群と比較して直接的に解釈したい場合に直感的です\n交互作用モデル: 主効果からの逸脱、つまり交互作用の大きさとその有意性を直接評価したい場合に適しています\n\nJoint Intervention Exposureにおいてはどちらのモデルを使おうが結果は同じとなる。あくまで解析には興味がなく、"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "",
    "text": "本記事では、Proc Contents ProcedureとProc Dtaset Procecdureについて解説する。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#sas",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#sas",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "",
    "text": "本記事では、Proc Contents ProcedureとProc Dtaset Procecdureについて解説する。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#proc-contents-procedure",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#proc-contents-procedure",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.2 Proc Contents Procedure",
    "text": "0.2 Proc Contents Procedure\nCONTENTS プロシージャは、SAS データセットの内容を表示し、SAS ライブラリのディレクトリを印刷します。一般的に、CONTENTS プロシージャは DATASETS プロシージャの CONTENTS ステートメントと同じ機能を持ちます。CONTENTS プロシージャと PROC DATASETS の CONTENTS ステートメントの違いは以下の通りです：\n\nPROC CONTENTS の DATA= オプションにおける libref のデフォルトは Work です。CONTENTS ステートメントでは、デフォルトはプロシージャ入力ライブラリの libref です。\nPROC CONTENTS は順次ファイルを読み取ることができます。CONTENTS ステートメントはできません。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#proc-contents-procedureの特徴",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#proc-contents-procedureの特徴",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.3 Proc Contents Procedureの特徴",
    "text": "0.3 Proc Contents Procedureの特徴\n\nPROC CONTENTS reports metadata about the table and the metadata about the variables.\nデータセットにおけるVariable、Type(Char、Num） 、Fromat、Labelをデータセット化できる！"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#構文",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#構文",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.4 構文",
    "text": "0.4 構文\nPROC CONTENTS &lt;options&gt;;\n\n0.4.1 DATA=SAS-file-specification\nspecifies an entire library or a specific SAS data set within a library. SAS-file-specification can take one of the following forms:\n\n\n0.4.2 &lt;libref.&gt;SAS-data-set\nnames one SAS data set to process. The default for libref is the libref of the procedure input library. For example, to obtain the contents of the SAS data set HtWt from the procedure input library, use the following CONTENTS statement:\ncontents data=HtWt;\nTo obtain the contents of a specific version from a generation group, use the GENNUM= data set option as shown in the following CONTENTS statement:\ncontents data=HtWt(gennum=3);\n\n\n0.4.3 &lt;libref.&gt;_ALL_\ngives you information about all SAS data sets that have the type or types specified by the MEMTYPE= option. libref refers to the SAS library. The default for libref is the libref of the procedure input library.\n\nIf you are using the _ALL_ keyword, you need Read access to all read-protected SAS data sets in the SAS library.\nDATA=_ALL_ automatically prints a listing of the SAS files that are contained in the SAS library. Note that for SAS views, all librefs that are associated with the views must be assigned in the current session in order for them to be processed for the listing.\n\n\n\n\n\n\n\n\nDefault\nmost recently created data set in your job or session, from any SAS library.\n\n\n\n\nTip\nIf you specify a read-protected data set in the DATA= option but do not give the Read password, by default the procedure looks in the PROC DATASETS statement for the Read password. However, if you do not specify the DATA= option and the default data set (last one created in the session) is Read protected, the procedure does not look in the PROC DATASETS statement for the Read password.\n\n\n\nすなわち指定したlibraryに含まれるSASデータセット全てを指定することもできるし、指定したlibraryの特定のデータセットを指定することもできる。\n\n\n0.4.4 MEMTYPE=(member-type(s))\nrestricts processing to one or more member types. The CONTENTS statement produces output only for member types DATA, VIEW, and ALL, which includes DATA and VIEW.\nMEMTYPE= in the CONTENTS statement differs from MEMTYPE= in most of the other statements in the DATASETS procedure in the following ways:\n\nA slash does not precede the option.\nYou cannot enclose the MEMTYPE= option in parentheses to limit its effect to only the SAS file immediately preceding it.\n\nMEMTYPE= results in a directory of the library in which the DATA= member is located. However, MEMTYPE= does not limit the types of members whose contents are displayed unless the _ALL_ keyword is used in the DATA= option. For example, the following statements produce the contents of only the SAS data sets with the member type DATA:\nproc datasets memtype=data;   \nmentypeはデータセットのみが欲しいときは指定したらよいと思うが、基本的にする必要はないだろう。\n\n\n0.4.5 NOPRINT\nsuppresses printing the output of the CONTENTS statement.\n\n\n0.4.6 ORDER=COLLATE | CASECOLLATE | IGNORECASE | VARNUM\n基本的にorder = varnumとしておけばよい。\n\n\n\n\n\n\n\nCOLLATE\nprints a list of variables in alphabetical order beginning with uppercase and then lowercase names.\n\n\nCASECOLLATE\nprints a list of variables in alphabetical order even if they include mixed-case names and numerics.\n\n\nIGNORECASE\nprints a list of variables in alphabetical order ignoring the case of the letters.\n\n\nVARNUM\nis the same as the VARNUM option.\n\n\n\n\n\n\nNote\nThe ORDER= option does not affect the order of the OUT= and OUT2= data sets.\n\n\n\n\nSee\nVARNUM\n\n\nExample\nSee Using the ORDER= Option to compare the default and the four options for ORDER=.\n\n\n\n\n\n0.4.7 OUT=SAS-data-set\nnames an output SAS data set.\n\n\n\nTip\nOUT= does not suppress the printed output from the statement. If you want to suppress the printed output, you must use the NOPRINT option.\n\n\n\n\nSee\nThe OUT= Data Set for a description of the variables in the OUT= data set.\n\n\n\n\n\n0.4.8 OUT2=SAS-data-set\nnames the output data set to contain information about indexes and integrity constraints.\n\n\n\nNote\nWhen you use the OUT2=PermanentLibrary_ALL_ option within PROC CONTENTS or PROC DATASETS with the CONTENTS statement, you must also set the REPLACE=YES data set option or the REPLACE system option.\n\n\n\n\nTips\nIf UPDATECENTILES was not specified in the index definition, then the default value of 5 is used in the re-create variable of the OUT2 data set.\n\n\nOUT2= does not suppress the printed output from the statement. To suppress the printed output, use the NOPRINT option.\n\n\n\nSee\nThe OUT2= Data Set for a description of the variables in the OUT2= data set.\n\n\n\n以下のようにしておけばよい\nproc contents data=sashelp.class out=out1 varnum ; run;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#short-option",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#short-option",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "0.5 Short Option",
    "text": "0.5 Short Option\nShort Optionを使えば、データセットに格納されている順番で、全変数を1つのマクロ変数に格納できる！たまに便利では？\n\n参考記事：PROC CONTENTSのSHORTオプションはアイディア次第で役に立ちそう。\n\n\n*** 全変数名を（データセットに格納されてる順で）1つのマクロ変数に格納する ;\nods output PositionShort = OUT1;\n    proc contents data=sashelp.class  short  varnum;\n    run;\nods output close;\n\ndata _NULL_ ;\n    set OUT1 ;\n    call symputx(\"VARS\", VARIABLES);\nrun;\n\n%put &VARS;\nOUT1にVARIABLESという1変数が格納され、そこにデータセットに含まれる全変数が格納されている。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#copy",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#copy",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.1 Copy",
    "text": "1.1 Copy\nUsed to copy or move a SAS member from one library to another.To limit copying to specific members, use either the SELECT or EXCLUDE options. To specify a different library to copy from use either the DATASETS LIBRARY option to specify a default library or use the IN= option. To move a member from one library to another and then delete the original member, use the MOVE optionThe following example moves two members from lib1 to lib2:\nLIBNAME lib1 ‘SAS-data-library’;\nLIBNAME lib2 ‘SAS-data-library’;\nPROC DATASETS;\nCOPY IN=lib1 OUT=lib2 MOVE;\nSELECT member1 member2;\nRUN;\nデータセットのCopyについてはProc Copyも役に立つ\n\n【PROC COPY】データセットを他のライブラリに一括コピー\n\n  PROC COPY\n       IN                =   コピー対象のライブラリ\n       OUT            =   出力先のライブラリ\n       MEMTYPE  =   (コピー対象のデータのタイプ) ;\n       SELECT     コピー対象のデータ ;\n       EXCLUDE  コピー対象外のデータ ;\n   RUN;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#kill",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#kill",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.2 Kill",
    "text": "1.2 Kill\nThe following example shows how to delete all the members within a permanent SAS library using the KILL option:\nLIBNAME input ‘SAS-data-library’;\nPROC DATASETS LIBRARY=input KILL;\nRUN;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#データセットのattribを全部消す",
    "href": "posts/statistics/2025/Proc_Contents_Proc_Dataset.html#データセットのattribを全部消す",
    "title": "Proc Contents ProcedureとProc Dataset Procedure",
    "section": "1.3 データセットのattribを全部消す",
    "text": "1.3 データセットのattribを全部消す\nlibname mylib 'c:\\mylib';\nproc contents data=mylib.class;\nrun;\nproc datasets lib=mylib memtype=data;\n   modify class;\n     attrib _all_ label=' ';\n     attrib _all_ format=;\ncontents data=mylib.class;\nrun;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Lifereg.html",
    "href": "posts/statistics/2025/Proc_Lifereg.html",
    "title": "Proc LIFEREG",
    "section": "",
    "text": "SASで生存時間分析を行う際、PROC LIFEREGのコードを見て、ふと疑問に思ったことはありませんか？\nproc lifereg data=mydata;\n    model log(time)*status(0) = treatment age;\nrun;\nなぜ、生存時間 time をそのまま使わず、一手間かけて log(time) と対数をとるのでしょうか？ 単純に time = treatment age; と書くのとでは、何が違うのでしょうか？\nこの記事では、そんな疑問に答えるべく、PROC LIFEREGがlog(T)をモデル化する理由を、統計的な背景から分かりやすく解説していきます。\n\n\nなぜ対数をとるのか？その最大の理由は、共変量と生存時間の関係を、シンプルで扱いやすい「線形モデル」として表現するためです。\nPROC LIFEREGで使われるモデルの基本形は、加速故障時間（AFT）モデルと呼ばれ、以下のように表現されます。\n\nlog(T)=\\beta_0+\\beta_1X_1+…+\\sigma\\epsilon\n\nの式こそが、すべての謎を解く鍵となります。\n\nlog(T): 生存時間の対数。これがモデルの「目的変数(Y)」になります。\nβX: β_0 + β_1X_1 + ... の部分。共変量（説明変数）から計算される予測部分です。\nσε: モデルの「誤差」部分。σはばらつきを調整するスケールパラメータ、εは基準となる標準化された誤差です。\n\nこの「線形」という形にすることで、私たち分析者には大きなメリットがもたらされます。\n\n\n\n\n\nもし生存時間Tを直接モデル化しようとすると、共変量Xとの関係は非常に複雑な曲線を描くことがほとんどです。しかし、log(T)に変換することで、その関係は美しい**一次方程式（直線）**になります。\nこれにより、「Xが1単位増えると、生存時間の対数がβだけ変化する」という、非常に直感的で分かりやすい解釈が可能になるのです。\n\n\n\nここがAFTモデルの最もエレガントな部分です。モデルの基本形 log(T) = βX + σε はそのままに、誤差項εが従う確率分布を変えるだけで、様々な生存時間分布を表現できます。\n\n\n\n\n\n\n\n\nεが従う分布（標準化済）\nTが従う生存時間分布\nPROC LIFEREGでの指定\n\n\n標準極値分布\nワイブル分布 (Weibull)\nDIST=WEIBULL (デフォルト)\n\n\n標準正規分布\n対数正規分布 (Lognormal)\nDIST=LNORMAL\n\n\n標準ロジスティック分布\n対数ロジスティック分布 (Log-logistic)\nDIST=LOGISTIC\n\n\n\nlog変換は、多種多様な分布を同じ土俵で議論するための「共通言語」のような役割を果たしているのです。\n\n\n\n\nLIFEREG procedure:\ndata Headache;\n   input Minutes Group Censor @@;\n   datalines;\n11  1  0   12  1  0   19  1  0   19  1  0\n19  1  0   19  1  0   21  1  0   20  1  0\n21  1  0   21  1  0   20  1  0   21  1  0\n20  1  0   21  1  0   25  1  0   27  1  0\n30  1  0   21  1  1   24  1  1   14  2  0\n16  2  0   16  2  0   21  2  0   21  2  0\n23  2  0   23  2  0   23  2  0   23  2  0\n25  2  1   23  2  0   24  2  0   24  2  0\n26  2  1   32  2  1   30  2  1   30  2  0\n32  2  1   20  2  1\n;\n\nproc lifereg data=Headache;\n   class Group;\n   model Minutes*Censor(1)=Group /dist = exponential;\n   output out=New cdf=Prob;\nrun;\n\n\n\nこんにちは！今回は、SASを使った生存時間分析の定番PROC LIFEREGの出力結果を、初心者の方にも分かりやすく解説していきます。\n頭痛薬の効果持続時間を2つのグループで比較する、というシナリオで見ていきましょう。\n\n\nまず、使用したSASコードはこちらです。\nSAS\ndata Headache;\n   input Minutes Group Censor @@;\n   datalines;\n11  1  0   12  1  0   19  1  0   19  1  0\n19  1  0   19  1  0   21  1  0   20  1  0\n21  1  0   21  1  0   20  1  0   21  1  0\n20  1  0   21  1  0   25  1  0   27  1  0\n30  1  0   21  1  1   24  1  1   14  2  0\n16  2  0   16  2  0   21  2  0   21  2  0\n23  2  0   23  2  0   23  2  0   23  2  0\n25  2  1   23  2  0   24  2  0   24  2  0\n26  2  1   32  2  1   30  2  1   30  2  0\n32  2  1   20  2  1\n;\n\nproc lifereg data=Headache;\n   class Group;\n   model Minutes*Censor(1)=Group /dist = exponential;\n   output out=New cdf=Prob;\nrun;\nmodelステートメントのdist = exponentialで、今回は指数分布を仮定して分析しています。Censor(1)は、Censor変数の値が1の場合にそのデータが「打ち切り」であることを示します。\nそれでは、このコードが生成したアウトプットを上から順に見ていきましょう！\n\n\n\n\n分離変数の水準の情報 (Level Information for Class Variables) CLASSステートメントで指定したGroup変数が、値として1と2を持っていることを示しています。\n適合度統計量 (Goodness-of-Fit Statistics) AICやBICといった指標が並んでいますね。これらの値は小さいほど、モデルの当てはまりが良いことを意味します。この結果だけでは評価できませんが、例えばdist = weibull（ワイブル分布）で分析した結果と比較して、どちらのモデルがよりデータにフィットしているかを見るために使います。\nアルゴリズムは収束しました。(The algorithm has converged.) モデルの計算が問題なく完了したことを示す、重要なメッセージです。これが表示されていれば一安心です。\n\n\n\n\n\n効果に対する Type III 分析 (Type III Analysis of Effects) ここが最初の重要な結果です。この表は、モデルに含まれる変数Groupが、生存時間（頭痛薬の効果持続時間）に統計的に有意な影響を与えているかを「全体として」検定します。\n注目するのはPr &gt; ChiSqの値です。これが、いわゆるp値です。\n\n結果: Pr &gt; ChiSq = 0.2778\n\n一般的にp値が0.05より小さい場合に「有意な差がある」と判断しますが、今回は0.2778と0.05より大きいです。 したがって、「2つのグループ間で、効果持続時間に統計的に有意な差があるとは言えない」という結論になります。\n\n\n\n\n\n最大尤度パラメータ推定値の分析 (Analysis of Maximum Likelihood Parameter Estimates) モデルの「中身」を詳しく見ていく部分です。\n\nIntercept (切片): これは基準となるグループ（今回はGroup 2）の対数スケールでの平均生存時間を示しています。推定値は3.5354です。\nGroup 1: これがこの分析の主役です。この行は、基準のGroup 2と比較して、Group 1がどれだけ違うかを示しています。\n\n推定値: -0.3999\nPr &gt; ChiSq (p値): 0.2778 p値はType III 分析の結果と一致していますね。やはり有意ではありません。\n\n尺度 (Scale) & Weibull 形状 (Weibull shape): dist = exponential（指数分布）を指定したため、尺度 (σ) は自動的に1に固定されます。Weibull 形状は尺度の逆数（1/σ）なので、こちらも1になります。これは、正しく指数分布モデルが適用されていることを示しています。\n\n\n\n\nGroup 1の推定値-0.3999はどう解釈すれば良いのでしょうか？ PROC LIFEREGは対数（log）で時間をモデル化しているので、元の時間スケールに戻すにはexp()を使います。\nexp(−0.3999)≈0.670\nこれは加速因子 (Acceleration Factor) と呼ばれ、「Group 1の時間は、Group 2の時間の0.67倍になる」と解釈できます。つまり、Group 1の方が効果持続時間（イベント発生までの時間）が短い傾向にある、という結果です。（ただし、この差は統計的に有意ではありませんでした。）\n\n\n\n\n今回の分析から分かったことをまとめると、以下のようになります。\n\n頭痛薬の効果持続時間について、指数分布モデルを適用して分析した。\nグループ（Group 1 vs Group 2）による持続時間の差は、統計的に有意ではなかった (p = 0.2778)。\nモデル上は、Group 1の効果持続時間はGroup 2の約0.67倍と、短い傾向が示唆されたが、これは偶然の範囲内と言える。\n\nPROC LIFEREGの出力は一見複雑に見えますが、見るべきポイントを押さえれば、分析結果を深く理解することができます。次はdist=weibullを試して、AICを比較してみるのも面白いかもしれませんね！\n\n\n\nこれは、モデルがlog(時間)を扱っていることに直結します。\nモデルの基本形は以下の通りです。\n\nGroup 2 (基準): log(Time_G2) = Intercept\nGroup 1: log(Time_G1) = Intercept + β_G1\n\nここで、2つの式の差をとってみます。\nlog(Time_G1) - log(Time_G2) = β_G1\n対数の性質上、「引き算」は「割り算」に変換できます（log(a) - log(b) = log(a/b)）。\nlog(Time_G1 / Time_G2) = β_G1\n最後に、両辺をexp()してlogを外すと、\nTime_G1 / Time_G2 = exp(β_G1)\nこの式が最終的な答えです。Group 1の時間とGroup 2の時間の関係は、差（Time_G1 - Time_G2）ではなく**比（Time_G1 / Time_G2）**で表されていますね。\nこのexp(β_G1)が、前回解説した加速因子 (0.67) です。グループの効果は、基準となる時間を何倍に「加速」または「減速」させるか、という乗法的な（掛け算の）効果として解釈されるのです。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Lifereg.html#結論ファーストすべては美しい線形モデルのため",
    "href": "posts/statistics/2025/Proc_Lifereg.html#結論ファーストすべては美しい線形モデルのため",
    "title": "Proc LIFEREG",
    "section": "",
    "text": "なぜ対数をとるのか？その最大の理由は、共変量と生存時間の関係を、シンプルで扱いやすい「線形モデル」として表現するためです。\nPROC LIFEREGで使われるモデルの基本形は、加速故障時間（AFT）モデルと呼ばれ、以下のように表現されます。\n\nlog(T)=\\beta_0+\\beta_1X_1+…+\\sigma\\epsilon\n\nの式こそが、すべての謎を解く鍵となります。\n\nlog(T): 生存時間の対数。これがモデルの「目的変数(Y)」になります。\nβX: β_0 + β_1X_1 + ... の部分。共変量（説明変数）から計算される予測部分です。\nσε: モデルの「誤差」部分。σはばらつきを調整するスケールパラメータ、εは基準となる標準化された誤差です。\n\nこの「線形」という形にすることで、私たち分析者には大きなメリットがもたらされます。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Lifereg.html#なぜ一手間かけて-logt-にするのか3つの大きなメリット",
    "href": "posts/statistics/2025/Proc_Lifereg.html#なぜ一手間かけて-logt-にするのか3つの大きなメリット",
    "title": "Proc LIFEREG",
    "section": "",
    "text": "もし生存時間Tを直接モデル化しようとすると、共変量Xとの関係は非常に複雑な曲線を描くことがほとんどです。しかし、log(T)に変換することで、その関係は美しい**一次方程式（直線）**になります。\nこれにより、「Xが1単位増えると、生存時間の対数がβだけ変化する」という、非常に直感的で分かりやすい解釈が可能になるのです。\n\n\n\nここがAFTモデルの最もエレガントな部分です。モデルの基本形 log(T) = βX + σε はそのままに、誤差項εが従う確率分布を変えるだけで、様々な生存時間分布を表現できます。\n\n\n\n\n\n\n\n\nεが従う分布（標準化済）\nTが従う生存時間分布\nPROC LIFEREGでの指定\n\n\n標準極値分布\nワイブル分布 (Weibull)\nDIST=WEIBULL (デフォルト)\n\n\n標準正規分布\n対数正規分布 (Lognormal)\nDIST=LNORMAL\n\n\n標準ロジスティック分布\n対数ロジスティック分布 (Log-logistic)\nDIST=LOGISTIC\n\n\n\nlog変換は、多種多様な分布を同じ土俵で議論するための「共通言語」のような役割を果たしているのです。"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Lifereg.html#参考sas-helpのプログラム",
    "href": "posts/statistics/2025/Proc_Lifereg.html#参考sas-helpのプログラム",
    "title": "Proc LIFEREG",
    "section": "",
    "text": "LIFEREG procedure:\ndata Headache;\n   input Minutes Group Censor @@;\n   datalines;\n11  1  0   12  1  0   19  1  0   19  1  0\n19  1  0   19  1  0   21  1  0   20  1  0\n21  1  0   21  1  0   20  1  0   21  1  0\n20  1  0   21  1  0   25  1  0   27  1  0\n30  1  0   21  1  1   24  1  1   14  2  0\n16  2  0   16  2  0   21  2  0   21  2  0\n23  2  0   23  2  0   23  2  0   23  2  0\n25  2  1   23  2  0   24  2  0   24  2  0\n26  2  1   32  2  1   30  2  1   30  2  0\n32  2  1   20  2  1\n;\n\nproc lifereg data=Headache;\n   class Group;\n   model Minutes*Censor(1)=Group /dist = exponential;\n   output out=New cdf=Prob;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/Proc_Lifereg.html#sasのproc-lifereg徹底解説指数分布モデルの結果を読み解く",
    "href": "posts/statistics/2025/Proc_Lifereg.html#sasのproc-lifereg徹底解説指数分布モデルの結果を読み解く",
    "title": "Proc LIFEREG",
    "section": "",
    "text": "こんにちは！今回は、SASを使った生存時間分析の定番PROC LIFEREGの出力結果を、初心者の方にも分かりやすく解説していきます。\n頭痛薬の効果持続時間を2つのグループで比較する、というシナリオで見ていきましょう。\n\n\nまず、使用したSASコードはこちらです。\nSAS\ndata Headache;\n   input Minutes Group Censor @@;\n   datalines;\n11  1  0   12  1  0   19  1  0   19  1  0\n19  1  0   19  1  0   21  1  0   20  1  0\n21  1  0   21  1  0   20  1  0   21  1  0\n20  1  0   21  1  0   25  1  0   27  1  0\n30  1  0   21  1  1   24  1  1   14  2  0\n16  2  0   16  2  0   21  2  0   21  2  0\n23  2  0   23  2  0   23  2  0   23  2  0\n25  2  1   23  2  0   24  2  0   24  2  0\n26  2  1   32  2  1   30  2  1   30  2  0\n32  2  1   20  2  1\n;\n\nproc lifereg data=Headache;\n   class Group;\n   model Minutes*Censor(1)=Group /dist = exponential;\n   output out=New cdf=Prob;\nrun;\nmodelステートメントのdist = exponentialで、今回は指数分布を仮定して分析しています。Censor(1)は、Censor変数の値が1の場合にそのデータが「打ち切り」であることを示します。\nそれでは、このコードが生成したアウトプットを上から順に見ていきましょう！\n\n\n\n\n分離変数の水準の情報 (Level Information for Class Variables) CLASSステートメントで指定したGroup変数が、値として1と2を持っていることを示しています。\n適合度統計量 (Goodness-of-Fit Statistics) AICやBICといった指標が並んでいますね。これらの値は小さいほど、モデルの当てはまりが良いことを意味します。この結果だけでは評価できませんが、例えばdist = weibull（ワイブル分布）で分析した結果と比較して、どちらのモデルがよりデータにフィットしているかを見るために使います。\nアルゴリズムは収束しました。(The algorithm has converged.) モデルの計算が問題なく完了したことを示す、重要なメッセージです。これが表示されていれば一安心です。\n\n\n\n\n\n効果に対する Type III 分析 (Type III Analysis of Effects) ここが最初の重要な結果です。この表は、モデルに含まれる変数Groupが、生存時間（頭痛薬の効果持続時間）に統計的に有意な影響を与えているかを「全体として」検定します。\n注目するのはPr &gt; ChiSqの値です。これが、いわゆるp値です。\n\n結果: Pr &gt; ChiSq = 0.2778\n\n一般的にp値が0.05より小さい場合に「有意な差がある」と判断しますが、今回は0.2778と0.05より大きいです。 したがって、「2つのグループ間で、効果持続時間に統計的に有意な差があるとは言えない」という結論になります。\n\n\n\n\n\n最大尤度パラメータ推定値の分析 (Analysis of Maximum Likelihood Parameter Estimates) モデルの「中身」を詳しく見ていく部分です。\n\nIntercept (切片): これは基準となるグループ（今回はGroup 2）の対数スケールでの平均生存時間を示しています。推定値は3.5354です。\nGroup 1: これがこの分析の主役です。この行は、基準のGroup 2と比較して、Group 1がどれだけ違うかを示しています。\n\n推定値: -0.3999\nPr &gt; ChiSq (p値): 0.2778 p値はType III 分析の結果と一致していますね。やはり有意ではありません。\n\n尺度 (Scale) & Weibull 形状 (Weibull shape): dist = exponential（指数分布）を指定したため、尺度 (σ) は自動的に1に固定されます。Weibull 形状は尺度の逆数（1/σ）なので、こちらも1になります。これは、正しく指数分布モデルが適用されていることを示しています。\n\n\n\n\nGroup 1の推定値-0.3999はどう解釈すれば良いのでしょうか？ PROC LIFEREGは対数（log）で時間をモデル化しているので、元の時間スケールに戻すにはexp()を使います。\nexp(−0.3999)≈0.670\nこれは加速因子 (Acceleration Factor) と呼ばれ、「Group 1の時間は、Group 2の時間の0.67倍になる」と解釈できます。つまり、Group 1の方が効果持続時間（イベント発生までの時間）が短い傾向にある、という結果です。（ただし、この差は統計的に有意ではありませんでした。）\n\n\n\n\n今回の分析から分かったことをまとめると、以下のようになります。\n\n頭痛薬の効果持続時間について、指数分布モデルを適用して分析した。\nグループ（Group 1 vs Group 2）による持続時間の差は、統計的に有意ではなかった (p = 0.2778)。\nモデル上は、Group 1の効果持続時間はGroup 2の約0.67倍と、短い傾向が示唆されたが、これは偶然の範囲内と言える。\n\nPROC LIFEREGの出力は一見複雑に見えますが、見るべきポイントを押さえれば、分析結果を深く理解することができます。次はdist=weibullを試して、AICを比較してみるのも面白いかもしれませんね！\n\n\n\nこれは、モデルがlog(時間)を扱っていることに直結します。\nモデルの基本形は以下の通りです。\n\nGroup 2 (基準): log(Time_G2) = Intercept\nGroup 1: log(Time_G1) = Intercept + β_G1\n\nここで、2つの式の差をとってみます。\nlog(Time_G1) - log(Time_G2) = β_G1\n対数の性質上、「引き算」は「割り算」に変換できます（log(a) - log(b) = log(a/b)）。\nlog(Time_G1 / Time_G2) = β_G1\n最後に、両辺をexp()してlogを外すと、\nTime_G1 / Time_G2 = exp(β_G1)\nこの式が最終的な答えです。Group 1の時間とGroup 2の時間の関係は、差（Time_G1 - Time_G2）ではなく**比（Time_G1 / Time_G2）**で表されていますね。\nこのexp(β_G1)が、前回解説した加速因子 (0.67) です。グループの効果は、基準となる時間を何倍に「加速」または「減速」させるか、という乗法的な（掛け算の）効果として解釈されるのです。"
  },
  {
    "objectID": "posts/statistics/2025/RAWデータ加工_Rename.html",
    "href": "posts/statistics/2025/RAWデータ加工_Rename.html",
    "title": "データセット作成のTips",
    "section": "",
    "text": "SASでデータ処理をしていると、時には「あれ？これってどういう意図があるんだろう？」と首をかしげるコードに出会うことがありますよね。今回は、そんな疑問を解消する、ちょっと高度だけど非常に便利なデータ変換テクニックをご紹介します！\n例として、次のようなSASコードを見てみましょう。\n*-----------------------------------------------------------------------------*;\n* DATA PROCESS ;\n*-----------------------------------------------------------------------------*;\n/* オリジナルデータセットから新しいデータセットを作成 */\ndata work.ProcessedData ;\n  /* 変数の長さと型を定義 */\n  length PatientID $15 VisitDate $10 Gender $1 GenderNum 8 AgeYears 8 UnitAge $5 ;\n  /* 元データセットを読み込み、特定変数をリネームして取り込む */\n  set work.RawData ( rename = (Gender = _Gender Age = _Age ) ) ;\n\n  /* 新しい変数の値を設定 */\n  PatientID = cats(\"PAT-\", _N_); /* 患者IDを自動生成 */\n  VisitDate = \"2024-06-15\" ; /* 仮の訪問日を設定 */\n\n  /* 年齢データの変換 */\n  AgeYears = input( _Age, best. ) ; /* _Age（元の年齢データ）を数値に変換 */\n  UnitAge = \"YEARS\" ; /* 年齢の単位を設定 */\n\n  /* 性別データの変換と数値化 */\n  if _Gender = \"1\" then Gender = \"M\" ; /* _Genderが\"1\"なら\"M\"（男性）に */\n  else if _Gender = \"2\" then Gender = \"F\" ; /* _Genderが\"2\"なら\"F\"（女性）に */\n  GenderNum = input( _Gender, best.) ; /* _Genderを数値としてGenderNumに格納 */\n\n  /* 新しいデータセットに残す変数を指定 */\n  keep PatientID VisitDate Gender GenderNum AgeYears UnitAge ;\n\nproc sort data=work.ProcessedData ;\n  by PatientID ; /* 患者IDでソート */\nrun ;\n\n---\n\ndata work.DAT9 ;\n  merge work.DAT9_1 work.DAT9_2 work.DAT9_3 work.DAT9_4 ;\n  by SUBJID ;\n\n  /* 日付・時刻データの変換例 */\n  /* 元データ: \"2023-01-01 10\" のような形式 */\n  FPAYDT  = input( substr(FPAYDTC, 1, 10), yymmdd10. ); /* 日付部分のみを抽出してSAS日付値に変換 */\n  PAYDT1  = input( substr(PAYDTC1, 1, 10), yymmdd10. ); /* 同上 */\n  PAYDT2  = input( substr(PAYDTC2, 1, 10), yymmdd10. ); /* 同上 */\n  \n  /* 完全な日時文字列を作成（例: \"2023-01-01 10:00\"）*/\n  _FPAYDTC = strip( FPAYDTC ) || \":00\" ; \n  _PAYDTC1 = strip( PAYDTC1 ) || \":00\" ;\n  _PAYDTC2 = strip( PAYDTC2 ) || \":00\" ;\n\n  /* 支払い期間に応じた時間差の計算 */\n  if PAYPD = '第1期' then do ;\n    ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC1, e8601dt19. ) ) / ( 60*60 ) , 1e-10 ); /* 時間単位の差分を計算 */\n  end ;\n  if PAYPD = '第2期' then do ;  \n    ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC2, e8601dt19. ) ) / ( 60*60 ), 1e-10 ) ; /* 時間単位の差分を計算 */\n  end ;\n\nrun ;\n\n---\n\ndata work.SCRCM ;\n  length SUBJID $12 SCRCMFL $1 ;\n  merge work.CM work.SCR;\n  by SBJID ;\n  SUBJID = SBJID ; /* 変数名を合わせる */\n\n  /* 日付形式の変換例 */\n  /* 元データ: \"YYYY/MM/DD\" -&gt; SASが扱える \"YYYY-MM-DD\" に変換 */\n  if CMSTDTC ^= \"\" then _CMSTDTC = tranwrd ( CMSTDTC , \"/\", \"-\" ) ;\n  if CMENDTC ^= \"\" then _CMENDTC = tranwrd ( CMENDTC , \"/\", \"-\" ) ;\n\n  /* 期間内に該当するかフラグを立てる */\n  if ( CMSTDTC ^= \"\" and CMENDTC ^= \"\" ) and input ( _CMSTDTC, yymmdd10. ) &lt;= SCRDT &lt;= input ( _CMENDTC, yymmdd10. ) then SCRCMFL = \"Y\" ;\n  /* 開始日または終了日と完全に一致する場合も対象 */\n  if SCRDT ^= . and ( input ( _CMSTDTC, yymmdd10. ) = SCRDT or SCRDT = input ( _CMENDTC, yymmdd10. )) then SCRCMFL = \"Y\" ;\n  /* 上記条件に当てはまらない場合は\"N\" */\n  if SCRCMFL = \"\" then SCRCMFL = \"N\" ;\n  /* 開始日または終了日が欠損している場合はフラグをクリア */\n  if ( CMSTDTC = \"\" or CMENDTC = \"\" ) and SCRCMFL ^= \"Y\" then SCRCMFL = \"\" ;\n  /* 開始日がSCRDTより未来の場合は\"N\" */\n  if CMSTDTC ^= \"\" and input ( _CMSTDTC, yymmdd10.) &gt; SCRDT then SCRCMFL = \"N\" ;\n\n  keep SUBJID SCRCMFL ;\nproc sort ;\n  by SUBJID decending SCRCMFL ;\nrun ;\nこのコード、特に注目してほしいのは、setステートメントの**renameオプションと、その後に続くGender = _Gender;のような処理、そして日付・時刻を扱う際に登場する様々な関数**です。「せっかくrenameで名前を変えたのに、なんでまた元の名前の変数に代入し直すの？」と感じるかもしれませんね。実はここに、データ処理のベストプラクティスが隠されているんです！\n\n\nまず、set work.RawData ( rename = (Gender = _Gender Age = _Age ) )の部分。 これは、元のデータセットwork.RawDataから変数を読み込む際に、Genderという変数名を一時的に_Genderに、Ageを_Ageにそれぞれ変更して、新しいデータセットwork.ProcessedDataに持ち込む、という指示です。\nなぜこんなことをするのでしょうか？\n\n\nこれが最も大きな理由です。多くの場合、元データ（ここではwork.RawData）のGender変数は「1（男性）」や「2（女性）」のような数値コードで格納されていることがあります。しかし、最終的に使いたいのは「M（Male）」や「F（Female）」のような、より直感的で標準化された文字データだったりします。\nこのコードでは、まさにその変換を行っています。\nif _Gender = \"1\" then Gender = \"M\" ;\n  else if _Gender = \"2\" then Gender = \"F\" ;\nここで、一時的に_Genderという名前で保持しておいた元の数値コードを参照し、新しいGender変数に変換後の「M」や「F」を代入しています。_Ageについても同様に、文字列として読み込まれた年齢データをinput関数を使って数値型のAgeYearsに変換しています。もしrenameで直接GenderやAgeとして読み込んでしまうと、このような元の値を使った条件分岐やデータ型変換が難しくなってしまいますよね。\n\n\n\n\nここで、renameオプションの働きをもう少し具体的に見てみましょう。\n元のデータセット work.RawData のイメージ:\n\n\n\nPatientID\nGender\nAge\nDiagnosis\n\n\nP001\n1\n35\n一般健診\n\n\nP002\n2\n48\n頭痛\n\n\nP003\n1\n22\n発熱\n\n\nP004\n2\n60\n高血圧\n\n\n\nこのwork.RawDataデータセットを、setステートメントで読み込む際に、次のように指定しています。\nset work.RawData ( rename = (Gender = _Gender Age = _Age ) ) ;\nこの一行が実行されると、work.ProcessedDataデータステップの内部では、Genderは_Genderとして、Ageは_Ageとして扱われます。つまり、データステップのその瞬間、変数は以下のように見えている、とイメージしてください。\ndata work.ProcessedData ステップ内部での変数の見え方（一時的）:\n\n\n\nPatientID\n_Gender\n_Age\nDiagnosis\n\n\nP001\n1\n35\n一般健診\n\n\nP002\n2\n48\n頭痛\n\n\nP003\n1\n22\n発熱\n\n\nP004\n2\n60\n高血圧\n\n\n\nこのように元の変数名を一時的に変更しておくことで、その後の処理で新しいGenderやAgeYearsといった変数を心置きなく作成できるわけです。\n\n\n\n提供されたコードには、日付や時刻の文字列をSASが認識できる数値（SAS日付値やSAS日時値）に変換するための様々な関数が使われています。これらは非常に頻繁に利用されるので、ぜひ使い方を覚えておきましょう。\n\n\nINPUT関数は、文字列をSASが扱える数値に変換するための万能選手です。特に日付や時刻の文字列を扱う際には、その文字列がどのような形式（フォーマット）であるかを指定する必要があります。\n\nYYYYMMDD10.: YYYY-MM-DD形式の文字列（例: “2023-01-01”）をSAS日付値に変換します。\n\n FPAYDT = input( substr(FPAYDTC, 1, 10), yymmdd10. );\n /* FPAYDTCが \"2023-01-01 10\" の場合、\"2023-01-01\" の部分だけを抽出して変換 */\n ```\n\n-   **`E8601DT19.`**: `YYYY-MM-DDTHH:MM:SS`または`YYYY-MM-DD HH:MM:SS`形式のISO 8601日時文字列（例: \"2023-01-01 10:00:00\"）をSAS日時値に変換します。SAS日時値は、1960年1月1日0時0分0秒からの秒数を表す数値です。\n\n``` {.sas eval=\"FALSE,\" code-line-numbers=\"true,\" code-overflow=\"wrap\"}     \n ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC1, e8601dt19. ) ) / ( 60*60 ) , 1e-10 );\n /* _FPAYDTCと_PAYDTC1（いずれも\"YYYY-MM-DD HH:MM\"形式）を日時値に変換し、その差を時間単位で計算 */ \n ```\n\n#### 2. `SUBSTR`関数\n\n`SUBSTR`関数は、\\*\\*文字列の一部を抜き出す（部分文字列を抽出する）\\*\\*ために使われます。\n\n``` {.sas eval=\"FALSE,\" code-line-numbers=\"true,\" code-overflow=\"wrap\"}        \nFPAYDT = input( substr(FPAYDTC, 1, 10), yymmdd10. );\n/* FPAYDTC（例: \"2023-01-01 10\"）の1文字目から10文字目（つまり\"2023-01-01\"）を抽出 */\nこの例では、日付と時間の情報が混ざった文字列から、日付の部分だけを取り出してINPUT関数に渡しています。\n\n\n\nSTRIP関数は、文字列の先頭や末尾にある余分な半角スペースを取り除くために使われます。特にファイルから読み込んだデータは、固定長形式などで不要なスペースが含まれていることがあるため、後の処理で問題を起こさないようにSTRIPで整形することが推奨されます。\n_FPAYDTC = strip( FPAYDTC ) || \":00\" ;\n/* FPAYDTCの末尾のスペースを取り除き、\"2023-01-01 10\" を \"2023-01-01 10:00\" のように変換 */\nこの例では、STRIPを使ってFPAYDTCから不要なスペースを削除し、それに:00を結合して、E8601DT19.フォーマットで読み取れる「時:分」の形式に整えています。\n\n\n\nTRANWRD関数は、文字列中の特定の文字列を別の文字列に置き換えるために使われます。\n_CMSTDTC = tranwrd ( CMSTDTC , \"/\", \"-\" ) ;\n/* CMSTDTC（例: \"2023/01/01\"）の \"/\" を \"-\" に置き換え、\"2023-01-01\" に変換 */\nこれは、元のデータの日付区切りがスラッシュ（/）なのに、SASの標準的な日付フォーマット（YYYYMMDD10.など）がハイフン（-）を要求する場合によく使われます。INPUT関数で正しく変換できるように、事前にTRANWRDで文字列を整形しているわけですね。\n\n\n\n\nこのように、setステートメントでのrenameオプション、そしてINPUT, SUBSTR, STRIP, TRANWRDといった関数を組み合わせることで、SASはどんな形式のデータでも柔軟に処理し、分析に適した形にクリーンアップできます。\n\n元の値を一時的に保持しつつ、\nデータ型や値を変換・整形し、\n新しい標準化された変数を作成する\n\nこの一連の流れを理解することで、より柔軟で堅牢なSASプログラムを書けるようになります。ぜひ皆さんのデータ処理にもこれらのテクニックを取り入れてみてくださいね！\nデータ処理は奥が深いですが、一つ一つのテクニックを理解していくと、どんどん楽しくなりますよ！何か他にSASに関する疑問があれば、いつでも聞いてくださいね！"
  },
  {
    "objectID": "posts/statistics/2025/RAWデータ加工_Rename.html#sasデータ処理の舞台裏renameと変数変換の賢いテクニック",
    "href": "posts/statistics/2025/RAWデータ加工_Rename.html#sasデータ処理の舞台裏renameと変数変換の賢いテクニック",
    "title": "データセット作成のTips",
    "section": "",
    "text": "SASでデータ処理をしていると、時には「あれ？これってどういう意図があるんだろう？」と首をかしげるコードに出会うことがありますよね。今回は、そんな疑問を解消する、ちょっと高度だけど非常に便利なデータ変換テクニックをご紹介します！\n例として、次のようなSASコードを見てみましょう。\n*-----------------------------------------------------------------------------*;\n* DATA PROCESS ;\n*-----------------------------------------------------------------------------*;\n/* オリジナルデータセットから新しいデータセットを作成 */\ndata work.ProcessedData ;\n  /* 変数の長さと型を定義 */\n  length PatientID $15 VisitDate $10 Gender $1 GenderNum 8 AgeYears 8 UnitAge $5 ;\n  /* 元データセットを読み込み、特定変数をリネームして取り込む */\n  set work.RawData ( rename = (Gender = _Gender Age = _Age ) ) ;\n\n  /* 新しい変数の値を設定 */\n  PatientID = cats(\"PAT-\", _N_); /* 患者IDを自動生成 */\n  VisitDate = \"2024-06-15\" ; /* 仮の訪問日を設定 */\n\n  /* 年齢データの変換 */\n  AgeYears = input( _Age, best. ) ; /* _Age（元の年齢データ）を数値に変換 */\n  UnitAge = \"YEARS\" ; /* 年齢の単位を設定 */\n\n  /* 性別データの変換と数値化 */\n  if _Gender = \"1\" then Gender = \"M\" ; /* _Genderが\"1\"なら\"M\"（男性）に */\n  else if _Gender = \"2\" then Gender = \"F\" ; /* _Genderが\"2\"なら\"F\"（女性）に */\n  GenderNum = input( _Gender, best.) ; /* _Genderを数値としてGenderNumに格納 */\n\n  /* 新しいデータセットに残す変数を指定 */\n  keep PatientID VisitDate Gender GenderNum AgeYears UnitAge ;\n\nproc sort data=work.ProcessedData ;\n  by PatientID ; /* 患者IDでソート */\nrun ;\n\n---\n\ndata work.DAT9 ;\n  merge work.DAT9_1 work.DAT9_2 work.DAT9_3 work.DAT9_4 ;\n  by SUBJID ;\n\n  /* 日付・時刻データの変換例 */\n  /* 元データ: \"2023-01-01 10\" のような形式 */\n  FPAYDT  = input( substr(FPAYDTC, 1, 10), yymmdd10. ); /* 日付部分のみを抽出してSAS日付値に変換 */\n  PAYDT1  = input( substr(PAYDTC1, 1, 10), yymmdd10. ); /* 同上 */\n  PAYDT2  = input( substr(PAYDTC2, 1, 10), yymmdd10. ); /* 同上 */\n  \n  /* 完全な日時文字列を作成（例: \"2023-01-01 10:00\"）*/\n  _FPAYDTC = strip( FPAYDTC ) || \":00\" ; \n  _PAYDTC1 = strip( PAYDTC1 ) || \":00\" ;\n  _PAYDTC2 = strip( PAYDTC2 ) || \":00\" ;\n\n  /* 支払い期間に応じた時間差の計算 */\n  if PAYPD = '第1期' then do ;\n    ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC1, e8601dt19. ) ) / ( 60*60 ) , 1e-10 ); /* 時間単位の差分を計算 */\n  end ;\n  if PAYPD = '第2期' then do ;  \n    ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC2, e8601dt19. ) ) / ( 60*60 ), 1e-10 ) ; /* 時間単位の差分を計算 */\n  end ;\n\nrun ;\n\n---\n\ndata work.SCRCM ;\n  length SUBJID $12 SCRCMFL $1 ;\n  merge work.CM work.SCR;\n  by SBJID ;\n  SUBJID = SBJID ; /* 変数名を合わせる */\n\n  /* 日付形式の変換例 */\n  /* 元データ: \"YYYY/MM/DD\" -&gt; SASが扱える \"YYYY-MM-DD\" に変換 */\n  if CMSTDTC ^= \"\" then _CMSTDTC = tranwrd ( CMSTDTC , \"/\", \"-\" ) ;\n  if CMENDTC ^= \"\" then _CMENDTC = tranwrd ( CMENDTC , \"/\", \"-\" ) ;\n\n  /* 期間内に該当するかフラグを立てる */\n  if ( CMSTDTC ^= \"\" and CMENDTC ^= \"\" ) and input ( _CMSTDTC, yymmdd10. ) &lt;= SCRDT &lt;= input ( _CMENDTC, yymmdd10. ) then SCRCMFL = \"Y\" ;\n  /* 開始日または終了日と完全に一致する場合も対象 */\n  if SCRDT ^= . and ( input ( _CMSTDTC, yymmdd10. ) = SCRDT or SCRDT = input ( _CMENDTC, yymmdd10. )) then SCRCMFL = \"Y\" ;\n  /* 上記条件に当てはまらない場合は\"N\" */\n  if SCRCMFL = \"\" then SCRCMFL = \"N\" ;\n  /* 開始日または終了日が欠損している場合はフラグをクリア */\n  if ( CMSTDTC = \"\" or CMENDTC = \"\" ) and SCRCMFL ^= \"Y\" then SCRCMFL = \"\" ;\n  /* 開始日がSCRDTより未来の場合は\"N\" */\n  if CMSTDTC ^= \"\" and input ( _CMSTDTC, yymmdd10.) &gt; SCRDT then SCRCMFL = \"N\" ;\n\n  keep SUBJID SCRCMFL ;\nproc sort ;\n  by SUBJID decending SCRCMFL ;\nrun ;\nこのコード、特に注目してほしいのは、setステートメントの**renameオプションと、その後に続くGender = _Gender;のような処理、そして日付・時刻を扱う際に登場する様々な関数**です。「せっかくrenameで名前を変えたのに、なんでまた元の名前の変数に代入し直すの？」と感じるかもしれませんね。実はここに、データ処理のベストプラクティスが隠されているんです！\n\n\nまず、set work.RawData ( rename = (Gender = _Gender Age = _Age ) )の部分。 これは、元のデータセットwork.RawDataから変数を読み込む際に、Genderという変数名を一時的に_Genderに、Ageを_Ageにそれぞれ変更して、新しいデータセットwork.ProcessedDataに持ち込む、という指示です。\nなぜこんなことをするのでしょうか？\n\n\nこれが最も大きな理由です。多くの場合、元データ（ここではwork.RawData）のGender変数は「1（男性）」や「2（女性）」のような数値コードで格納されていることがあります。しかし、最終的に使いたいのは「M（Male）」や「F（Female）」のような、より直感的で標準化された文字データだったりします。\nこのコードでは、まさにその変換を行っています。\nif _Gender = \"1\" then Gender = \"M\" ;\n  else if _Gender = \"2\" then Gender = \"F\" ;\nここで、一時的に_Genderという名前で保持しておいた元の数値コードを参照し、新しいGender変数に変換後の「M」や「F」を代入しています。_Ageについても同様に、文字列として読み込まれた年齢データをinput関数を使って数値型のAgeYearsに変換しています。もしrenameで直接GenderやAgeとして読み込んでしまうと、このような元の値を使った条件分岐やデータ型変換が難しくなってしまいますよね。\n\n\n\n\nここで、renameオプションの働きをもう少し具体的に見てみましょう。\n元のデータセット work.RawData のイメージ:\n\n\n\nPatientID\nGender\nAge\nDiagnosis\n\n\nP001\n1\n35\n一般健診\n\n\nP002\n2\n48\n頭痛\n\n\nP003\n1\n22\n発熱\n\n\nP004\n2\n60\n高血圧\n\n\n\nこのwork.RawDataデータセットを、setステートメントで読み込む際に、次のように指定しています。\nset work.RawData ( rename = (Gender = _Gender Age = _Age ) ) ;\nこの一行が実行されると、work.ProcessedDataデータステップの内部では、Genderは_Genderとして、Ageは_Ageとして扱われます。つまり、データステップのその瞬間、変数は以下のように見えている、とイメージしてください。\ndata work.ProcessedData ステップ内部での変数の見え方（一時的）:\n\n\n\nPatientID\n_Gender\n_Age\nDiagnosis\n\n\nP001\n1\n35\n一般健診\n\n\nP002\n2\n48\n頭痛\n\n\nP003\n1\n22\n発熱\n\n\nP004\n2\n60\n高血圧\n\n\n\nこのように元の変数名を一時的に変更しておくことで、その後の処理で新しいGenderやAgeYearsといった変数を心置きなく作成できるわけです。\n\n\n\n提供されたコードには、日付や時刻の文字列をSASが認識できる数値（SAS日付値やSAS日時値）に変換するための様々な関数が使われています。これらは非常に頻繁に利用されるので、ぜひ使い方を覚えておきましょう。\n\n\nINPUT関数は、文字列をSASが扱える数値に変換するための万能選手です。特に日付や時刻の文字列を扱う際には、その文字列がどのような形式（フォーマット）であるかを指定する必要があります。\n\nYYYYMMDD10.: YYYY-MM-DD形式の文字列（例: “2023-01-01”）をSAS日付値に変換します。\n\n FPAYDT = input( substr(FPAYDTC, 1, 10), yymmdd10. );\n /* FPAYDTCが \"2023-01-01 10\" の場合、\"2023-01-01\" の部分だけを抽出して変換 */\n ```\n\n-   **`E8601DT19.`**: `YYYY-MM-DDTHH:MM:SS`または`YYYY-MM-DD HH:MM:SS`形式のISO 8601日時文字列（例: \"2023-01-01 10:00:00\"）をSAS日時値に変換します。SAS日時値は、1960年1月1日0時0分0秒からの秒数を表す数値です。\n\n``` {.sas eval=\"FALSE,\" code-line-numbers=\"true,\" code-overflow=\"wrap\"}     \n ELATIME = round( ( input( _FPAYDTC, e8601dt19. ) - input( _PAYDTC1, e8601dt19. ) ) / ( 60*60 ) , 1e-10 );\n /* _FPAYDTCと_PAYDTC1（いずれも\"YYYY-MM-DD HH:MM\"形式）を日時値に変換し、その差を時間単位で計算 */ \n ```\n\n#### 2. `SUBSTR`関数\n\n`SUBSTR`関数は、\\*\\*文字列の一部を抜き出す（部分文字列を抽出する）\\*\\*ために使われます。\n\n``` {.sas eval=\"FALSE,\" code-line-numbers=\"true,\" code-overflow=\"wrap\"}        \nFPAYDT = input( substr(FPAYDTC, 1, 10), yymmdd10. );\n/* FPAYDTC（例: \"2023-01-01 10\"）の1文字目から10文字目（つまり\"2023-01-01\"）を抽出 */\nこの例では、日付と時間の情報が混ざった文字列から、日付の部分だけを取り出してINPUT関数に渡しています。\n\n\n\nSTRIP関数は、文字列の先頭や末尾にある余分な半角スペースを取り除くために使われます。特にファイルから読み込んだデータは、固定長形式などで不要なスペースが含まれていることがあるため、後の処理で問題を起こさないようにSTRIPで整形することが推奨されます。\n_FPAYDTC = strip( FPAYDTC ) || \":00\" ;\n/* FPAYDTCの末尾のスペースを取り除き、\"2023-01-01 10\" を \"2023-01-01 10:00\" のように変換 */\nこの例では、STRIPを使ってFPAYDTCから不要なスペースを削除し、それに:00を結合して、E8601DT19.フォーマットで読み取れる「時:分」の形式に整えています。\n\n\n\nTRANWRD関数は、文字列中の特定の文字列を別の文字列に置き換えるために使われます。\n_CMSTDTC = tranwrd ( CMSTDTC , \"/\", \"-\" ) ;\n/* CMSTDTC（例: \"2023/01/01\"）の \"/\" を \"-\" に置き換え、\"2023-01-01\" に変換 */\nこれは、元のデータの日付区切りがスラッシュ（/）なのに、SASの標準的な日付フォーマット（YYYYMMDD10.など）がハイフン（-）を要求する場合によく使われます。INPUT関数で正しく変換できるように、事前にTRANWRDで文字列を整形しているわけですね。\n\n\n\n\nこのように、setステートメントでのrenameオプション、そしてINPUT, SUBSTR, STRIP, TRANWRDといった関数を組み合わせることで、SASはどんな形式のデータでも柔軟に処理し、分析に適した形にクリーンアップできます。\n\n元の値を一時的に保持しつつ、\nデータ型や値を変換・整形し、\n新しい標準化された変数を作成する\n\nこの一連の流れを理解することで、より柔軟で堅牢なSASプログラムを書けるようになります。ぜひ皆さんのデータ処理にもこれらのテクニックを取り入れてみてくださいね！\nデータ処理は奥が深いですが、一つ一つのテクニックを理解していくと、どんどん楽しくなりますよ！何か他にSASに関する疑問があれば、いつでも聞いてくださいね！"
  },
  {
    "objectID": "posts/statistics/2025/SAS_Proc Transpose_arrayによるデータ転置.html",
    "href": "posts/statistics/2025/SAS_Proc Transpose_arrayによるデータ転置.html",
    "title": "Proc Transpose/ARRAYによる転置",
    "section": "",
    "text": "0.1 SAS初心者必見！横持ちデータを縦持ちに変換する3つの方法【ADaM対応・完全コード付き】\nこんにちは！SASプログラミングを学び始めたばかりの皆さん、データ形式の「横持ち」「縦持ち」で困ったことはありませんか？\n臨床試験データの標準モデルであるADaMでは、基本的に「1行に1つの分析結果」を格納する縦持ち形式が求められます。しかし、元のデータは被験者IDごとに検査結果が横に並んだ横持ち形式であることがよくあります。\n今回は、この横持ちデータを縦持ちに変換するための代表的な3つの方法を、ADaM変数（PARAM, AVAL, AVISITNなど）を使いながら、初心者向けにじっくり解説していきます。すべてのコードはコピー＆ペーストで実行可能です。\n\n0.1.1 準備：今回のサンプルデータとゴール\nまず、変換元となる横持ちデータ（source_data）を見てみましょう。被験者ごと、訪問ごと（VISIT 1, 2, 3）の検査値（TC: 総コレステロール, HDL: HDLコレステロール）が横に並んでいます。\n【変換元】横持ちデータ\nUSUBJID | TC_1 | HDL_1 | TC_2 | HDL_2 | TC_3 | HDL_3\n-------------------------------------------------------\nP01     | 212  | 50    | 224  | 64    | 204  | 73\nP02     | 206  | 58    | 208  | 63    | 212  | 58\nP03     | 221  | 47    | 236  | 70    | 242  | 38\nそして、このデータを以下の縦持ち形式に変換するのが今回のゴールです。\n【ゴール】縦持ちデータ (ADaM風)\nUSUBJID | PARAMN | PARAM     | AVISITN | AVAL\n-------------------------------------------------\nP01     | 1      | TC        | 1       | 212\nP01     | 1      | TC        | 2       | 224\nP01     | 1      | TC        | 3       | 204\nP01     | 2      | HDL       | 1       | 50\n...     | ...    | ...       | ...     | ...\nそれでは、具体的な変換方法を見ていきましょう！\n\n\n\n0.2 方法1：PROC TRANSPOSE - SASの変形マジック\nPROC TRANSPOSEは、その名の通りデータセットの行と列を入れ替える（転置する）ための強力なプロシジャです。\n\n0.2.1 ステップ1：まず転置してみる\nproc transpose data=source_data out=transposed_data(rename=(COL1=AVAL _NAME_=VARNAME));\n  by USUBJID;\n  var TC_1--TC_3 HDL_1--HDL_3;\nrun;\n\nproc transpose ...; run;: PROC TRANSPOSEの開始と終了を示します。\ndata=source_data: 変換の対象データセットを指定します。\nout=transposed_data(...): 変換後のデータセット名と、オプションを指定します。\nrename=(...): 自動生成される変数名を、より分かりやすい名前に変更します。\nby USUBJID;: 非常に重要なステートメントです。「どの変数を基準にグループ化するか」を指定します。今回はUSUBJIDごとに行をまとめたいので、USUBJIDを指定します。\nvar ...;: どの変数を縦持ちに変換（転置）するかを指定します。\n\n\n\n0.2.2 ステップ2：データステップでADaM変数に整える\n次に、この中間データをデータステップで加工し、VARNAMEからPARAMとAVISITNを作り出します。\ndata final_data_transpose;\n  set transposed_data;\n  \n  PARAM   = scan(VARNAME, 1, '_');\n  AVISITN = input(scan(VARNAME, 2, '_'), 8.);\n  \n  if PARAM = 'TC' then PARAMN = 1;\n  else if PARAM = 'HDL' then PARAMN = 2;\n  \n  drop VARNAME;\nrun;\nscan関数は、指定した区切り文字（今回は_）で文字列を分割してくれる便利な関数です。これでPROC TRANSPOSEを使った変換が完成です！\n\n\n\n0.3 方法2：ARRAYステートメント - 最もスマートな方法\nARRAYは**「複数の変数を一時的にグループ化して、番号で扱えるようにする」**機能です。 これを使いこなすと、非常に効率的なプログラミングが可能になります。\ndata final_data_array;\n  set source_data;\n  \n  /*【重要ポイント】\n   * '--'記法は変数の物理的順序に依存しエラーの原因になりうるため、\n   * ここでは変数をすべて明示的にリストアップします。\n   */\n  array aval_group{2, 3} TC_1 TC_2 TC_3 HDL_1 HDL_2 HDL_3; \n  \n  array params{2} $ _temporary_ ('TC', 'HDL');\n  array paramns{2} _temporary_ (1, 2);\n  \n  do j = 1 to 2; [cite: 434]\n    do i = 1 to 3; [cite: 435]\n      PARAMN  = paramns{j};\n      PARAM   = params{j};\n      AVISITN = i;\n      AVAL    = aval_group{j, i}; [cite: 436]\n      output; [cite: 437]\n    end;\n  end;\n  \n  keep USUBJID PARAMN PARAM AVISITN AVAL;\nrun;\n\narray aval_group{2, 3} ...;: 2行3列の二次元配列を定義します。 SASはリストされた変数を行優先で配列に格納します。\n_temporary_: このオプションで定義した配列は、データセットに出力されない一時的な作業領域として使えます。\ndo j = 1 to 2; do i = 1 to 3;: 外側のループで検査項目を、内側のループで訪問を回しています。\n\nこの方法は、一つのデータステップで完結するため、非常に効率的でコードもスッキリします。\n\n\n0.4 方法3：マクロ - 同じ作業はSASに任せよう\n最後は、地道なDATAステップの繰り返しを自動化するマクロを使った方法です。\n%macro reshape(param_nm, param_num);\n  %do visit = 1 %to 3;\n    data temp_&param_nm._&visit.;\n      set source_data;\n      PARAMN  = &param_num.;\n      PARAM   = \"&param_nm.\";\n      AVISITN = &visit.;\n      AVAL    = &param_nm._&visit;\n      keep USUBJID PARAMN PARAM AVISITN AVAL;\n    run;\n  %end;\n%mend reshape;\n\n%reshape(TC, 1);\n%reshape(HDL, 2);\n\ndata final_data_macro;\n  /*【重要ポイント】\n   * '--'記法はデータセットの物理的順序に依存しエラーの原因になるため、\n   * ここでは結合したいデータセット名をすべて明示的にリストアップします。\n   */\n  set temp_TC_1 temp_TC_2 temp_TC_3\n      temp_HDL_1 temp_HDL_2 temp_HDL_3;\nrun;\n\n%macro ... %mend;: このブロックで一連の処理をマクロとして定義します。\n%do ... %end;: マクロ内で繰り返し処理を行います。\n&param_nm.や&visit.はマクロ変数と呼ばれ、マクロ呼び出し時に指定された値に置き換わります。\n\nこの方法は、一つ一つの処理は単純ですが、中間データセットが複数作られるのが特徴です。\n\n\n0.5 まとめとAppendix\n3つの方法を紹介しましたが、いかがでしたか？\n\n\n\n\n\n\n\n\n\nアプローチ\nメリット\nデメリット\nこんな人におすすめ\n\n\nPROC TRANSPOSE\n大量の変数を一度に転置できる\n複数ステップが必要になることがある\nまずはSASのプロシジャに慣れたい人\n\n\nARRAY\nコードが簡潔で最も効率的\n配列の概念（特に二次元）に慣れが必要\nSASでのデータ加工を極めたい人\n\n\nマクロ\n繰り返し処理を自動化できる\n中間データセットが多くなりがち\n特定の定型処理を何度も再利用したい人\n\n\n\n初学者の皆さんは、まずはPROC TRANSPOSEから試してみて、慣れてきたらぜひARRAYステートメントに挑戦してみてください。\n\n0.5.1 Appendix: 全手法の完全なサンプルプログラム\n以下に、本稿で紹介した3つのアプローチについて、横持ちの疑似データ作成から縦持ちデータへ変換するまでの一連のSASプログラムを掲載します。\n/* ============================================== */\n/* 1. 変換元となる横持ちデータを作成              */\n/* ============================================== */\ndata source_data;\n  input USUBJID $ TC_1 HDL_1 TC_2 HDL_2 TC_3 HDL_3;\n  cards;\nP01 212 50 224 64 204 73\nP02 206 58 208 63 212 58\nP03 221 47 236 70 242 38\n;\nrun;\n\ntitle \"変換前の横持ちデータ (source_data)\";\nproc print data=source_data;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法1: PROC TRANSPOSE を使用したプログラム       */\n/* ============================================== */\nproc transpose data=source_data out=transposed_data(rename=(COL1=AVAL _NAME_=VARNAME));\n  by USUBJID;\n  var TC_1--TC_3 HDL_1--HDL_3;\nrun;\n\ndata final_data_transpose;\n  set transposed_data;\n  PARAM   = scan(VARNAME, 1, '_');\n  AVISITN = input(scan(VARNAME, 2, '_'), 8.);\n  if PARAM = 'TC' then PARAMN = 1;\n  else if PARAM = 'HDL' then PARAMN = 2;\n  drop VARNAME;\nrun;\n\nproc sort data=final_data_transpose;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法1 (PROC TRANSPOSE) による変換結果\";\nproc print data=final_data_transpose;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法2: ARRAY を使用したプログラム              */\n/* ============================================== */\ndata final_data_array;\n  set source_data;\n  \n  array aval_group{2, 3} TC_1 TC_2 TC_3 HDL_1 HDL_2 HDL_3;\n  \n  array params{2} $ _temporary_ ('TC', 'HDL');\n  array paramns{2} _temporary_ (1, 2);\n  \n  do j = 1 to 2;\n    do i = 1 to 3;\n      PARAMN  = paramns{j};\n      PARAM   = params{j};\n      AVISITN = i;\n      AVAL    = aval_group{j, i};\n      output;\n    end;\n  end;\n  \n  keep USUBJID PARAMN PARAM AVISITN AVAL;\nrun;\n\nproc sort data=final_data_array;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法2 (ARRAY) による変換結果\";\nproc print data=final_data_array;\nrun;\ntitle;\n\n/* ============================================== */\n/* 手法3: マクロを使用したプログラム              */\n/* ============================================== */\n%macro reshape(param_nm, param_num);\n  %do visit = 1 %to 3;\n    data temp_&param_nm._&visit.;\n      set source_data;\n      PARAMN  = &param_num.;\n      PARAM   = \"&param_nm.\";\n      AVISITN = &visit.;\n      AVAL    = &param_nm._&visit;\n      \n      keep USUBJID PARAMN PARAM AVISITN AVAL;\n    run;\n  %end;\n%mend reshape;\n\n%reshape(TC, 1);\n%reshape(HDL, 2);\n\ndata final_data_macro;\n  set temp_TC_1 temp_TC_2 temp_TC_3\n      temp_HDL_1 temp_HDL_2 temp_HDL_3;\nrun;\n\nproc sort data=final_data_macro;\n  by USUBJID PARAMN AVISITN;\nrun;\n\ntitle \"手法3 (マクロ) による変換結果\";\nproc print data=final_data_macro;\nrun;\ntitle;\n\nproc datasets lib=work nolist;\n  delete temp_:;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html",
    "href": "posts/statistics/2025/SASによる便利関数1.html",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "CATS関数\nCATX関数\nWHICHN・WHICHC関数\nCHOOSEN・CHOOSEC関数\nCOALESCE・COALESCEC関数\nVVALUE・VVALUEX関数\nCMISS関数\nIFN・IFC関数\nCALL MISSING\nCALL SYMPUTX\n\nSASプログラミングで頻繁に使用される便利な関数を、実用的なプログラム例とともに解説します。\n\n\n機能： 複数の文字列を連結し、各引数の前後の空白を自動削除\ndata example1;     name = \"田中\";     id = \"001\";     dept = \"営業部\";          /* 従来の方法 */     result1 = trim(name) || trim(id) || trim(dept);          /* CATS関数を使用 */     result2 = cats(name, id, dept);          put result1= result2=; run;\n出力： result1=田中001営業部 result2=田中001営業部\nCATS関数は自動的に前後の空白を削除するため、TRIMやLEFT関数が不要になり、コードがシンプルになります。\n\n\n\n機能： 指定した区切り文字で複数の文字列を連結\ndata example2;     year = 2025;     month = 6;     day = 16;          /* 日付文字列の作成 */     date_slash = catx(\"/\", year, month, day);     date_hyphen = catx(\"-\", year, month, day);          /* CSVフォーマットの作成 */     csv_line = catx(\",\", \"田中太郎\", 30, \"東京都\");          put date_slash= date_hyphen= csv_line=; run;\n出力： date_slash=2025/6/16 date_hyphen=2025-6-16 csv_line=田中太郎,30,東京都\n\n\n\n機能： 指定した値がリストの何番目にあるかを返す\ndata ae_severity;     input pt $ severity $;          /* 重篤度レベルをコード化 */     severity_code = whichc(severity, \"軽度\", \"中等度\", \"重度\", \"重篤\");          /* グレード分類への変換 */     ctcae_grade = whichc(severity, \"Grade1\", \"Grade2\", \"Grade3\", \"Grade4\", \"Grade5\");      datalines; 頭痛 軽度 発熱 中等度 呼吸困難 重度 ; run;\npt=頭痛 severity=軽度 severity_code=1 ctcae_grade=0\npt=発熱 severity=中等度 severity_code=2 ctcae_grade=0\npt=呼吸困難 severity=重度 severity_code=3 ctcae_grade=0\n\nseverity_code：指定したリスト内での位置を返す\n\n“軽度” → 1番目 → 1\n“中等度” → 2番目 → 2\n“重度” → 3番目 → 3\n\n\n\n\nctcae_grade：CTCAEグレード用のリストにマッチしないため全て0\n\nデータの”軽度”、“中等度”、“重度”は”Grade1”、“Grade2”等とマッチしない\nマッチしない場合はWHICHC関数は0を返す\n\n\n\n\n\n機能： インデックス番号に基づいてリストから値を選択\ndata example4;     do i = 1 to 4;         /* 数値版：CHOOSEN */         threshold = choosen(i, 60, 70, 80, 90);                  /* 文字版：CHOOSEC */         grade = choosec(i, \"D\", \"C\", \"B\", \"A\");                  put i= threshold= grade=;     end; run;\n出力： i=1 threshold=60 grade=D i=2 threshold=70 grade=C i=3 threshold=80 grade=B i=4 threshold=90 grade=A\n・Y番目のXの値を返す。\n・第2引数以降に数値型の変数または値を指定する場合はCHOOSEN関数を用いる。\n・第2引数以降に文字型の変数または値を指定する場合はCHOOSEC関数を用いる。\n\n\n\n機能： 最初の非欠損値を返す\n/* サンプルデータの作成 */ data sample_data;     input ID X1 $ X2 $ X3 $;     datalines; 1 AA    BB 2    CC DD 3       EE 4 FF     5           6 GG HH II ; run;  /* 方法1: IF-ELSE文を使用 */ data result1;     set sample_data;     length Y $2.;     if X1^=\"\" then Y=X1;     else if X2^=\"\" then Y=X2;     else if X3^=\"\" then Y=X3; run;  /* 方法2: COALESCEC関数を使用 */ data result2;     set sample_data;     length Y $2.;     Y = coalescec(X1, X2, X3); run;\nポイント：\n\nこの関数は「引数のうち最初に欠損値以外で登場する値を返す」という機能を持っています。\nCOALESCE： 数値の場合、欠損値（.）をスキップして最初の有効な値（85）を返す\nCOALESCEC： 文字の場合、空白をスキップして最初の有効な文字列を返す\n\n\n\n\n機能： フォーマットが適用された値を文字列として取得\ndata DT1;   format X yymmdd10.;   X = '13jun2017'd; run;   data DT2;   set DT1;   length Y $20.;   Y = put( X, yymmdd10.); run;   data DT2;   set DT1;   length Y1 Y2 $20.;    /* vvalue関数を使った例 */   Y1 = vvalue( X );    /* vvaluex関数を使った例 */   Y2 = vvaluex( \"X\" );  run;\n\nY1 = vvalue( X )：「 vvalue( X ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。\nY2 = vvaluex( “X” );vvaluex も vvalue と同じ機能を持っているのですが、違いは以下の通り。\nvvalue( X )      … 変数名を指定\nvvaluex( “X” )  … 変数名を表す文字値を指定\nつまり、「 vvaluex( “X” ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。\n\n\n\n\n機能： 欠損値の個数をカウント\ndata example7;     input name $ age height weight;          missing_count = cmiss(age, height, weight);     complete_data = (missing_count = 0);          put name= missing_count= complete_data=;      datalines; 田中 25 170 65 佐藤 . 165 . 山田 30 . 70 ; run;\n出力： name=田中 missing_count=0 complete_data=1 name=佐藤 missing_count=2 complete_data=0 name=山田 missing_count=1 complete_data=0\n\n\n\n機能： 条件に基づいて値を返す三項演算子\ndata DT1;    length X1 $10.;    X1=\"YES\"; output;    X1=\"NO\"; output; run;  #Before data DT2;    set DT1;    if X1 = \"YES\" then X2=1;    else  X2=0; run;  #After data DT2;    set DT1;    X2 = ifn(X1=\"YES\",1,0); run;\nRのifelse関数みたいな気持ち。\n\n\n\n機能： 複数の変数を一度に欠損値に設定\ndata example9;     name = \"田中\";     age = 25;     score = 85;          /* 条件に応じて全データを欠損値に */     if age &lt; 20 then call missing(of name age score);          put name= age= score=; run;\nこのSASコードはCALL MISSINGルーチンを使って、条件に応じて複数の変数を一度に欠損値に設定する例です。\n\n\n\n機能： データステップ内でマクロ変数を作成・更新\ndata example10;     input dept $ sales;          /* 部門別に動的にマクロ変数を作成 */     call symputx(cats(\"sales_\", dept), sales);          /* 最大売上をマクロ変数に格納 */     retain max_sales;     if _n_ = 1 then max_sales = sales;     else max_sales = max(max_sales, sales);     if  _EOF then call symputx(\"OBS\", _N_);      datalines; 営業 1200 技術 800 総務 300 ; run;  /* データステップ終了後に最大値を取得 */ data _null_;     set example10 end=last;     retain max_sales;     if _n_ = 1 then max_sales = sales;     else max_sales = max(max_sales, sales);     if last then call symputx(\"max_sales_total\", max_sales); run;  %put &sales_営業 &sales_技術 &sales_総務; %put &max_sales_total;\n出力： 1200 800 300 1200\nこれらの関数を使いこなすことで、SASプログラミングの効率と可読性が大幅に向上します。特にデータクリーニングや条件分岐処理において威力を発揮する関数群です。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#cats関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#cats関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 複数の文字列を連結し、各引数の前後の空白を自動削除\ndata example1;     name = \"田中\";     id = \"001\";     dept = \"営業部\";          /* 従来の方法 */     result1 = trim(name) || trim(id) || trim(dept);          /* CATS関数を使用 */     result2 = cats(name, id, dept);          put result1= result2=; run;\n出力： result1=田中001営業部 result2=田中001営業部\nCATS関数は自動的に前後の空白を削除するため、TRIMやLEFT関数が不要になり、コードがシンプルになります。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#catx関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#catx関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 指定した区切り文字で複数の文字列を連結\ndata example2;     year = 2025;     month = 6;     day = 16;          /* 日付文字列の作成 */     date_slash = catx(\"/\", year, month, day);     date_hyphen = catx(\"-\", year, month, day);          /* CSVフォーマットの作成 */     csv_line = catx(\",\", \"田中太郎\", 30, \"東京都\");          put date_slash= date_hyphen= csv_line=; run;\n出力： date_slash=2025/6/16 date_hyphen=2025-6-16 csv_line=田中太郎,30,東京都"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#whichnwhichc関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#whichnwhichc関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 指定した値がリストの何番目にあるかを返す\ndata ae_severity;     input pt $ severity $;          /* 重篤度レベルをコード化 */     severity_code = whichc(severity, \"軽度\", \"中等度\", \"重度\", \"重篤\");          /* グレード分類への変換 */     ctcae_grade = whichc(severity, \"Grade1\", \"Grade2\", \"Grade3\", \"Grade4\", \"Grade5\");      datalines; 頭痛 軽度 発熱 中等度 呼吸困難 重度 ; run;\npt=頭痛 severity=軽度 severity_code=1 ctcae_grade=0\npt=発熱 severity=中等度 severity_code=2 ctcae_grade=0\npt=呼吸困難 severity=重度 severity_code=3 ctcae_grade=0\n\nseverity_code：指定したリスト内での位置を返す\n\n“軽度” → 1番目 → 1\n“中等度” → 2番目 → 2\n“重度” → 3番目 → 3\n\n\n\n\nctcae_grade：CTCAEグレード用のリストにマッチしないため全て0\n\nデータの”軽度”、“中等度”、“重度”は”Grade1”、“Grade2”等とマッチしない\nマッチしない場合はWHICHC関数は0を返す"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#choosenchoosec関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#choosenchoosec関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： インデックス番号に基づいてリストから値を選択\ndata example4;     do i = 1 to 4;         /* 数値版：CHOOSEN */         threshold = choosen(i, 60, 70, 80, 90);                  /* 文字版：CHOOSEC */         grade = choosec(i, \"D\", \"C\", \"B\", \"A\");                  put i= threshold= grade=;     end; run;\n出力： i=1 threshold=60 grade=D i=2 threshold=70 grade=C i=3 threshold=80 grade=B i=4 threshold=90 grade=A\n・Y番目のXの値を返す。\n・第2引数以降に数値型の変数または値を指定する場合はCHOOSEN関数を用いる。\n・第2引数以降に文字型の変数または値を指定する場合はCHOOSEC関数を用いる。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#coalescecoalescec関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#coalescecoalescec関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 最初の非欠損値を返す\n/* サンプルデータの作成 */ data sample_data;     input ID X1 $ X2 $ X3 $;     datalines; 1 AA    BB 2    CC DD 3       EE 4 FF     5           6 GG HH II ; run;  /* 方法1: IF-ELSE文を使用 */ data result1;     set sample_data;     length Y $2.;     if X1^=\"\" then Y=X1;     else if X2^=\"\" then Y=X2;     else if X3^=\"\" then Y=X3; run;  /* 方法2: COALESCEC関数を使用 */ data result2;     set sample_data;     length Y $2.;     Y = coalescec(X1, X2, X3); run;\nポイント：\n\nこの関数は「引数のうち最初に欠損値以外で登場する値を返す」という機能を持っています。\nCOALESCE： 数値の場合、欠損値（.）をスキップして最初の有効な値（85）を返す\nCOALESCEC： 文字の場合、空白をスキップして最初の有効な文字列を返す"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#vvaluevvaluex関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#vvaluevvaluex関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： フォーマットが適用された値を文字列として取得\ndata DT1;   format X yymmdd10.;   X = '13jun2017'd; run;   data DT2;   set DT1;   length Y $20.;   Y = put( X, yymmdd10.); run;   data DT2;   set DT1;   length Y1 Y2 $20.;    /* vvalue関数を使った例 */   Y1 = vvalue( X );    /* vvaluex関数を使った例 */   Y2 = vvaluex( \"X\" );  run;\n\nY1 = vvalue( X )：「 vvalue( X ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。\nY2 = vvaluex( “X” );vvaluex も vvalue と同じ機能を持っているのですが、違いは以下の通り。\nvvalue( X )      … 変数名を指定\nvvaluex( “X” )  … 変数名を表す文字値を指定\nつまり、「 vvaluex( “X” ) 」で変数Xに割り当てられているFORMAT「YYMMDD10.」を使って文字変換した値「2017-06-13」を返しています。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#cmiss関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#cmiss関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 欠損値の個数をカウント\ndata example7;     input name $ age height weight;          missing_count = cmiss(age, height, weight);     complete_data = (missing_count = 0);          put name= missing_count= complete_data=;      datalines; 田中 25 170 65 佐藤 . 165 . 山田 30 . 70 ; run;\n出力： name=田中 missing_count=0 complete_data=1 name=佐藤 missing_count=2 complete_data=0 name=山田 missing_count=1 complete_data=0"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#ifnifc関数",
    "href": "posts/statistics/2025/SASによる便利関数1.html#ifnifc関数",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 条件に基づいて値を返す三項演算子\ndata DT1;    length X1 $10.;    X1=\"YES\"; output;    X1=\"NO\"; output; run;  #Before data DT2;    set DT1;    if X1 = \"YES\" then X2=1;    else  X2=0; run;  #After data DT2;    set DT1;    X2 = ifn(X1=\"YES\",1,0); run;\nRのifelse関数みたいな気持ち。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#call-missing",
    "href": "posts/statistics/2025/SASによる便利関数1.html#call-missing",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： 複数の変数を一度に欠損値に設定\ndata example9;     name = \"田中\";     age = 25;     score = 85;          /* 条件に応じて全データを欠損値に */     if age &lt; 20 then call missing(of name age score);          put name= age= score=; run;\nこのSASコードはCALL MISSINGルーチンを使って、条件に応じて複数の変数を一度に欠損値に設定する例です。"
  },
  {
    "objectID": "posts/statistics/2025/SASによる便利関数1.html#call-symputx",
    "href": "posts/statistics/2025/SASによる便利関数1.html#call-symputx",
    "title": "SASによる便利関数1",
    "section": "",
    "text": "機能： データステップ内でマクロ変数を作成・更新\ndata example10;     input dept $ sales;          /* 部門別に動的にマクロ変数を作成 */     call symputx(cats(\"sales_\", dept), sales);          /* 最大売上をマクロ変数に格納 */     retain max_sales;     if _n_ = 1 then max_sales = sales;     else max_sales = max(max_sales, sales);     if  _EOF then call symputx(\"OBS\", _N_);      datalines; 営業 1200 技術 800 総務 300 ; run;  /* データステップ終了後に最大値を取得 */ data _null_;     set example10 end=last;     retain max_sales;     if _n_ = 1 then max_sales = sales;     else max_sales = max(max_sales, sales);     if last then call symputx(\"max_sales_total\", max_sales); run;  %put &sales_営業 &sales_技術 &sales_総務; %put &max_sales_total;\n出力： 1200 800 300 1200\nこれらの関数を使いこなすことで、SASプログラミングの効率と可読性が大幅に向上します。特にデータクリーニングや条件分岐処理において威力を発揮する関数群です。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "",
    "text": "How Not to SAS: Avoiding Common Pitfalls and Bad Habits\nSAS is a powerful tool for data analysis, but its flexibility can sometimes lead you into developing bad programming habits. Although these shortcuts might not break your programs immediately, they can lead to inefficient, error-prone, and hard-to-maintain code. This paper identifies common pitfalls and provides straightforward, practical solutions to avoid them.\nEffective code organization is foundational to successful SAS programming. Yet, it’s easy to overlook best practices and fall into poor habits. Here are three common pitfalls you should avoid:"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#本記事では以下の文献を参考にsasのpitfallsとbad-hatibsをまとめます",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#本記事では以下の文献を参考にsasのpitfallsとbad-hatibsをまとめます",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "",
    "text": "How Not to SAS: Avoiding Common Pitfalls and Bad Habits\nSAS is a powerful tool for data analysis, but its flexibility can sometimes lead you into developing bad programming habits. Although these shortcuts might not break your programs immediately, they can lead to inefficient, error-prone, and hard-to-maintain code. This paper identifies common pitfalls and provides straightforward, practical solutions to avoid them.\nEffective code organization is foundational to successful SAS programming. Yet, it’s easy to overlook best practices and fall into poor habits. Here are three common pitfalls you should avoid:"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#code-organization-readability",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#code-organization-readability",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "2 CODE ORGANIZATION ＆ READABILITY",
    "text": "2 CODE ORGANIZATION ＆ READABILITY\nGood Practice\n\nUse Clear and concise SAS Comments in SAS Code\n\nblock comments like /* my comment */\nsingle-line comments like * my comment;\n\n\n/* my program comment */\ndata one; set sashelp.cars;\n*subset to certain car types - SUV;\nwhere type = \"SUV\";\nrun;\nBad Tips\n\nWRITE ALL YOUR CODE IN ONE LONG, CONTINUOUS BLOCK\n\n「コードを延々とスクロールして見ることは、忍耐力と視力を試すエキサイティングな方法だから」。コードを1つの巨大なブロックとして書くのは、よくある有害な習慣です。このような方法はデバッグやコード修正を煩雑にし、エラーが見逃される可能性を高めます。\n推奨される方法：モジュラーにコードを書く\nコードをより小さく、論理的なステップに分割し、明確なヘッダーやモジュラーセクションを使って各ブロックの目的を定義しましょう。モジュラーコードは読みやすさを向上させるだけでなく、他のプロジェクトや分析でセクションを簡単に再利用でき、貴重な時間を節約できます。\n/* 悪い例：すべてが1つのブロック */\ndata work.analysis;set mylib.rawdata;if age &gt;= 18 and status='Active';length category $20;if score &gt;= 90 then category='Excellent';else if score &gt;= 80 then category='Good';else category='Needs Improvement';run;proc sort data=work.analysis;by category descending score;run;proc means data=work.analysis mean std;class category;var score;output out=work.summary mean=avg_score std=std_score;run;\n\n/* 良い例：モジュラー構造 */\n/*************************************/\n/* Step 1: Data Filtering & Cleanup */\n/*************************************/\ndata work.filtered_data;\n    set mylib.rawdata;\n    where age &gt;= 18 and status = 'Active';\nrun;\n\n/********************************/\n/* Step 2: Category Assignment */\n/********************************/\ndata work.categorized_data;\n    set work.filtered_data;\n    length category $20;\n    \n    if score &gt;= 90 then category = 'Excellent';\n    else if score &gt;= 80 then category = 'Good';\n    else category = 'Needs Improvement';\nrun;\n\n/************************/\n/* Step 3: Data Sorting */\n/************************/\nproc sort data=work.categorized_data;\n    by category descending score;\nrun;\n\n/****************************/\n/* Step 4: Summary Analysis */\n/****************************/\nproc means data=work.categorized_data mean std;\n    class category;\n    var score;\n    output out=work.summary \n           mean=avg_score \n           std=std_score;\nrun;\nGood Practice：\n\nUse modular, structured code\n\nclearly separate different steps with comments\nさっきと同じことですね。\n\n\nBad Tips：\n\nUSE UNCLEAR OR ARBITRARY VARIABLE NAMES （不明確または恣意的な変数名を使用する）\n\nVAR1やXのような暗号的な変数名を使うことは、あなたのコードを、あなた自身や後にそのコードを引き継ぐ人にとって解けないパズルゲームに変えてしまいます。VAR1、X、TEMPのような貧弱な変数名を選択することは、可読性を低下させ、コードに混乱をもたらします（Program 2）。また、汎用的な名前は、エラーや結果の誤解釈の可能性を高めます。\n推奨：意味のある説明的な変数名を使用する\ndata new;\n    set old;\n    x = a * b;\n    y = x + c;\n    if z &gt; 10 then flag = 1;\n    temp = var1 / var2;\nrun;\nGood Practice：Use meaningful and descriptive variable names\n意味のある説明的な変数名（Xの代わりにCustomerAgeなど）を使用することで、あなたや同僚が各変数の目的と内容を素早く把握できるようになります（Program 3）。アンダースコア（customer_age）やキャメルケース（CustomerAge）などの一貫した命名規則を採用することで、さらに明確性が向上します。明確に命名された変数は、デバッグを簡素化し、分析中のエラーの可能性を大幅に削減します。\ndata salaryinfo2021;\n    set salaryinfo2020;\n    newsalary = oldsalary + increase;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#debugging-error-handling",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#debugging-error-handling",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "3 DEBUGGING ＆ ERROR HANDLING",
    "text": "3 DEBUGGING ＆ ERROR HANDLING\nProper debugging and error handling are critical for creating reliable SAS programs. Here are common pitfalls and the best practices you should follow:\nBad Tips:\n\nIGNORING THE SAS LOG WINDOW\n\nRed text is just a suggestion. Who needs to debug when you can keep running the code? Ignoring the log window means missing critical information about errors and warnings, causing unnoticed mistakes and incorrect results.\nGood Practices:\n\nCheck all the messages in your log\n\nAlways check for ERROR, WARNING, and NOTE messages in your log. Each of these messages can indicate fatal failures in your code . Understanding SAS Log Messages:\n\nERROR: Critical issues that prevent SAS from executing your code. Your results are incomplete or incorrect until these are resolved.\nWARNING: Potential issues that SAS identifies but doesn’t stop execution. These should be reviewed and addressed to ensure accuracy.\nNOTE: Informational messages about code execution. These offer insights into dataset creation, memory usage, and other operational details.\n\nBad Tips:\n\nNEVER USE DEBUGGING OPTIONS\n\nSkipping debugging options is a great way to keep your coding life exciting—who doesn’t love spending hours chasing hidden bugs? Avoiding the use of debugging options can significantly hinder your ability to troubleshoot and resolve standard SAS code and macro-related issues efficiently.\nGood Practices:\n\nUse system options to help your debug SAS code\n\n便利なGlobal option\n\nMSGLEVEL=I: Provides additional informational messages in the log, especially useful when merging datasets to identify issues such as mismatches or data alignment problems.（ndefined）\nSOURCE: Displays the original SAS statements in the log.\nSOURCE2: Shows included SAS code from %INCLUDE statements.\nFMTERR: Issues an error if a specified format cannot be found.\nDSNFERR: Issues an error when a referenced dataset does not exist.\nOBS=0: Compiles the program without executing it, useful for syntax checking.\nNOREPLACE: Prevents accidental overwriting of existing datasets.\n\nプログラム開発時（デバック環境）と本番環境実行時でglobal optionを使い分けることができると上級者になれるかもしれないですね。\noptions MSGLEVEL=I \n        SOURCE \n        SOURCE2 \n        FMTERR \n        DSNFERR \n        OBS=0 \n        NOREPLACE;\nマクロ実行時は以下のglobal optionが役に立つ。\nUse debugging options specifically designed for macros: OPTIONS MPRINT SYMBOLGEN MLOGIC;\n\nMPRINT: Displays the actual SAS statements generated by macro execution, helping you identify issues within macros.\nSYMBOLGEN: Shows the resolution of macro variables, assisting you in confirming that macro variables resolve correctly.\nMLOGIC: Provides detailed information about macro execution, including macro parameter values and logical branching, useful for troubleshooting complex macro logic.\n\n/* Turn on options */\noptions mprint symbolgen mlogic mautosource mcompilenote=ALL;\nBad Tips:\n\nRUNNING CODE WITHOUT VERIFYING INPUT DATA\n\nJust assume your dataset is perfect—because real-world data is always flawless, right? Trusting imported data without verification can lead to incorrect analyses, wasted time, and unreliable results.\nGood Practices:\nAssume all data is “guilty until proven innocent”\n\nInspect dataset properties using PROC CONTENTS, PROC MEANS, and PROC FREQ before analysis.\nValidate key uniqueness, check for missing values, and confirm data quality before merging datasets.\nCheck for numeric-to-character conversions and unexpected results to avoid unintended data type changes and associated analytical errors."
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#data-management-mistakes",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#data-management-mistakes",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "4 DATA MANAGEMENT MISTAKES",
    "text": "4 DATA MANAGEMENT MISTAKES\nEfficient data management is crucial in SAS programming to avoid data loss, facilitate easy retrieval, and ensure accurate analyses. Here are some common mistakes to avoid and best practices to adopt:\nBad Tips:\n\nSTORE ALL YOUR DATA IN WORK\n\nBecause who doesn’t enjoy the adrenaline rush of potentially losing hours of work? Storing all data in the temporary WORK library is risky because data stored there is deleted once your SAS session ends. This practice can lead to significant data loss, especially if you encounter unexpected session closures or interruptions.\nGood Practices:\n\nStore important data in permanent libraries\n\nStore important datasets in permanent libraries to ensure data persistence beyond the current session. Permanent libraries help secure your data, enabling long-term storage, sharing across sessions, and preventing accidental data loss.\nBAD TIP:\n\nAVOID USING LIBRARIES Why make things easy when you can spend extra hours hunting for files? Avoiding the use of libraries can lead to disorganized file management, making it challenging to locate datasets and maintain clean project structures.\n\nGood Practice:\n\nCreate and use SAS libraries Use SAS libraries to streamline data management by logically grouping related datasets. Clearly named and structured libraries improve data accessibility, simplify data sharing, and enhance project collaboration.\n\nBAD TIP:\n\nRUNNING CODE ON PRODUCTION DATABASE WITHOUT TESTING IT FIRST Nothing spices up the workday quite like taking unnecessary risks with live data! Running untested code directly on a production database risks data integrity, can cause significant disruptions, and might lead to costly errors or downtime.\n\nGood Practice:\n\nUse a development or test environment for creating code\nAlways test your code thoroughly in a safe, isolated environment before deploying it to production.Comprehensive testing helps identify potential issues early, ensuring that your code operates reliably and safeguards the production environment."
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#working-with-dates-times-in-sas",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#working-with-dates-times-in-sas",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "5 WORKING WITH DATES ＆ TIMES IN SAS",
    "text": "5 WORKING WITH DATES ＆ TIMES IN SAS\nAccurate handling of dates and times is critical for reliable analyses in SAS. Mistakes in this area can lead to serious analytical errors and confusion. Here are common pitfalls and best practices to adopt:\nUNDERSTANDING SAS DATES\nSAS dates are numeric values representing the number of days since January 1, 1960. This numeric representation simplifies calculations involving dates, such as finding differences between two dates or shifting dates by specific intervals.\nExample:\n\nJanuary 1, 1960, is represented as 0.\nJanuary 2, 1960, is represented as 1.\nDecember 31, 1959, is represented as -1. When printed or displayed, SAS applies date formats to convert these numeric values into readable dates.\n\ndata _null_;\n today_date = today();\n put today_date= date9.;\nrun;\n\ntoday_date=17MAR2025\nGood Practice:\n\nEfficiently handle date values\n\nSAS dates, times, and datetime values are stored as numbers, making them ideal for calculations and comparisons.\nUse the DATEPART(datetime_variable) function to easily extract date values from datetime variables.\nUtilize the INTNX function for precise date shifting, such as adjusting to the first day of the next month.\n\ndata one;\ndtvalue=2064365417;\nStartDate=put(datepart(dtvalue), date9.);\nEndDate=put(intnx('DAY', datepart(dtvalue), 3), date9.);\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#automationreusability",
    "href": "posts/statistics/2025/SASプログラミングにおけるPitfalls.html#automationreusability",
    "title": "SASプログラミングのPitfalls and Bad Habits",
    "section": "6 AUTOMATION＆REUSABILITY",
    "text": "6 AUTOMATION＆REUSABILITY\nAutomation and reuse of code are essential for improving efficiency, accuracy, and maintainability in your SAS workflows. Here are two common pitfalls to avoid and best practices to adopt:\nここは、基本的にマクロを使おうという趣旨。原文を参照。\n## Bad\n\ndata report1;\n set sales;\n where year = 2025;\nrun;\ndata report2;\n set expenses;\n where year = 2025;\nrun;\n## Good\n%let report_year = 2025;\ndata report1;\n set sales;\n where year = &report_year;\nrun;\ndata report2;\n set expenses;\n where year = &report_year;\nrun;\n## Bad\n\nproc means data=dataset1;\n var sales;\nrun;\nproc means data=dataset2;\n var sales;\nrun;\n## Good\n%macro summarize_sales(dataset);\nproc means data=&dataset;\n var sales;\nrun;\n%mend;\n%summarize_sales(dataset1);\n%summarize_sales(dataset2);"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "",
    "text": "大阪SASユーザー総会の下記資料が大変勉強になるので、自分の備忘録用にコピペさせていただきた。基本的に下記資料をみればよい。\n\nThink Framework"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#はじめに",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#はじめに",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.1 はじめに",
    "text": "2.1 はじめに\nSASプログラミングにおいて、毎回同じような処理を一から書くのは非効率的です。本記事では、Yugo Mikiさんの「Think Framework」の知見を参考に、SASプログラムをフレームワーク化することで、開発効率を大幅に向上させる手法について解説します。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#library-vs-framework根本的な発想の違い",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#library-vs-framework根本的な発想の違い",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.2 Library vs Framework：根本的な発想の違い",
    "text": "2.2 Library vs Framework：根本的な発想の違い\n\n2.2.1 従来のLibraryアプローチ\n\nマクロライブラリなどが有名\nライブラリからマクロやプログラムを参照してプログラム中に利用する\nプログラムの再利用に特化した使い方\nプログラミングコードを部品化し、組み合わせる事でプログラムを作成する\n\n\n\n2.2.2 新しいFrameworkアプローチ\n\nSAS LSAFなどが有名。一方、「それって一体何なの？」ってくらい実体が見えない\n一般的な機能を持つ共通コードを持つ\n標準的なコードはフレームワークが持ち、要求されるコードの実現にプログラマーのリソースを集中させる事で効率化を達成する"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#だからどういうことなのさ",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#だからどういうことなのさ",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.3 「だからどういうことなのさ？」",
    "text": "2.3 「だからどういうことなのさ？」\nつまり：\n\nいつも書くコードはフレームワークに持たせましょう！\n\n- いつも使う機能はフレームワークに持たせましょう！\n- よく使うマクロとかもフレームワークに持たせましょう！\n- ついでに社内ルールとかもフレームワークに持たせておきましょう！\nってこと。\nこれをSASで良い感じに実現して、快適な開発環境を作りましょう！"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasプログラムの要素分析とフレームワーク化判断",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasプログラムの要素分析とフレームワーク化判断",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.4 SASプログラムの要素分析とフレームワーク化判断",
    "text": "2.4 SASプログラムの要素分析とフレームワーク化判断\n\n2.4.1 SDTM to ADaM変換の場合\n\n\n\n\n\n\n\n\n処理項目\n考察\nフレームワーク化判断\n\n\n\n\nClear log and data\n毎回使う。対象とする。\n✅ 完全自動化\n\n\nSetting macros\n毎回使うところだけ対象とする。\n⚡ 部分自動化\n\n\nSetting library\n毎回違う。出来るだけ一箇所に集約したい。\n🔧 設定管理\n\n\nSetting format\n仕様書のコードリストにあるものは対象とする。\n✅ 完全自動化\n\n\nImport data and files\nファイル名と仕様が毎回違う。やや無理。\n⚡ テンプレート化\n\n\nMerge\n毎回違う。対象外。\n❌ プログラマーの腕の見せ所\n\n\nMapping to new variables\n毎回違う。対象外。\n❌ プログラマーの腕の見せ所\n\n\nSort\nマクロ化してライブラリへ。\n✅ 共通化\n\n\nDrop extra variables\n仕様書から自動取得。\n✅ メタデータ連携\n\n\nUpload\nマクロ化してライブラリへ。\n✅ 共通化\n\n\nHeader, sections, comments\nSOPや手順との兼ね合い。対象とする。\n✅ テンプレート自動生成\n\n\n\n\n\n2.4.2 ADaM to TFLs変換の場合\n\nClear log and data\nSetting macros\nSetting library\nSetting format\nImport data and files\nMerge\nCall procedures（プロシージャの呼び出し）\nSort\nMake up to requests from mockup（モックアップからのリクエスト作成）\nUpload\nHeader, section, and comments\n\n🎯 重要な気づき\nプログラマーに頑張って欲しい所はここ！（MergeとMapping）\nということはそれ以外の所はフレームワークに持たせた方がいい！"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasによるフレームワーク設計",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#sasによるフレームワーク設計",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.5 SASによるフレームワーク設計",
    "text": "2.5 SASによるフレームワーク設計\n\n2.5.1 基本コンセプト\n\nSASプログラム開発時を想定\nSASによるプログラムテンプレート作成の一歩先\n\n\n\n2.5.2 URS（User Requirement Specification）\n\n使用するのはBase SASと一般的な外部ファイル（EXCEL）\nプログラムからプログラムをcallしても良い\n本番実行時のみログを外部に保管\nマクロは今回はmacro.sasを毎回includeする\nフレームワーク化検討のほぼ全てを実装する\n\n\n\n2.5.3 フレームワーク仕様\n\n2.5.3.1 全実行プログラム\n\n全実行時ログを保管\n\n\n\n2.5.3.2 Macro.sas\n\nSort\nインポート（proc sort）\nエクスポート（proc sort）\n仕様書から変数のattribute作成\n仕様書からcodelistのformat作成\n仕様書からkeepする変数リスト作成\n\n\n\n2.5.3.3 Each_dsn.sas\n\nStand aloneで動く\n実施時にログ、データセット等をクリアする\n社内規則に従ったheader, section, commentを作成する\n\nプログラムにおける面倒な”いつもの”を持たせておくのがフレームワークです。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実装例とテクニック",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実装例とテクニック",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.6 実装例とテクニック",
    "text": "2.6 実装例とテクニック\n\n2.6.1 全実行プログラム：環境分離の巧妙な仕組み\n/* 基本的にはマクロで実装 */\n%macro derive(dsn, title);\n   proc printto log = \"&path.¥&project._&dsn._log.txt\" new;\n   title1 \"&project.:&title.\";\n   run;\n   \n   %include \"&pgpath.¥&dsn..sas\";\n   \n   proc printto; \n   run;\n%mend;\n\n%derive(adsl)\n%derive(adae)\nPrinttoでincludeを挟むだけで開発環境と本番実行環境を分離できる！ 開発時：それぞれのプログラムで実行。ログはログ画面へ出力される 本番実行時：ログはprinttoで指定したフォルダへ出力される\n%macro derive(lib, dsn, key, where);\n    proc sort data = &lib..&dsn out = work.&dsn;\n        by &key.;\n        &where.;\n    run;\n%mend;\nMacroはlibraryにして保管・管理しておくと楽です。今回のmacro.sasはそれ自体がマクロライブラリとして機能します。 フレームワークからライブラリが読み込まれるような仕様にしています。 個別プログラムの構造化 ログクリアとヘッダーの順序問題 常識的に考えるとheaderが先である。だって”head”erだから。でも少し考えてみてもいい。\n/* パターン1 */\ndm \"log; clear;\";\n/* program name : test */\n/* author : anonymous */\n\n/* パターン2 */\n/* program name : test */\n/* author : anonymous */\ndm \"log; clear;\";\nどっちも同じ？ でも少し考えてみてもいい。もし、printtoではなくdmステートメントでログを保存していたら？後者の場合、ログからheaderが消えてしまう。どうやってログを残すかによって使えないパターンがあるので注意しよう。\nPhUSE GPPの参考から持ってきました。立派なヘッダーです。 これを作るの時間かかるんじゃない？ → こういうものはフレームワークに持たせましょう。 ちょっと工夫すると結構作れちゃったりするものです。 よく見たら進捗管理ファイル、帳票一覧、ADaM仕様書にほとんどの情報が入っている。\n/***********************************************************************\n* Project         : Sample Drug, Sample Indication,Study1\n* Program name    : sample.sas\n* Author          : smithb\n* Date created    : 20100816\n* Purpose         : Summarize demographics data for the study.\n* Revision History :\n* Date        Author      Ref     Revision (Date in YYYYMMDD format)\n* 20100818    smithb      1       Removed subjects with who have not been dosed per spec.\n***********************************************************************/"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#マクロの使用パターン",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#マクロの使用パターン",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "2.7 マクロの使用パターン",
    "text": "2.7 マクロの使用パターン\nマクロはいつもどうやって使う？\n/* 1. %include statement */\n%include \"macro.sas\";\n\n/* 2. Set auto compiled macro */\nFILENAME fileref 'the path to the AUTOCALL library';\nOPTIONS MAUTOSOURCE SASAUTOS=(SASAUTOS fileref);\n\n/* 3. Set stored macro */\nLIBNAME mylib 'C:¥temp';\nOPTIONS MSTORED SASMSTORE=mylib;"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実践的な考察",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#実践的な考察",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.1 実践的な考察",
    "text": "6.1 実践的な考察\n\n6.1.1 良かった点\n\nHeaderの記入箇所が少なくて楽\n毎回やってた設定が不要になり、ミスもなくなった\n余計な設定や処理に悩まされないので、データを見る時間などに作業時間を使えている気がする\n\n\n\n6.1.2 良くなかった点（正直な評価）\n\n簡単なプログラムのはずなんだけどやたらとコードが長い\n少しプログラムの構造が変わると、適用できない\n開発計画が大きく変わると対応できない"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#組織レベルでの戦略的価値",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#組織レベルでの戦略的価値",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.2 組織レベルでの戦略的価値",
    "text": "6.2 組織レベルでの戦略的価値\n\n6.2.1 会社としての評価\n\nやってみてもいい。\n申請や海外に提供するなど、プログラムへの要求が高くなればなるほど威力が出る\n会社として基本的なプログラムの書き方やセクションわけなどを決めてしまっても、この方法ならコスト高にならない。むしろ、いつもここにこういう事が書かれていると分かった方が開発、またはそのための教育においても有利。"
  },
  {
    "objectID": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#フレームワーク化の本質的な価値",
    "href": "posts/statistics/2025/SASプログラミング業務のフレームワーク.html#フレームワーク化の本質的な価値",
    "title": "SASプログラミング業務のフレームワーク",
    "section": "6.3 フレームワーク化の本質的な価値",
    "text": "6.3 フレームワーク化の本質的な価値\n\n6.3.1 抽象化レベルの設定\n\n6.3.1.1 高レベル抽象化（完全自動化）\n\n環境設定、ログ管理、基本的なハウスキーピング\n一度設定すれば、プログラマーは意識する必要がない\n\n\n\n6.3.1.2 中レベル抽象化（テンプレート化）\n\nプログラム構造、ヘッダー、セクション分け\n骨格は提供するが、中身はプログラマーが記述\n\n\n\n6.3.1.3 低レベル抽象化（ユーティリティ提供）\n\nよく使う処理の関数化\n呼び出すかどうかはプログラマーの判断\n\n\n\n\n6.3.2 組織的導入戦略\n\n6.3.2.1 段階的導入アプローチ\n\nPhase 1: 基盤整備：標準的なフォルダ構造とユーティリティマクロ\nPhase 2: テンプレート化：プログラムテンプレートとヘッダー標準化\nPhase 3: 自動化拡張：設定管理の自動化とバリデーション機能\nPhase 4: 最適化：継続的な改善とパターンの蓄積\n\n\n\n\n6.3.3 フレームワーク化の真の価値は：\n🎯 焦点の明確化 本当に重要な作業（データ変換ロジック、分析手法の選択）に集中できる環境の構築\n🚀 スケーラビリティの確保 個人の経験や知識に依存しない、組織として継続可能な開発体制\n🔄 継続的改善の文化 一度作って終わりではなく、常に最適化し続ける仕組み\n🤝 協働の促進 標準化されたアプローチにより、チームメンバー間の連携と知識共有の促進"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html",
    "href": "posts/statistics/2025/SQL入門1.html",
    "title": "SQL入門1",
    "section": "",
    "text": "本記事では、SASによるProc SQL Procedureについて解説する。参考文献は以下の通りである。\n\n\n\n2021年度SASユーザー総会：臨床試験のデータハンドリングとSQLプロシジャ\n2007年度SASユーザー総会：臨床試験データの加工におけるSAS/Proc SQL の活用事例：データセット併合と図表作成\n2007年度SASユーザー総会：SQL プロシジャの利用－安全性の集計を題材に－\n2016年度：データハンドリングにおけるSQLプロシジャの利活用 -PROC SQL入門ー"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#参考文献",
    "href": "posts/statistics/2025/SQL入門1.html#参考文献",
    "title": "SQL入門1",
    "section": "",
    "text": "2021年度SASユーザー総会：臨床試験のデータハンドリングとSQLプロシジャ\n2007年度SASユーザー総会：臨床試験データの加工におけるSAS/Proc SQL の活用事例：データセット併合と図表作成\n2007年度SASユーザー総会：SQL プロシジャの利用－安全性の集計を題材に－\n2016年度：データハンドリングにおけるSQLプロシジャの利活用 -PROC SQL入門ー"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点1事前ソートが不要",
    "href": "posts/statistics/2025/SQL入門1.html#利点1事前ソートが不要",
    "title": "SQL入門1",
    "section": "2.1 利点1：事前ソートが不要",
    "text": "2.1 利点1：事前ソートが不要\nData Stepの場合：\n/* 各データセットを事前にソートする必要がある */\nproc sort data=dataset1; by id; run;\nproc sort data=dataset2; by id; run;\ndata merged;\n    merge dataset1 dataset2;\n    by id;\nrun;\nProc SQLの場合：\n/* ソート不要で直接結合可能 */\nproc sql;\n    create table merged as\n    select * from dataset1 a\n    left join dataset2 b\n    on a.id = b.id;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点2併合と同時にソートが可能",
    "href": "posts/statistics/2025/SQL入門1.html#利点2併合と同時にソートが可能",
    "title": "SQL入門1",
    "section": "2.2 利点2：併合と同時にソートが可能",
    "text": "2.2 利点2：併合と同時にソートが可能\nProc SQLでは、order byを用いることにより、データセットの併合と同時にデータをソートすることが可能である。そのため、データセットの併合後にProc sortで改めてソートすることはせずに、Proc SQLのみで目的に応じた並び順にすることが可能である。\nproc sql;\n    create table result as\n    select * from dataset1 a\n    left join dataset2 b\n    on a.id = b.id\n    order by id, visit_date;  /* 結合と同時にソート */\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点3同名変数の上書き回避",
    "href": "posts/statistics/2025/SQL入門1.html#利点3同名変数の上書き回避",
    "title": "SQL入門1",
    "section": "2.3 利点3：同名変数の上書き回避",
    "text": "2.3 利点3：同名変数の上書き回避\nData Stepの問題： 併合前の2つのデータセットに同じ変数名が存在する場合、データステップでマージするとその変数名のデータは上書きされてしまう\nProc SQLの解決策：\n/* 表4.1.5のような状況での外部結合 */\nproc sql;\n    create table result as\n    select a.subject_id, a.sex as patient_sex, a.test_code, a.value,\n           b.sex as reference_sex, b.lower_limit, b.upper_limit\n    from measurement_data a\n    left join reference_data b\n    on a.test_code = b.test_code\n    and (b.sex = '.' or a.sex = b.sex);\nquit;\n基準値データセットに「性別」のデータが存在し、かつ測定値データセットの「性別」と他の異なるオブザベーションは結合データセットから削除される"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#利点4集計関数による個別値と平均値の比較",
    "href": "posts/statistics/2025/SQL入門1.html#利点4集計関数による個別値と平均値の比較",
    "title": "SQL入門1",
    "section": "2.4 利点4：集計関数による個別値と平均値の比較",
    "text": "2.4 利点4：集計関数による個別値と平均値の比較\n従来の方法の問題： 従来方向のデータの平均値を求めることは、SAS関数のmeanを用いることでデータステップでも可能である。しかし、オブザベーション方向のデータの平均値を求めるためには、Proc MEANSなどの別のプロシジャを用いる必要がある。また、retainステートメントを用いたオブザベーション方向の累計の計算により、データステップでもオブザベーション方向の平均値を求めることは可能であるが、個々の測定値と求めた平均値を比較するためには別工程の処理が必要である。\nProc SQLの解決策：\nproc sql;\n    create table comparison as\n    select subjid, paramcd, value,\n           mean(value) as group_mean,\n           value - mean(value) as deviation_from_mean\n    from lab_data\n    group by paramcd;\nquit;\nそれに対して、Proc SQLでは、集計するための関数を用いることで、個々の測定値とオブザベーション方向の平均値を比較することが可能となる。"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#基本構文",
    "href": "posts/statistics/2025/SQL入門1.html#基本構文",
    "title": "SQL入門1",
    "section": "3.1 基本構文",
    "text": "3.1 基本構文\n1つのデータセットを加工して、1つのデータセットを作成する場合の基本的なProc SQLの構文：他にも諸々の指定ができるが、基礎的な事項は以下の通りである。\nProc SQL ;\n    create table 作成データセット名    as\n    select      元のデータセット名.変数名1,\n                元のデータセット名.変数名2    as  変更後の変数名2\n    from        元のデータセット名\n    where       データ抽出の条件1\n    group by    グループ分け\n    having      データ抽出の条件2\n    order by    ソート変数\n;\n複数SQLステートメントのまとめ書き\nproc sql &lt;オプション&gt; ;\n    sqlステートメント1 ;\n    sqlステートメント2 ;\n    sqlステートメント3 ;\n;\nquit;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#各構文要素の説明",
    "href": "posts/statistics/2025/SQL入門1.html#各構文要素の説明",
    "title": "SQL入門1",
    "section": "3.2 各構文要素の説明",
    "text": "3.2 各構文要素の説明\n\n3.2.1 create table 作成データセット名 as\n作成するデータセットの名称を定義する。\n\n\n3.2.2 select\nselect  元のデータセット名.変数名1,\n        元のデータセット名.変数名2 as 変更後の変数名2\n\n作成するデータセットに保存する変数を定義する（データステップではkeepステートメントに相当）\n元のデータセットにおける変数名を指定した後に「as」を加え、変更後の変数名を記載することで、作成するデータセットに保存する変数の変数名を変更することが可能（データステップではrenameステートメントに相当）\n基本的に作成するデータセットに保存する全ての変数を定義する必要がある\n元のデータセットに存在する全ての変数をそのまま用いる場合には「*」で代用することも可能\n定義された変数名の順でデータセットが作成されるため、変数の並び順を変更することが簡単\n\n\n\n3.2.3 from 元のデータセット名\n元のデータセットを指定する（データステップではsetステートメントに相当）。\n\n\n3.2.4 where データ抽出の条件1\n元のデータセットからデータを抽出する条件を指定する。\n\n\n3.2.5 group by グループ分け\n集計する場合などの状況においてグループ分けの条件を設定する。\n\n\n3.2.6 having データ抽出の条件2\n元のデータセットからデータを抽出する条件を指定する。集計するための関数を利用して条件を指定する場合には、「where」ではなく「having」で指定する。\n\n\n3.2.7 order by ソート変数\nデータのソートに用いる変数を指定する。Proc SQLでは、データセット作成と同時にデータをソートすることが可能である。"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#data-stepとの比較",
    "href": "posts/statistics/2025/SQL入門1.html#data-stepとの比較",
    "title": "SQL入門1",
    "section": "3.3 Data Stepとの比較",
    "text": "3.3 Data Stepとの比較\n上記のProc SQLで作成したプログラムをデータステップおよびProc SQL以外のプロシジャで作成する場合：\nData 作成データセット名 ;\n    set 元のデータセット名 ;\n    where       データ抽出の条件1 ;\n    rename      変数名2 = 変更後の変数名2 ;\n    keep        変数名1  変更後の変数名2 ;\n    if          データ抽出の条件2 ;\nrun ;\n\nProc sort data=作成データセット名 ;\n    by ソート変数 ;\nrun ;"
  },
  {
    "objectID": "posts/statistics/2025/SQL入門1.html#proc-sqlの利点",
    "href": "posts/statistics/2025/SQL入門1.html#proc-sqlの利点",
    "title": "SQL入門1",
    "section": "3.4 Proc SQLの利点",
    "text": "3.4 Proc SQLの利点\n\n複数の工程を1工程にまとめられる：プログラム作成においてエラーを少なくするという利点がある\n変更箇所の特定が容易：変更箇所を見つけやすいため、変数名の変更や条件の変更を行なう際に変更漏れを少なくするという利点がある\n統一された記法：Proc SQLでは「Proc SQL;」～「quit」、データステップでは「Data」～「run;」、Proc SQL以外のプロシジャでは「Proc」～「run;」を1工程と表現する"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html",
    "href": "posts/statistics/2025/サンプルサイズ設計.html",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "",
    "text": "本書は、頻繁に利用されるサンプルサイズ設計SASプログラムをまとめます。実務において、本記事のSASプログラムをコピーして利用することのみを念頭に置いています。数学的な導出は省略します。"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "3.1 2値アウトカム",
    "text": "3.1 2値アウトカム\n単群試験で2値アウトカムの場合、サンプルサイズは、P0（閾値奏効割合）、P1（期待奏効割合）、α（第一種の過誤確率）、β（第二種の過誤確率）を事前に仮定することで計算できます。閾値奏効割合とは、これ以上の奏効割合がなければ治療効果がない（開発中止をしたい）と考えられる割合のことです。期待奏効割合とは、治療効果があると考えられる割合（次相に進みたい程度）のことです。これらの割合は臨床仮説や先行研究に基づいて決定するため、試験統計家がコメントすることはあまりありません。ICHガイドラインに準じて、SASプログラムは全て両側検定として両側有意水準5%としています。これは、なお、ICH E9では以下のような記載があります。すなわち、GCP準拠の治験においては原則として以下の記載に準じて試験計画を考える必要があります。\n「規制上の観点から、本ガイドラインの施行に伴い、原則として片側仮説を検証する場合は2.5％、両側仮説の場合は5％とすることとした。」\nなお、ICH E9にはQ＆AがありQ2で有意水準について言及されている。\n\n\n\n\n\n\nノート\n\n\n\n片側検定又は両側検定のどちらを用いるか、またそこでの有意水準をいくらにすべき かを、優越性試験と非劣性試験のそれぞれで説明願いたい。\n(答) ガイドラインでは、同等性を示す場合には両側信頼区間、非劣性試験では片側信頼 区間による解析を行うことが記載されているが、一般には推測を片側と考えるか両側 と考えるかには議論があり一概に決められるものではないとされている。また、有意 水準についても、個々の試験において適切な基準を設定すべきである旨の記載がある。 しかしながら、推論を片側とするか両側とするかにより統計的な判断に大きな差異 が生じることは規制上の観点から望ましくない。また、一方で、臨床試験における有 効性の評価では、検定により有意差があるか否かを判断するだけでなく、試験治療効 果の大きさ(比較群間の差の大きさ)がどの程度であるかを推定することも重要である。 そこで、今後は、検証的試験においては、仮説の検定においてどちらの方法を用いる 場合であっても、効果の推定には95％信頼係数の両側信頼区間を用い、検定の際の有水準は、これによる判断との整合性を図るため、優越性試験、非劣性試験のいずれにおいても、片側2.5％又は両側5％とすることを原則とする。用量反応試験についても、用量反応性を示すことにより薬剤の有効性を検証するような試験においては上記と同様である。ただし、適切な説明ができるのであれば、より強固な有効性の根拠を 示すために有意水準を厳しくする、稀少疾病用医薬品にみられる例のように十分な被 験者を集めることが困難な場合は有意水準を緩くする、などの措置をとってもよい。 なお、生物学的同等性試験については、「後発医薬品の生物学的同等性試験ガイドライン(平成9年12月22日医薬審第487号)」により、90％信頼係数の両側信頼区間を用いるとされているが、臨床効果を指標に標準製剤との同等性を検証しようとする場合(臨床的同等性試験)は、上記と同様に95％信頼係数の両側信頼区間を用いることを原則とする。\n\n\n　特に重要なのは、「適切な説明ができるのであれば、より強固な有効性の根拠を示すために有意水準を厳しくする、稀少疾病用医薬品にみられる例のように十分な被験者を集めることが困難な場合は有意水準を緩くする、などの措置をとってもよい。」の記載である。すなわち、両側10%や片側5%も、きちんと説明をして納得していただければ許容されるということである。これらの【5%か2.5%か】の議論については、以下のJCOGプロトコールマニュアルにも記載がある。\n\n\n\n\n\n\nJCOGプロトコール\n\n\n\n国立がん研究センターでの第2相相当の臨床試験では、片側検定を用いることもありえます。これは、標準治療 vs 試験治療であり、少なくとも試験治療が標準治療より劣っているとは考えておらず、片側検定の方が適切と考えられるからです。 JCOGのプロトコールマニュアルのURLは以下です。 JCOGプロトコールマニュアル\n\n\n試験計画時の例：\n\np0 = 0.1（閾値奏効割合）\np1 = 0.3（期待奏効割合）\nα = 0.05（第一種の過誤、片側）\nβ = 0.2（第二種の過誤）\n\n以下は、正規近似を用いたサンプルサイズ計算の例です。 連続修正は行いません。正規近似に基づく症例数設計では、H0におけるp0を用いて分散が計算されている点に注意してください。数理統計学を学ばれた方からみるとスコア検定に基づく方法に相当します。Wald検定に基づく例数設計とするとp1を用いて分散が計算されることになります。中間解析を勉強するとWald検定に基づく方法でサンプルサイズ設計がされることもあると気付きます。中間解析では検定統計量間の相関を考えるため、漸近正規性を仮定したサンプルサイズ設計をするためWald型の統計量を利用します。\n　実務上では、抗がん剤の単群試験では中間解析を事前に規定して、2項分布に基づいてに基づいて無効中止や有効中止を考慮したくなる場面が多いです。それは患者さんにとっての倫理性や開発戦略の観点からも重要な要素です。中間解析を行う場合、無効中止や有効中止の基準を事前に規定する必要があります。無効中止や有効中止の基準は、試験の目的やデザインに応じて異なるため、試験統計家と相談して決定することが重要です。無効中止や有効中止の基準を事前に規定することで、試験の透明性が向上し、倫理的な問題を回避することができます。そのような場合は、単純な2値データの割合のサンプルサイズ設計では実施できず、適切な試験統計家がSimonの2段階デザインやFlemingの2段階デザインを用いて例数設計がなされます。また、単群試験において、ベイズ流の例数設計も提案されていることから、ベイズ流例数設計も考慮していただきたい。なお、中間解析やベイズ流例数設計は常に必要ではなく、SASでの実装はシンプルではないため、ここでは割愛します。別記事で説明します。\n通常の単群試験の例数設計は以下のように行います。以下のSASプログラムは、対照群のリスクp0 = 0.1、実験群のリスクp1 = 0.3、リスク差 = 0.2を想定しています。なお、sides = 2は両側検定を意味します。片側検定を行う場合は、sides = 1としてください。\nproc power;\nonesamplefreq test=z\n    method = normal\n    sides = 2\n    alpha = 0.05\n    nullproportion = 0.1\n    proportion = 0.3\n    ntotal = .\n    power = 0.8;\nrun;\n対象者数が多い場合（シミュレーションによる確認要です）、上記の正規分布に基づく方法でも良いと考えます。しかし、一般的に2項分布による正確な検定に基づく症例数設計を利用することが標準的な方法です。理由は正規近似による例数設計が二項分布の中心極限定理を用いているため、あくまで対象者数が十分多い状況における中心極限定理を仮定しているためです。中心極限定理を利用せず、2項分布を用いて症例数設計をするSASプログラムは以下です。\n先ほどと異なり、test = exactを指定しています。これにより、2項分布に基づく正確な検定が行われます。これにより、サンプルサイズ計算がより正確になります。また、plotオプションを使用して、サンプルサイズに対する検出力の変化を視覚化しています。これにより、必要なサンプルサイズをより直感的に理解できます。\nproc power;\n    onesamplefreq test=exact\n        sides = 2\n        alpha = 0.05\n        nullproportion = 0.1\n        proportion = 0.3\n        ntotal = 2 to 100\n        power = .;\nrun;\nExact法に基づく症例数設計では、検出力は単調増加にならず、test = normalと異なり、N = xxのように数値が出力されません。そのため、SASの出力を結果を見ながら、目標とする検出力を満たす最小の整数値 or 目標とする検出力を満たす最大の整数値とします。個人的には、より保守的であるため後者を推奨します。実際、より大きなサンプルサイズを選ぶことで、検出力の目標値をより確実に達成できる可能性が高まります。ただし、リソースの制約がある場合は、目標検出力を満たす最小の症例数を選ぶことも実用的な選択肢となり得ます。基本的にtest = exactとすることを推奨します。"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#検定仮説について片側検定と両側検定有意水準優越性非劣性",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#検定仮説について片側検定と両側検定有意水準優越性非劣性",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "3.2 検定仮説について：片側検定と両側検定、有意水準、優越性、非劣性",
    "text": "3.2 検定仮説について：片側検定と両側検定、有意水準、優越性、非劣性\n上のプログラムでは、よく利用されるであろう両側検定（sides=2 ）を指定して、両側有意水準をalpha=0.05を指定しています。この説ではここら辺のシナリオについて、もう少し深堀したいと思います。\nsides optionについて、SAS helpでは以下のように説明されています。\n\n\n\n\n\n\nノート\n\n\n\n\nSIDES=keyword-list\n\nspecifies the number of sides (or tails) and the direction of the statistical test. For information about specifying the keyword-list, see the section Specifying Value Lists in Analysis Statements. You can specify the following keywords:\n\n1\n\nspecifies a one-sided test, with the alternative hypothesis in the same direction as the effect.\n\n2\n\nspecifies a two-sided test.\n\nU\n\nspecifies an upper one-sided test, with the alternative hypothesis indicating a proportion greater than the null value.\n\nL\n\nspecifies a lower one-sided test, with the alternative hypothesis indicating a proportion less than the null value.\n\n\nIf the effect size is zero, then SIDES=1 is not permitted; instead, specify the direction of the test explicitly in this case with either SIDES=L or SIDES=U. By default, SIDES=2.\n\n\n\n\n\n3.2.1 パラメータの正しい役割\nSASのproc powerにおけるパラメータは、以下のように解釈するのが正解です。\n\nnullproportion (または nullp): 帰無仮説 (H₀)で「真実ではないか」と疑う基準値です。これを p₀ とします。今回の例では p₀ = 0.1 です。\nproportion (または p): 対立仮説 (H₁) が正しいとした場合に「実際にはこの値だろう」と想定する具体的な値です。この値を使って検出力（Power）を計算します。これを p_alt とします。今回の例では p_alt = 0.3 です。\n\n重要なのは、仮説に登場する p は「未知の真の比率」という記号であり、proportionパラメータの値 (0.3) そのものではない、という点です。\n\n\n3.2.2 仮説の正しい立て方\n上記の役割を踏まえると、今回の例 (nullpropotion=0.1, p=0.3) における仮説は以下のようになります。\n\n帰無仮説 (H₀): 真の比率は 0.1 に等しい。\n\nH_0 : p=0.1\n\n対立仮説 (H₁):\n\n片側（上側）検定 (SIDES=U) の場合\n\n真の比率は 0.1 より大きい。\nH_1 : p&gt;0.1\n\n片側（下側）検定 (SIDES=L) の場合\n\n真の比率は 0.1 より小さい。\nH_1 : p&lt;0.1\n\n\n\n二項検定の検出力は、「もし対立仮説が真実だったとしたら、どれくらいの確率で正しく帰無仮説を棄却できるか」を計算しています。\n計算は、大きく分けて2つのステップで行われます。\n\n\n3.2.3 ## 計算の具体的なステップ\nここでは、前の例に出てきた値を使って具体的に説明します。\n\n帰無仮説 (H₀): p=0.1\n対立仮説 (H₁) で想定する真の値: palt​=0.3\nサンプルサイズ (n): 100\n有意水準 (α): 0.05\n検定の種類: 片側上側検定 (H1​:p&gt;0.1)\n\n\n3.2.3.1 ステップ1：棄却域（帰無仮説を棄却する領域）を決める\nまず、「もし帰無仮説 (p=0.1) が正しいとしたら」という世界で考えます。このとき、100人中何人以上の成功が観察されたら、「これは偶然とは考えにくい、帰無仮説は間違いだろう」と判断するか、その境界線（臨界値）を決めます。これは、その値以上になる確率が有意水準α (5%) を下回るように設定します。n=100, p=0.1 の二項分布に従うとすると、成功数が k 回以上になる確率 P(X≥k) が 0.05 以下になる最小の k を探します。\n計算すると、k=16 となります。\n\nP(X≥15∣p=0.1)≈0.06 (まだ5%より大きい)\nP(X≥16∣p=0.1)≈0.03 (5%を下回った！)\n\nつまり、「もし真の比率が0.1なら、成功数が16回以上になることは滅多にない(確率3%)。だから、もし16回以上の成功を観測したら、帰無仮説を棄却しよう」とルールを決めます。この「16回以上」が棄却域です。\n\n\n3.2.3.2 ステップ2：棄却域に入る確率（検出力）を計算する\n次に、「もし対立仮説 (p=0.3) が真実だったとしたら」という世界に切り替えます。この世界で、ステップ1で決めた棄却域（成功数が16回以上）に入る確率を計算します。これこそが検出力です。n=100, p=0.3 の二項分布に従うとして、成功数が16回以上になる確率 P(X≥16∣p=0.3) を計算します。この確率を計算すると、およそ 0.998、つまり 99.8% となります。これが検出力です。つまり、「もし真の比率が0.3であれば、サンプルサイズ100の実験で『p&gt;0.1である』と正しく結論付けられる確率は99.8%である」ということを意味します。\n臨床試験において、片側検定というと一般的にSIDES=Uを指すことが一般的である。帰無仮説のp0より大きいかどうかを検証したいためです。抗がん剤の第2相試験はまさにそれが頻繁に利用される。Simonの2段階デザインやFlemmigデザインの数理を勉強すると理解が深まるだろう。そのため、実務上で片側検定と言われた場合はSIDES=1と指定すると、指定した値に応じて、SASが指定した治療効果の方向に基づいて、対立仮説が自動的に決定される。今回の例 (nullpropotion=0.1, p=0.3) でいえば、0.1&lt;0.3であるため、SASが自動で、 H_1 : null proportion = 0.1 &lt; pの仮説を指定してくれている。結果的に、SIDES=Uを指定することと同じになる。一方、例 (nullpropotion=0.1, p=0.05) でいえば、0.1&lt;0.05であるため、SASが自動でH_1 : p &lt; 0.1$\nの仮説を指定してくれている。結果的に、SIDES=Lを指定することと同じになる。実務上は、基本的にUpperを考えることが多いし、pの対立仮説の方が多いため実務上の問題はない。ただし、統計家として、SIDES=1 で適当に指定するより、正しく理解してSIDES=U を指定することを標準にすべきである。この姿勢は特に、非劣性試験/同等性試験の検定問題を考えるときに正しく指定できる力となる。\n\n\n\n3.2.4 非劣性試験におけるmargin option\nSASのproc powerのonesamplefreqにはmargin optionがある。SAS helpでは以下のように記載されている。\n\n\n\n\n\n\nノート\n\n\n\nMARGIN=number-list\nspecifies the equivalence or noninferiority or superiority margin, depending on the analysis.\nThe MARGIN= option can be used with one-sided analyses (SIDES = 1 | U | L), in which case it specifies the margin added to the null proportion value in the hypothesis test, resulting in a noninferiority or superiority test (depending on the agreement between the effect and hypothesis directions and the sign of the margin). A test with a null proportion and a margin m is the same as a test with null proportion and no margin.\nThe MARGIN= option can also be used with equivalence analyses (TEST=EQUIV_ADJZ | EQUIV_EXACT | EQUIV_Z) when the NULLPROPORTION= option is used, in which case it specifies the lower and upper equivalence bounds as and , where is the value of the NULLPROPORTION= option and m is the value of the MARGIN= option.\nThe MARGIN= option cannot be used in conjunction with the SIDES=2 option. (Instead, specify an equivalence analysis by using TEST=EQUIV_ADJZ or TEST=EQUIV_EXACT or TEST=EQUIV_Z). Also, the MARGIN= option cannot be used with the CI= option.\nValues must be strictly between –1 and 1. In addition, the sum of NULLPROPORTION and MARGIN must be strictly between 0 and 1 for one-sided analyses, and the derived lower equivalence bound (2 * NULLPROPORTION – MARGIN) must be strictly between 0 and 1 for equivalence analyses.\nFor information about specifying the number-list, see the section Specifying Value Lists in Analysis Statements."
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#はじめに",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#はじめに",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.1 はじめに",
    "text": "4.1 はじめに\n臨床試験の世界では、従来の2群比較試験（RCT）が金本位とされていますが、希少疾患の治療薬開発や倫理的制約がある状況では、単群試験での評価が必要となることがあります。本記事では、歴史的対照を用いた単群非劣性試験の統計設計について、SAS PROC POWERを用いた具体的な実装方法を解説します。"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#単群非劣性試験とは",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#単群非劣性試験とは",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.2 単群非劣性試験とは",
    "text": "4.2 単群非劣性試験とは\n\n4.2.1 基本概念\n単群非劣性試験は、新治療を単一群で評価し、歴史的対照（過去の研究や文献値）と比較して「劣らない」ことを示す統計手法です。これは以下のような状況で用いられます：\n\n希少疾患: 患者数の制約により対照群の設定が困難\n倫理的制約: プラセボ群や無治療群の設定が非倫理的\n歴史的対照が確立: 標準治療の効果が文献で明確\n探索的研究: Phase II試験での preliminary evaluation"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#統計的仮説設定",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#統計的仮説設定",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.3 統計的仮説設定",
    "text": "4.3 統計的仮説設定\n\n4.3.1 抽象的な仮説設定\n単群非劣性試験の一般的な仮説は以下のように設定されます：\n\n4.3.1.1 パラメータ定義\n\np: 新治療の真の反応率\np₀: 歴史的対照の反応率\nδ: 非劣性マージン（δ &gt; 0）\n\n\n\n4.3.1.2 仮説設定\n帰無仮説（H₀）: p ≤ p₀ - δ\n対立仮説（H₁）: p &gt; p₀ - δ\n\n\n\n4.3.2 仮説の臨床的解釈\n\nH₀: 新治療は歴史的対照より非劣性マージン以上劣る（臨床的に許容できない）\nH₁: 新治療は歴史的対照に対し非劣性である（臨床的に許容可能）"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#実臨床での事例希少血液疾患治療薬の開発",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#実臨床での事例希少血液疾患治療薬の開発",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.4 実臨床での事例：希少血液疾患治療薬の開発",
    "text": "4.4 実臨床での事例：希少血液疾患治療薬の開発\n\n4.4.1 研究背景\nある希少な血液疾患の新薬開発を想定しましょう：\n\n対象疾患: 希少な血液疾患\n評価項目: 6ヶ月後の完全寛解率\n歴史的対照: 既存標準治療での完全寛解率 10%\n新薬の期待効果: 15%の完全寛解率\n非劣性マージン: 2%（臨床的に許容できる効果の低下）\n\n\n\n4.4.2 具体的な仮説設定\nこの設定では：\n\np₀ = 0.10（歴史的対照）\nδ = 0.02（非劣性マージン）\n実効的境界値 = 0.10 - 0.02 = 0.08\n\n帰無仮説: p ≤ 0.08 対立仮説: p &gt; 0.08"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#sas-proc-powerによる実装",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#sas-proc-powerによる実装",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.5 SAS PROC POWERによる実装",
    "text": "4.5 SAS PROC POWERによる実装\n\n4.5.1 基本的な検出力計算\n/* 単群非劣性試験の検出力計算 */\nproc power;\n   onesamplefreq test=exact\n      sides = U                   /* 上側片側検定 */\n      nullproportion = 0.1        /* 歴史的対照の効果 */\n      proportion = 0.15           /* 新薬の想定効果 */\n      margin = -0.02              /* 非劣性マージン（負値で指定） */\n      ntotal = 130                /* 計画症例数 */\n      power = .;                  /* 検出力を計算 */\n   title \"単群非劣性試験：検出力計算\";\nrun;\n\n\n4.5.2 SASパラメータの詳細説明\n\n\n\nパラメータ\n説明\n値\n\n\n\n\ntest=exact\n正確検定（小サンプル・低事象率向け）\n-\n\n\nsides=U\n上側片側検定\n-\n\n\nproportion\n新治療の想定反応率（p）\n0.15\n\n\nnullproportion\n歴史的対照の反応率（p₀）\n0.10\n\n\nmargin\n非劣性マージン（-δ、負値で指定）\n-0.02\n\n\nntotal\n計画症例数\n130\n\n\n\n\n\n4.5.3 なぜmarginは負の値なのか\nSASでは以下の計算を行います：\n実効的帰無仮説の境界 = nullproportion + margin = 0.10 + (-0.02) = 0.08\nこれにより、「p &gt; 0.08」という対立仮説を検定することになります。"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#同等性検定について",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#同等性検定について",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.6 同等性検定について",
    "text": "4.6 同等性検定について\n他にもTest Optionにて様々な検定仮説を選択することができる。\n中々利用しないが、TOSTという二重片側検定を用いた同等性試験もありえる。TOST（Two One-Sided Tests）を用いた同等性試験は、主に後発品（ジェネリック医薬品）の生物学的同等性試験で使用される統計手法です。機会があれば、紹介します。\n\n\n\n\n\n\nノート\n\n\n\nTEST= ADJZ | EQUIV_ADJZ | EQUIV_EXACT | EQUIV_Z | EXACT | Z\nTEST\n: specifies the statistical analysis. TEST=ADJZ specifies a normal-approximate z test with continuity adjustment. TEST=EQUIV_ADJZ specifies a normal-approximate two-sided equivalence test based on the z statistic with continuity adjustment and a TOST (two one-sided tests) procedure. TEST=EQUIV_EXACT specifies the exact binomial two-sided equivalence test based on a TOST (two one-sided tests) procedure. TEST=EQUIV_Z specifies a normal-approximate two-sided equivalence test based on the z statistic without any continuity adjustment, which is the same as the chi-square statistic, and a TOST (two one-sided tests) procedure. TEST or TEST=EXACT (the default) specifies the exact binomial test. TEST=Z specifies a normal-approximate z test without any continuity adjustment, which is the same as the chi-square test when SIDES=2."
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#信頼区間の基づくサンプルサイズ設計",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#信頼区間の基づくサンプルサイズ設計",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "4.7 信頼区間の基づくサンプルサイズ設計",
    "text": "4.7 信頼区間の基づくサンプルサイズ設計\nSASでは、信頼区間に基づくサンプルサイズ設計も完備されている。The following statements performs a confidence interval precision analysis for the Wilson score-based confidence interval for a binomial proportion. The default value of the ALPHA= option specifies a confidence level of 0.95.\nproc power;\n   onesamplefreq ci=wilson\n      halfwidth = 0.1\n      proportion = 0.3\n      ntotal = 70\n      probwidth = .;\nrun;\n\n4.7.1 参考文献\n\nOneSampleFreq Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#連続量アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#連続量アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "5.1 連続量アウトカム",
    "text": "5.1 連続量アウトカム\n連続量アウトカムの場合、サンプルサイズは以下の式で計算できます。 以下では優越性を示す検証的試験を想定しています。 twosamplemeans test = diffを用いて、2群間の平均値の差を検定する方法を想定しています。以下では、対照群の平均値μ0 = 0、実験群の平均値μ1 = 0.5、標準偏差σ = 1を想定しています。\nproc power;\n    twosamplemeans test=diff\n        meandiff = 0.5\n        stddev = 1\n        alpha = 0.05\n        power = 0.8\n        nptotal = .;\nrun;\n複数の状況をまとめて計算する場合は、以下のようにします。\nproc power;\n    twosamplemeans test=diff\n        meandiff = 0.5 , 1 , 1.5\n        stddev = 1 , 2 , 3\n        alpha = 0.05\n        power = 0.8\n        ntotal = .;\nrun;\n　平均値の差の検定は一般的であり、連続量のアウトカムを用いた試験では最も多く利用される方法です。平均値の差の検定は、通常、正規分布に従うと仮定される連続量データに適用されます。連続量アウトカムにおける経時測定データのサンプルサイズ設計が求められることもあるかと思います。その場合、最終観察時点における平均値の差を検定する方法として上記のプログラムを利用することが保守的で望ましいと考えます。例数設計としてはt検定に基づきより保守的なサンプルサイズ設計をする。統計解析においては、共分散分析やMMRMなどの同じEstimandを推定する方法で、より検出力の高い解析方法を適用することが治験の分野では求められると考えます。\n\n5.1.1 参考文献\nTwoSampleMeans Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム-1",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#値アウトカム-1",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "5.2 2値アウトカム",
    "text": "5.2 2値アウトカム\n2値アウトカムの場合、サンプルサイズは以下の式で計算できます。リスク差（割合の差）に基づいて優越性を検討することを想定しています。p0を対照群のリスク、p1を実験群のリスクとします。リスク差は、対照群のリスクp0に基づいて計算されるため、対照群のp0を指定する必要があります。以下では、対照群のリスクp0 = 0.1、実験群のリスクp1 = 0.3、リスク差 = 0.2を想定しています。\n\np0 = 0.1（対照群の和依頼）\np1 = 0.3（実験群の割合）\nα = 0.05（第一種の過誤、両側）\nβ = 0.2（第二種の過誤）\n\nSASプログラムは以下となります。ここでは、対照群のリスク及びリスク差を指定している。リスク差は、対照群のp0に基づいて計算されるため、対照群のp0を指定する必要があります。\nproc power;\ntwosamplefreq test=pchi\n    sides = 2\n    alpha = 0.05\n    refproportion = 0.1\n    proportiondiff = 0.2\n    npergroup = .\n    power = 0.8;\nrun;\n\n5.2.1 参考文献\n\nTWOSAMPLEFREQ Statement"
  },
  {
    "objectID": "posts/statistics/2025/サンプルサイズ設計.html#生存時間アウトカム",
    "href": "posts/statistics/2025/サンプルサイズ設計.html#生存時間アウトカム",
    "title": "臨床試験のサンプルサイズ設計",
    "section": "5.3 生存時間アウトカム",
    "text": "5.3 生存時間アウトカム\n生存時間アウトカムの場合、サンプルサイズは以下の式で計算できます。以下では優越性を示す検証的試験を想定しています。アウトカムはハザード比として、生存時間解析のノンパラメトリック検定（ログランク検定等）を前提とした例数設計を想定する。例えば生存時間アウトカムとして生存割合（死亡、生存）を前提として例数設計を考える場合、本節に基づく方法での例数設計も考えられるが、より保守的に2値データに基づく例数設計を行うことが望ましい場合もありえます。この違いについては、別記事で説明します。生存時間の例数設計については、SAS user総会のSASプロシジャを用いた生存時間データに対する例数設計の変革が参考になります。\nSASのtwosamplesurvival statementではLakatosの方法が採用されています。これは区分指数分布を前提としており解析的にN = xxの形で表すことはできません。教育的な立場だと、解析的にN = xxの形で表すことができる方法としてFreedmanの方法やSchoenfeldの方法がありますが、上記のSASユーザー総会の資料によると、Lakatosの方法の方が性能が良いことが報告されているそうです。実務上もproc power procedureを用いて、再現可能な状態で例数設計を行うことが望ましいので、基本的にLakatosの方法を採用します。\n生存時間アウトカムに基づく症例数設計では以下のような情報が必要です。特徴的なのは、登録期間とフォローアップ期間の情報が必要な点です。登録期間は、患者さんを試験に登録するための期間であり、フォローアップ期間は、患者さんを追跡するための期間です。これらの情報は、試験のデザインや目的に応じて異なるため、試験統計家と相談して決定することが重要です。 なお、通常登録は一様に登録されると仮定され、一様分布を仮定することがデフォルトです。\n\nS_c(3) = 0.3（対照群Cの3年あたりの生存率）\nS_a(2) = 0.2（実験群Aの3年あたりの生存率）\n登録期間：A = 3年\nフォローアップ期間：F = 2年\nα = 0.05（第一種の過誤、両側）\nβ = 0.2（第二種の過誤）\n\nSASでは以下のように実行します。ここでは、対照群の生存率S_c(3) = 0.3、実験群の生存率S_a(2) = 0.2を想定しています。登録期間は3年、フォローアップ期間は2年としています。これにより、試験のデザインや目的に応じたサンプルサイズを計算することができます。\nproc power;\n    twosamplesurvival test = logrank\n    curve(\"Control\") = 3:0.3\n    curve(\"Experimental\") = 3:0.2\n    groupsurvival = \"Control\" | \"Experimental\"\n    groupweights = (1 1)\n    accrualtime = 3 \n    followuptime = 2\n    ntotal = .\n    power = 0.8\n    alpha = 0.05\n    sides = 2;\nrun;\n通常、生存時間の例数設計で3年間での生存割合20%や、30%ということを仮定できる状況は多くないと思います。例えば第2相試験では1年間の追跡しかしていない場合に3年生存割合を仮定することは難しいです。そこで、通常は生存時間Tが指数分布に従うとして以下の式を用いてハザードを基にサンプルサイズ設計は有用です。ただし、ハザード比は生存時間の分布に依存するため、注意が必要です。生存時間Tが指数分布に従う場合、ハザード比は以下のように表されます。\n\nS(t) = 1-F(t) = exp(-λt) ⇔ λ = -\\frac{log(S(t))}{t}\n\nこの関係を用いて、ある時点tとその時点のKM推定量の結果を用いて各群のハザードを指定してサンプルサイズ計算をする方法は以下となります。\nproc power;\n    twosamplesurvival test = logrank\n    groupsurvexphazards = (0.05 0.01)\n    groupweights = (1 1)\n    accrualtime = 3 \n    followuptime = 2\n    ntotal = .\n    power = 0.8\n    alpha = 0.05\n    sides = 2;\nrun;\n他にも、中央生存時間を用いて計算することもできる。これも生存時間アウトカムに指数分布を仮定すると簡単に示せます。\n\nS(1/2) = exp(-λt) ⇔ λ = -\\frac{log(S(1/2))}{t}\n\nこの関係を用いて、KM推定量の結果を用いて各群の中央生存時間からハザードを推定することもできる。いずれの方法もTに指数分布を仮定している。\n\n5.3.1 参考文献\n\nTwoSsampleSurvival Statement"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html",
    "href": "posts/statistics/2025/相対Path.html",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "相対パスは、現在いる場所を基準にしたファイルやフォルダの位置を表す方法です。\n\n\n\n. = 現在のディレクトリ\n.. = 1つ上のディレクトリ\n../../ = 2つ上のディレクトリ\n../../../ = 3つ上のディレクトリ\n\n\n\n\n\nProject/                    ← プロジェクトルート\n├── 01_Data/\n│   ├── 00_RAW/\n│   │   └── EXT/\n│   └── 01_PROCESSED/\n├── 02_Programs/\n│   ├── ADaM/\n│   │   └── v2.0/           ← 現在ここにいる\n│   └── TLF/\n└── 03_Output/\n\n\n\n*------------------------------------------------------------------------------;\n* Get Current Directory Path ;\n*------------------------------------------------------------------------------;\nfilename *Dir* \".\" ;\n%let PgmType = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n%put  &PgmType. ;\nfilename *Dir* \"../\" ;\n%let PgmEnv  = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n%put  &PgmEnv. ;\nfilename *Dir* \"../../\" ;\n%let Dir     = %sysfunc ( pathname ( *DIR* ) ) ;\n%put  &Dir. ;\nfilename *Dir* clear ;\n\n\n1行目: 現在のディレクトリ（“.”）にファイル参照を設定\nfilename *Dir* \".\" ;\n2行目: 現在のディレクトリ名を取得\n%let PgmType = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n\n%sysfunc(pathname(*DIR*)) → フルパスを取得\n%scan(..., -1, %str(\\)) → パスを\\で区切って最後の部分を取得\n結果: v2.0 （現在のフォルダ名）\n\n4行目: 1つ上のディレクトリに参照を変更\nfilename *Dir* \"../\" ;\n5行目: 1つ上のディレクトリ名を取得\n%let PgmEnv  = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n\n結果: ADaM （1つ上のフォルダ名）\n\n7行目: 2つ上のディレクトリに参照を変更\nfilename *Dir* \"../../\" ;\n8行目: 2つ上のディレクトリのフルパスを取得\n%let Dir     = %sysfunc ( pathname ( *DIR* ) ) ;\n\n結果: C:\\Project\\02_Programs （2つ上のフルパス）\n\n10行目: ファイル参照をクリア\nfilename *Dir* clear ;\n\n\n\nPgmType: v2.0\nPgmEnv: ADaM  \nDir: C:\\Project\\02_Programs\n\n\n\n\n\n\n/* 現在地: C:\\Project\\02_Programs\\ADaM\\v2.0\\ */\n\n/* プロジェクトルートに移動 */\nX \"cd ../../../\" ;\n\n/* または、絶対パスで移動 */\n%let PROJECT_ROOT = C:\\Project ;\nX \"cd &PROJECT_ROOT.\" ;\n\n\n\n/* 現在のプログラムパスを取得 */\n%let execpath = %sysfunc(getoption(sysin)) ;\n%let CURRENT = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n\n/* プロジェクトルートを算出 */\nfilename *Dir* \"../../../\" ;\n%let PROJECT_ROOT = %sysfunc(pathname(*DIR*)) ;\nfilename *Dir* clear ;\n\n/* プロジェクトルートに移動 */\nX \"cd &PROJECT_ROOT.\" ;\n%put 現在地をプロジェクトルートに変更: &PROJECT_ROOT. ;\n\n/* これで相対パスがシンプルになる */\n%let RAW_DATA = 01_Data\\00_RAW ;\n%let PROCESSED_DATA = 01_Data\\01_PROCESSED ;\n%let OUTPUT_DIR = 03_Output ;\n\n\n\n/* X commandでプロジェクトルートに移動後 */\nX \"cd &PROJECT_ROOT.\" ;\n\n/* 相対パスがシンプルに！ */\n%let external = 01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n%include \"00_Settings\\init.sas\" ;\nods pdf file=\"03_Output\\ADSL_Summary.pdf\" ;\n\n/* 移動前だと... */\n%let external = ..\\..\\..\\01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n%include \"..\\..\\..\\00_Settings\\init.sas\" ;\nods pdf file=\"..\\..\\..\\03_Output\\ADSL_Summary.pdf\" ;\n\n\n\n\n# 現在のディレクトリ情報を取得\nget_directory_info &lt;- function() {\n  current_path &lt;- getwd()\n  \n  # 現在のディレクトリ名\n  PgmType &lt;- basename(current_path)\n  \n  # 1つ上のディレクトリ名\n  parent_path &lt;- dirname(current_path)\n  PgmEnv &lt;- basename(parent_path)\n  \n  # 2つ上のディレクトリのフルパス\n  Dir &lt;- dirname(parent_path)\n  \n  # 結果を表示\n  cat(\"PgmType:\", PgmType, \"\\n\")\n  cat(\"PgmEnv:\", PgmEnv, \"\\n\") \n  cat(\"Dir:\", Dir, \"\\n\")\n  \n  # リストで返す\n  list(\n    PgmType = PgmType,\n    PgmEnv = PgmEnv,\n    Dir = Dir\n  )\n}\n\n# 実行\ndir_info &lt;- get_directory_info()\n\n# プロジェクトルートに移動\nPROJECT_ROOT &lt;- dirname(dirname(dirname(getwd())))\nsetwd(PROJECT_ROOT)\n\n# 相対パスがシンプルに\nexternal_file &lt;- \"01_Data/00_RAW/EXT/external_data.xlsx\"\nsource(\"00_Settings/init.R\")\n\n\n\n現在地：02_Programs/ADaM/v2.0/ にいる場合\n\n\n\n.. → 02_Programs/ADaM/ に移動\n../ → 02_Programs/ に移動\n01_Data/ → 01_Data/ フォルダに入る\n00_RAW/EXT/ → さらに奥のフォルダに入る\n\n結果: Project/01_Data/00_RAW/EXT/\n\n\n\n\n\n\n/* プログラム冒頭でプロジェクトルートに移動 */\nfilename *Dir* \"../../../\" ;\n%let PROJECT_ROOT = %sysfunc(pathname(*DIR*)) ;\nfilename *Dir* clear ;\nX \"cd &PROJECT_ROOT.\" ;\n\n/* 以降はシンプルな相対パス */\n%include \"00_Settings\\init.sas\" ;\n%let external = 01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n\n\n\n/* 現在地を変更せず、長い相対パスを使用 */\n%include \"..\\..\\..\\00_Settings\\init.sas\" ;\n%let external = ..\\..\\..\\01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n\n\n\nプロジェクトルート移動（推奨）\n\n✅ パスがシンプル\n✅ 可読性が良い\n✅ 他のプログラムでも同じパターン使用可能\n❌ 作業ディレクトリが変わる\n\n長い相対パス\n\n✅ 作業ディレクトリが変わらない\n❌ パスが長くて読みにくい\n❌ メンテナンスが大変\n\n\n\n\n\n\n\n/* 現在地を間違えている */\n%let external = ../01_Data/00_RAW/EXT/file.xlsx ;  /* ..が足りない */\n\n/* フォルダ名を間違えている */\n%let external = ../../Data/RAW/EXT/file.xlsx ;     /* 01_が抜けている */\n\n/* X command後にパスが混乱 */\nX \"cd &PROJECT_ROOT.\" ;\n%let external = ../../01_Data/00_RAW/EXT/file.xlsx ; /* もう..は不要 */\n\n\n\n/* 段階的に確認 */\nfilename test1 \"..\" ;\n%put %sysfunc(pathname(test1)) ;  /* 1つ上を確認 */\n\nfilename test2 \"../..\" ;\n%put %sysfunc(pathname(test2)) ;  /* 2つ上を確認 */\n\nfilename test3 \"../../01_Data\" ;\n%put %sysfunc(pathname(test3)) ;  /* 目的フォルダを確認 */\n\n\n\n\n\n\n/* SAS */\nfilename chkpath \"../../01_Data\" ;\n%put パス確認: %sysfunc(pathname(chkpath)) ;\nfilename chkpath clear ;\n# R\nfile.exists(\"../../01_Data\")  # TRUE/FALSEで確認\nnormalizePath(\"../../01_Data\")  # 絶対パス表示\n\n\n\n/* SAS - プロジェクトルート移動後 */\nX \"cd &PROJECT_ROOT.\" ;\n%let DATA_ROOT = 01_Data ;\n%let RAW_DATA = &DATA_ROOT.\\00_RAW ;\n%let EXT_DATA = &RAW_DATA.\\EXT ;\n%let external = &EXT_DATA.\\target_file.xlsx ;\n# R\nsetwd(PROJECT_ROOT)\nDATA_ROOT &lt;- \"01_Data\"\nRAW_DATA &lt;- file.path(DATA_ROOT, \"00_RAW\")\nEXT_DATA &lt;- file.path(RAW_DATA, \"EXT\")\nexternal_file &lt;- file.path(EXT_DATA, \"target_file.xlsx\")\n\n\n\n/* SAS */\n%put 現在地: %sysfunc(getoption(work)) ;\nfilename pwd \".\" ;\n%put 現在地: %sysfunc(pathname(pwd)) ;\nfilename pwd clear ;\n# R\ngetwd()  # 現在の作業ディレクトリ\n\n\n\n\n\n.. の数 = 上に戻る階層数\nX commandでプロジェクトルートに移動すると相対パスがシンプルになる\nフォルダ構造を把握してから相対パスを設計\nパス確認を習慣化する\n変数化で管理しやすくする\nSASのfilenameとRのgetwd()系関数で現在地を把握\n\n相対パスとX commandをマスターすれば、プロジェクト全体の移動や共有が格段に楽になります！"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#相対パスとは",
    "href": "posts/statistics/2025/相対Path.html#相対パスとは",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "相対パスは、現在いる場所を基準にしたファイルやフォルダの位置を表す方法です。\n\n\n\n. = 現在のディレクトリ\n.. = 1つ上のディレクトリ\n../../ = 2つ上のディレクトリ\n../../../ = 3つ上のディレクトリ"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#フォルダ構造の例",
    "href": "posts/statistics/2025/相対Path.html#フォルダ構造の例",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "Project/                    ← プロジェクトルート\n├── 01_Data/\n│   ├── 00_RAW/\n│   │   └── EXT/\n│   └── 01_PROCESSED/\n├── 02_Programs/\n│   ├── ADaM/\n│   │   └── v2.0/           ← 現在ここにいる\n│   └── TLF/\n└── 03_Output/"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#現在のディレクトリ情報を取得するsasコード",
    "href": "posts/statistics/2025/相対Path.html#現在のディレクトリ情報を取得するsasコード",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "*------------------------------------------------------------------------------;\n* Get Current Directory Path ;\n*------------------------------------------------------------------------------;\nfilename *Dir* \".\" ;\n%let PgmType = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n%put  &PgmType. ;\nfilename *Dir* \"../\" ;\n%let PgmEnv  = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n%put  &PgmEnv. ;\nfilename *Dir* \"../../\" ;\n%let Dir     = %sysfunc ( pathname ( *DIR* ) ) ;\n%put  &Dir. ;\nfilename *Dir* clear ;\n\n\n1行目: 現在のディレクトリ（“.”）にファイル参照を設定\nfilename *Dir* \".\" ;\n2行目: 現在のディレクトリ名を取得\n%let PgmType = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n\n%sysfunc(pathname(*DIR*)) → フルパスを取得\n%scan(..., -1, %str(\\)) → パスを\\で区切って最後の部分を取得\n結果: v2.0 （現在のフォルダ名）\n\n4行目: 1つ上のディレクトリに参照を変更\nfilename *Dir* \"../\" ;\n5行目: 1つ上のディレクトリ名を取得\n%let PgmEnv  = %scan ( %sysfunc ( pathname ( *DIR* ) ) , -1 , %str ( \\ ) ) ;\n\n結果: ADaM （1つ上のフォルダ名）\n\n7行目: 2つ上のディレクトリに参照を変更\nfilename *Dir* \"../../\" ;\n8行目: 2つ上のディレクトリのフルパスを取得\n%let Dir     = %sysfunc ( pathname ( *DIR* ) ) ;\n\n結果: C:\\Project\\02_Programs （2つ上のフルパス）\n\n10行目: ファイル参照をクリア\nfilename *Dir* clear ;\n\n\n\nPgmType: v2.0\nPgmEnv: ADaM  \nDir: C:\\Project\\02_Programs"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#x-commandでディレクトリ移動",
    "href": "posts/statistics/2025/相対Path.html#x-commandでディレクトリ移動",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "/* 現在地: C:\\Project\\02_Programs\\ADaM\\v2.0\\ */\n\n/* プロジェクトルートに移動 */\nX \"cd ../../../\" ;\n\n/* または、絶対パスで移動 */\n%let PROJECT_ROOT = C:\\Project ;\nX \"cd &PROJECT_ROOT.\" ;\n\n\n\n/* 現在のプログラムパスを取得 */\n%let execpath = %sysfunc(getoption(sysin)) ;\n%let CURRENT = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n\n/* プロジェクトルートを算出 */\nfilename *Dir* \"../../../\" ;\n%let PROJECT_ROOT = %sysfunc(pathname(*DIR*)) ;\nfilename *Dir* clear ;\n\n/* プロジェクトルートに移動 */\nX \"cd &PROJECT_ROOT.\" ;\n%put 現在地をプロジェクトルートに変更: &PROJECT_ROOT. ;\n\n/* これで相対パスがシンプルになる */\n%let RAW_DATA = 01_Data\\00_RAW ;\n%let PROCESSED_DATA = 01_Data\\01_PROCESSED ;\n%let OUTPUT_DIR = 03_Output ;\n\n\n\n/* X commandでプロジェクトルートに移動後 */\nX \"cd &PROJECT_ROOT.\" ;\n\n/* 相対パスがシンプルに！ */\n%let external = 01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n%include \"00_Settings\\init.sas\" ;\nods pdf file=\"03_Output\\ADSL_Summary.pdf\" ;\n\n/* 移動前だと... */\n%let external = ..\\..\\..\\01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n%include \"..\\..\\..\\00_Settings\\init.sas\" ;\nods pdf file=\"..\\..\\..\\03_Output\\ADSL_Summary.pdf\" ;"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#r版での同等処理",
    "href": "posts/statistics/2025/相対Path.html#r版での同等処理",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "# 現在のディレクトリ情報を取得\nget_directory_info &lt;- function() {\n  current_path &lt;- getwd()\n  \n  # 現在のディレクトリ名\n  PgmType &lt;- basename(current_path)\n  \n  # 1つ上のディレクトリ名\n  parent_path &lt;- dirname(current_path)\n  PgmEnv &lt;- basename(parent_path)\n  \n  # 2つ上のディレクトリのフルパス\n  Dir &lt;- dirname(parent_path)\n  \n  # 結果を表示\n  cat(\"PgmType:\", PgmType, \"\\n\")\n  cat(\"PgmEnv:\", PgmEnv, \"\\n\") \n  cat(\"Dir:\", Dir, \"\\n\")\n  \n  # リストで返す\n  list(\n    PgmType = PgmType,\n    PgmEnv = PgmEnv,\n    Dir = Dir\n  )\n}\n\n# 実行\ndir_info &lt;- get_directory_info()\n\n# プロジェクトルートに移動\nPROJECT_ROOT &lt;- dirname(dirname(dirname(getwd())))\nsetwd(PROJECT_ROOT)\n\n# 相対パスがシンプルに\nexternal_file &lt;- \"01_Data/00_RAW/EXT/external_data.xlsx\"\nsource(\"00_Settings/init.R\")"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#相対パスの読み方",
    "href": "posts/statistics/2025/相対Path.html#相対パスの読み方",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "現在地：02_Programs/ADaM/v2.0/ にいる場合\n\n\n\n.. → 02_Programs/ADaM/ に移動\n../ → 02_Programs/ に移動\n01_Data/ → 01_Data/ フォルダに入る\n00_RAW/EXT/ → さらに奥のフォルダに入る\n\n結果: Project/01_Data/00_RAW/EXT/"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#実践的な使用パターン",
    "href": "posts/statistics/2025/相対Path.html#実践的な使用パターン",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "/* プログラム冒頭でプロジェクトルートに移動 */\nfilename *Dir* \"../../../\" ;\n%let PROJECT_ROOT = %sysfunc(pathname(*DIR*)) ;\nfilename *Dir* clear ;\nX \"cd &PROJECT_ROOT.\" ;\n\n/* 以降はシンプルな相対パス */\n%include \"00_Settings\\init.sas\" ;\n%let external = 01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n\n\n\n/* 現在地を変更せず、長い相対パスを使用 */\n%include \"..\\..\\..\\00_Settings\\init.sas\" ;\n%let external = ..\\..\\..\\01_Data\\00_RAW\\EXT\\external_data.xlsx ;\n\n\n\nプロジェクトルート移動（推奨）\n\n✅ パスがシンプル\n✅ 可読性が良い\n✅ 他のプログラムでも同じパターン使用可能\n❌ 作業ディレクトリが変わる\n\n長い相対パス\n\n✅ 作業ディレクトリが変わらない\n❌ パスが長くて読みにくい\n❌ メンテナンスが大変"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#よくある失敗パターン",
    "href": "posts/statistics/2025/相対Path.html#よくある失敗パターン",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "/* 現在地を間違えている */\n%let external = ../01_Data/00_RAW/EXT/file.xlsx ;  /* ..が足りない */\n\n/* フォルダ名を間違えている */\n%let external = ../../Data/RAW/EXT/file.xlsx ;     /* 01_が抜けている */\n\n/* X command後にパスが混乱 */\nX \"cd &PROJECT_ROOT.\" ;\n%let external = ../../01_Data/00_RAW/EXT/file.xlsx ; /* もう..は不要 */\n\n\n\n/* 段階的に確認 */\nfilename test1 \"..\" ;\n%put %sysfunc(pathname(test1)) ;  /* 1つ上を確認 */\n\nfilename test2 \"../..\" ;\n%put %sysfunc(pathname(test2)) ;  /* 2つ上を確認 */\n\nfilename test3 \"../../01_Data\" ;\n%put %sysfunc(pathname(test3)) ;  /* 目的フォルダを確認 */"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#実践的なコツ",
    "href": "posts/statistics/2025/相対Path.html#実践的なコツ",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": "/* SAS */\nfilename chkpath \"../../01_Data\" ;\n%put パス確認: %sysfunc(pathname(chkpath)) ;\nfilename chkpath clear ;\n# R\nfile.exists(\"../../01_Data\")  # TRUE/FALSEで確認\nnormalizePath(\"../../01_Data\")  # 絶対パス表示\n\n\n\n/* SAS - プロジェクトルート移動後 */\nX \"cd &PROJECT_ROOT.\" ;\n%let DATA_ROOT = 01_Data ;\n%let RAW_DATA = &DATA_ROOT.\\00_RAW ;\n%let EXT_DATA = &RAW_DATA.\\EXT ;\n%let external = &EXT_DATA.\\target_file.xlsx ;\n# R\nsetwd(PROJECT_ROOT)\nDATA_ROOT &lt;- \"01_Data\"\nRAW_DATA &lt;- file.path(DATA_ROOT, \"00_RAW\")\nEXT_DATA &lt;- file.path(RAW_DATA, \"EXT\")\nexternal_file &lt;- file.path(EXT_DATA, \"target_file.xlsx\")\n\n\n\n/* SAS */\n%put 現在地: %sysfunc(getoption(work)) ;\nfilename pwd \".\" ;\n%put 現在地: %sysfunc(pathname(pwd)) ;\nfilename pwd clear ;\n# R\ngetwd()  # 現在の作業ディレクトリ"
  },
  {
    "objectID": "posts/statistics/2025/相対Path.html#まとめ",
    "href": "posts/statistics/2025/相対Path.html#まとめ",
    "title": "SAS・Rでの相対パス ../../ の使い方完全ガイド",
    "section": "",
    "text": ".. の数 = 上に戻る階層数\nX commandでプロジェクトルートに移動すると相対パスがシンプルになる\nフォルダ構造を把握してから相対パスを設計\nパス確認を習慣化する\n変数化で管理しやすくする\nSASのfilenameとRのgetwd()系関数で現在地を把握\n\n相対パスとX commandをマスターすれば、プロジェクト全体の移動や共有が格段に楽になります！"
  },
  {
    "objectID": "posts/statistics/2025/統計方法論研究におけるフォルダ構成.html",
    "href": "posts/statistics/2025/統計方法論研究におけるフォルダ構成.html",
    "title": "方法論研究におけるフォルダ構成を考える",
    "section": "",
    "text": "実データ解析に関するフォルダ構成は、別記事で作成済である。実務と同様の構成で実施したらよい。ここでは、実データを利用することを主眼とせず、特定の統計方法論に基づくシミュレーション研究/方法論研究のフォルダ構造について考える。そして、Rにて自動でフォルダを作成するような標準テンプレートを作成することを目的とする。以下はGeminiに作ってもらったもの。\n\n\nこんにちは！研究者の皆さん、日々のシミュレーション研究、お疲れ様です。\nシミュレーション研究って、実データ解析とはまた違った難しさがありますよね。特に、様々なパラメータ設定、シナリオごとの結果管理、そしていつどのスクリプトを実行したかといった記録の管理は、研究の再現性や効率に直結する重要な課題です。\n「あの時の結果、どのファイルだっけ…？」 「このスクリプト、どのシミュレーション設定で走らせたんだっけ…？」\nこんな経験、ありませんか？\n今回は、そんな悩みを解決するための「シミュレーション研究に特化した理想のフォルダ構成」と、それをRで自動生成する便利なテンプレートをご紹介します。Git管理や複雑なドキュメント、さらにはRの初期設定ファイルも一旦置いておいて、まずは研究に集中できるミニマルで効率的な環境をサッと作っちゃいましょう！\n\n\nシミュレーション研究では、特に以下の点が管理のポイントになります。\n\n再現性: どのスクリプトが、いつ、どの設定で実行され、どんな結果が出たのかが明確であること。\n効率性: 目的のファイルに素早くアクセスでき、新しいシミュレーションを追加しやすいこと。\n整理整頓: 膨大になりがちな中間ファイルや結果を体系的に保存できること。\n\nこれらを解決するために、以下のようなフォルダ構成をおすすめします。\n\n\n\n私たちが提案するフォルダ構成は、研究のワークフローを考慮し、以下のように整理されています。特に、日々の進捗を明確にするために日付(YYYYMMDD)でのフォルダ管理を取り入れています。フォルダ名の先頭に数字を付けることで、常に意図した順序で表示されるよう工夫しています。\nプロジェクトルート/\n├── 001_data/\n│   └── raw/           # シミュレーションの元となる外部データや真のパラメータ設定\n├── 002_R/\n│   ├── functions/     # シミュレーションの中核となるR関数群\n│   └── utils/         # 汎用的なユーティリティR関数\n├── 003_output/        # シミュレーション結果の出力ルート\n│   └── YYYYMMDD/      # 例: 20250711 (その日のシミュレーション結果を格納)\n├── 004_src/           # シミュレーション実行スクリプトのルート\n│   └── YYYYMMDD/      # 例: 20250711 (その日に実行したスクリプトを格納)\n├── 005_scripts/       # シミュレーション設定やバッチ処理用スクリプト\n├── 006_docs/          # 研究ノート、アイデアなど（論文以外のドキュメント）\n├── 007_meeting/       # 指導教官との打ち合わせ記録\n│   └── YYYYMMDD/      # 例: 20250710 (その日の打ち合わせ資料・議事録など)\n├── 008_Paper/         # 論文ドラフトや最終版の図・表、参考文献ファイル\n├── renv/              # Rパッケージ管理（renvを使用する場合）\n\n\n\nそれぞれのフォルダには明確な役割があります。適切に使い分けることで、プロジェクト全体が整理され、将来の自分や共同研究者が困ることがなくなります。\n\n\n\n目的: シミュレーションの元となる固定データを格納する場所です。\n内容:\n\nraw/: 外部から取得した生データや、シミュレーションの「真の値」として設定するパラメータのファイルなど。シミュレーション内で動的に生成されるデータはここには置きません。\n\n使い分け: シミュレーションの入力となる、変更されない静的なデータを置きます。\n\n\n\n\n\n目的: Rの関数ファイルを格納する場所です。これにより、スクリプト本体がすっきりし、関数を再利用しやすくなります。\n内容:\n\nfunctions/: シミュレーションの中核となるカスタム関数を定義したファイル。例えば、特定の分布からデータを生成する関数、開発中の推定量を計算する関数、統計モデルをフィットする関数などです。これらの関数は、004_src内の実行スクリプトから呼び出して使います。\nutils/: シミュレーション結果の集計、プロット作成、結果の整形など、汎用的に利用するユーティリティ関数を定義したファイル。特定のシミュレーションに限定されず、複数の研究で使い回せるような関数が該当します。\n\n使い分け: 長いRスクリプトを機能ごとに分割し、再利用可能な部品として管理します。実行スクリプトはこれらの関数を「呼び出す」だけに留めます。\n\n\n\n\n\n目的: シミュレーションによって生成された結果を保存する場所です。\n内容:\n\nYYYYMMDD/: シミュレーションを実行した日付ごとのフォルダ。この中に、その日の実行で得られた結果を保存します。\n\nresults/: シミュレーションによって得られた数値結果（例: 推定量、標準誤差、p値、バイアスなど）を.rdsファイルや.csvファイルとして保存します。\nfigures/: 結果を可視化したグラフや図を.pngや.pdf形式で保存します。\ntables/: 結果をまとめた表を.texや.docx形式で保存します。\n\n\n使い分け: シミュレーションの結果として「残すべきもの」は全てここに集約します。日付フォルダにより、いつの結果かが一目でわかります。\n\n\n\n\n\n目的: シミュレーションの具体的な実行ロジックと、それに伴う結果解析のコードを格納する場所です。\n内容:\n\nYYYYMMDD/: シミュレーションを実行した日付ごとのフォルダ。この中に、その日の特定のシミュレーション実行に関するスクリプトを格納します。\n\n01_run_simulation.R: シミュレーションを実際に実行し、データを生成し、003_output/YYYYMMDD/results/ に保存するスクリプト。\n02_analyze_results.R: 003_output/YYYYMMDD/results/ に保存された結果を読み込み、解析し、003_output/YYYYMMDD/figures/ や 003_output/YYYYMMDD/tables/ に保存するスクリプト。\n03_generate_report.R: シミュレーション結果をまとめた簡易レポートやQuartoドキュメントを生成するスクリプト。\n\n\n使い分け: **「このシミュレーション結果を得るために、どのコードを走らせたか？」**という問いに直接答えるコードを置きます。日付フォルダにまとめることで、再現性が飛躍的に向上します。\n\n\n\n\n\n目的: プロジェクト全体をスムーズに進めるための補助的なスクリプトやユーティリティを置く場所です。\n内容:\n\nシミュレーション実行前に必要な環境設定スクリプト（例: パス設定、共通オプション）。\n複数のシミュレーションを自動で実行するためのバッチ処理スクリプト（例: HPC環境でのジョブ投入スクリプト）。\n001_data/raw にある生データを、シミュレーションで使いやすい形に加工する一度きりの前処理スクリプト。\n複数のシミュレーションシナリオで共通して使われるパラメータ設定を定義するスクリプトなど。\n\n使い分け: **「このプロジェクトを進める上で、どんなツールや設定が必要か？」**という問いに答えるコードを置きます。特定のシミュレーション実行とは独立しており、汎用性が高いコードが該当します。\n\n\n\n\n\n目的: 研究に関するドキュメントやアイデア、メモなどを格納する場所です。\n内容: 研究ノート、ブレインストーミングのメモ、学会発表の草案、今後の研究アイデア、関連論文のまとめなど。\n使い分け: 008_Paper/ が論文原稿そのものであるのに対し、こちらは論文に直接ならないような「研究の過程」を示す資料を置きます。\n\n\n\n\n\n目的: 指導教官や共同研究者との打ち合わせ記録を保存する場所です。\n内容:\n\nYYYYMMDD/: 打ち合わせがあった日付ごとのフォルダ。この中に、議事録、議論のポイント、ToDoリスト、共有資料などを保存します。\n\n使い分け: 打ち合わせの履歴を時系列で管理することで、以前の議論内容をすぐに確認できます。\n\n\n\n\n\n目的: 論文のドラフトや、論文に最終的に含める図表のファイル、参考文献ファイルなどを格納する場所です。\n内容: Quarto（.qmd）ファイル、LaTeX（.tex）ファイル、Word（.docx）ファイルなどの論文原稿、論文で使う高品質な図（.pdf, .tiff）、表（.tex, .csv）、参考文献データベース（.bib）など。\n使い分け: シミュレーション結果 (003_output/) から論文に直接持っていく最終的な成果物をここに集約します。\n\n\n\n\n\nこの理想的なフォルダ構成を、Rのスクリプトでサクッと自動生成しちゃいましょう！以下のコードをRコンソールに貼り付けて実行するだけです。プロジェクトを作成したいディレクトリに移動してから実行してください。\n#' シミュレーション研究プロジェクトのフォルダ構造を自動生成する関数 (究極のフォルダのみ版)\n#'\n#' @param project_name 作成するプロジェクトのルートフォルダ名\n#' @param use_renv renvパッケージを使用するかどうか (TRUE/FALSE)\n#'\n#' @return なし。指定されたパスにフォルダ構造を作成します。\n#' @export\ncreate_sim_project_structure_minimal &lt;- function(project_name, use_renv = TRUE) {\n  \n  # プロジェクトルートのパスを設定 (現在の作業ディレクトリに作成)\n  project_path &lt;- file.path(getwd(), project_name)\n\n  # ルートフォルダの作成\n  if (dir.exists(project_path)) {\n    stop(paste0(\"フォルダ '\", project_path, \"' は既に存在します。別の名前を指定するか、既存のフォルダを削除してください。\"))\n  }\n  dir.create(project_path, recursive = TRUE)\n  message(paste0(\"プロジェクトルートフォルダ '\", project_path, \"' を作成しました。\\n\"))\n  \n  # サブフォルダの定義\n  # src, output, meetingの内部は日付管理されるため、ここでは親フォルダのみ作成\n  sub_folders &lt;- c(\n    \"001_data/raw\",\n    \"002_R/functions\",\n    \"002_R/utils\",\n    \"003_output\",\n    \"004_src\",\n    \"005_scripts\",\n    \"006_docs\",\n    \"007_meeting\",\n    \"008_Paper\"\n  )\n  \n  # サブフォルダの作成\n  for (folder in sub_folders) {\n    dir.create(file.path(project_path, folder), recursive = TRUE)\n    message(paste0(\"  - フォルダ '\", file.path(project_path, folder), \"' を作成しました。\\n\"))\n  }\n  \n  # renvの初期化\n  if (use_renv) {\n    message(\"renvの初期化を開始します。これには少し時間がかかる場合があります...\\n\")\n    # 作業ディレクトリを一時的にプロジェクトルートに変更してrenvを初期化\n    old_wd &lt;- getwd()\n    setwd(project_path) # ここでプロジェクトパスに移動\n    tryCatch({\n      if (!requireNamespace(\"renv\", quietly = TRUE)) {\n        install.packages(\"renv\")\n      }\n      renv::init()\n      message(\"  - renvを初期化しました。\\n\")\n      message(\"    プロジェクトルートに '.Rprofile' と 'renv.lock' が生成されます。\\n\")\n    }, error = function(e) {\n      message(paste0(\"  - renvの初期化中にエラーが発生しました: \", e$message, \"\\n\"))\n      message(\"    手動で `renv::init()` を実行してください。\\n\")\n    }, finally = {\n      setwd(old_wd) # 元の作業ディレクトリに戻す\n    })\n  }\n  \n  message(paste0(\"\\nプロジェクト '\", project_name, \"' のフォルダ構造が正常に作成されました。\"))\n  if (use_renv) {\n    message(paste0(\"RStudioで '\", project_name, \".Rproj' を開いた後、`renv::restore()` を実行して必要なパッケージをインストールしてください。\"))\n  } else {\n    message(paste0(\"RStudioで '\", project_name, \".Rproj' を開いて作業を開始してください。\"))\n  }\n  message(\"\\n**補足:**\")\n  message(\"  - `004_src/`, `003_output/`, `007_meeting/` フォルダ内は、ご自身で `YYYYMMDD/` 形式のサブフォルダを作成し、ファイルを整理してください。\")\n  message(\"  - `008_Paper/` フォルダ内には、論文ドラフトや関連ファイルを自由に配置してください。\")\n}\n使い方：\n\n上記Rコードをコピーし、RStudioのコンソールに貼り付けるか、新しい .R ファイルとして保存します。\nプロジェクトを作成したい場所に移動します（例: setwd(\"~/Your/Projects/Path\")）。\nコンソールで create_sim_project_structure_minimal(\"任意のプロジェクト名\", use_renv = TRUE) を呼び出します。\n\n\"任意のプロジェクト名\" は、新しく作るプロジェクトのルートフォルダ名です。\nuse_renv = TRUE にすると renv が自動的に初期化されます。もし renv も不要であれば、use_renv = FALSE に設定してください。\n\n\n\n\n\n\nシミュレーション実行日:\n\n今日が2025年7月11日なら、004_src/20250711/ フォルダを作り、その中に実行スクリプト (01_run_sim_A.R など) を置きます。\n実行結果は 003_output/20250711/ フォルダ内に保存します（例: results/sim_A_summary.rds, figures/plot_A.png）。\n\n打ち合わせ日:\n\n2025年7月10日に指導教官と打ち合わせをしたら、007_meeting/20250710/ フォルダを作り、議事録や資料をそこに保存します。\n\n論文執筆:\n\n008_Paper/ フォルダには、論文のQuartoファイルやLaTeXファイル、そして論文に含める最終的な図表などを格納します。\n\n\nこの自動生成テンプレートを活用して、シミュレーション研究をより効率的かつ体系的に進め、素晴らしい成果に繋げていきましょう！"
  },
  {
    "objectID": "posts/statistics/2025/統計方法論研究におけるフォルダ構成.html#シミュレーション研究の強い味方rで自動生成する理想のフォルダ構成",
    "href": "posts/statistics/2025/統計方法論研究におけるフォルダ構成.html#シミュレーション研究の強い味方rで自動生成する理想のフォルダ構成",
    "title": "方法論研究におけるフォルダ構成を考える",
    "section": "",
    "text": "こんにちは！研究者の皆さん、日々のシミュレーション研究、お疲れ様です。\nシミュレーション研究って、実データ解析とはまた違った難しさがありますよね。特に、様々なパラメータ設定、シナリオごとの結果管理、そしていつどのスクリプトを実行したかといった記録の管理は、研究の再現性や効率に直結する重要な課題です。\n「あの時の結果、どのファイルだっけ…？」 「このスクリプト、どのシミュレーション設定で走らせたんだっけ…？」\nこんな経験、ありませんか？\n今回は、そんな悩みを解決するための「シミュレーション研究に特化した理想のフォルダ構成」と、それをRで自動生成する便利なテンプレートをご紹介します。Git管理や複雑なドキュメント、さらにはRの初期設定ファイルも一旦置いておいて、まずは研究に集中できるミニマルで効率的な環境をサッと作っちゃいましょう！\n\n\nシミュレーション研究では、特に以下の点が管理のポイントになります。\n\n再現性: どのスクリプトが、いつ、どの設定で実行され、どんな結果が出たのかが明確であること。\n効率性: 目的のファイルに素早くアクセスでき、新しいシミュレーションを追加しやすいこと。\n整理整頓: 膨大になりがちな中間ファイルや結果を体系的に保存できること。\n\nこれらを解決するために、以下のようなフォルダ構成をおすすめします。\n\n\n\n私たちが提案するフォルダ構成は、研究のワークフローを考慮し、以下のように整理されています。特に、日々の進捗を明確にするために日付(YYYYMMDD)でのフォルダ管理を取り入れています。フォルダ名の先頭に数字を付けることで、常に意図した順序で表示されるよう工夫しています。\nプロジェクトルート/\n├── 001_data/\n│   └── raw/           # シミュレーションの元となる外部データや真のパラメータ設定\n├── 002_R/\n│   ├── functions/     # シミュレーションの中核となるR関数群\n│   └── utils/         # 汎用的なユーティリティR関数\n├── 003_output/        # シミュレーション結果の出力ルート\n│   └── YYYYMMDD/      # 例: 20250711 (その日のシミュレーション結果を格納)\n├── 004_src/           # シミュレーション実行スクリプトのルート\n│   └── YYYYMMDD/      # 例: 20250711 (その日に実行したスクリプトを格納)\n├── 005_scripts/       # シミュレーション設定やバッチ処理用スクリプト\n├── 006_docs/          # 研究ノート、アイデアなど（論文以外のドキュメント）\n├── 007_meeting/       # 指導教官との打ち合わせ記録\n│   └── YYYYMMDD/      # 例: 20250710 (その日の打ち合わせ資料・議事録など)\n├── 008_Paper/         # 論文ドラフトや最終版の図・表、参考文献ファイル\n├── renv/              # Rパッケージ管理（renvを使用する場合）\n\n\n\nそれぞれのフォルダには明確な役割があります。適切に使い分けることで、プロジェクト全体が整理され、将来の自分や共同研究者が困ることがなくなります。\n\n\n\n目的: シミュレーションの元となる固定データを格納する場所です。\n内容:\n\nraw/: 外部から取得した生データや、シミュレーションの「真の値」として設定するパラメータのファイルなど。シミュレーション内で動的に生成されるデータはここには置きません。\n\n使い分け: シミュレーションの入力となる、変更されない静的なデータを置きます。\n\n\n\n\n\n目的: Rの関数ファイルを格納する場所です。これにより、スクリプト本体がすっきりし、関数を再利用しやすくなります。\n内容:\n\nfunctions/: シミュレーションの中核となるカスタム関数を定義したファイル。例えば、特定の分布からデータを生成する関数、開発中の推定量を計算する関数、統計モデルをフィットする関数などです。これらの関数は、004_src内の実行スクリプトから呼び出して使います。\nutils/: シミュレーション結果の集計、プロット作成、結果の整形など、汎用的に利用するユーティリティ関数を定義したファイル。特定のシミュレーションに限定されず、複数の研究で使い回せるような関数が該当します。\n\n使い分け: 長いRスクリプトを機能ごとに分割し、再利用可能な部品として管理します。実行スクリプトはこれらの関数を「呼び出す」だけに留めます。\n\n\n\n\n\n目的: シミュレーションによって生成された結果を保存する場所です。\n内容:\n\nYYYYMMDD/: シミュレーションを実行した日付ごとのフォルダ。この中に、その日の実行で得られた結果を保存します。\n\nresults/: シミュレーションによって得られた数値結果（例: 推定量、標準誤差、p値、バイアスなど）を.rdsファイルや.csvファイルとして保存します。\nfigures/: 結果を可視化したグラフや図を.pngや.pdf形式で保存します。\ntables/: 結果をまとめた表を.texや.docx形式で保存します。\n\n\n使い分け: シミュレーションの結果として「残すべきもの」は全てここに集約します。日付フォルダにより、いつの結果かが一目でわかります。\n\n\n\n\n\n目的: シミュレーションの具体的な実行ロジックと、それに伴う結果解析のコードを格納する場所です。\n内容:\n\nYYYYMMDD/: シミュレーションを実行した日付ごとのフォルダ。この中に、その日の特定のシミュレーション実行に関するスクリプトを格納します。\n\n01_run_simulation.R: シミュレーションを実際に実行し、データを生成し、003_output/YYYYMMDD/results/ に保存するスクリプト。\n02_analyze_results.R: 003_output/YYYYMMDD/results/ に保存された結果を読み込み、解析し、003_output/YYYYMMDD/figures/ や 003_output/YYYYMMDD/tables/ に保存するスクリプト。\n03_generate_report.R: シミュレーション結果をまとめた簡易レポートやQuartoドキュメントを生成するスクリプト。\n\n\n使い分け: **「このシミュレーション結果を得るために、どのコードを走らせたか？」**という問いに直接答えるコードを置きます。日付フォルダにまとめることで、再現性が飛躍的に向上します。\n\n\n\n\n\n目的: プロジェクト全体をスムーズに進めるための補助的なスクリプトやユーティリティを置く場所です。\n内容:\n\nシミュレーション実行前に必要な環境設定スクリプト（例: パス設定、共通オプション）。\n複数のシミュレーションを自動で実行するためのバッチ処理スクリプト（例: HPC環境でのジョブ投入スクリプト）。\n001_data/raw にある生データを、シミュレーションで使いやすい形に加工する一度きりの前処理スクリプト。\n複数のシミュレーションシナリオで共通して使われるパラメータ設定を定義するスクリプトなど。\n\n使い分け: **「このプロジェクトを進める上で、どんなツールや設定が必要か？」**という問いに答えるコードを置きます。特定のシミュレーション実行とは独立しており、汎用性が高いコードが該当します。\n\n\n\n\n\n目的: 研究に関するドキュメントやアイデア、メモなどを格納する場所です。\n内容: 研究ノート、ブレインストーミングのメモ、学会発表の草案、今後の研究アイデア、関連論文のまとめなど。\n使い分け: 008_Paper/ が論文原稿そのものであるのに対し、こちらは論文に直接ならないような「研究の過程」を示す資料を置きます。\n\n\n\n\n\n目的: 指導教官や共同研究者との打ち合わせ記録を保存する場所です。\n内容:\n\nYYYYMMDD/: 打ち合わせがあった日付ごとのフォルダ。この中に、議事録、議論のポイント、ToDoリスト、共有資料などを保存します。\n\n使い分け: 打ち合わせの履歴を時系列で管理することで、以前の議論内容をすぐに確認できます。\n\n\n\n\n\n目的: 論文のドラフトや、論文に最終的に含める図表のファイル、参考文献ファイルなどを格納する場所です。\n内容: Quarto（.qmd）ファイル、LaTeX（.tex）ファイル、Word（.docx）ファイルなどの論文原稿、論文で使う高品質な図（.pdf, .tiff）、表（.tex, .csv）、参考文献データベース（.bib）など。\n使い分け: シミュレーション結果 (003_output/) から論文に直接持っていく最終的な成果物をここに集約します。\n\n\n\n\n\nこの理想的なフォルダ構成を、Rのスクリプトでサクッと自動生成しちゃいましょう！以下のコードをRコンソールに貼り付けて実行するだけです。プロジェクトを作成したいディレクトリに移動してから実行してください。\n#' シミュレーション研究プロジェクトのフォルダ構造を自動生成する関数 (究極のフォルダのみ版)\n#'\n#' @param project_name 作成するプロジェクトのルートフォルダ名\n#' @param use_renv renvパッケージを使用するかどうか (TRUE/FALSE)\n#'\n#' @return なし。指定されたパスにフォルダ構造を作成します。\n#' @export\ncreate_sim_project_structure_minimal &lt;- function(project_name, use_renv = TRUE) {\n  \n  # プロジェクトルートのパスを設定 (現在の作業ディレクトリに作成)\n  project_path &lt;- file.path(getwd(), project_name)\n\n  # ルートフォルダの作成\n  if (dir.exists(project_path)) {\n    stop(paste0(\"フォルダ '\", project_path, \"' は既に存在します。別の名前を指定するか、既存のフォルダを削除してください。\"))\n  }\n  dir.create(project_path, recursive = TRUE)\n  message(paste0(\"プロジェクトルートフォルダ '\", project_path, \"' を作成しました。\\n\"))\n  \n  # サブフォルダの定義\n  # src, output, meetingの内部は日付管理されるため、ここでは親フォルダのみ作成\n  sub_folders &lt;- c(\n    \"001_data/raw\",\n    \"002_R/functions\",\n    \"002_R/utils\",\n    \"003_output\",\n    \"004_src\",\n    \"005_scripts\",\n    \"006_docs\",\n    \"007_meeting\",\n    \"008_Paper\"\n  )\n  \n  # サブフォルダの作成\n  for (folder in sub_folders) {\n    dir.create(file.path(project_path, folder), recursive = TRUE)\n    message(paste0(\"  - フォルダ '\", file.path(project_path, folder), \"' を作成しました。\\n\"))\n  }\n  \n  # renvの初期化\n  if (use_renv) {\n    message(\"renvの初期化を開始します。これには少し時間がかかる場合があります...\\n\")\n    # 作業ディレクトリを一時的にプロジェクトルートに変更してrenvを初期化\n    old_wd &lt;- getwd()\n    setwd(project_path) # ここでプロジェクトパスに移動\n    tryCatch({\n      if (!requireNamespace(\"renv\", quietly = TRUE)) {\n        install.packages(\"renv\")\n      }\n      renv::init()\n      message(\"  - renvを初期化しました。\\n\")\n      message(\"    プロジェクトルートに '.Rprofile' と 'renv.lock' が生成されます。\\n\")\n    }, error = function(e) {\n      message(paste0(\"  - renvの初期化中にエラーが発生しました: \", e$message, \"\\n\"))\n      message(\"    手動で `renv::init()` を実行してください。\\n\")\n    }, finally = {\n      setwd(old_wd) # 元の作業ディレクトリに戻す\n    })\n  }\n  \n  message(paste0(\"\\nプロジェクト '\", project_name, \"' のフォルダ構造が正常に作成されました。\"))\n  if (use_renv) {\n    message(paste0(\"RStudioで '\", project_name, \".Rproj' を開いた後、`renv::restore()` を実行して必要なパッケージをインストールしてください。\"))\n  } else {\n    message(paste0(\"RStudioで '\", project_name, \".Rproj' を開いて作業を開始してください。\"))\n  }\n  message(\"\\n**補足:**\")\n  message(\"  - `004_src/`, `003_output/`, `007_meeting/` フォルダ内は、ご自身で `YYYYMMDD/` 形式のサブフォルダを作成し、ファイルを整理してください。\")\n  message(\"  - `008_Paper/` フォルダ内には、論文ドラフトや関連ファイルを自由に配置してください。\")\n}\n使い方：\n\n上記Rコードをコピーし、RStudioのコンソールに貼り付けるか、新しい .R ファイルとして保存します。\nプロジェクトを作成したい場所に移動します（例: setwd(\"~/Your/Projects/Path\")）。\nコンソールで create_sim_project_structure_minimal(\"任意のプロジェクト名\", use_renv = TRUE) を呼び出します。\n\n\"任意のプロジェクト名\" は、新しく作るプロジェクトのルートフォルダ名です。\nuse_renv = TRUE にすると renv が自動的に初期化されます。もし renv も不要であれば、use_renv = FALSE に設定してください。\n\n\n\n\n\n\nシミュレーション実行日:\n\n今日が2025年7月11日なら、004_src/20250711/ フォルダを作り、その中に実行スクリプト (01_run_sim_A.R など) を置きます。\n実行結果は 003_output/20250711/ フォルダ内に保存します（例: results/sim_A_summary.rds, figures/plot_A.png）。\n\n打ち合わせ日:\n\n2025年7月10日に指導教官と打ち合わせをしたら、007_meeting/20250710/ フォルダを作り、議事録や資料をそこに保存します。\n\n論文執筆:\n\n008_Paper/ フォルダには、論文のQuartoファイルやLaTeXファイル、そして論文に含める最終的な図表などを格納します。\n\n\nこの自動生成テンプレートを活用して、シミュレーション研究をより効率的かつ体系的に進め、素晴らしい成果に繋げていきましょう！"
  },
  {
    "objectID": "posts/statistics/2025/解析プロジェクトの最初に作成するSAS_PGM.html",
    "href": "posts/statistics/2025/解析プロジェクトの最初に作成するSAS_PGM.html",
    "title": "解析プロジェクトの最初に作成するSASプログラム",
    "section": "",
    "text": "SASを使った解析プロジェクトを始める際、毎回同じような初期設定のコードを書いている方も多いのではないでしょうか。この技術メモでは、解析プロジェクトの最初に作成する**Run_ADAM-Prg.sas**というメインプログラムについて、その構成と各セクションの意図を詳しく解説します。この初期設定をしっかり行うことで、プロジェクト全体の効率性と再現性が大幅に向上します。\n\n\nproc datasets kill nolist ; run ; quit ;\ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : Run_ADAM-Prg.sas\n* Author          : Kota Sakamoto\n* Date created    : 2025/07/02\n* Purpose         : ADaM作成プログラム\n* Revision History :\n***********************************************************************/\nプログラムの冒頭にこれらを記述することで、SASセッションを完全にクリーンな状態から始めることができます。\n\nproc datasets kill nolist ; run ; quit ;: 現在のSASセッションに存在するすべてのライブラリ（特にWORKライブラリ）内のデータセットとカタログを削除します。これにより、以前の実行で残った一時ファイルによる予期せぬエラーを防ぎます。\ndm 'out ; clear ; log ; clear ;' ;: SASログウィンドウと出力ウィンドウの内容をクリアします。これにより、現在の実行に関するログのみが表示され、デバッグがしやすくなります。\n\nその下には、ご指定のプログラムヘッダを記述します。プロジェクト名、ファイル名、作成者、作成日、目的、変更履歴などの情報を含めることで、プログラムの目的が明確になり、後から見返したり他の人と共有したりする際に非常に役立ちます。特に変更履歴は、問題発生時の原因特定や、新しいメンバーへの引き継ぎにおいて不可欠です。\n\n\n\nSAS\n*--- オプション設定 ---*;\noptions noxwait;    * XコマンドでSASシステムから制御した後、自動的に再度SASシステムに戻る ;\noptions noxsync;  * Xコマンドで開始した処理の終了を待たずにSASシステムに戻る ;\noptions noquotelenmax;  * 引用符で囲んだ文字が長すぎる場合のNOTEを出さないようにする ;\noptions source2;    * 2次ソースステートメントをSASログに書き込む ;\nSASの**OPTIONSステートメント**は、SASセッションの動作を制御するためのものです。プロジェクトの性質や個人の好みに応じて設定しますが、特に重要なものをいくつかご紹介します。\n\nnoxwait / noxsync: 外部コマンド（Xコマンドなど）の実行に関するオプションです。これらを指定することで、外部プロセスの完了を待たずにSASに戻る、または外部プロセスの実行中にSASがブロックされないようにすることができます。これは、外部スクリプトの呼び出しや、大量のファイル操作を行う際に役立ちます。\nnoquotelenmax: 長い文字列を引用符で囲んだ際に表示されるNOTEメッセージを抑制します。ログをきれいに保ちたい場合に便利です。\nsource2: INCLUDEステートメントなどで読み込まれた二次ソースコードもSASログに出力するようになります。デバッグ時にどのコードが実行されているかを確認するのに非常に役立ちます。\n追加の推奨オプション:\n\nls=MAX / ps=MAX: ログの行長とページ長を最大に設定し、ログが見やすくなります。\nfmterr: フォーマットが見つからない場合にエラーを発生させます。予期せぬフォーマットエラーを防ぐために重要です。\nerrors=0: SASセッション中のエラー表示数を無制限にします。これにより、すべてのエラーを確認できます。\n\n\n\n\n\nSAS\n*--- マクロ変数のクリア ---*;\n%put _user_;\ndata vars;\n    set sashelp.vmacro;\nrun;\n\ndata symdel;\n  set sashelp.vmacro;\n  where scope = 'GLOBAL' and NAME not in ('SYS_SQL_IP_ALL', 'SYS_SQL_IP_STMT');\nrun;\n\ndata _null_;\n  set symdel;\n  call symdel(name);\nrun; \n前のセッションやテスト実行で残ったグローバルマクロ変数が、現在の実行に影響を与えることを防ぐために、不要なマクロ変数をクリアします。sashelp.vmacroは現在定義されているマクロ変数の情報を持ち、CALL SYMDEL関数を使って特定の変数を削除できます。これにより、常にクリーンな状態でプログラムを実行できます。\n\n\n\nSAS\n*--- データセットの一括クリア ---*;\nproc delete data=work._all_;\nrun;\nSASの**WORKライブラリ**は一時的なデータセットが格納される場所です。過去の実行で作成されたデータセットが残っていると、意図しない結果を招いたり、ディスク容量を圧迫したりする可能性があります。PROC DELETE DATA=WORK._ALL_を使用することで、WORKライブラリ内のすべてのデータセットを効率的に削除し、常にゼロベースで解析を開始できます。\n\n\n\nSAS\n*--- ディレクトリの設定 ---*;\n* フルパスの取得 ;\n%let path = %sysget(SAS_EXECFILEPATH);\n%put &path.;\n\n* ファイル名の取得 ;\n%let filename = %SCAN(&path., -1, \"\\\");\n%put &filename.;\n\n* ディレクトリの取得 ;\n%let drct = %substr(&path., 1, %length(&path.)-%length(%SCAN(&path.,-1,\"\\\"))-1);\n%put &drct.;\n\n* ディレクトリ設定 ;\ndata _null_;\n    call system(\"cd &drct.\");\nrun;\nプロジェクトのパスを動的に設定することは非常に重要です。これにより、プログラムを異なる環境やPCに移動しても、パスを手動で変更する必要がなくなります。\n\n%sysget(SAS_EXECFILEPATH): 現在実行しているSASプログラムのフルパスを取得します。\n%SCAN / %SUBSTR / %LENGTH: マクロ関数を組み合わせて、フルパスからファイル名やディレクトリパスを抽出します。\nCALL SYSTEM(\"cd &drct.\"): SASセッションのカレントディレクトリを実行プログラムのディレクトリに設定します。これにより、相対パスでのファイル指定が容易になります。\n\n\n\n\nSAS\n*--- マクロ変数の定義 ---*;\n%let InputPath = &drct.\\Input;\n%let OutputPath = &drct.\\Output;\n%let LogPath = &drct.\\Log;\n%let PrgPath = &drct.\\Prg;\n%let SettingsPath = &drct.\\Settings;\n%let SpecPath = &drct.\\Spec;\n\n%let SettingsFile = ADAM設定ファイル.xlsx;\n%let SettingsSheet = 設定;\n\n%put _user_;\nプロジェクト内で頻繁に使用するパスやファイル名をマクロ変数として定義します。これにより、コードの可読性が向上し、将来的にパスが変更になった場合でも、このセクションを修正するだけで済みます。\n\nInputPath: 生データや外部ファイルなど、入力データが置かれるディレクトリ\nOutputPath: 出力される解析結果やレポートが保存されるディレクトリ\nLogPath: SASログファイルが保存されるディレクトリ（ログの自動保存を設定する場合）\nPrgPath: サブプログラムが置かれるディレクトリ\nSettingsPath: 設定ファイルが置かれるディレクトリ\nSpecPath: 仕様書が置かれるディレクトリ\n\nまた、設定ファイル名やシート名などもマクロ変数として定義しておくと、変更があった際に対応が容易になります。\n\n\n\nSAS\n*--- 実行Prgのパス設定 ---*;\nfilename saspgm \"&PrgPath.\";\nFILENAMEステートメントを使用して、サブプログラムが格納されているディレクトリに**fileref（ファイル参照名）**を割り当てます。これにより、後続の%INCLUDEステートメントで、相対パスでサブプログラムを指定できるようになります。\n\n\n\n/*--- 基本設定の読み込み ---*/\n%include saspgm( \"01_LoadBaseSettings.sas\" );\n\n\n/*--- プロジェクト設定の読み込み ---*/\n%include saspgm( \"02_ImportProjectConfig.sas\" );\n\n\n/*--- データソース定義のロード ---*/\n%include saspgm( \"03_DefineDataSources.sas\" );\n\n\n/*--- 外部ライブラリ接続 ---*/\n%include saspgm( \"04_LinkExternalLibs.sas\" );\n\n\n/*--- フォーマット定義の生成 ---*/\n%include saspgm( \"05_GenerateFormatDefs.sas\" );\n\n\n/*--- 全体設定の統合 ---*/\n%include saspgm( \"06_IntegrateGlobalSettings.sas\");\n\n\n/*--- 共通マクロのロード ---*/\n%include saspgm( \"11_McrBuildMasterDataset.sas\" );\n%include saspgm( \"12_McrStandardizeDates.sas\" );\n%include saspgm( \"13_McrCreateCoreADaMs.sas\" );\n%include saspgm( \"14_McrAppendSuppData.sas\" );\n%include saspgm( \"15_McrRecodeVariables_V2.sas\" );\n\n\n/*--- ADaMデータセットの作成 ---*/\n%include saspgm( \"21_DeriveADSL.sas\" );\n%include saspgm( \"22_DeriveADLB.sas\" );\n%include saspgm( \"23_DeriveADVS.sas\" );\n%include saspgm( \"24_DeriveADRS.sas\" );\n%include saspgm( \"25_DeriveADAE.sas\" );\n\n\n/*--- 後処理とクリーンアップ ---*/\n%include saspgm( \"99_PostProcessingAndCleanup.sas\" );\nメインプログラムの役割は、各機能ごとのサブプログラムを**%INCLUDEステートメント**で呼び出すことです。これにより、プログラム全体がモジュール化され、以下の利点が得られます。\n\n可読性の向上: 各ファイルが特定の機能に集中するため、コードが読みやすくなります。\n保守性の向上: 特定の機能を変更したい場合、該当するサブプログラムのみを修正すればよいため、影響範囲が限定されます。\n再利用性の向上: 各サブプログラムは独立した機能を持つため、他のプロジェクトでも再利用しやすくなります。\nデバッグの容易性: エラーが発生した場合、どのモジュールで問題が起きているかを特定しやすくなります。\n\n特に、以下のような処理をモジュール化すると良いでしょう。\n\n基本設定の読み込み（01_LoadBaseSettings.sas）: 環境変数や基本的なオプション設定の読み込み。\nプロジェクト設定の読み込み（02_ImportProjectConfig.sas）: 解析に必要な各種設定を外部ファイルから読み込む処理。\nデータソース定義のロード（03_DefineDataSources.sas）: 使用するデータのソースや構造を定義する処理。\n外部ライブラリ接続（04_LinkExternalLibs.sas）: データベースや他のSASライブラリへの接続設定。\nフォーマット定義の生成（05_GenerateFormatDefs.sas）: 値のラベル付けなど、解析に必要なSASフォーマットの作成。\n全体設定の統合（06_IntegrateGlobalSettings.sas）: 読み込んだ設定や定義を統合する処理。\n共通マクロのロード（11_McrBuildMasterDataset.sasなど）: プロジェクト全体で利用する汎用的なSASマクロの定義。\nADaMデータセットの作成（21_DeriveADSL.sasなど）: 各ADaMデータセットの具体的な作成ロジック。\n後処理とクリーンアップ（99_PostProcessingAndCleanup.sas）: ログファイルの保存、一時的なリソースの解放など、プログラム終了時に行うべき処理。\n\n以下のプログラムも便利です。\n*-----------------------------------------------------------------------------*;\n* Initial ;\n*-----------------------------------------------------------------------------*;\n%let execpath = \"\" ;\n\n/* 現在実行しているプログラムのパスを取得 (ファイル名を含む) */\n%macro setexecpath ;\n  %let execpath = %sysfunc(getoption(sysin)) ;\n  %if %length(&execpath.) = 0 %then %let execpath = %sysget(sas_execfilepath) ;\n%mend setexecpath ;\n%setexecpath ;\n\n/* ファイル名からドメイン名の切出し */\n%let DOMAIN = %scan(%scan(&execpath, -1, \"\\\"), 1, \".\") ;\n/* パスのみの切り出し (プログラムパスからファイル名を削除) */\n%let CURRENT = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n\n%put &DOMAIN. &CURRENT. ;\n\n/* 接続先をカレントパスに変更 */\nX \"cd &CURRENT.\" ;\n\n/* init.sas を実行 */\n%inc \"../../05_Macro\\init.sas\" ;\n\n/* 定数の定義 */\n%let FNAME = %upcase(&DOMAIN.) ;\n%let LABEL = Laboratory Tests Analysis Dataset ;\n%let key = STUDYID USUBJID APERIOD PARAMN VISITNUM ;\n\n\n\nこのRun_ADAM-Prg.sasのような初期設定プログラムは、SAS解析プロジェクトの基盤となります。プログラムの冒頭で環境を整え、パスを動的に管理し、処理をモジュール化することで、コードの品質、保守性、そして何よりも解析の信頼性を向上させることができます。ぜひ、あなたの解析プロジェクトでもこのベストプラクティスを取り入れてみてください。\n\n\n\n*--- データセットとログの一括クリア ---*;\nproc datasets kill nolist ; run ; quit ;\ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : Run_ADAM-Prg.sas\n* Author          : Kota Sakamoto\n* Date created    : 2025/07/02\n* Purpose         : ADaM作成プログラム\n* Revision History :\n***********************************************************************/\n\n*--- オプション設定 ---*;\noptions noxwait;    * XコマンドでSASシステムから制御した後、自動的に再度SASシステムに戻る ;\noptions noxsync;  * Xコマンドで開始した処理の終了を待たずにSASシステムに戻る ;\noptions noquotelenmax;  * 引用符で囲んだ文字が長すぎる場合のNOTEを出さないようにする ;\noptions source2;    * 2次ソースステートメントをSASログに書き込む ;\n\n*--- マクロ変数のクリア ---*;\n%put _user_;\ndata vars;\n    set sashelp.vmacro;\nrun;\n\ndata symdel;\n  set sashelp.vmacro;\n  where scope = 'GLOBAL' and NAME not in ('SYS_SQL_IP_ALL', 'SYS_SQL_IP_STMT');\nrun;\n\ndata _null_;\n  set symdel;\n  call symdel(name);\nrun;\n\n*--- ディレクトリの設定 ---*;\n* フルパスの取得 ;\n%let path = %sysget(SAS_EXECFILEPATH);\n%put &path.;\n\n* ファイル名の取得 ;\n%let filename = %SCAN(&path., -1, \"\\\");\n%put &filename.;\n\n* ディレクトリの取得 ;\n%let drct = %substr(&path., 1, %length(&path.)-%length(%SCAN(&path.,-1,\"\\\"))-1);\n%put &drct.;\n\n* ディレクトリ設定 ;\ndata _null_;\n    call system(\"cd &drct.\");\nrun;\n\n\n*--- マクロ変数の定義 ---*;\n%let InputPath = &drct.\\Input;\n%let OutputPath = &drct.\\Output;\n%let LogPath = &drct.\\Log;\n%let PrgPath = &drct.\\Prg;\n%let SettingsPath = &drct.\\Settings;\n%let SpecPath = &drct.\\Spec;\n\n%let SettingsFile = ADAM設定ファイル.xlsx;\n%let SettingsSheet = 設定;\n\n%put _user_;\n\n\n*--- 実行Prgのパス設定 ---*;\nfilename saspgm \"&PrgPath.\";\n\n\n/*--- 基本設定の読み込み ---*/\n%include saspgm( \"01_LoadBaseSettings.sas\" );\n\n\n/*--- プロジェクト設定の読み込み ---*/\n%include saspgm( \"02_ImportProjectConfig.sas\" );\n\n\n/*--- データソース定義のロード ---*/\n%include saspgm( \"03_DefineDataSources.sas\" );\n\n\n/*--- 外部ライブラリ接続 ---*/\n%include saspgm( \"04_LinkExternalLibs.sas\" );\n\n\n/*--- フォーマット定義の生成 ---*/\n%include saspgm( \"05_GenerateFormatDefs.sas\" );\n\n\n/*--- 全体設定の統合 ---*/\n%include saspgm( \"06_IntegrateGlobalSettings.sas\");\n\n\n/*--- 共通マクロのロード ---*/\n%include saspgm( \"11_McrBuildMasterDataset.sas\" );\n%include saspgm( \"12_McrStandardizeDates.sas\" );\n%include saspgm( \"13_McrCreateCoreADaMs.sas\" );\n%include saspgm( \"14_McrAppendSuppData.sas\" );\n%include saspgm( \"15_McrRecodeVariables_V2.sas\" );\n\n\n/*--- ADaMデータセットの作成 ---*/\n%include saspgm( \"21_DeriveADSL.sas\" );\n%include saspgm( \"22_DeriveADLB.sas\" );\n%include saspgm( \"23_DeriveADVS.sas\" );\n%include saspgm( \"24_DeriveADRS.sas\" );\n%include saspgm( \"25_DeriveADAE.sas\" );\n\n\n/*--- 後処理とクリーンアップ ---*/\n%include saspgm( \"99_PostProcessingAndCleanup.sas\" );\n\n\n\n*---------------------- EOF （Run_ADAM-Prg.sas） ------------------------------- ;"
  },
  {
    "objectID": "posts/statistics/2025/解析プロジェクトの最初に作成するSAS_PGM.html#sas解析プロジェクトを始める前にプログラム初期設定のベストプラクティス",
    "href": "posts/statistics/2025/解析プロジェクトの最初に作成するSAS_PGM.html#sas解析プロジェクトを始める前にプログラム初期設定のベストプラクティス",
    "title": "解析プロジェクトの最初に作成するSASプログラム",
    "section": "",
    "text": "SASを使った解析プロジェクトを始める際、毎回同じような初期設定のコードを書いている方も多いのではないでしょうか。この技術メモでは、解析プロジェクトの最初に作成する**Run_ADAM-Prg.sas**というメインプログラムについて、その構成と各セクションの意図を詳しく解説します。この初期設定をしっかり行うことで、プロジェクト全体の効率性と再現性が大幅に向上します。\n\n\nproc datasets kill nolist ; run ; quit ;\ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : Run_ADAM-Prg.sas\n* Author          : Kota Sakamoto\n* Date created    : 2025/07/02\n* Purpose         : ADaM作成プログラム\n* Revision History :\n***********************************************************************/\nプログラムの冒頭にこれらを記述することで、SASセッションを完全にクリーンな状態から始めることができます。\n\nproc datasets kill nolist ; run ; quit ;: 現在のSASセッションに存在するすべてのライブラリ（特にWORKライブラリ）内のデータセットとカタログを削除します。これにより、以前の実行で残った一時ファイルによる予期せぬエラーを防ぎます。\ndm 'out ; clear ; log ; clear ;' ;: SASログウィンドウと出力ウィンドウの内容をクリアします。これにより、現在の実行に関するログのみが表示され、デバッグがしやすくなります。\n\nその下には、ご指定のプログラムヘッダを記述します。プロジェクト名、ファイル名、作成者、作成日、目的、変更履歴などの情報を含めることで、プログラムの目的が明確になり、後から見返したり他の人と共有したりする際に非常に役立ちます。特に変更履歴は、問題発生時の原因特定や、新しいメンバーへの引き継ぎにおいて不可欠です。\n\n\n\nSAS\n*--- オプション設定 ---*;\noptions noxwait;    * XコマンドでSASシステムから制御した後、自動的に再度SASシステムに戻る ;\noptions noxsync;  * Xコマンドで開始した処理の終了を待たずにSASシステムに戻る ;\noptions noquotelenmax;  * 引用符で囲んだ文字が長すぎる場合のNOTEを出さないようにする ;\noptions source2;    * 2次ソースステートメントをSASログに書き込む ;\nSASの**OPTIONSステートメント**は、SASセッションの動作を制御するためのものです。プロジェクトの性質や個人の好みに応じて設定しますが、特に重要なものをいくつかご紹介します。\n\nnoxwait / noxsync: 外部コマンド（Xコマンドなど）の実行に関するオプションです。これらを指定することで、外部プロセスの完了を待たずにSASに戻る、または外部プロセスの実行中にSASがブロックされないようにすることができます。これは、外部スクリプトの呼び出しや、大量のファイル操作を行う際に役立ちます。\nnoquotelenmax: 長い文字列を引用符で囲んだ際に表示されるNOTEメッセージを抑制します。ログをきれいに保ちたい場合に便利です。\nsource2: INCLUDEステートメントなどで読み込まれた二次ソースコードもSASログに出力するようになります。デバッグ時にどのコードが実行されているかを確認するのに非常に役立ちます。\n追加の推奨オプション:\n\nls=MAX / ps=MAX: ログの行長とページ長を最大に設定し、ログが見やすくなります。\nfmterr: フォーマットが見つからない場合にエラーを発生させます。予期せぬフォーマットエラーを防ぐために重要です。\nerrors=0: SASセッション中のエラー表示数を無制限にします。これにより、すべてのエラーを確認できます。\n\n\n\n\n\nSAS\n*--- マクロ変数のクリア ---*;\n%put _user_;\ndata vars;\n    set sashelp.vmacro;\nrun;\n\ndata symdel;\n  set sashelp.vmacro;\n  where scope = 'GLOBAL' and NAME not in ('SYS_SQL_IP_ALL', 'SYS_SQL_IP_STMT');\nrun;\n\ndata _null_;\n  set symdel;\n  call symdel(name);\nrun; \n前のセッションやテスト実行で残ったグローバルマクロ変数が、現在の実行に影響を与えることを防ぐために、不要なマクロ変数をクリアします。sashelp.vmacroは現在定義されているマクロ変数の情報を持ち、CALL SYMDEL関数を使って特定の変数を削除できます。これにより、常にクリーンな状態でプログラムを実行できます。\n\n\n\nSAS\n*--- データセットの一括クリア ---*;\nproc delete data=work._all_;\nrun;\nSASの**WORKライブラリ**は一時的なデータセットが格納される場所です。過去の実行で作成されたデータセットが残っていると、意図しない結果を招いたり、ディスク容量を圧迫したりする可能性があります。PROC DELETE DATA=WORK._ALL_を使用することで、WORKライブラリ内のすべてのデータセットを効率的に削除し、常にゼロベースで解析を開始できます。\n\n\n\nSAS\n*--- ディレクトリの設定 ---*;\n* フルパスの取得 ;\n%let path = %sysget(SAS_EXECFILEPATH);\n%put &path.;\n\n* ファイル名の取得 ;\n%let filename = %SCAN(&path., -1, \"\\\");\n%put &filename.;\n\n* ディレクトリの取得 ;\n%let drct = %substr(&path., 1, %length(&path.)-%length(%SCAN(&path.,-1,\"\\\"))-1);\n%put &drct.;\n\n* ディレクトリ設定 ;\ndata _null_;\n    call system(\"cd &drct.\");\nrun;\nプロジェクトのパスを動的に設定することは非常に重要です。これにより、プログラムを異なる環境やPCに移動しても、パスを手動で変更する必要がなくなります。\n\n%sysget(SAS_EXECFILEPATH): 現在実行しているSASプログラムのフルパスを取得します。\n%SCAN / %SUBSTR / %LENGTH: マクロ関数を組み合わせて、フルパスからファイル名やディレクトリパスを抽出します。\nCALL SYSTEM(\"cd &drct.\"): SASセッションのカレントディレクトリを実行プログラムのディレクトリに設定します。これにより、相対パスでのファイル指定が容易になります。\n\n\n\n\nSAS\n*--- マクロ変数の定義 ---*;\n%let InputPath = &drct.\\Input;\n%let OutputPath = &drct.\\Output;\n%let LogPath = &drct.\\Log;\n%let PrgPath = &drct.\\Prg;\n%let SettingsPath = &drct.\\Settings;\n%let SpecPath = &drct.\\Spec;\n\n%let SettingsFile = ADAM設定ファイル.xlsx;\n%let SettingsSheet = 設定;\n\n%put _user_;\nプロジェクト内で頻繁に使用するパスやファイル名をマクロ変数として定義します。これにより、コードの可読性が向上し、将来的にパスが変更になった場合でも、このセクションを修正するだけで済みます。\n\nInputPath: 生データや外部ファイルなど、入力データが置かれるディレクトリ\nOutputPath: 出力される解析結果やレポートが保存されるディレクトリ\nLogPath: SASログファイルが保存されるディレクトリ（ログの自動保存を設定する場合）\nPrgPath: サブプログラムが置かれるディレクトリ\nSettingsPath: 設定ファイルが置かれるディレクトリ\nSpecPath: 仕様書が置かれるディレクトリ\n\nまた、設定ファイル名やシート名などもマクロ変数として定義しておくと、変更があった際に対応が容易になります。\n\n\n\nSAS\n*--- 実行Prgのパス設定 ---*;\nfilename saspgm \"&PrgPath.\";\nFILENAMEステートメントを使用して、サブプログラムが格納されているディレクトリに**fileref（ファイル参照名）**を割り当てます。これにより、後続の%INCLUDEステートメントで、相対パスでサブプログラムを指定できるようになります。\n\n\n\n/*--- 基本設定の読み込み ---*/\n%include saspgm( \"01_LoadBaseSettings.sas\" );\n\n\n/*--- プロジェクト設定の読み込み ---*/\n%include saspgm( \"02_ImportProjectConfig.sas\" );\n\n\n/*--- データソース定義のロード ---*/\n%include saspgm( \"03_DefineDataSources.sas\" );\n\n\n/*--- 外部ライブラリ接続 ---*/\n%include saspgm( \"04_LinkExternalLibs.sas\" );\n\n\n/*--- フォーマット定義の生成 ---*/\n%include saspgm( \"05_GenerateFormatDefs.sas\" );\n\n\n/*--- 全体設定の統合 ---*/\n%include saspgm( \"06_IntegrateGlobalSettings.sas\");\n\n\n/*--- 共通マクロのロード ---*/\n%include saspgm( \"11_McrBuildMasterDataset.sas\" );\n%include saspgm( \"12_McrStandardizeDates.sas\" );\n%include saspgm( \"13_McrCreateCoreADaMs.sas\" );\n%include saspgm( \"14_McrAppendSuppData.sas\" );\n%include saspgm( \"15_McrRecodeVariables_V2.sas\" );\n\n\n/*--- ADaMデータセットの作成 ---*/\n%include saspgm( \"21_DeriveADSL.sas\" );\n%include saspgm( \"22_DeriveADLB.sas\" );\n%include saspgm( \"23_DeriveADVS.sas\" );\n%include saspgm( \"24_DeriveADRS.sas\" );\n%include saspgm( \"25_DeriveADAE.sas\" );\n\n\n/*--- 後処理とクリーンアップ ---*/\n%include saspgm( \"99_PostProcessingAndCleanup.sas\" );\nメインプログラムの役割は、各機能ごとのサブプログラムを**%INCLUDEステートメント**で呼び出すことです。これにより、プログラム全体がモジュール化され、以下の利点が得られます。\n\n可読性の向上: 各ファイルが特定の機能に集中するため、コードが読みやすくなります。\n保守性の向上: 特定の機能を変更したい場合、該当するサブプログラムのみを修正すればよいため、影響範囲が限定されます。\n再利用性の向上: 各サブプログラムは独立した機能を持つため、他のプロジェクトでも再利用しやすくなります。\nデバッグの容易性: エラーが発生した場合、どのモジュールで問題が起きているかを特定しやすくなります。\n\n特に、以下のような処理をモジュール化すると良いでしょう。\n\n基本設定の読み込み（01_LoadBaseSettings.sas）: 環境変数や基本的なオプション設定の読み込み。\nプロジェクト設定の読み込み（02_ImportProjectConfig.sas）: 解析に必要な各種設定を外部ファイルから読み込む処理。\nデータソース定義のロード（03_DefineDataSources.sas）: 使用するデータのソースや構造を定義する処理。\n外部ライブラリ接続（04_LinkExternalLibs.sas）: データベースや他のSASライブラリへの接続設定。\nフォーマット定義の生成（05_GenerateFormatDefs.sas）: 値のラベル付けなど、解析に必要なSASフォーマットの作成。\n全体設定の統合（06_IntegrateGlobalSettings.sas）: 読み込んだ設定や定義を統合する処理。\n共通マクロのロード（11_McrBuildMasterDataset.sasなど）: プロジェクト全体で利用する汎用的なSASマクロの定義。\nADaMデータセットの作成（21_DeriveADSL.sasなど）: 各ADaMデータセットの具体的な作成ロジック。\n後処理とクリーンアップ（99_PostProcessingAndCleanup.sas）: ログファイルの保存、一時的なリソースの解放など、プログラム終了時に行うべき処理。\n\n以下のプログラムも便利です。\n*-----------------------------------------------------------------------------*;\n* Initial ;\n*-----------------------------------------------------------------------------*;\n%let execpath = \"\" ;\n\n/* 現在実行しているプログラムのパスを取得 (ファイル名を含む) */\n%macro setexecpath ;\n  %let execpath = %sysfunc(getoption(sysin)) ;\n  %if %length(&execpath.) = 0 %then %let execpath = %sysget(sas_execfilepath) ;\n%mend setexecpath ;\n%setexecpath ;\n\n/* ファイル名からドメイン名の切出し */\n%let DOMAIN = %scan(%scan(&execpath, -1, \"\\\"), 1, \".\") ;\n/* パスのみの切り出し (プログラムパスからファイル名を削除) */\n%let CURRENT = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n\n%put &DOMAIN. &CURRENT. ;\n\n/* 接続先をカレントパスに変更 */\nX \"cd &CURRENT.\" ;\n\n/* init.sas を実行 */\n%inc \"../../05_Macro\\init.sas\" ;\n\n/* 定数の定義 */\n%let FNAME = %upcase(&DOMAIN.) ;\n%let LABEL = Laboratory Tests Analysis Dataset ;\n%let key = STUDYID USUBJID APERIOD PARAMN VISITNUM ;\n\n\n\nこのRun_ADAM-Prg.sasのような初期設定プログラムは、SAS解析プロジェクトの基盤となります。プログラムの冒頭で環境を整え、パスを動的に管理し、処理をモジュール化することで、コードの品質、保守性、そして何よりも解析の信頼性を向上させることができます。ぜひ、あなたの解析プロジェクトでもこのベストプラクティスを取り入れてみてください。\n\n\n\n*--- データセットとログの一括クリア ---*;\nproc datasets kill nolist ; run ; quit ;\ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : Run_ADAM-Prg.sas\n* Author          : Kota Sakamoto\n* Date created    : 2025/07/02\n* Purpose         : ADaM作成プログラム\n* Revision History :\n***********************************************************************/\n\n*--- オプション設定 ---*;\noptions noxwait;    * XコマンドでSASシステムから制御した後、自動的に再度SASシステムに戻る ;\noptions noxsync;  * Xコマンドで開始した処理の終了を待たずにSASシステムに戻る ;\noptions noquotelenmax;  * 引用符で囲んだ文字が長すぎる場合のNOTEを出さないようにする ;\noptions source2;    * 2次ソースステートメントをSASログに書き込む ;\n\n*--- マクロ変数のクリア ---*;\n%put _user_;\ndata vars;\n    set sashelp.vmacro;\nrun;\n\ndata symdel;\n  set sashelp.vmacro;\n  where scope = 'GLOBAL' and NAME not in ('SYS_SQL_IP_ALL', 'SYS_SQL_IP_STMT');\nrun;\n\ndata _null_;\n  set symdel;\n  call symdel(name);\nrun;\n\n*--- ディレクトリの設定 ---*;\n* フルパスの取得 ;\n%let path = %sysget(SAS_EXECFILEPATH);\n%put &path.;\n\n* ファイル名の取得 ;\n%let filename = %SCAN(&path., -1, \"\\\");\n%put &filename.;\n\n* ディレクトリの取得 ;\n%let drct = %substr(&path., 1, %length(&path.)-%length(%SCAN(&path.,-1,\"\\\"))-1);\n%put &drct.;\n\n* ディレクトリ設定 ;\ndata _null_;\n    call system(\"cd &drct.\");\nrun;\n\n\n*--- マクロ変数の定義 ---*;\n%let InputPath = &drct.\\Input;\n%let OutputPath = &drct.\\Output;\n%let LogPath = &drct.\\Log;\n%let PrgPath = &drct.\\Prg;\n%let SettingsPath = &drct.\\Settings;\n%let SpecPath = &drct.\\Spec;\n\n%let SettingsFile = ADAM設定ファイル.xlsx;\n%let SettingsSheet = 設定;\n\n%put _user_;\n\n\n*--- 実行Prgのパス設定 ---*;\nfilename saspgm \"&PrgPath.\";\n\n\n/*--- 基本設定の読み込み ---*/\n%include saspgm( \"01_LoadBaseSettings.sas\" );\n\n\n/*--- プロジェクト設定の読み込み ---*/\n%include saspgm( \"02_ImportProjectConfig.sas\" );\n\n\n/*--- データソース定義のロード ---*/\n%include saspgm( \"03_DefineDataSources.sas\" );\n\n\n/*--- 外部ライブラリ接続 ---*/\n%include saspgm( \"04_LinkExternalLibs.sas\" );\n\n\n/*--- フォーマット定義の生成 ---*/\n%include saspgm( \"05_GenerateFormatDefs.sas\" );\n\n\n/*--- 全体設定の統合 ---*/\n%include saspgm( \"06_IntegrateGlobalSettings.sas\");\n\n\n/*--- 共通マクロのロード ---*/\n%include saspgm( \"11_McrBuildMasterDataset.sas\" );\n%include saspgm( \"12_McrStandardizeDates.sas\" );\n%include saspgm( \"13_McrCreateCoreADaMs.sas\" );\n%include saspgm( \"14_McrAppendSuppData.sas\" );\n%include saspgm( \"15_McrRecodeVariables_V2.sas\" );\n\n\n/*--- ADaMデータセットの作成 ---*/\n%include saspgm( \"21_DeriveADSL.sas\" );\n%include saspgm( \"22_DeriveADLB.sas\" );\n%include saspgm( \"23_DeriveADVS.sas\" );\n%include saspgm( \"24_DeriveADRS.sas\" );\n%include saspgm( \"25_DeriveADAE.sas\" );\n\n\n/*--- 後処理とクリーンアップ ---*/\n%include saspgm( \"99_PostProcessingAndCleanup.sas\" );\n\n\n\n*---------------------- EOF （Run_ADAM-Prg.sas） ------------------------------- ;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "効率的なフォルダ構成でプロジェクトを管理する\n\n\nSAS（Statistical Analysis System）を使ったデータ分析プロジェクトにおいて、最初に決めるべき重要な要素の一つがフォルダ構成です。適切なフォルダ構成を設定することで、プロジェクトの管理が格段に楽になり、チームでの作業効率も向上します。\n多くのSAS初心者は、とりあえずデスクトップやマイドキュメントにファイルを保存してしまいがちですが、プロジェクトが進むにつれて「あのファイルはどこに保存したっけ？」「これは最新バージョン？」といった問題に直面することになります。\n\n\n\n\nSASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬）\n\n\n\n\nSASプログラミングを実施する際は、フォルダ構成をまず設定します。ここでは、実際の業務で使用することができそうな標準的な構成例を紹介します。 任意のプロジェクトフォルダに対して以下のようなフォルダを作成します。テンプレートを作成しておくのが便利でしょう。もしくはProjectフォルダを作成して、自動でフォルダを作成するSASプログラムを準備しておくこともよいかもしれません。ここでの例は、あくまで1つの例であり、より使いやすくなるようなフォルダ構成に変更しても差し支えない。なお、このフォルダ構成はTLF作成のプログラムにおいても引用できる可能性がある。、TLFの解析を踏まえたフォルダ構成は別途提案する。\n\nInput\nLog\nOutput\nPrg\nSetting\nSpec\n\n\n\nInput：分析に使用する元データを格納\n\n外部から受け取ったCSVファイル、Excelファイル -\nデータベースから抽出した生データ\n既存のSASデータセット\n\nLog：SASプログラムの実行ログを保存\n\nプログラム実行時に出力されるログファイル\nエラーメッセージや警告の記録\n処理時間やデータ件数の確認用\n\nOutput：分析結果や成果物を保存\n\n作成されたSASデータセット\nデータ品質チェック結果\n\nPrg：SASプログラムファイル（.sas）を格納\n\nデータ処理プログラム（1_xx、2_xxのように実行するプログラムの順番が分かる方が望ましい）\nデータクリーニングプログラム\n派生変数作成プログラム\n\nSetting：\n\n設定ファイルや共通処理を保存\nよく使用するマクロ定義\nプロジェクト固有の設定\n\nSpec：仕様書や設計書類を格納\n\n解析用データセット仕様書\n\n\n\n\n\n実際のプロジェクトでは、解析用データセット作成プログラミングと、解析プログラミングはフォルダを分けることを推奨しています。\nここでは、解析用データセット作成に焦点を当てたフォルダ構成について詳しく説明します。\n\n\n解析用データセット作成用のフォルダ構成例：\n\nProject/\nInput/\n\nRaw_Data/ # 生データ（CSV、Excel等）\nExternal/ # 外部参照データ、マスタ情報\n\nLog/ # データ処理ログ\nOutput/ # 作成されたSASデータセット\nPrg/ # データ処理プログラム\nSetting/ # 設定ファイル、マクロ\n\n\n\n\nデータ取り込み（PROC IMPORT）\n\n解析用データ仕様書に基づいて、変数のlength,format,labelが入った空データセット（メタデータ）を作成する。\n文字エンコーディングの統一\n変数名の標準化\n\nデータクリーニング\n\n欠損値の処理（削除、補完、フラグ付け）\n重複レコードの確認と処理\nデータ型の統一\n\n派生変数の作成\n\n年齢の計算（生年月日から）\nカテゴリ変数の作成（連続変数の区分化）\n合計値や比率の計算\nフラグ変数の作成\n\n\n\n\n\nSASプログラミングにおいて、プログラムの更新履歴を管理することは非常に重要です。特にデータ処理では、どの時点のプログラムで作成されたデータセットなのかを明確にする必要があります。\n\n\nデータセット作成プログラムの命名例\n\n01_data_import_20250614.sas # 初回作成\n01_data_import_20250615.sas # 修正版\n01_data_import_20250620.sas # 最新版\n02_data_cleaning_20250614.sas # データクリーニング\n03_variable_creation_20250615.sas # 派生変数作成\n04_quality_check_20250620.sas # 品質チェック\n\n\n\n\n各SASプログラムの冒頭には、以下のような標準的なヘッダーを記述することを必須とします。\n/*=================================\nプログラム名: 01_data_import.sas\nプロジェクト: プロジェクト名\n作成者      : 山田太郎\n作成日      : 2025/06/14\n最終更新日  : 2025/06/20\nバージョン  : v1.2\n目的        : 顧客アンケートデータの取り込みとクリーニング\n\n入力データ  : Raw_Data/survey_data.csv\n出力データ  : Output/cleaned_survey.sas7bdat\n\n更新履歴:\nv1.0 2025/06/14 初回作成\nv1.1 2025/06/15 欠損値処理ロジック追加\nv1.2 2025/06/20 外れ値検出機能追加\n=================================*/\n\n\n\n\n*---------------------- EOF （プログラム名.sas） ------------------------------- ;\n\n\n\n\nプログラム実行時に、実行日時をログに記録する仕組みを組み込むことも有効です：\n/* 実行開始時刻を記録 */\n%let start_time = %sysfunc(datetime());\n%put NOTE: データセット作成開始 - %sysfunc(datetime(), datetime19.);\n\n/* データ取り込み処理 */\nproc import datafile=\"Input/Raw_Data/survey_data.csv\"\n    out=work.raw_data\n    dbms=csv replace;\n    getnames=yes;\nrun;\n\n/* 実行終了時刻を記録 */\n%let end_time = %sysfunc(datetime());\n%let elapsed_time = %sysevalf(&end_time - &start_time);\n%put NOTE: データセット作成終了 - %sysfunc(datetime(), datetime19.);\n%put NOTE: 実行時間: %sysfunc(&elapsed_time, time8.);\n%put NOTE: 処理件数: %sysfunc(attrn(open(work.raw_data), nobs));\n\n\n\nログファイルの活用 データ処理では、どのような処理が行われたかを正確に記録することが重要です：\n/* ログファイルの出力先を指定（日付付き） */\n%let today = %sysfunc(today(), yymmddn8.);\nproc printto log=\"Log/data_creation_&today..log\";\nrun;\n\n/* データ処理 */\n/* ... */\n\n/* ログ出力を元に戻す */\nproc printto;\nrun;\n\n\n\nSettingフォルダでは、事前に解析用データセット仕様書のinputするファイル情報やPath、InputデータのPaht、OutputデータのPathを指定しておく。これを作成しておくことで、第3者に解析用データセット作成プログラムを提供した際でも、このSettingフォルダのPathだけを更新することで、再現可能な状態がすぐに作ることができる。\nExcelファイルには以下の3つの要素を設定します。：\n\nパス（Path）：ファイルの保存場所\nファイル名：Excelファイル名\nシート名：参照するワークシート名"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#はじめに",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#はじめに",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SAS（Statistical Analysis System）を使ったデータ分析プロジェクトにおいて、最初に決めるべき重要な要素の一つがフォルダ構成です。適切なフォルダ構成を設定することで、プロジェクトの管理が格段に楽になり、チームでの作業効率も向上します。\n多くのSAS初心者は、とりあえずデスクトップやマイドキュメントにファイルを保存してしまいがちですが、プロジェクトが進むにつれて「あのファイルはどこに保存したっけ？」「これは最新バージョン？」といった問題に直面することになります。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#参考文献",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#参考文献",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASユーザー総会2014年度：PMDAへの承認申請時 CDISC標準電子データ提出に向けた社内標準のリモデリング（塩野義製薬）"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成における基本的なフォルダ構成案",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成における基本的なフォルダ構成案",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASプログラミングを実施する際は、フォルダ構成をまず設定します。ここでは、実際の業務で使用することができそうな標準的な構成例を紹介します。 任意のプロジェクトフォルダに対して以下のようなフォルダを作成します。テンプレートを作成しておくのが便利でしょう。もしくはProjectフォルダを作成して、自動でフォルダを作成するSASプログラムを準備しておくこともよいかもしれません。ここでの例は、あくまで1つの例であり、より使いやすくなるようなフォルダ構成に変更しても差し支えない。なお、このフォルダ構成はTLF作成のプログラムにおいても引用できる可能性がある。、TLFの解析を踏まえたフォルダ構成は別途提案する。\n\nInput\nLog\nOutput\nPrg\nSetting\nSpec\n\n\n\nInput：分析に使用する元データを格納\n\n外部から受け取ったCSVファイル、Excelファイル -\nデータベースから抽出した生データ\n既存のSASデータセット\n\nLog：SASプログラムの実行ログを保存\n\nプログラム実行時に出力されるログファイル\nエラーメッセージや警告の記録\n処理時間やデータ件数の確認用\n\nOutput：分析結果や成果物を保存\n\n作成されたSASデータセット\nデータ品質チェック結果\n\nPrg：SASプログラムファイル（.sas）を格納\n\nデータ処理プログラム（1_xx、2_xxのように実行するプログラムの順番が分かる方が望ましい）\nデータクリーニングプログラム\n派生変数作成プログラム\n\nSetting：\n\n設定ファイルや共通処理を保存\nよく使用するマクロ定義\nプロジェクト固有の設定\n\nSpec：仕様書や設計書類を格納\n\n解析用データセット仕様書"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成に特化したフォルダ構成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#解析用データセット作成に特化したフォルダ構成",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "実際のプロジェクトでは、解析用データセット作成プログラミングと、解析プログラミングはフォルダを分けることを推奨しています。\nここでは、解析用データセット作成に焦点を当てたフォルダ構成について詳しく説明します。\n\n\n解析用データセット作成用のフォルダ構成例：\n\nProject/\nInput/\n\nRaw_Data/ # 生データ（CSV、Excel等）\nExternal/ # 外部参照データ、マスタ情報\n\nLog/ # データ処理ログ\nOutput/ # 作成されたSASデータセット\nPrg/ # データ処理プログラム\nSetting/ # 設定ファイル、マクロ\n\n\n\n\nデータ取り込み（PROC IMPORT）\n\n解析用データ仕様書に基づいて、変数のlength,format,labelが入った空データセット（メタデータ）を作成する。\n文字エンコーディングの統一\n変数名の標準化\n\nデータクリーニング\n\n欠損値の処理（削除、補完、フラグ付け）\n重複レコードの確認と処理\nデータ型の統一\n\n派生変数の作成\n\n年齢の計算（生年月日から）\nカテゴリ変数の作成（連続変数の区分化）\n合計値や比率の計算\nフラグ変数の作成"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#プログラムの日付管理とバージョン管理",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#プログラムの日付管理とバージョン管理",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "SASプログラミングにおいて、プログラムの更新履歴を管理することは非常に重要です。特にデータ処理では、どの時点のプログラムで作成されたデータセットなのかを明確にする必要があります。\n\n\nデータセット作成プログラムの命名例\n\n01_data_import_20250614.sas # 初回作成\n01_data_import_20250615.sas # 修正版\n01_data_import_20250620.sas # 最新版\n02_data_cleaning_20250614.sas # データクリーニング\n03_variable_creation_20250615.sas # 派生変数作成\n04_quality_check_20250620.sas # 品質チェック\n\n\n\n\n各SASプログラムの冒頭には、以下のような標準的なヘッダーを記述することを必須とします。\n/*=================================\nプログラム名: 01_data_import.sas\nプロジェクト: プロジェクト名\n作成者      : 山田太郎\n作成日      : 2025/06/14\n最終更新日  : 2025/06/20\nバージョン  : v1.2\n目的        : 顧客アンケートデータの取り込みとクリーニング\n\n入力データ  : Raw_Data/survey_data.csv\n出力データ  : Output/cleaned_survey.sas7bdat\n\n更新履歴:\nv1.0 2025/06/14 初回作成\nv1.1 2025/06/15 欠損値処理ロジック追加\nv1.2 2025/06/20 外れ値検出機能追加\n=================================*/\n\n\n\n\n*---------------------- EOF （プログラム名.sas） ------------------------------- ;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#自動的な実行日時記録",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#自動的な実行日時記録",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "プログラム実行時に、実行日時をログに記録する仕組みを組み込むことも有効です：\n/* 実行開始時刻を記録 */\n%let start_time = %sysfunc(datetime());\n%put NOTE: データセット作成開始 - %sysfunc(datetime(), datetime19.);\n\n/* データ取り込み処理 */\nproc import datafile=\"Input/Raw_Data/survey_data.csv\"\n    out=work.raw_data\n    dbms=csv replace;\n    getnames=yes;\nrun;\n\n/* 実行終了時刻を記録 */\n%let end_time = %sysfunc(datetime());\n%let elapsed_time = %sysevalf(&end_time - &start_time);\n%put NOTE: データセット作成終了 - %sysfunc(datetime(), datetime19.);\n%put NOTE: 実行時間: %sysfunc(&elapsed_time, time8.);\n%put NOTE: 処理件数: %sysfunc(attrn(open(work.raw_data), nobs));"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#実践的な運用のコツ",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#実践的な運用のコツ",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "ログファイルの活用 データ処理では、どのような処理が行われたかを正確に記録することが重要です：\n/* ログファイルの出力先を指定（日付付き） */\n%let today = %sysfunc(today(), yymmddn8.);\nproc printto log=\"Log/data_creation_&today..log\";\nrun;\n\n/* データ処理 */\n/* ... */\n\n/* ログ出力を元に戻す */\nproc printto;\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#settingフォルダについて",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#settingフォルダについて",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "",
    "text": "Settingフォルダでは、事前に解析用データセット仕様書のinputするファイル情報やPath、InputデータのPaht、OutputデータのPathを指定しておく。これを作成しておくことで、第3者に解析用データセット作成プログラムを提供した際でも、このSettingフォルダのPathだけを更新することで、再現可能な状態がすぐに作ることができる。\nExcelファイルには以下の3つの要素を設定します。：\n\nパス（Path）：ファイルの保存場所\nファイル名：Excelファイル名\nシート名：参照するワークシート名"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#attrib-statement",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#attrib-statement",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.1 Attrib statement",
    "text": "2.1 Attrib statement\n具体的なプログラミングについては、別記事で解説をするが、ここでは解析用データセットを作成する上で大事なAttrib Statementについて解説する。\n以下記事が参考になる。\n\nATTRIBステートメント\n変数属性を定義した空のデータセットを作成する方法【まとめ】\n\n解析用データ仕様書にて、各変数のLabel、Length、formatを指定する必要がある。 その際に、解析用データセットに対してattrib statementを適用することで簡単に設定できる。\nちなみに、変数の順番だけを入れ替えるならばformat Statementでも簡単にできる。こちらのブログが参考になります。\ndata ADSL;\n    set ADSL;\n    attrib \n        STUDYID   label=\"Study Identifier\"           length=$12  format=$12.\n        USUBJID   label=\"Unique Subject Identifier\"  length=$40  format=$40.\n        SUBJID    label=\"Subject Identifier\"         length=$20  format=$20.\n        AGE       label=\"Age\"                        length=8    format=8.\n        SEX       label=\"Sex\"                        length=$1   format=SEX.\n        TRT01P    label=\"Planned Treatment for Period 1\"  length=$200  format=$200.\n        TRT01A    label=\"Actual Treatment for Period 1\"   length=$200  format=$200.\n        TRT01PN   label=\"Planned Treatment for Period 1 (N)\"  length=8  format=8.\n        TRT01AN   label=\"Actual Treatment for Period 1 (N)\"  length=8  format=8.\n        FASFL     label=\"Full Analysis Set Flag\"     length=$1   format=NYFL.\n    ;\nrun;\n実際は手入力ですることは人為的ミスの元となるのでマクロ化等で自動化することを推奨するが考え方は上記の通りである。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#proc-format",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#proc-format",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.2 Proc format",
    "text": "2.2 Proc format\n以下記事が参考になる。 - PROC FORMAT入門1 : VALUEステートメント\nPROC FORMATは、SASにおいてユーザー定義フォーマットを作成するプロシージャです。数値や文字データを、より読みやすい形式に変換して表示することができます。 基本構文は以下の通りです。\nproc format;\n    value フォーマット名\n        値1 = \"ラベル1\"\n        値2 = \"ラベル2\"\n        値3 = \"ラベル3\";\nrun;\n文字フォーマットには先頭にドルマークを付けます。\nproc format;\n    value trtf\n        1 = \"プラセボ\"\n        2 = \"低用量\"\n        3 = \"高用量\"\n        . = \"欠測\";\n        \n    value sexf\n        1 = \"男性\"\n        2 = \"女性\"\n        . = \"不明\";\n        \n    value nyf\n        0 = \"No\"\n        1 = \"Yes\"\n        . = \"Missing\";\nrun;\n\nproc format;\n    value $sexf\n        \"M\" = \"男性\"\n        \"F\" = \"女性\"\n        \" \" = \"不明\";\n        \n    value $countryfmt\n        \"JPN\" = \"日本\"\n        \"USA\" = \"アメリカ合衆国\"\n        \"GBR\" = \"イギリス\"\n        other = \"その他\";\nrun;"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#データセットからのフォーマット作成",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#データセットからのフォーマット作成",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "2.3 データセットからのフォーマット作成",
    "text": "2.3 データセットからのフォーマット作成\n\n2.3.1 3.1 CNTLIN=オプションの使用\nデータセットからフォーマットを作成する場合、特定の変数名を持つデータセットを準備する必要があります。 必要な変数：\n\nFMTNAME：フォーマット名\nSTART：変換前の値（開始値）\nEND：変換前の値（終了値、範囲指定時）\nLABEL：変換後のラベル\nTYPE：フォーマットタイプ（‘N’=数値、‘C’=文字）\n\n/* 治療群フォーマット用データセット */\ndata trt_fmt;\n    retain fmtname 'trtf' type 'N';\n    input start end label $20.;\n    datalines;\n1 1 プラセボ\n2 2 低用量\n3 3 高用量\n. . 欠測\n;\nrun;\n\n/* 性別フォーマット用データセット */\ndata sex_fmt;\n    retain fmtname '$sexf' type 'C';\n    input start $1. end $1. label $10.;\n    datalines;\nM M 男性\nF F 女性\n   不明\n;\nrun;\n\n/* フォーマットの作成 */\nproc format cntlin=trt_fmt;\nrun;\n\nproc format cntlin=sex_fmt;\nrun;\nPROC FORMATは以下の2つの方法でフォーマットを作成できます：\nVALUEステートメント：直接コードに記述する方法。シンプルで直感的 CNTLIN=オプション：データセットから作成する方法。大量のフォーマットや動的な作成に適している\n適切なフォーマットの使用により、データの可読性が大幅に向上し、レポート作成時の効率も改善されます。"
  },
  {
    "objectID": "posts/statistics/2025/解析用データセット作成の流れ1.html#sasプログラムの例",
    "href": "posts/statistics/2025/解析用データセット作成の流れ1.html#sasプログラムの例",
    "title": "解析用データセット作成の流れ1（フォルダ構造等）",
    "section": "3.1 SASプログラムの例",
    "text": "3.1 SASプログラムの例\n以下のプロジェクトは人間が主導でProjectフォルダを適当な場所に作成して、そのフォルダにて以下のプログラムを実行するだけで、上記のフォルダ構造を作成するものである。\nproc datasets kill nolist ; run ; quit ; \ndm 'out ; clear ; log ; clear ;' ;\n\n/***********************************************************************\n* Project         : 臨床研究の統計解析プログラミング\n* Program name    : 01_Folder_Setting.sas\n* Author          : Kota Sakamoto\n* Date created    : 20250617\n* Purpose         :　プロジェクト開始時のフォルダ構造の標準化\n* Revision History :\n***********************************************************************/\n\n/* 1. /* --- 日付設定 --- */ */;\ndata _null_;\n   dt = datetime();\n   Date1 = put(datepart(dt), yymmdds10.);\n   Date2 = compress(Date1, \"/\");\n   Time1 = put(timepart(dt), tod8.);\n   Time2 = compress(Time1, \":\");   \n   call symputx('StDates', Date1);\n   call symputx('StDate', Date2);\n   call symputx('StTimes', Time1);\n   call symputx('StTime', Time2);\nrun;\n\n%put 日付: &StDates. (&StDate.) 時刻: &StTimes. (&StTime.);\n\n/* 2. /* --- フォルダのマクロ変数の取得 --- */ */;\n%LET execpath=\" \";\n%MACRO setexecpath;\n    %LET execpath=%SYSFUNC(GETOPTION(SYSIN));\n    %IF %LENGTH(&execpath)=0\n    %THEN %LET execpath=%SYSGET(SAS_EXECFILEPATH);\n%MEND setexecpath;\n%setexecpath;\n%PUT &execpath;\n\n%let CURRENT_DIR = %qsubstr(\"&execpath.\", 2, %eval(%index(\"&execpath.\", %scan(&execpath, -1, \"\\\")))-2) ;\n%put &CURRENT_DIR;\n\n\n/* 3. /* --- フォルダのlibnameの指定 --- */ */;\n%let folder1 = Document;\n%let folder2 = ADS_Program;\n%let folder3 = ADS_Program\\Input;\n%let folder4 = ADS_Program\\Input\\Raw;\n%let folder5 = ADS_Program\\Input\\External;\n%let folder6 = ADS_Program\\Log;\n%let folder7 = ADS_Program\\Output;\n%let folder8 = ADS_Program\\Prg;\n%let folder9 = ADS_Program\\Prg\\Develop;\n%let folder10 = ADS_Program\\Prg\\Fix;\n%let folder11 = ADS_Program\\Macro;\n%let folder12 = ADS_Program\\Setting;\n%let folder13 = ADS_Program\\Spec;\n%let folder14 = Analysis_Program;\n%let folder15 = Analysis_Program\\Input;\n%let folder16 = Analysis_Program\\Log;\n%let folder17 = Analysis_Program\\Output;\n%let folder18 = Analysis_Program\\Prg;\n%let folder19 = Analysis_Program\\Prg\\Develop;\n%let folder20 = Analysis_Program\\Prg\\Fix;\n%let folder21 = Analysis_Program\\Macro;\n%let folder22 = Analysis_Program\\Setting;\n%let folder23 = Analysis_Program\\Spec;\n%let folder24 = Paper;\n\n\n/* まとめて一気に実施する */\n%macro create_folder_paths;\n    data _null_;\n        %do i = 1 %to 24;\n            folder&i = cat(\"&CURRENT_DIR\", \"\\\", \"&&folder&i..\");\n            call symputx(\"folder&i\", folder&i);\n        %end;\n    run;\n%mend;\n\n%create_folder_paths;\n%put _user_;\n    \n\n/* 4. /* --- フォルダ作成 --- */ */;\n/* ディレクトリ自動作成マクロ */\n%macro create_dir(path);\n   %local parent_dir dir_name;\n   %let path = %sysfunc(strip(&path));\n   %let parent_dir = %substr(&path, 1, %length(&path)-%length(%scan(&path, -1, '\\')));\n   %let dir_name = %scan(&path, -1, '\\');\n   \n   %if %sysfunc(fileexist(&path)) = 0 %then %do;\n       %if %length(&parent_dir) &gt; 0 %then %do;\n           %if %sysfunc(fileexist(&parent_dir)) = 0 %then %do;\n               %create_dir(&parent_dir);\n           %end;\n       %end;\n       %let rc = %sysfunc(dcreate(&dir_name, &parent_dir));\n   %end;\n%mend;\n\n/* プロジェクトフォルダ構造の自動作成 */\n%macro create_all_folders;\n   %do i = 1 %to 24;\n       %create_dir(&&folder&i);\n   %end;\n%mend;\n\n%create_all_folders;\n\n/* 5. /* --- 解析用データセットと解析プログラムについて、開発日付を逐次作成する --- */ */;\ndata _null_;\n    /* 各フォルダパスを作成 */\n    Prg_Develop1= cat( \"&CURRENT_DIR\",\"ADS_Program\\Prg\\Develop\",\"\\\", \"&StDate\");\n    Prg_Develop2  = catx( \"&CURRENT_DIR\",\"Analysis_Program\\Prg\\Develop\",\"\\\", \"&StDate\");\n    \n    /* マクロ変数に格納 */\n    call symputx(\"Prg_Develop1\", Prg_Develop1);\n    call symputx(\"Prg_Develop2\", Prg_Develop2);\n  \nrun;\n\n/* 作成されたパスを確認 */\n%put &Prg_Develop1;\n%put  &Prg_Develop2;\n\n%create_dir(&Prg_Develop1);\n%create_dir(&Prg_Develop2);"
  },
  {
    "objectID": "posts/statistics/index.html",
    "href": "posts/statistics/index.html",
    "title": "Notes",
    "section": "",
    "text": "方法論研究におけるフォルダ構成を考える\n\n\n\n博士課程\n\n\n\n\n\n\n2025-07-11\n\n\n\n\n\n\n\nSAS・Rでの相対パス ../../ の使い方完全ガイド\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-07-03\n\n\n\n\n\n\n\nRWD研究における解析用データセット仕様書\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-07-02\n\n\n\n\n\n\n\nSASによる便利関数1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-07-02\n\n\n\n\n\n\n\n解析プロジェクトの最初に作成するSASプログラム\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-07-02\n\n\n\n\n\n\n\nJoint Interventionにおけるモデル構築\n\n\n\n方法論\n\n\n\n\n\n\n2025-07-01\n\n\n\n\n\n\n\nProc LIFEREG\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-07-01\n\n\n\n\n\n\n\nADaM作成においてDataステップにおける便利な関数\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\n臨床試験データ処理の実践：人口統計データ（ADSL）作成テクニック\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nDDEによるExcelデータの読み込み\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nProc Contentsを利用したRawデータの変数を_varにするマクロ\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nデータセット作成のTips\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nProc Transpose/ARRAYによる転置\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nSASのProc SGPLOTに関するTips\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nTTE総説論文\n\n\n\n薬剤疫学\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nSAS：要約統計量作成マクロ\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-29\n\n\n\n\n\n\n\nSASプログラミングのPitfalls and Bad Habits\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-28\n\n\n\n\n\n\n\nProc Contents ProcedureとProc Dataset Procedure\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\n臨床試験における有害事象データの集計：PROC SQL\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nPROGRAMMING FOR JOB SECURITY REVISITED\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nプログラミング一般的な考え方（MUST DO , MUST NOT DO)\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-25\n\n\n\n\n\n\n\nADaM IG1.3\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-18\n\n\n\n\n\n\n\nSASによる解析業務開始時のフォルダ整理・作成\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-16\n\n\n\n\n\n\n\n解析用データセット作成の流れ2\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-16\n\n\n\n\n\n\n\nMarkdown記法について\n\n\n\nMarkdown\n\n\n\n\n\n\n2025-06-15\n\n\n\n\n\n\n\nSQL入門1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-15\n\n\n\n\n\n\n\ngithubのブログ更新手順について\n\n\n\ngithub\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\nSASプログラミング業務のフレームワーク\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\nSASマクロ入門1\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n解析用データセット仕様書\n\n\n\nSAS\n\nR\n\n解析用データセット\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n解析用データセット作成の流れ1（フォルダ構造等）\n\n\n\nSAS\n\n解析プログラミング\n\n\n\n\n\n\n2025-06-14\n\n\n\n\n\n\n\n第2相抗がん剤開発及び検証的試験の中間解析\n\n\n\n臨床試験\n\nSAS\n\n\n\n\n\n\n2025-05-24\n\n\n\n\n\n\n\n臨床試験のサンプルサイズ設計\n\n\n\n臨床試験\n\nSAS\n\n\n\n\n\n\n2025-05-17\n\n\n\n\n\n一致なし"
  }
]