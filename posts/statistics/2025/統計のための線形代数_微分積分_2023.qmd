---
title: "統計のための線形代数・微分積分まとめ1"
author: "坂本航太"
categories: [数理統計]
date-modified: "2025-08-18"
abstract-title: Abstract
abstract: ""
date: "2025-08-18"
---

## 目次

## ベクトル

実数を一列に並べたものを$v= (v_1,..,v_d)^T$をベクトルとよぶ。d次元空間$R^d$上の原点から伸びる矢印だとイメージするとわかりやすいでしょう。ベクトルは向きと大きさの情報を持っていて、大きさは矢印の長さ、向きに対応しています。

## ベクトルの内積と相関係数

yとxの偏差ベクトルとCosθの関係を説明する。

## 内積とcos類似度

類似度の起点を0とするのか、相関係数のように平均値とするのかの違い。

## 行列の掛け算の解釈

1.  行列とベクトルの積：列ベクトルとその重みという解釈

    -   行列の掛け算は、左側の行列を列ベクトルのまとまり、右側のベクトル/行列を列ベクトルの重みとして線形和を計算したものとして解釈する。

2.  ベクトルの内積をまとめたものとしての解釈

    -   行列の掛け算は、左側の行列を行ベクトルのまとまり、右側の行列を列ベクトルのまとまりとして、それぞれの内積を計算したものだと考えることができる

3.  連立一次方程式の係数としての行列

    -   一次連立方程式の係数行列をA、解きたい変数をベクトルxとすれば、一次連立方程式はAx=bとしてあらわすことができる。

# 線形回帰モデル

線形回帰モデルは、１の列ベクトルとその重みという解釈でみるとよい。

また、正規方程式を導出するさいに、yをベクトルXβの空間へ射影する（すなわち、Xβとeの大きさが最小となるよう）に考えると、残差eがXの全ての列ベクトルと直交するようにβを求めてあげれば良いと考えられる。

すなわち、内積=0から正規方程式を考えることができる。

$X^T(y-X\beta)=0$

これを式変形して、

$X^TX\beta=X^Ty$

## 共分散行列

$S=\frac{1}{n} S^TS$

## 多変数関数の微分から求める線形回帰分析

残差平方和（$Y-X\beta$）の二乗和を考えて、これを最小にするようなβを求める方法を考えている。

残差平方和は$||y-X\beta||^2$にに対応します。この大きさの二乗は自分自身の内積に対応するので、以下のように変形できます。

$$
||y-X\beta||^2 = (y-X\beta)^T(y-X\beta) = (y^T-\beta^TX^T)(y-X\beta)=y^Ty-\beta^TX^Ty - y^TX\beta+\beta^TX^TX\beta
$$

ここで、

$\beta^TX^Ty = (X\beta)^Ty=y^TX\beta$

と表すことできるので、内積に対応するので、これらの値は等しいと分かる。（スカラーである）

$$
||y-X\beta||^2 = (y-X\beta)^T(y-X\beta) = (y^T-\beta^TX^T)(y-X\beta)=y^Ty- 2y^TX\beta+\beta^TX^TX\beta
$$

残差平方和はβの一次関数と二次形式でできています。

微分の公式は以下の通りです。

$\frac{\partial a^Tx}{\partial x}=a$

$\frac{\partial x^T Ax}{\partial x}=2Ax$

よって、残差平方和を微分すると、以下の式となる。

$$
-2X^Ty + 2X^TX\beta =0
$$

これより、正規方程式が得られて、$X^TX$が逆行列を持てば、最小二乗推定量が得られる。

## 主成分分析と固有値分解

主成分分析は$||w||^2$の主成分の係数ベクトルに$||w||^2 = 1$の制約をつけたなかで、主成分の分散$s_z^2=\frac{w^TX^TXw}{n}$が最も大きくなるように求めるものである。

### 固有値

正方行列Aに対して、次のようにベクトルvと数λの組を見つける問題を固有値問題といいます。

$Av=\lambda v$

ただし、ベクトルvは0でないものとします。このようなベクトルvを固有ベクトル、λを固有値といいます。

この固有方程式を式変形することで、$(A-\lambda I)v=0$について解いたときに、v=0以外の解がみつかるようなλを見つけ、そのときの解vを求めたい。

ここで、右辺=0というのが大事である。ここで、A-λIが一次独立であれば、v=0しか解がなくなってしまう。v=0の解を見つけるためには、A-λIが線形従属、すなわちrank落ち、すなわち行列式=0出ないとダメとなります。そこから、以下を満たすλとベクトルvを見つけることを考えます。

$|A-\lambda I|=0$

## Ridge回帰分析

## 勾配ベクトルとその応用

## 対角化

正方行列Aに対して、以下のような等式を正則行列Vと対角行列Λがみつかるとします。

$A=V\Lambda V^{-1}$

これを行列Aの対角化といいます。対角化は行列のべき乗を計算するときに便利で、マルコフ連鎖を計算するときに便利です。

## 行列のtrace

-   $tr(A+B)=tr(A)+tr(B)$

-   $tr(A^T)=tr(A)$

-   $tr(AB)=tr(BA)$

## 特異値分解

特異値分解とは、サイズ（m,n）の行列Xをm次直交行列U、n次直交行列V、サイズ(m,n)で特に非対角成分が0の行列Σによって以下のように分解することを呼ぶ。

$X=U\Sigma V^T$